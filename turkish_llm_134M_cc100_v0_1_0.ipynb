{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i3Y8n1DVWnN"
      },
      "source": [
        "Verisetinin indirilmesi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDsX_GURRahl",
        "outputId": "6ff88c32-8227-40fd-a189-7f748bb2eaa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-08-07 16:17:41--  http://data.statmt.org/cc-100/tr.txt.xz\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.32.28\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://data.statmt.org/cc-100/tr.txt.xz [following]\n",
            "--2025-08-07 16:17:41--  https://data.statmt.org/cc-100/tr.txt.xz\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5710467188 (5.3G) [application/x-xz]\n",
            "Saving to: ‘/content/drive/MyDrive/turkish_llm/cc100-tr.txt.xz’\n",
            "\n",
            "/content/drive/MyDr 100%[===================>]   5.32G  9.61MB/s    in 9m 35s  \n",
            "\n",
            "2025-08-07 16:27:16 (9.48 MB/s) - ‘/content/drive/MyDrive/turkish_llm/cc100-tr.txt.xz’ saved [5710467188/5710467188]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ↳ yaklaşık 3 GB .xz dosyası (~11 GB açılmış metin)\n",
        "!wget -c http://data.statmt.org/cc-100/tr.txt.xz \\\n",
        "      -O /content/drive/MyDrive/turkish_llm/cc100-tr.txt.xz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jrO4qfGWyoD"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet fasttext tqdm xxhash\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewQCSZswW8_1",
        "outputId": "ff3b6174-40ca-4e72-a649-caefb0809266"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "İndiriliyor… (~126 MB)\n",
            "✓ Dil modeli indirildi → /content/lid.176.bin\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ],
      "source": [
        "import pathlib, requests, shutil, os, gzip, lzma, xxhash, json, math, itertools\n",
        "from tqdm import tqdm\n",
        "\n",
        "lid_path = pathlib.Path('/content/lid.176.bin')\n",
        "if not lid_path.exists():\n",
        "    url = 'https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin'\n",
        "    print('İndiriliyor… (~126 MB)')\n",
        "    with requests.get(url, stream=True) as r, open(lid_path, 'wb') as f:\n",
        "        shutil.copyfileobj(r.raw, f)\n",
        "    print('✓ Dil modeli indirildi →', lid_path)\n",
        "\n",
        "import fasttext\n",
        "lid_model = fasttext.load_model(str(lid_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zu2zpvMPYK8b",
        "outputId": "f97126f7-d70c-4bf8-e99c-6143ac13c854"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --quiet --upgrade \"numpy<2.0\" \"fasttext==0.9.2\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0M5Rj4JXAsD",
        "outputId": "c61a7649-7f04-4467-8333-c7ab7c9de2d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "İşleniyor: 99822767 satır [2:55:03, 9503.42 satır/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "⏹  2,000,000,047 token hedefine ulaşıldı. Durduruluyor…\n",
            "\n",
            "✓ Temizleme tamamlandı → /content/drive/MyDrive/turkish_llm/cc100-tr.clean.txt.gz\n",
            "Toplam token: 2,000,000,047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# === CC100-tr TEMİZLEME HÜCRESİ =========================================\n",
        "# Girdi  : /content/drive/MyDrive/turkish_llm/cc100-tr.txt.xz\n",
        "# Çıktı  : /content/drive/MyDrive/turkish_llm/cc100-tr.clean.txt.gz\n",
        "# Amaç   : Dil filtresi (TR), uzun/kısa satır filtresi, deduplikasyon,\n",
        "#          ~2B token hedefi (isteğe bağlı) – çıkış ≈ 12 GB ham metin\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)   # zaten bağlıysa değişmez\n",
        "\n",
        "import lzma, gzip, xxhash, fasttext, pathlib, requests, shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -------- Ayarlar --------\n",
        "RAW_PATH   = '/content/drive/MyDrive/turkish_llm/cc100-tr.txt.xz'\n",
        "CLEAN_PATH = '/content/drive/MyDrive/turkish_llm/cc100-tr.clean.txt.gz'\n",
        "\n",
        "MIN_TOKENS    = 5          # satırdaki min token\n",
        "MAX_TOKENS    = 200        # satırdaki max token\n",
        "MAX_CHARS     = 1000       # satırdaki max karakter\n",
        "TARGET_TOKENS = 2_000_000_000  # None => sınır yok (~2B token hedefi)\n",
        "\n",
        "# -------- Dil modeli (FastText LID-176) --------\n",
        "lid_path = pathlib.Path('/content/lid.176.bin')\n",
        "if not lid_path.exists():\n",
        "    print('► FastText model indiriliyor…')\n",
        "    url = 'https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin'\n",
        "    with requests.get(url, stream=True) as r, open(lid_path, 'wb') as f:\n",
        "        shutil.copyfileobj(r.raw, f)\n",
        "ft = fasttext.load_model(str(lid_path))\n",
        "\n",
        "def is_turkish(text: str) -> bool:\n",
        "    \"\"\"0-1 Türkçe satır filtresi (≥0.80 olasılık).\"\"\"\n",
        "    text = text.strip()\n",
        "    if not text:\n",
        "        return False\n",
        "    label, prob = ft.predict(text, k=1)\n",
        "    return label[0] == '__label__tr' and prob[0] > 0.80\n",
        "\n",
        "def simple_tokenize(t: str):\n",
        "    return t.split()\n",
        "\n",
        "# -------- Akışlı okuma / yazma --------\n",
        "seen_hashes = set()\n",
        "total_tokens = 0\n",
        "\n",
        "with lzma.open(RAW_PATH, mode='rt', encoding='utf-8', errors='ignore') as fin, \\\n",
        "     gzip.open(CLEAN_PATH, mode='wt', encoding='utf-8') as fout, \\\n",
        "     tqdm(total=None, unit=' satır', desc='İşleniyor') as pbar:\n",
        "\n",
        "    for raw_line in fin:\n",
        "        pbar.update()\n",
        "        line = raw_line.rstrip('\\n')\n",
        "\n",
        "        # Uzunluk filtreleri\n",
        "        if len(line) < 2 or len(line) > MAX_CHARS:\n",
        "            continue\n",
        "        tokens = simple_tokenize(line)\n",
        "        if not (MIN_TOKENS <= len(tokens) <= MAX_TOKENS):\n",
        "            continue\n",
        "\n",
        "        # Dil filtresi\n",
        "        if not is_turkish(line):\n",
        "            continue\n",
        "\n",
        "        # Basit deduplikasyon\n",
        "        h = xxhash.xxh64(line).intdigest()\n",
        "        if h in seen_hashes:\n",
        "            continue\n",
        "        seen_hashes.add(h)\n",
        "        if len(seen_hashes) > 10_000_000:   # bellek koruması\n",
        "            seen_hashes.clear()\n",
        "\n",
        "        # Yaz & sayaç\n",
        "        fout.write(line + '\\n')\n",
        "        total_tokens += len(tokens)\n",
        "\n",
        "        if TARGET_TOKENS and total_tokens >= TARGET_TOKENS:\n",
        "            print(f'\\n⏹  {total_tokens:,} token hedefine ulaşıldı. Durduruluyor…')\n",
        "            break\n",
        "\n",
        "print(f'\\n✓ Temizleme tamamlandı → {CLEAN_PATH}')\n",
        "print(f'Toplam token: {total_tokens:,}')\n",
        "# ========================================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLJXb4GTKgTA",
        "outputId": "0e93d137-264c-4280-ba2a-9bd17391162e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw------- 1 root root 5.9G Aug  7 19:32 /content/drive/MyDrive/turkish_llm/cc100-tr.clean.txt.gz\n",
            "         compressed        uncompressed  ratio uncompressed_name\n",
            "         6273266558          3584799583 -75.0% /content/drive/MyDrive/turkish_llm/cc100-tr.clean.txt\n"
          ]
        }
      ],
      "source": [
        "!ls -lh /content/drive/MyDrive/turkish_llm/cc100-tr.clean.txt.gz\n",
        "!gzip -l  /content/drive/MyDrive/turkish_llm/cc100-tr.clean.txt.gz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqbl7HSBiW97",
        "outputId": "6020cce6-ba9c-4c04-f7d4-534863951edf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: NVIDIA A100-SXM4-40GB\n",
            "VRAM: 42.5 GB\n",
            "İmportlar tamamlandı\n"
          ]
        }
      ],
      "source": [
        "# === HÜCRE 1: İMPORTLAR VE GPU KONTROLÜ ===================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import numpy as np\n",
        "import sentencepiece as spm\n",
        "import gzip\n",
        "import time\n",
        "import os\n",
        "import gc\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# GPU kontrolü\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"🎮 GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"💾 VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"GPU bulunamadı!\")\n",
        "\n",
        "# Pathler\n",
        "DATA_PATH = '/content/drive/MyDrive/turkish_llm/cc100-tr.clean.txt.gz'\n",
        "TOKENIZER_PATH = '/content/drive/MyDrive/turkish_llm/tokenizer_tr_32k_v2.model'\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/turkish_llm/checkpoints/'\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"İmportlar tamamlandı\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC2lKinUiaCq",
        "outputId": "e84529bd-b827-429f-9ebe-085e2ab8cd4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer yüklendi (vocab size: 32000)\n",
            "\n",
            "Test: 'Merhaba dünya, nasılsınız?'\n",
            "Tokens (6): [2514, 1212, 31895, 782, 1243, 31934]\n",
            "Decoded: 'Merhaba dünya, nasılsınız?'\n"
          ]
        }
      ],
      "source": [
        "# === HÜCRE 2: TOKENIZER YÜKLEME ===================================\n",
        "\n",
        "# Tokenizer yükle\n",
        "sp = spm.SentencePieceProcessor(model_file=TOKENIZER_PATH)\n",
        "print(f\"Tokenizer yüklendi (vocab size: {sp.vocab_size()})\")\n",
        "\n",
        "# Test\n",
        "test_text = \"Merhaba dünya, nasılsınız?\"\n",
        "tokens = sp.encode(test_text)\n",
        "decoded = sp.decode(tokens)\n",
        "print(f\"\\nTest: '{test_text}'\")\n",
        "print(f\"Tokens ({len(tokens)}): {tokens}\")\n",
        "print(f\"Decoded: '{decoded}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDw6yE2VicJQ",
        "outputId": "365b0e3d-0994-4343-cfff-e01e7f5f3aef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Config: 12 layers, 768 dim, 12 heads\n",
            "Training Config: batch_size=8, max_steps=10000\n"
          ]
        }
      ],
      "source": [
        "# === HÜCRE 3: MODEL KONFİGÜRASYONU ===================================\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    dim: int = 768\n",
        "    n_layers: int = 12\n",
        "    n_heads: int = 12\n",
        "    n_kv_heads: int = 12\n",
        "    vocab_size: int = 32000\n",
        "    max_seq_len: int = 1024  # Optimize edilmiş\n",
        "    dropout: float = 0.0\n",
        "\n",
        "    multiple_of: int = 256\n",
        "    ffn_dim_multiplier: float = 2.7\n",
        "    norm_eps: float = 1e-5\n",
        "    rope_theta: float = 10000.0\n",
        "\n",
        "    def __post_init__(self):\n",
        "        hidden_dim = int(2 * self.dim * self.ffn_dim_multiplier / 3)\n",
        "        self.ffn_hidden_dim = self.multiple_of * ((hidden_dim + self.multiple_of - 1) // self.multiple_of)\n",
        "        self.head_dim = self.dim // self.n_heads\n",
        "\n",
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    batch_size: int = 8           # A100 için optimize\n",
        "    max_length: int = 1024\n",
        "    num_workers: int = 2\n",
        "\n",
        "    learning_rate: float = 5e-4\n",
        "    weight_decay: float = 0.1\n",
        "    adam_beta1: float = 0.9\n",
        "    adam_beta2: float = 0.95\n",
        "    grad_clip: float = 1.0\n",
        "\n",
        "    warmup_steps: int = 1000\n",
        "    max_steps: int = 10000\n",
        "    eval_interval: int = 250\n",
        "    save_interval: int = 1000\n",
        "    log_interval: int = 10\n",
        "\n",
        "    use_amp: bool = True\n",
        "\n",
        "config = ModelConfig()\n",
        "train_config = TrainingConfig()\n",
        "\n",
        "print(f\"Model Config: {config.n_layers} layers, {config.dim} dim, {config.n_heads} heads\")\n",
        "print(f\"Training Config: batch_size={train_config.batch_size}, max_steps={train_config.max_steps}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRZ_9mr5id-z",
        "outputId": "dc4dcd98-71ac-4e43-9571-7812a7ee4954"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model componentleri tanımlandı\n"
          ]
        }
      ],
      "source": [
        "# === HÜCRE 4: MODEL COMPONENTLERİ ===================================\n",
        "\n",
        "# RMSNorm\n",
        "class RMSNorm(nn.Module):\n",
        "    def __init__(self, dim: int, eps: float = 1e-6):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.weight = nn.Parameter(torch.ones(dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        norm = x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
        "        return self.weight * norm\n",
        "\n",
        "# SwiGLU activation\n",
        "class SwiGLU(nn.Module):\n",
        "    def forward(self, x, gate):\n",
        "        return F.silu(gate) * x\n",
        "\n",
        "# FeedForward\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, config: ModelConfig):\n",
        "        super().__init__()\n",
        "        self.w1 = nn.Linear(config.dim, config.ffn_hidden_dim, bias=False)\n",
        "        self.w2 = nn.Linear(config.ffn_hidden_dim, config.dim, bias=False)\n",
        "        self.w3 = nn.Linear(config.dim, config.ffn_hidden_dim, bias=False)\n",
        "        self.swiglu = SwiGLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w2(self.swiglu(self.w1(x), self.w3(x)))\n",
        "\n",
        "print(\"Model componentleri tanımlandı\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR4Powzwif0r",
        "outputId": "e97512bc-c3e9-4ade-fa91-63d9b0f26fe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RoPE ve Attention tanımlandı\n"
          ]
        }
      ],
      "source": [
        "# === HÜCRE 5: ROPE VE ATTENTION ===================================\n",
        "\n",
        "# RoPE fonksiyonları\n",
        "def precompute_freqs_cis(dim: int, max_seq_len: int, theta: float = 10000.0):\n",
        "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
        "    t = torch.arange(max_seq_len, device=freqs.device)\n",
        "    freqs = torch.outer(t, freqs).float()\n",
        "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)\n",
        "    return freqs_cis\n",
        "\n",
        "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
        "    ndim = x.ndim\n",
        "    assert 0 <= 1 < ndim\n",
        "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
        "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
        "    return freqs_cis.view(*shape)\n",
        "\n",
        "def apply_rotary_emb(xq, xk, freqs_cis):\n",
        "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
        "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
        "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
        "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
        "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
        "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
        "\n",
        "# Attention\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.n_heads = config.n_heads\n",
        "        self.n_kv_heads = config.n_kv_heads\n",
        "        self.head_dim = config.head_dim\n",
        "        self.n_rep = self.n_heads // self.n_kv_heads\n",
        "\n",
        "        self.wq = nn.Linear(config.dim, config.n_heads * config.head_dim, bias=False)\n",
        "        self.wk = nn.Linear(config.dim, config.n_kv_heads * config.head_dim, bias=False)\n",
        "        self.wv = nn.Linear(config.dim, config.n_kv_heads * config.head_dim, bias=False)\n",
        "        self.wo = nn.Linear(config.n_heads * config.head_dim, config.dim, bias=False)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, x, freqs_cis, mask=None):\n",
        "        bsz, seqlen, _ = x.shape\n",
        "\n",
        "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
        "        xq = xq.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
        "        xk = xk.view(bsz, seqlen, self.n_kv_heads, self.head_dim)\n",
        "        xv = xv.view(bsz, seqlen, self.n_kv_heads, self.head_dim)\n",
        "\n",
        "        xq, xk = apply_rotary_emb(xq, xk, freqs_cis)\n",
        "\n",
        "        if self.n_rep > 1:\n",
        "            xk = xk.unsqueeze(3).expand(-1, -1, -1, self.n_rep, -1).flatten(2, 3)\n",
        "            xv = xv.unsqueeze(3).expand(-1, -1, -1, self.n_rep, -1).flatten(2, 3)\n",
        "\n",
        "        xq = xq.transpose(1, 2)\n",
        "        xk = xk.transpose(1, 2)\n",
        "        xv = xv.transpose(1, 2)\n",
        "\n",
        "        scores = torch.matmul(xq, xk.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
        "        if mask is not None:\n",
        "            scores = scores + mask\n",
        "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
        "        scores = self.dropout(scores)\n",
        "        output = torch.matmul(scores, xv)\n",
        "\n",
        "        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)\n",
        "        return self.wo(output)\n",
        "\n",
        "print(\"RoPE ve Attention tanımlandı\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKtllILSiiID",
        "outputId": "fd792d1a-c6a3-4693-b3a1-025aeb30c000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model oluşturuldu: 120.0M parametre\n",
            "VRAM kullanımı: 0.48 GB\n"
          ]
        }
      ],
      "source": [
        "# === HÜCRE 6: TRANSFORMER BLOCK VE ANA MODEL ===================================\n",
        "\n",
        "# Transformer Block\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.attention = Attention(config)\n",
        "        self.feed_forward = FeedForward(config)\n",
        "        self.attention_norm = RMSNorm(config.dim, eps=config.norm_eps)\n",
        "        self.ffn_norm = RMSNorm(config.dim, eps=config.norm_eps)\n",
        "\n",
        "    def forward(self, x, freqs_cis, mask=None):\n",
        "        h = x + self.attention(self.attention_norm(x), freqs_cis, mask)\n",
        "        out = h + self.feed_forward(self.ffn_norm(h))\n",
        "        return out\n",
        "\n",
        "# Ana Model\n",
        "class TurkishLLaMA(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.tok_embeddings = nn.Embedding(config.vocab_size, config.dim)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.layers = nn.ModuleList([TransformerBlock(config) for _ in range(config.n_layers)])\n",
        "        self.norm = RMSNorm(config.dim, eps=config.norm_eps)\n",
        "        self.output = nn.Linear(config.dim, config.vocab_size, bias=False)\n",
        "\n",
        "        self.register_buffer(\"freqs_cis\", precompute_freqs_cis(\n",
        "            config.head_dim, config.max_seq_len * 2, config.rope_theta\n",
        "        ))\n",
        "\n",
        "    def forward(self, tokens: torch.Tensor):\n",
        "        bsz, seqlen = tokens.shape\n",
        "        h = self.tok_embeddings(tokens)\n",
        "        h = self.dropout(h)\n",
        "\n",
        "        mask = torch.full((1, 1, seqlen, seqlen), float(\"-inf\"), device=tokens.device)\n",
        "        mask = torch.triu(mask, diagonal=1).type_as(h)\n",
        "\n",
        "        freqs_cis = self.freqs_cis[:seqlen]\n",
        "        for layer in self.layers:\n",
        "            h = layer(h, freqs_cis, mask)\n",
        "\n",
        "        h = self.norm(h)\n",
        "        output = self.output(h)\n",
        "        return output\n",
        "\n",
        "# Model oluştur\n",
        "model = TurkishLLaMA(config).cuda()\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\" Model oluşturuldu: {total_params/1e6:.1f}M parametre\")\n",
        "print(f\" VRAM kullanımı: {torch.cuda.memory_allocated()/1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lT_qs_fDikKz",
        "outputId": "413e9301-68e8-4cfb-e169-17916bd629f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Dataset sınıfı tanımlandı\n"
          ]
        }
      ],
      "source": [
        "# === HÜCRE 7: DATASET SINIFI ===================================\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, file_path, tokenizer, max_length=1024, max_samples=None):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.samples = []\n",
        "\n",
        "        print(\" Veri yükleniyor...\")\n",
        "        with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
        "            current_chunk = []\n",
        "            current_len = 0\n",
        "\n",
        "            for i, line in enumerate(tqdm(f, desc=\"Satırlar işleniyor\", total=max_samples or 100000)):\n",
        "                if max_samples and len(self.samples) >= max_samples:\n",
        "                    break\n",
        "\n",
        "                tokens = tokenizer.encode(line.strip())\n",
        "                if not tokens:\n",
        "                    continue\n",
        "\n",
        "                if current_len + len(tokens) > max_length:\n",
        "                    if current_chunk:\n",
        "                        self.samples.append(current_chunk[:max_length])\n",
        "                    current_chunk = tokens\n",
        "                    current_len = len(tokens)\n",
        "                else:\n",
        "                    current_chunk.extend(tokens)\n",
        "                    current_len += len(tokens)\n",
        "\n",
        "            if current_chunk and len(current_chunk) > 100:\n",
        "                self.samples.append(current_chunk[:max_length])\n",
        "\n",
        "        print(f\" {len(self.samples):,} örnek hazır\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.samples[idx]\n",
        "\n",
        "        if len(tokens) < self.max_length:\n",
        "            tokens = tokens + [self.tokenizer.pad_id()] * (self.max_length - len(tokens))\n",
        "\n",
        "        input_ids = torch.tensor(tokens[:-1], dtype=torch.long)\n",
        "        labels = torch.tensor(tokens[1:], dtype=torch.long)\n",
        "\n",
        "        return input_ids, labels\n",
        "\n",
        "print(\" Dataset sınıfı tanımlandı\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1B-gEVQimJu",
        "outputId": "c1e8bf13-0172-4c6e-de26-3585f5427168"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 10M SATIRLIK BÜYÜK VERİ SETİ HAZIRLANIYOR\n",
            "\n",
            "📚 10,000,000 satır okunacak...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Satırlar işleniyor: 100%|██████████| 10000000/10000000 [23:20<00:00, 7140.33it/s, Örnekler=400,000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "404,561 örnek oluşturuldu\n",
            "Ortalama: 24.7 satır/örnek\n",
            "\n",
            "============================================================\n",
            "📊 VERİ SETİ ÖZETİ:\n",
            "  Örnek sayısı: 404,561\n",
            "  Toplam token: ~414M\n",
            "  Token/parametre: 3.5\n",
            "  Batch size: 32\n",
            "  Batch count: 12,642\n",
            "  Tokens per batch: 32,768\n",
            "\n",
            "📊 EĞİTİM PLANI:\n",
            "  Max steps: 50,000\n",
            "  Warmup steps: 2,000\n",
            "  Epoch sayısı: ~4.0\n",
            "  Toplam token (training): ~1.6B\n",
            "\n",
            "💾 BELLEK DURUMU:\n",
            "  Model VRAM: 0.48 GB\n",
            "  Toplam VRAM: 40 GB\n",
            "  Kullanılabilir: 39.52 GB\n",
            "\n",
            "⚡ TAHMİNİ PERFORMANS:\n",
            "  Beklenen hız: ~200-250K token/saniye\n",
            "  Tahmini süre: 2.3-1.8 saat\n",
            "\n",
            "SİSTEM HAZIR! Eğitim başlatılabilir.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# === 10M SATIRLA VERİ YÜKLEME (A100 40GB için optimal) ===================================\n",
        "\n",
        "import gc\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import gzip\n",
        "\n",
        "# Bellek temizliği\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "print(\"10M SATIRLIK BÜYÜK VERİ SETİ HAZIRLANIYOR\")\n",
        "\n",
        "class OptimizedTextDataset(Dataset):\n",
        "    def __init__(self, file_path, tokenizer, max_length=1024, max_lines=10_000_000):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.samples = []\n",
        "\n",
        "        print(f\"📚 {max_lines:,} satır okunacak...\")\n",
        "\n",
        "        with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
        "            current_chunk = []\n",
        "            current_len = 0\n",
        "            lines_processed = 0\n",
        "\n",
        "            pbar = tqdm(total=max_lines, desc=\"Satırlar işleniyor\")\n",
        "\n",
        "            for line in f:\n",
        "                if lines_processed >= max_lines:\n",
        "                    break\n",
        "\n",
        "                lines_processed += 1\n",
        "                pbar.update(1)\n",
        "\n",
        "                # Boş veya çok kısa satırları atla\n",
        "                line = line.strip()\n",
        "                if len(line) < 30:  # Min 30 karakter\n",
        "                    continue\n",
        "\n",
        "                tokens = tokenizer.encode(line)\n",
        "                if not tokens or len(tokens) < 5:\n",
        "                    continue\n",
        "\n",
        "                # Chunk'lara böl\n",
        "                if current_len + len(tokens) > max_length:\n",
        "                    if len(current_chunk) > 100:\n",
        "                        self.samples.append(current_chunk[:max_length])\n",
        "\n",
        "                        # Her 10K örnekte durum bildir\n",
        "                        if len(self.samples) % 10000 == 0:\n",
        "                            pbar.set_postfix({\"Örnekler\": f\"{len(self.samples):,}\"})\n",
        "\n",
        "                    current_chunk = tokens\n",
        "                    current_len = len(tokens)\n",
        "                else:\n",
        "                    current_chunk.extend(tokens)\n",
        "                    current_len += len(tokens)\n",
        "\n",
        "            pbar.close()\n",
        "\n",
        "            # Son chunk\n",
        "            if len(current_chunk) > 100:\n",
        "                self.samples.append(current_chunk[:max_length])\n",
        "\n",
        "        print(f\"\\n {len(self.samples):,} örnek oluşturuldu\")\n",
        "        print(f\" Ortalama: {lines_processed/len(self.samples):.1f} satır/örnek\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.samples[idx]\n",
        "\n",
        "        if len(tokens) < self.max_length:\n",
        "            tokens = tokens + [self.tokenizer.pad_id()] * (self.max_length - len(tokens))\n",
        "\n",
        "        input_ids = torch.tensor(tokens[:-1], dtype=torch.long)\n",
        "        labels = torch.tensor(tokens[1:], dtype=torch.long)\n",
        "\n",
        "        return input_ids, labels\n",
        "\n",
        "# Dataset oluştur\n",
        "dataset = OptimizedTextDataset(\n",
        "    DATA_PATH,\n",
        "    sp,\n",
        "    max_length=1024,\n",
        "    max_lines=10_000_000  # 10M satır\n",
        ")\n",
        "\n",
        "# A100 için optimal batch size\n",
        "BATCH_SIZE = 32  # VRAM'e göre artırılabilir\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "    drop_last=True,\n",
        "    persistent_workers=True\n",
        ")\n",
        "\n",
        "# Training config güncelle\n",
        "train_config.batch_size = BATCH_SIZE\n",
        "train_config.max_steps = 50_000  # Yeterli step\n",
        "train_config.eval_interval = 500\n",
        "train_config.save_interval = 5000\n",
        "train_config.warmup_steps = 2000\n",
        "\n",
        "# Optimizer'ı yeniden oluştur\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=train_config.learning_rate,\n",
        "    weight_decay=train_config.weight_decay,\n",
        "    betas=(train_config.adam_beta1, train_config.adam_beta2),\n",
        "    fused=True  # A100 optimizasyonu\n",
        ")\n",
        "\n",
        "scaler = torch.amp.GradScaler('cuda')\n",
        "\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(f\" VERİ SETİ ÖZETİ:\")\n",
        "print(f\"  Örnek sayısı: {len(dataset):,}\")\n",
        "print(f\"  Toplam token: ~{len(dataset) * 1024 / 1e6:.0f}M\")\n",
        "print(f\"  Token/parametre: {(len(dataset) * 1024) / (120 * 1e6):.1f}\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  Batch count: {len(train_loader):,}\")\n",
        "print(f\"  Tokens per batch: {BATCH_SIZE * 1024:,}\")\n",
        "\n",
        "print(f\"\\n EĞİTİM PLANI:\")\n",
        "print(f\"  Max steps: {train_config.max_steps:,}\")\n",
        "print(f\"  Warmup steps: {train_config.warmup_steps:,}\")\n",
        "print(f\"  Epoch sayısı: ~{train_config.max_steps / len(train_loader):.1f}\")\n",
        "print(f\"  Toplam token (training): ~{train_config.max_steps * BATCH_SIZE * 1024 / 1e9:.1f}B\")\n",
        "\n",
        "print(f\"\\n BELLEK DURUMU:\")\n",
        "print(f\"  Model VRAM: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
        "print(f\"  Toplam VRAM: 40 GB\")\n",
        "print(f\"  Kullanılabilir: {(40 - torch.cuda.memory_allocated()/1e9):.2f} GB\")\n",
        "\n",
        "print(f\"\\n TAHMİNİ PERFORMANS:\")\n",
        "print(f\"  Beklenen hız: ~200-250K token/saniye\")\n",
        "print(f\"  Tahmini süre: {train_config.max_steps * BATCH_SIZE * 1024 / (200_000 * 3600):.1f}-{train_config.max_steps * BATCH_SIZE * 1024 / (250_000 * 3600):.1f} saat\")\n",
        "\n",
        "print(f\"\\n SİSTEM HAZIR! Eğitim başlatılabilir.\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FD0GfHreitwq",
        "outputId": "293c893a-41b3-42d8-d182-090f803e372f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⏳ Veri yüklenmesini bekleyin, sonra bu hücreyi çalıştırın:\n",
            "train_losses, eval_losses = train()\n"
          ]
        }
      ],
      "source": [
        "# === EĞİTİM DÖNGÜSÜ (A100 Optimized) ===================================\n",
        "\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Helper fonksiyonlar\n",
        "def get_lr(step, config):\n",
        "    \"\"\"Cosine learning rate schedule with warmup\"\"\"\n",
        "    if step < config.warmup_steps:\n",
        "        return config.learning_rate * step / config.warmup_steps\n",
        "    progress = (step - config.warmup_steps) / (config.max_steps - config.warmup_steps)\n",
        "    return config.learning_rate * 0.5 * (1.0 + np.cos(np.pi * progress))\n",
        "\n",
        "def format_time(seconds):\n",
        "    \"\"\"Saniyeyi saat:dakika:saniye formatına çevir\"\"\"\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    seconds = int(seconds % 60)\n",
        "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
        "\n",
        "# Training step\n",
        "def train_step(model, batch, optimizer, scaler, config):\n",
        "    \"\"\"Tek training step\"\"\"\n",
        "    model.train()\n",
        "\n",
        "    inputs, targets = batch\n",
        "    inputs = inputs.cuda()\n",
        "    targets = targets.cuda()\n",
        "\n",
        "    # Mixed precision training\n",
        "    with torch.amp.autocast('cuda', enabled=config.use_amp):\n",
        "        logits = model(inputs)\n",
        "        loss = F.cross_entropy(\n",
        "            logits.view(-1, logits.size(-1)),\n",
        "            targets.view(-1),\n",
        "            ignore_index=sp.pad_id()\n",
        "        )\n",
        "\n",
        "    # Backward pass\n",
        "    scaler.scale(loss).backward()\n",
        "\n",
        "    # Gradient clipping\n",
        "    scaler.unscale_(optimizer)\n",
        "    grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip)\n",
        "\n",
        "    # Optimizer step\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "    return loss.item(), grad_norm.item()\n",
        "\n",
        "# Evaluation\n",
        "@torch.no_grad()\n",
        "def evaluate(model, data_loader, num_batches=50):\n",
        "    \"\"\"Model evaluation\"\"\"\n",
        "    model.eval()\n",
        "    losses = []\n",
        "\n",
        "    for i, (inputs, targets) in enumerate(data_loader):\n",
        "        if i >= num_batches:\n",
        "            break\n",
        "\n",
        "        inputs = inputs.cuda()\n",
        "        targets = targets.cuda()\n",
        "\n",
        "        logits = model(inputs)\n",
        "        loss = F.cross_entropy(\n",
        "            logits.view(-1, logits.size(-1)),\n",
        "            targets.view(-1),\n",
        "            ignore_index=sp.pad_id()\n",
        "        )\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    model.train()\n",
        "    return np.mean(losses)\n",
        "\n",
        "# Text generation\n",
        "@torch.no_grad()\n",
        "def generate(model, prompt, max_tokens=50, temperature=0.8, top_p=0.9):\n",
        "    \"\"\"Generate text from prompt\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize prompt\n",
        "    tokens = sp.encode(prompt)\n",
        "    tokens = torch.tensor([tokens], dtype=torch.long).cuda()\n",
        "\n",
        "    generated = []\n",
        "    for _ in range(max_tokens):\n",
        "        # Forward pass\n",
        "        with torch.amp.autocast('cuda', enabled=False):  # Generation'da amp kapalı\n",
        "            logits = model(tokens)\n",
        "\n",
        "        logits = logits[:, -1, :] / temperature\n",
        "\n",
        "        # Top-p (nucleus) sampling\n",
        "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "        sorted_indices_to_remove = cumulative_probs > top_p\n",
        "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "        sorted_indices_to_remove[..., 0] = 0\n",
        "        indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)\n",
        "        logits[indices_to_remove] = float('-inf')\n",
        "\n",
        "        # Sample\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "        generated.append(next_token.item())\n",
        "\n",
        "        # Stop at EOS\n",
        "        if next_token.item() == sp.eos_id():\n",
        "            break\n",
        "\n",
        "        # Append token\n",
        "        tokens = torch.cat([tokens, next_token], dim=1)\n",
        "\n",
        "        # Truncate if too long\n",
        "        if tokens.shape[1] > config.max_seq_len:\n",
        "            tokens = tokens[:, -config.max_seq_len:]\n",
        "\n",
        "    model.train()\n",
        "    return sp.decode(generated)\n",
        "\n",
        "# Ana eğitim fonksiyonu\n",
        "def train():\n",
        "    \"\"\"Ana eğitim döngüsü\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\" \"*25 + \"🚀 EĞİTİM BAŞLIYOR!\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Test prompts\n",
        "    test_prompts = [\n",
        "        \"Bugün hava\",\n",
        "        \"Türkiye'nin başkenti\",\n",
        "        \"Yapay zeka teknolojisi\",\n",
        "        \"İnsanlar neden\",\n",
        "    ]\n",
        "\n",
        "    # Training state\n",
        "    step = 0\n",
        "    best_loss = float('inf')\n",
        "    train_losses = []\n",
        "    eval_losses = []\n",
        "\n",
        "    # Timing\n",
        "    start_time = time.time()\n",
        "    tokens_processed = 0\n",
        "\n",
        "    # Data iterator\n",
        "    train_iter = iter(train_loader)\n",
        "\n",
        "    # Initial evaluation\n",
        "    print(\"\\n Başlangıç değerlendirmesi...\")\n",
        "    initial_loss = evaluate(model, train_loader, num_batches=50)\n",
        "    print(f\"  Initial loss: {initial_loss:.4f}\")\n",
        "    print(f\"  Perplexity: {np.exp(initial_loss):.2f}\")\n",
        "\n",
        "    # Initial generation samples\n",
        "    print(\"\\n İlk üretim örnekleri:\")\n",
        "    for prompt in test_prompts[:2]:\n",
        "        output = generate(model, prompt, max_tokens=30, temperature=1.0)\n",
        "        print(f\"  '{prompt}' → {output}\")\n",
        "\n",
        "    print(\"\\n\" + \"-\"*70)\n",
        "    print(\"Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    # Training loop\n",
        "    while step < train_config.max_steps:\n",
        "        try:\n",
        "            batch = next(train_iter)\n",
        "        except StopIteration:\n",
        "            train_iter = iter(train_loader)\n",
        "            batch = next(train_iter)\n",
        "\n",
        "        # Update learning rate\n",
        "        lr = get_lr(step, train_config)\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "        # Training step\n",
        "        loss, grad_norm = train_step(model, batch, optimizer, scaler, train_config)\n",
        "\n",
        "        train_losses.append(loss)\n",
        "        tokens_processed += train_config.batch_size * train_config.max_length\n",
        "        step += 1\n",
        "\n",
        "        # Logging\n",
        "        if step % train_config.log_interval == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            tokens_per_sec = tokens_processed / elapsed\n",
        "            progress = step / train_config.max_steps * 100\n",
        "\n",
        "            print(f\"{step:5d} | {loss:.4f} | {lr:.1e} | {grad_norm:.2f} | \"\n",
        "                  f\"{tokens_per_sec/1000:.1f}K | {format_time(elapsed)} | {progress:5.1f}%\")\n",
        "\n",
        "        # Evaluation\n",
        "        if step % train_config.eval_interval == 0:\n",
        "            print(\"\\n\" + \"=\"*70)\n",
        "            print(f\" EVALUATION @ Step {step}\")\n",
        "            print(\"-\"*70)\n",
        "\n",
        "            # Evaluate\n",
        "            eval_loss = evaluate(model, train_loader, num_batches=100)\n",
        "            eval_losses.append(eval_loss)\n",
        "\n",
        "            print(f\"  Eval loss: {eval_loss:.4f}\")\n",
        "            print(f\"  Perplexity: {np.exp(eval_loss):.2f}\")\n",
        "            print(f\"  Train loss (avg): {np.mean(train_losses[-100:]):.4f}\")\n",
        "\n",
        "            # Generation samples\n",
        "            print(\"\\n   Üretim örnekleri:\")\n",
        "            for i, prompt in enumerate(test_prompts[:3]):\n",
        "                output = generate(model, prompt, max_tokens=40, temperature=0.8)\n",
        "                print(f\"    [{i+1}] '{prompt}' →\")\n",
        "                print(f\"        {output}\")\n",
        "\n",
        "            # Best model\n",
        "            if eval_loss < best_loss:\n",
        "                best_loss = eval_loss\n",
        "                print(f\"\\n   Yeni en iyi model! (loss: {best_loss:.4f})\")\n",
        "\n",
        "                # Save best model\n",
        "                best_path = f\"{CHECKPOINT_DIR}/best_model.pt\"\n",
        "                torch.save({\n",
        "                    'step': step,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'loss': best_loss,\n",
        "                    'config': config,\n",
        "                }, best_path)\n",
        "\n",
        "            # Performance stats\n",
        "            elapsed = time.time() - start_time\n",
        "            tokens_per_sec = tokens_processed / elapsed\n",
        "            eta = (train_config.max_steps - step) / (step / elapsed)\n",
        "\n",
        "            print(f\"\\n   Performans:\")\n",
        "            print(f\"     Tokens/sec: {tokens_per_sec/1000:.1f}K\")\n",
        "            print(f\"     Steps/sec: {step/elapsed:.2f}\")\n",
        "            print(f\"     ETA: {format_time(eta)}\")\n",
        "\n",
        "            print(\"=\"*70 + \"\\n\")\n",
        "            print(\"Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\")\n",
        "            print(\"-\"*70)\n",
        "\n",
        "        # Checkpoint save\n",
        "        if step % train_config.save_interval == 0:\n",
        "            checkpoint_path = f\"{CHECKPOINT_DIR}/checkpoint_step_{step}.pt\"\n",
        "            print(f\"\\n Checkpoint kaydediliyor: {checkpoint_path}\")\n",
        "\n",
        "            torch.save({\n",
        "                'step': step,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': loss,\n",
        "                'config': config,\n",
        "                'train_losses': train_losses,\n",
        "                'eval_losses': eval_losses,\n",
        "            }, checkpoint_path)\n",
        "\n",
        "            print(f\"   Checkpoint kaydedildi!\\n\")\n",
        "\n",
        "        # Early stopping check\n",
        "        if step > 1000 and loss > 15.0:\n",
        "            print(\"\\n Model diverge ediyor! Eğitim durduruluyor.\")\n",
        "            break\n",
        "\n",
        "    # Training complete\n",
        "    total_time = time.time() - start_time\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\" \"*25 + \" EĞİTİM TAMAMLANDI!\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\n Final İstatistikler:\")\n",
        "    print(f\"  Toplam süre: {format_time(total_time)}\")\n",
        "    print(f\"  Toplam step: {step:,}\")\n",
        "    print(f\"  Toplam token: {tokens_processed/1e9:.2f}B\")\n",
        "    print(f\"  Final loss: {loss:.4f}\")\n",
        "    print(f\"  Best eval loss: {best_loss:.4f}\")\n",
        "    print(f\"  Ortalama hız: {tokens_processed/(total_time*1000):.1f}K token/s\")\n",
        "\n",
        "    # Save final model\n",
        "    final_path = f\"{CHECKPOINT_DIR}/final_model.pt\"\n",
        "    torch.save({\n",
        "        'step': step,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss,\n",
        "        'config': config,\n",
        "        'train_losses': train_losses,\n",
        "        'eval_losses': eval_losses,\n",
        "        'total_time': total_time,\n",
        "    }, final_path)\n",
        "\n",
        "    print(f\"\\n Final model kaydedildi: {final_path}\")\n",
        "\n",
        "    # Final generation samples\n",
        "    print(\"\\n Final üretim örnekleri:\")\n",
        "    for prompt in test_prompts:\n",
        "        output = generate(model, prompt, max_tokens=50, temperature=0.7)\n",
        "        print(f\"\\n'{prompt}':\")\n",
        "        print(f\"  → {output}\")\n",
        "\n",
        "    return train_losses, eval_losses\n",
        "\n",
        "# Eğitimi başlat (veri yüklendikten sonra çalıştırın)\n",
        "print(\"\\n Veri yüklenmesini bekleyin, sonra bu hücreyi çalıştırın:\")\n",
        "print(\"train_losses, eval_losses = train()\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === BELLEK TEMİZLEME VE OPTİMİZASYON ===================================\n",
        "\n",
        "import gc\n",
        "import torch\n",
        "\n",
        "# Belleği tamamen temizle\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "print(\"🧹 GPU belleği temizlendi\")\n",
        "print(f\" Mevcut VRAM: {torch.cuda.memory_allocated()/1e9:.2f} GB\\n\")\n",
        "\n",
        "# Batch size'ı düşür\n",
        "OPTIMAL_BATCH_SIZE = 8  # 32'den 8'e düşür\n",
        "GRADIENT_ACCUMULATION = 4  # Efektif batch size: 32\n",
        "\n",
        "# DataLoader'ı yeniden oluştur\n",
        "train_loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=OPTIMAL_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "# Config güncelle\n",
        "train_config.batch_size = OPTIMAL_BATCH_SIZE\n",
        "train_config.gradient_accumulation = GRADIENT_ACCUMULATION\n",
        "\n",
        "print(f\" Yeni ayarlar:\")\n",
        "print(f\"  Batch size: {OPTIMAL_BATCH_SIZE}\")\n",
        "print(f\"  Gradient accumulation: {GRADIENT_ACCUMULATION}\")\n",
        "print(f\"  Efektif batch size: {OPTIMAL_BATCH_SIZE * GRADIENT_ACCUMULATION}\")\n",
        "print(f\"  Batch count: {len(train_loader):,}\")\n",
        "\n",
        "# Optimizer'ı yeniden oluştur\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=train_config.learning_rate,\n",
        "    weight_decay=train_config.weight_decay,\n",
        "    betas=(train_config.adam_beta1, train_config.adam_beta2)\n",
        ")\n",
        "\n",
        "scaler = torch.amp.GradScaler('cuda')\n",
        "\n",
        "# PYTORCH_CUDA_ALLOC_CONF ayarla\n",
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "print(f\"\\n VRAM Durumu:\")\n",
        "print(f\"  Kullanılan: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
        "print(f\"  Toplam: 40 GB\")\n",
        "print(f\"  Boş: {(40 - torch.cuda.memory_allocated()/1e9):.2f} GB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XENxpKa7H5U9",
        "outputId": "8f92e020-8f10-4bc8-8007-7cd9a5da5909"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " GPU belleği temizlendi\n",
            " Mevcut VRAM: 1.54 GB\n",
            "\n",
            " Yeni ayarlar:\n",
            "  Batch size: 8\n",
            "  Gradient accumulation: 4\n",
            "  Efektif batch size: 32\n",
            "  Batch count: 50,570\n",
            "\n",
            " VRAM Durumu:\n",
            "  Kullanılan: 1.54 GB\n",
            "  Toplam: 40 GB\n",
            "  Boş: 38.46 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === GRADIENT ACCUMULATION'LI TRAINING STEP ===================================\n",
        "\n",
        "def train_step_with_accumulation(model, data_loader, optimizer, scaler, config, step):\n",
        "    \"\"\"Gradient accumulation ile training step\"\"\"\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "    # Gradient accumulation loop\n",
        "    for micro_step in range(config.gradient_accumulation):\n",
        "        try:\n",
        "            batch = next(data_loader)\n",
        "        except StopIteration:\n",
        "            data_loader = iter(train_loader)\n",
        "            batch = next(data_loader)\n",
        "\n",
        "        inputs, targets = batch\n",
        "        inputs = inputs.cuda()\n",
        "        targets = targets.cuda()\n",
        "\n",
        "        # Forward pass\n",
        "        with torch.amp.autocast('cuda', enabled=config.use_amp):\n",
        "            logits = model(inputs)\n",
        "            loss = F.cross_entropy(\n",
        "                logits.view(-1, logits.size(-1)),\n",
        "                targets.view(-1),\n",
        "                ignore_index=sp.pad_id()\n",
        "            )\n",
        "            loss = loss / config.gradient_accumulation  # Scale loss\n",
        "\n",
        "        # Backward pass\n",
        "        scaler.scale(loss).backward()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Optimizer step (her N micro-step'te bir)\n",
        "    scaler.unscale_(optimizer)\n",
        "    grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip)\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()\n",
        "\n",
        "    return total_loss * config.gradient_accumulation, grad_norm.item()\n",
        "\n",
        "# train() fonksiyonunda train_step yerine train_step_with_accumulation kullan\n",
        "print(\"\\n Sistem optimize edildi!\")\n",
        "print(\" Eğitimi tekrar başlatabilirsiniz:\")\n",
        "print(\"train_losses, eval_losses = train()\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QH9E9d0BOnV6",
        "outputId": "0c666b3b-5478-4446-c2b1-65c3bd04ed57"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Sistem optimize edildi!\n",
            "train_losses, eval_losses = train()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === EĞİTİMİ BAŞLAT ===================================\n",
        "\n",
        "# Veri yüklendiğini kontrol et\n",
        "try:\n",
        "    print(f\" Dataset hazır: {len(dataset):,} örnek\")\n",
        "    print(f\" DataLoader hazır: {len(train_loader):,} batch\")\n",
        "    print(f\" Model hazır: {sum(p.numel() for p in model.parameters())/1e6:.1f}M parametre\")\n",
        "    print(f\" VRAM: {torch.cuda.memory_allocated()/1e9:.2f}/{40:.0f} GB\\n\")\n",
        "\n",
        "    # Eğitimi başlat\n",
        "    train_losses, eval_losses = train()\n",
        "\n",
        "except NameError as e:\n",
        "    print(f\" Hata: {e}\")\n",
        "    print(\"Önce veri yükleme hücresinin bitmesini bekleyin!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt-GpJ8mO1ef",
        "outputId": "e5965356-4cce-4e3f-d41c-1ec750547bfb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mGörüntülenen çıkış son 5000 satıra kısaltıldı.\u001b[0m\n",
            "17050 | 4.6403 | 3.9e-04 | 0.89 | 38.6K | 01:00:20 |  34.1%\n",
            "17060 | 4.6486 | 3.9e-04 | 0.92 | 38.6K | 01:00:22 |  34.1%\n",
            "17070 | 4.5201 | 3.9e-04 | 0.99 | 38.6K | 01:00:24 |  34.1%\n",
            "17080 | 4.5719 | 3.9e-04 | 0.93 | 38.6K | 01:00:25 |  34.2%\n",
            "17090 | 4.7263 | 3.9e-04 | 0.97 | 38.6K | 01:00:27 |  34.2%\n",
            "17100 | 4.4889 | 3.9e-04 | 0.91 | 38.6K | 01:00:29 |  34.2%\n",
            "17110 | 4.6243 | 3.9e-04 | 0.92 | 38.6K | 01:00:30 |  34.2%\n",
            "17120 | 4.6772 | 3.9e-04 | 0.96 | 38.6K | 01:00:32 |  34.2%\n",
            "17130 | 4.6167 | 3.9e-04 | 0.95 | 38.6K | 01:00:34 |  34.3%\n",
            "17140 | 4.5441 | 3.9e-04 | 0.91 | 38.6K | 01:00:36 |  34.3%\n",
            "17150 | 4.6358 | 3.9e-04 | 0.92 | 38.6K | 01:00:37 |  34.3%\n",
            "17160 | 4.6652 | 3.9e-04 | 0.93 | 38.6K | 01:00:39 |  34.3%\n",
            "17170 | 4.6051 | 3.9e-04 | 0.91 | 38.6K | 01:00:41 |  34.3%\n",
            "17180 | 4.6446 | 3.9e-04 | 0.90 | 38.6K | 01:00:42 |  34.4%\n",
            "17190 | 4.5981 | 3.9e-04 | 0.93 | 38.6K | 01:00:44 |  34.4%\n",
            "17200 | 4.5814 | 3.9e-04 | 0.91 | 38.6K | 01:00:46 |  34.4%\n",
            "17210 | 4.8100 | 3.9e-04 | 0.90 | 38.6K | 01:00:48 |  34.4%\n",
            "17220 | 4.5021 | 3.9e-04 | 1.01 | 38.7K | 01:00:49 |  34.4%\n",
            "17230 | 4.3308 | 3.9e-04 | 0.99 | 38.7K | 01:00:51 |  34.5%\n",
            "17240 | 4.4855 | 3.9e-04 | 1.02 | 38.7K | 01:00:53 |  34.5%\n",
            "17250 | 4.7194 | 3.9e-04 | 0.96 | 38.7K | 01:00:54 |  34.5%\n",
            "17260 | 4.3949 | 3.9e-04 | 0.98 | 38.7K | 01:00:56 |  34.5%\n",
            "17270 | 4.6419 | 3.9e-04 | 1.01 | 38.7K | 01:00:58 |  34.5%\n",
            "17280 | 4.8110 | 3.9e-04 | 0.91 | 38.7K | 01:01:00 |  34.6%\n",
            "17290 | 4.4734 | 3.8e-04 | 0.97 | 38.7K | 01:01:01 |  34.6%\n",
            "17300 | 4.6455 | 3.8e-04 | 0.96 | 38.7K | 01:01:03 |  34.6%\n",
            "17310 | 4.7039 | 3.8e-04 | 0.91 | 38.7K | 01:01:05 |  34.6%\n",
            "17320 | 4.4760 | 3.8e-04 | 0.94 | 38.7K | 01:01:06 |  34.6%\n",
            "17330 | 4.6009 | 3.8e-04 | 0.93 | 38.7K | 01:01:08 |  34.7%\n",
            "17340 | 4.4310 | 3.8e-04 | 1.11 | 38.7K | 01:01:10 |  34.7%\n",
            "17350 | 4.4785 | 3.8e-04 | 0.91 | 38.7K | 01:01:12 |  34.7%\n",
            "17360 | 4.7936 | 3.8e-04 | 0.97 | 38.7K | 01:01:13 |  34.7%\n",
            "17370 | 4.7287 | 3.8e-04 | 0.93 | 38.7K | 01:01:15 |  34.7%\n",
            "17380 | 4.7556 | 3.8e-04 | 0.88 | 38.7K | 01:01:17 |  34.8%\n",
            "17390 | 4.8929 | 3.8e-04 | 0.92 | 38.7K | 01:01:18 |  34.8%\n",
            "17400 | 4.4046 | 3.8e-04 | 0.94 | 38.7K | 01:01:20 |  34.8%\n",
            "17410 | 4.6182 | 3.8e-04 | 0.93 | 38.7K | 01:01:22 |  34.8%\n",
            "17420 | 4.5264 | 3.8e-04 | 0.98 | 38.7K | 01:01:24 |  34.8%\n",
            "17430 | 4.4829 | 3.8e-04 | 0.92 | 38.7K | 01:01:25 |  34.9%\n",
            "17440 | 4.7710 | 3.8e-04 | 0.91 | 38.7K | 01:01:27 |  34.9%\n",
            "17450 | 4.1770 | 3.8e-04 | 1.53 | 38.7K | 01:01:29 |  34.9%\n",
            "17460 | 4.6141 | 3.8e-04 | 0.93 | 38.8K | 01:01:30 |  34.9%\n",
            "17470 | 4.8251 | 3.8e-04 | 0.94 | 38.8K | 01:01:32 |  34.9%\n",
            "17480 | 4.5095 | 3.8e-04 | 0.94 | 38.8K | 01:01:34 |  35.0%\n",
            "17490 | 4.5382 | 3.8e-04 | 0.93 | 38.8K | 01:01:35 |  35.0%\n",
            "17500 | 4.5617 | 3.8e-04 | 0.90 | 38.8K | 01:01:37 |  35.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 17500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.5842\n",
            "  Perplexity: 97.92\n",
            "  Train loss (avg): 4.5957\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        sıcaklıkları düşükse kış aylarında sıcaklığın en yüksek olduğu ve en sıcak olan bir sıcaklığa sahip olan terlik, grip, grip, grip, bronşit, grip, grip gibi hastalıklara karşı savaştığı\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        ve dünyanın en büyük ve en büyük halklarının katıldığı \"Silahlı\". UNESCO'nun başkenti ve dünya genelindeki tüm ülke vatandaşlarının katıldığı \"Silahlı Kent\" ve \"Astantlı\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , günümüzde, teknolojik girişimlerin ve sosyal ekosistemin gelişmesine, bilimsel ve dijitalleşme alışkanlığının geliştirilmesine kadar pek çok alanda önemli aktörler haline gelmiştir. Bu bağlamda, yapay zeka, kütüphane, ev-\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.5842)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.71\n",
            "     ETA: 01:55:05\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "17510 | 4.5931 | 3.8e-04 | 0.94 | 38.6K | 01:02:00 |  35.0%\n",
            "17520 | 4.1729 | 3.8e-04 | 1.00 | 38.6K | 01:02:01 |  35.0%\n",
            "17530 | 4.6902 | 3.8e-04 | 0.91 | 38.6K | 01:02:03 |  35.1%\n",
            "17540 | 4.6710 | 3.8e-04 | 0.90 | 38.6K | 01:02:05 |  35.1%\n",
            "17550 | 4.5302 | 3.8e-04 | 0.93 | 38.6K | 01:02:07 |  35.1%\n",
            "17560 | 4.8319 | 3.8e-04 | 0.95 | 38.6K | 01:02:08 |  35.1%\n",
            "17570 | 4.6848 | 3.8e-04 | 0.91 | 38.6K | 01:02:10 |  35.1%\n",
            "17580 | 4.7484 | 3.8e-04 | 0.98 | 38.6K | 01:02:12 |  35.2%\n",
            "17590 | 4.5371 | 3.8e-04 | 1.00 | 38.6K | 01:02:13 |  35.2%\n",
            "17600 | 4.7008 | 3.8e-04 | 0.96 | 38.6K | 01:02:15 |  35.2%\n",
            "17610 | 4.5617 | 3.8e-04 | 0.91 | 38.6K | 01:02:17 |  35.2%\n",
            "17620 | 4.6905 | 3.8e-04 | 0.91 | 38.6K | 01:02:19 |  35.2%\n",
            "17630 | 4.7018 | 3.8e-04 | 0.95 | 38.6K | 01:02:20 |  35.3%\n",
            "17640 | 4.8154 | 3.8e-04 | 0.94 | 38.6K | 01:02:22 |  35.3%\n",
            "17650 | 4.7043 | 3.8e-04 | 0.91 | 38.6K | 01:02:24 |  35.3%\n",
            "17660 | 4.5573 | 3.8e-04 | 1.05 | 38.6K | 01:02:25 |  35.3%\n",
            "17670 | 4.5851 | 3.8e-04 | 0.95 | 38.6K | 01:02:27 |  35.3%\n",
            "17680 | 4.7006 | 3.8e-04 | 1.00 | 38.6K | 01:02:29 |  35.4%\n",
            "17690 | 4.4586 | 3.8e-04 | 0.95 | 38.6K | 01:02:31 |  35.4%\n",
            "17700 | 4.7871 | 3.8e-04 | 0.92 | 38.6K | 01:02:32 |  35.4%\n",
            "17710 | 4.6827 | 3.8e-04 | 0.91 | 38.6K | 01:02:34 |  35.4%\n",
            "17720 | 4.4409 | 3.8e-04 | 0.95 | 38.6K | 01:02:36 |  35.4%\n",
            "17730 | 4.5099 | 3.8e-04 | 0.97 | 38.7K | 01:02:37 |  35.5%\n",
            "17740 | 4.6519 | 3.8e-04 | 0.95 | 38.7K | 01:02:39 |  35.5%\n",
            "17750 | 4.5653 | 3.8e-04 | 1.01 | 38.7K | 01:02:41 |  35.5%\n",
            "17760 | 4.7751 | 3.8e-04 | 0.92 | 38.7K | 01:02:43 |  35.5%\n",
            "17770 | 4.6912 | 3.8e-04 | 0.91 | 38.7K | 01:02:44 |  35.5%\n",
            "17780 | 4.7174 | 3.8e-04 | 0.95 | 38.7K | 01:02:46 |  35.6%\n",
            "17790 | 4.8509 | 3.8e-04 | 0.93 | 38.7K | 01:02:48 |  35.6%\n",
            "17800 | 4.7406 | 3.8e-04 | 1.00 | 38.7K | 01:02:49 |  35.6%\n",
            "17810 | 4.5699 | 3.8e-04 | 0.92 | 38.7K | 01:02:51 |  35.6%\n",
            "17820 | 4.1645 | 3.8e-04 | 1.08 | 38.7K | 01:02:53 |  35.6%\n",
            "17830 | 4.5813 | 3.8e-04 | 1.04 | 38.7K | 01:02:55 |  35.7%\n",
            "17840 | 4.2549 | 3.8e-04 | 0.91 | 38.7K | 01:02:56 |  35.7%\n",
            "17850 | 4.7585 | 3.8e-04 | 0.93 | 38.7K | 01:02:58 |  35.7%\n",
            "17860 | 4.6176 | 3.8e-04 | 0.98 | 38.7K | 01:03:00 |  35.7%\n",
            "17870 | 4.8348 | 3.8e-04 | 0.92 | 38.7K | 01:03:01 |  35.7%\n",
            "17880 | 4.5652 | 3.8e-04 | 0.94 | 38.7K | 01:03:03 |  35.8%\n",
            "17890 | 4.7113 | 3.8e-04 | 0.91 | 38.7K | 01:03:05 |  35.8%\n",
            "17900 | 4.5212 | 3.8e-04 | 0.99 | 38.7K | 01:03:07 |  35.8%\n",
            "17910 | 4.5618 | 3.8e-04 | 0.90 | 38.7K | 01:03:08 |  35.8%\n",
            "17920 | 4.7030 | 3.8e-04 | 0.97 | 38.7K | 01:03:10 |  35.8%\n",
            "17930 | 4.8365 | 3.8e-04 | 0.92 | 38.7K | 01:03:12 |  35.9%\n",
            "17940 | 4.5032 | 3.8e-04 | 0.98 | 38.7K | 01:03:13 |  35.9%\n",
            "17950 | 4.4759 | 3.8e-04 | 0.95 | 38.7K | 01:03:15 |  35.9%\n",
            "17960 | 4.8598 | 3.8e-04 | 0.94 | 38.7K | 01:03:17 |  35.9%\n",
            "17970 | 4.7818 | 3.8e-04 | 1.01 | 38.7K | 01:03:19 |  35.9%\n",
            "17980 | 4.7562 | 3.8e-04 | 0.94 | 38.8K | 01:03:20 |  36.0%\n",
            "17990 | 4.6198 | 3.8e-04 | 0.94 | 38.8K | 01:03:22 |  36.0%\n",
            "18000 | 4.6864 | 3.8e-04 | 0.97 | 38.8K | 01:03:24 |  36.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 18000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.5586\n",
            "  Perplexity: 95.45\n",
            "  Train loss (avg): 4.6176\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        sıcaklığının 300 ile 400 bandında olduğu tahmin ediliyor. Hava sıcaklığının 400 ile 350 bandında olduğu tahmin ediliyor. Hava sıcaklığının 400 ile 300 bandında olduğu tahmin ediliyor. Hava sıcaklığının 70 ile\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Antalya'da bulunan tarihi ve turistik yerleri gezme imkanı. Antalya'da şehrin en güzel yerlerinden biri olan ve içerisinde birçok tarihi yapıları, tarihi ve turistik mekanları, tarihini, tarihini, tarihini, tarihini,\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        ve yapay zeka teknolojisi sayesinde insan sanal gerçeklik olarak algılanabilir. Ancak teknoloji, günlük yaşantımızda onların gerçek ve sezgisel gözlemler, robotlar ve robotlar için yeni teknoloji türlerini içeren teknolojik verileri\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.5586)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.71\n",
            "     ETA: 01:53:19\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "18010 | 4.3230 | 3.7e-04 | 1.04 | 38.6K | 01:03:46 |  36.0%\n",
            "18020 | 4.6833 | 3.7e-04 | 0.94 | 38.6K | 01:03:48 |  36.0%\n",
            "18030 | 4.5749 | 3.7e-04 | 1.05 | 38.6K | 01:03:50 |  36.1%\n",
            "18040 | 4.4938 | 3.7e-04 | 0.92 | 38.6K | 01:03:51 |  36.1%\n",
            "18050 | 4.4774 | 3.7e-04 | 1.01 | 38.6K | 01:03:53 |  36.1%\n",
            "18060 | 4.6612 | 3.7e-04 | 1.13 | 38.6K | 01:03:55 |  36.1%\n",
            "18070 | 4.6988 | 3.7e-04 | 0.93 | 38.6K | 01:03:56 |  36.1%\n",
            "18080 | 4.7359 | 3.7e-04 | 0.94 | 38.6K | 01:03:58 |  36.2%\n",
            "18090 | 4.6143 | 3.7e-04 | 0.96 | 38.6K | 01:04:00 |  36.2%\n",
            "18100 | 4.5059 | 3.7e-04 | 1.00 | 38.6K | 01:04:02 |  36.2%\n",
            "18110 | 4.6119 | 3.7e-04 | 0.97 | 38.6K | 01:04:03 |  36.2%\n",
            "18120 | 4.5778 | 3.7e-04 | 0.91 | 38.6K | 01:04:05 |  36.2%\n",
            "18130 | 4.6366 | 3.7e-04 | 0.98 | 38.6K | 01:04:07 |  36.3%\n",
            "18140 | 4.6158 | 3.7e-04 | 0.93 | 38.6K | 01:04:08 |  36.3%\n",
            "18150 | 4.4299 | 3.7e-04 | 0.98 | 38.6K | 01:04:10 |  36.3%\n",
            "18160 | 4.7519 | 3.7e-04 | 0.99 | 38.6K | 01:04:12 |  36.3%\n",
            "18170 | 4.6396 | 3.7e-04 | 0.94 | 38.6K | 01:04:14 |  36.3%\n",
            "18180 | 4.7124 | 3.7e-04 | 0.90 | 38.6K | 01:04:15 |  36.4%\n",
            "18190 | 4.5583 | 3.7e-04 | 1.05 | 38.6K | 01:04:17 |  36.4%\n",
            "18200 | 4.8592 | 3.7e-04 | 0.91 | 38.6K | 01:04:19 |  36.4%\n",
            "18210 | 4.6476 | 3.7e-04 | 1.00 | 38.6K | 01:04:20 |  36.4%\n",
            "18220 | 4.6224 | 3.7e-04 | 0.95 | 38.6K | 01:04:22 |  36.4%\n",
            "18230 | 4.7086 | 3.7e-04 | 0.95 | 38.6K | 01:04:24 |  36.5%\n",
            "18240 | 4.4395 | 3.7e-04 | 0.96 | 38.7K | 01:04:26 |  36.5%\n",
            "18250 | 4.5014 | 3.7e-04 | 0.91 | 38.7K | 01:04:27 |  36.5%\n",
            "18260 | 4.6304 | 3.7e-04 | 0.91 | 38.7K | 01:04:29 |  36.5%\n",
            "18270 | 4.3691 | 3.7e-04 | 1.04 | 38.7K | 01:04:31 |  36.5%\n",
            "18280 | 4.7342 | 3.7e-04 | 0.97 | 38.7K | 01:04:32 |  36.6%\n",
            "18290 | 4.3917 | 3.7e-04 | 1.00 | 38.7K | 01:04:34 |  36.6%\n",
            "18300 | 4.7063 | 3.7e-04 | 0.95 | 38.7K | 01:04:36 |  36.6%\n",
            "18310 | 4.5486 | 3.7e-04 | 0.93 | 38.7K | 01:04:38 |  36.6%\n",
            "18320 | 4.6147 | 3.7e-04 | 0.96 | 38.7K | 01:04:39 |  36.6%\n",
            "18330 | 4.7051 | 3.7e-04 | 0.94 | 38.7K | 01:04:41 |  36.7%\n",
            "18340 | 4.6957 | 3.7e-04 | 0.95 | 38.7K | 01:04:43 |  36.7%\n",
            "18350 | 4.6875 | 3.7e-04 | 0.93 | 38.7K | 01:04:44 |  36.7%\n",
            "18360 | 4.6466 | 3.7e-04 | 0.95 | 38.7K | 01:04:46 |  36.7%\n",
            "18370 | 4.6831 | 3.7e-04 | 0.94 | 38.7K | 01:04:48 |  36.7%\n",
            "18380 | 4.7451 | 3.7e-04 | 0.93 | 38.7K | 01:04:50 |  36.8%\n",
            "18390 | 4.7153 | 3.7e-04 | 0.92 | 38.7K | 01:04:51 |  36.8%\n",
            "18400 | 4.6722 | 3.7e-04 | 0.95 | 38.7K | 01:04:53 |  36.8%\n",
            "18410 | 4.5816 | 3.7e-04 | 0.92 | 38.7K | 01:04:55 |  36.8%\n",
            "18420 | 4.3175 | 3.7e-04 | 0.98 | 38.7K | 01:04:56 |  36.8%\n",
            "18430 | 4.6589 | 3.7e-04 | 0.99 | 38.7K | 01:04:58 |  36.9%\n",
            "18440 | 4.8814 | 3.7e-04 | 0.93 | 38.7K | 01:05:00 |  36.9%\n",
            "18450 | 4.7954 | 3.7e-04 | 0.98 | 38.7K | 01:05:02 |  36.9%\n",
            "18460 | 4.4478 | 3.7e-04 | 0.93 | 38.7K | 01:05:03 |  36.9%\n",
            "18470 | 4.8682 | 3.7e-04 | 0.95 | 38.7K | 01:05:05 |  36.9%\n",
            "18480 | 4.2712 | 3.7e-04 | 1.01 | 38.7K | 01:05:07 |  37.0%\n",
            "18490 | 4.7802 | 3.7e-04 | 0.97 | 38.8K | 01:05:08 |  37.0%\n",
            "18500 | 4.6087 | 3.7e-04 | 0.96 | 38.8K | 01:05:10 |  37.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 18500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.5451\n",
            "  Perplexity: 94.17\n",
            "  Train loss (avg): 4.6112\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        durumu, hava şartları, hava koşulları, hava koşulları ve dikkat süresi gibi unsurlar ile ilgili olarak, 2003-2009 yılları arasında, Türkiye'de, Refahiye Mahsulleri Ofisi'nde görevli olarak\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Washington'da bulunan Katowers'ın hizmet binası, her yıl ev yapımı sokaklardan oluşuyor. Varşova'nın batı kıyısında yer aldığı Katowers'ın burada da bulunduğu ileri karakol,\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        sayesinde sadece 20 dakikada bir arada çalışabilme imkanınız var mı? Microsoft artık bu hizmete açık değil. Kişiselleştirilmiş içerikte de kendi ürettikleri telefon üzerinden Office veya IOS için çalışan bir ülke haline geliyorlar\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.5451)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.71\n",
            "     ETA: 01:51:33\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "18510 | 4.7507 | 3.7e-04 | 0.95 | 38.6K | 01:05:32 |  37.0%\n",
            "18520 | 4.5066 | 3.7e-04 | 0.92 | 38.6K | 01:05:34 |  37.0%\n",
            "18530 | 4.5711 | 3.7e-04 | 0.93 | 38.6K | 01:05:36 |  37.1%\n",
            "18540 | 4.3525 | 3.7e-04 | 1.08 | 38.6K | 01:05:38 |  37.1%\n",
            "18550 | 4.3188 | 3.7e-04 | 0.96 | 38.6K | 01:05:39 |  37.1%\n",
            "18560 | 4.7873 | 3.7e-04 | 1.01 | 38.6K | 01:05:41 |  37.1%\n",
            "18570 | 4.2072 | 3.7e-04 | 1.87 | 38.6K | 01:05:43 |  37.1%\n",
            "18580 | 4.8041 | 3.7e-04 | 0.95 | 38.6K | 01:05:44 |  37.2%\n",
            "18590 | 4.3685 | 3.7e-04 | 0.99 | 38.6K | 01:05:46 |  37.2%\n",
            "18600 | 4.4054 | 3.7e-04 | 1.02 | 38.6K | 01:05:48 |  37.2%\n",
            "18610 | 4.5332 | 3.7e-04 | 0.97 | 38.6K | 01:05:50 |  37.2%\n",
            "18620 | 4.6509 | 3.7e-04 | 0.96 | 38.6K | 01:05:51 |  37.2%\n",
            "18630 | 4.3273 | 3.7e-04 | 0.99 | 38.6K | 01:05:53 |  37.3%\n",
            "18640 | 4.4670 | 3.7e-04 | 0.96 | 38.6K | 01:05:55 |  37.3%\n",
            "18650 | 4.6254 | 3.7e-04 | 0.98 | 38.6K | 01:05:56 |  37.3%\n",
            "18660 | 4.7216 | 3.7e-04 | 0.94 | 38.6K | 01:05:58 |  37.3%\n",
            "18670 | 4.5446 | 3.7e-04 | 0.96 | 38.6K | 01:06:00 |  37.3%\n",
            "18680 | 4.6593 | 3.7e-04 | 0.99 | 38.6K | 01:06:02 |  37.4%\n",
            "18690 | 4.4628 | 3.7e-04 | 0.95 | 38.6K | 01:06:03 |  37.4%\n",
            "18700 | 4.6709 | 3.6e-04 | 0.94 | 38.6K | 01:06:05 |  37.4%\n",
            "18710 | 4.2814 | 3.6e-04 | 1.07 | 38.6K | 01:06:07 |  37.4%\n",
            "18720 | 4.7475 | 3.6e-04 | 0.95 | 38.6K | 01:06:08 |  37.4%\n",
            "18730 | 4.6956 | 3.6e-04 | 0.93 | 38.6K | 01:06:10 |  37.5%\n",
            "18740 | 4.7527 | 3.6e-04 | 0.94 | 38.6K | 01:06:12 |  37.5%\n",
            "18750 | 4.6073 | 3.6e-04 | 0.99 | 38.7K | 01:06:14 |  37.5%\n",
            "18760 | 4.6110 | 3.6e-04 | 1.20 | 38.7K | 01:06:15 |  37.5%\n",
            "18770 | 4.7245 | 3.6e-04 | 0.92 | 38.7K | 01:06:17 |  37.5%\n",
            "18780 | 4.5729 | 3.6e-04 | 0.94 | 38.7K | 01:06:19 |  37.6%\n",
            "18790 | 4.5236 | 3.6e-04 | 0.95 | 38.7K | 01:06:20 |  37.6%\n",
            "18800 | 4.6086 | 3.6e-04 | 0.95 | 38.7K | 01:06:22 |  37.6%\n",
            "18810 | 4.2646 | 3.6e-04 | 0.96 | 38.7K | 01:06:24 |  37.6%\n",
            "18820 | 4.4468 | 3.6e-04 | 0.96 | 38.7K | 01:06:26 |  37.6%\n",
            "18830 | 4.3181 | 3.6e-04 | 1.05 | 38.7K | 01:06:27 |  37.7%\n",
            "18840 | 4.5739 | 3.6e-04 | 0.95 | 38.7K | 01:06:29 |  37.7%\n",
            "18850 | 4.4475 | 3.6e-04 | 0.92 | 38.7K | 01:06:31 |  37.7%\n",
            "18860 | 4.3371 | 3.6e-04 | 0.97 | 38.7K | 01:06:32 |  37.7%\n",
            "18870 | 4.8200 | 3.6e-04 | 1.01 | 38.7K | 01:06:34 |  37.7%\n",
            "18880 | 4.4746 | 3.6e-04 | 0.92 | 38.7K | 01:06:36 |  37.8%\n",
            "18890 | 4.6973 | 3.6e-04 | 0.96 | 38.7K | 01:06:38 |  37.8%\n",
            "18900 | 4.7961 | 3.6e-04 | 0.93 | 38.7K | 01:06:39 |  37.8%\n",
            "18910 | 4.5848 | 3.6e-04 | 0.96 | 38.7K | 01:06:41 |  37.8%\n",
            "18920 | 4.5422 | 3.6e-04 | 0.95 | 38.7K | 01:06:43 |  37.8%\n",
            "18930 | 4.2776 | 3.6e-04 | 0.95 | 38.7K | 01:06:44 |  37.9%\n",
            "18940 | 4.5355 | 3.6e-04 | 0.98 | 38.7K | 01:06:46 |  37.9%\n",
            "18950 | 4.6593 | 3.6e-04 | 0.95 | 38.7K | 01:06:48 |  37.9%\n",
            "18960 | 4.4653 | 3.6e-04 | 1.01 | 38.7K | 01:06:50 |  37.9%\n",
            "18970 | 4.4472 | 3.6e-04 | 0.98 | 38.7K | 01:06:51 |  37.9%\n",
            "18980 | 4.3745 | 3.6e-04 | 1.01 | 38.7K | 01:06:53 |  38.0%\n",
            "18990 | 4.6196 | 3.6e-04 | 0.97 | 38.7K | 01:06:55 |  38.0%\n",
            "19000 | 4.3269 | 3.6e-04 | 0.95 | 38.7K | 01:06:56 |  38.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 19000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.5323\n",
            "  Perplexity: 92.97\n",
            "  Train loss (avg): 4.5692\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        sıcaklıklarının düşük olduğu günlerde, hava sıcaklıklarının düşmesiyle beraber artan yağış miktarı artacak, hafta sonları güneşle ve gece saatlerindeki güneş ışınları ile daha da kuvvetlenecektir. Bunun da etkisiyle enerji,\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Ankara'nın en gözde şehirlerindendir. New York, Kuzey Amerika, Afrika, Asya, Asya, Avrupa ve Avrupa, Amerika, Japonya, Fransa, Fransa, Fransa, İngiltere, İtalya, İtalya,\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        ; başarı, sosyal ilişkiler ve güvenlilik gibi birçok alanda, sanal gerçeklik ile dünyanın en önde gelen iletişim ağıdır. Bu sayede hem basit bir şekilde sanal gerçeklik farklarının azalmasını sağlar, hem de sanal\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.5323)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.5K\n",
            "     Steps/sec: 4.71\n",
            "     ETA: 01:49:47\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "19010 | 4.3506 | 3.6e-04 | 1.04 | 38.6K | 01:07:19 |  38.0%\n",
            "19020 | 4.4911 | 3.6e-04 | 0.92 | 38.6K | 01:07:21 |  38.0%\n",
            "19030 | 4.6830 | 3.6e-04 | 0.95 | 38.6K | 01:07:22 |  38.1%\n",
            "19040 | 4.6294 | 3.6e-04 | 0.93 | 38.6K | 01:07:24 |  38.1%\n",
            "19050 | 4.6713 | 3.6e-04 | 0.92 | 38.6K | 01:07:26 |  38.1%\n",
            "19060 | 4.5832 | 3.6e-04 | 0.95 | 38.6K | 01:07:27 |  38.1%\n",
            "19070 | 4.5507 | 3.6e-04 | 0.99 | 38.6K | 01:07:29 |  38.1%\n",
            "19080 | 4.6042 | 3.6e-04 | 0.99 | 38.6K | 01:07:31 |  38.2%\n",
            "19090 | 4.8783 | 3.6e-04 | 1.00 | 38.6K | 01:07:33 |  38.2%\n",
            "19100 | 4.5620 | 3.6e-04 | 0.97 | 38.6K | 01:07:34 |  38.2%\n",
            "19110 | 4.5652 | 3.6e-04 | 1.06 | 38.6K | 01:07:36 |  38.2%\n",
            "19120 | 4.5602 | 3.6e-04 | 0.97 | 38.6K | 01:07:38 |  38.2%\n",
            "19130 | 4.7128 | 3.6e-04 | 0.94 | 38.6K | 01:07:39 |  38.3%\n",
            "19140 | 4.3664 | 3.6e-04 | 0.97 | 38.6K | 01:07:41 |  38.3%\n",
            "19150 | 4.7611 | 3.6e-04 | 0.93 | 38.6K | 01:07:43 |  38.3%\n",
            "19160 | 4.6006 | 3.6e-04 | 0.95 | 38.6K | 01:07:45 |  38.3%\n",
            "19170 | 4.7866 | 3.6e-04 | 0.97 | 38.6K | 01:07:46 |  38.3%\n",
            "19180 | 4.5016 | 3.6e-04 | 0.94 | 38.6K | 01:07:48 |  38.4%\n",
            "19190 | 4.2373 | 3.6e-04 | 1.01 | 38.6K | 01:07:50 |  38.4%\n",
            "19200 | 4.4584 | 3.6e-04 | 0.98 | 38.6K | 01:07:51 |  38.4%\n",
            "19210 | 4.7748 | 3.6e-04 | 0.92 | 38.6K | 01:07:53 |  38.4%\n",
            "19220 | 4.5135 | 3.6e-04 | 1.04 | 38.6K | 01:07:55 |  38.4%\n",
            "19230 | 4.5446 | 3.6e-04 | 0.98 | 38.6K | 01:07:57 |  38.5%\n",
            "19240 | 4.3352 | 3.6e-04 | 1.03 | 38.6K | 01:07:58 |  38.5%\n",
            "19250 | 4.7688 | 3.6e-04 | 0.95 | 38.6K | 01:08:00 |  38.5%\n",
            "19260 | 4.6653 | 3.6e-04 | 1.00 | 38.7K | 01:08:02 |  38.5%\n",
            "19270 | 4.6365 | 3.6e-04 | 0.99 | 38.7K | 01:08:03 |  38.5%\n",
            "19280 | 4.6420 | 3.6e-04 | 0.93 | 38.7K | 01:08:05 |  38.6%\n",
            "19290 | 4.4981 | 3.6e-04 | 0.96 | 38.7K | 01:08:07 |  38.6%\n",
            "19300 | 4.6408 | 3.6e-04 | 0.95 | 38.7K | 01:08:09 |  38.6%\n",
            "19310 | 4.8212 | 3.6e-04 | 0.95 | 38.7K | 01:08:10 |  38.6%\n",
            "19320 | 4.6089 | 3.6e-04 | 0.95 | 38.7K | 01:08:12 |  38.6%\n",
            "19330 | 4.0897 | 3.6e-04 | 1.10 | 38.7K | 01:08:14 |  38.7%\n",
            "19340 | 4.7680 | 3.6e-04 | 0.96 | 38.7K | 01:08:15 |  38.7%\n",
            "19350 | 4.3721 | 3.6e-04 | 1.11 | 38.7K | 01:08:17 |  38.7%\n",
            "19360 | 4.5714 | 3.6e-04 | 0.94 | 38.7K | 01:08:19 |  38.7%\n",
            "19370 | 4.9029 | 3.6e-04 | 0.98 | 38.7K | 01:08:21 |  38.7%\n",
            "19380 | 4.6822 | 3.5e-04 | 0.93 | 38.7K | 01:08:22 |  38.8%\n",
            "19390 | 4.7166 | 3.5e-04 | 0.98 | 38.7K | 01:08:24 |  38.8%\n",
            "19400 | 4.6131 | 3.5e-04 | 0.98 | 38.7K | 01:08:26 |  38.8%\n",
            "19410 | 4.8610 | 3.5e-04 | 0.97 | 38.7K | 01:08:27 |  38.8%\n",
            "19420 | 4.1461 | 3.5e-04 | 0.94 | 38.7K | 01:08:29 |  38.8%\n",
            "19430 | 4.3655 | 3.5e-04 | 1.00 | 38.7K | 01:08:31 |  38.9%\n",
            "19440 | 4.7877 | 3.5e-04 | 0.94 | 38.7K | 01:08:32 |  38.9%\n",
            "19450 | 4.5304 | 3.5e-04 | 1.00 | 38.7K | 01:08:34 |  38.9%\n",
            "19460 | 4.4776 | 3.5e-04 | 0.95 | 38.7K | 01:08:36 |  38.9%\n",
            "19470 | 4.4581 | 3.5e-04 | 0.95 | 38.7K | 01:08:38 |  38.9%\n",
            "19480 | 4.6013 | 3.5e-04 | 0.99 | 38.7K | 01:08:39 |  39.0%\n",
            "19490 | 4.6208 | 3.5e-04 | 0.97 | 38.7K | 01:08:41 |  39.0%\n",
            "19500 | 4.2525 | 3.5e-04 | 0.97 | 38.7K | 01:08:43 |  39.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 19500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.5579\n",
            "  Perplexity: 95.38\n",
            "  Train loss (avg): 4.5906\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        sıcaklıklarıyla birlikte yüzlere çıkan yaz mevsiminin aydınlığı bir yandan da sıcaklığın etkisiyle, doğayla iç içe olduğumuz koşullar bir yandan da iç içe olan mevsiminin yenilenmesine yol açarken, geçişimizin\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        İstanbul'da her türlü şekilde insanların yaşadığı bir şehir olarak bu bölgede konumlanan şehirlerle dünyanın en popüler şehirlerinin başında geliyor. Günümüzde de İstanbul'un her yeri gezilip görülmesi gereken bir şehir. Farklı\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        firmalarını bir araya getiren bir çok firma bulunuyor. Firmaların özel ev kullanıcıları için özel bir program hazırlamak da bu firmalardan biri. Başvuru süresi dolmadan, 35 saatten az bir süre de olsa tüm müşterilerin\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.71\n",
            "     ETA: 01:47:56\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "19510 | 4.7144 | 3.5e-04 | 0.98 | 38.6K | 01:09:02 |  39.0%\n",
            "19520 | 4.5843 | 3.5e-04 | 1.00 | 38.6K | 01:09:04 |  39.0%\n",
            "19530 | 4.9122 | 3.5e-04 | 0.93 | 38.6K | 01:09:05 |  39.1%\n",
            "19540 | 4.2563 | 3.5e-04 | 0.94 | 38.6K | 01:09:07 |  39.1%\n",
            "19550 | 4.6005 | 3.5e-04 | 0.96 | 38.6K | 01:09:09 |  39.1%\n",
            "19560 | 4.4661 | 3.5e-04 | 1.02 | 38.6K | 01:09:10 |  39.1%\n",
            "19570 | 4.2887 | 3.5e-04 | 1.01 | 38.6K | 01:09:12 |  39.1%\n",
            "19580 | 4.6567 | 3.5e-04 | 0.95 | 38.6K | 01:09:14 |  39.2%\n",
            "19590 | 4.6891 | 3.5e-04 | 0.95 | 38.6K | 01:09:16 |  39.2%\n",
            "19600 | 4.5786 | 3.5e-04 | 0.95 | 38.6K | 01:09:17 |  39.2%\n",
            "19610 | 4.5586 | 3.5e-04 | 0.96 | 38.6K | 01:09:19 |  39.2%\n",
            "19620 | 4.5616 | 3.5e-04 | 0.93 | 38.6K | 01:09:21 |  39.2%\n",
            "19630 | 4.5202 | 3.5e-04 | 0.96 | 38.6K | 01:09:22 |  39.3%\n",
            "19640 | 4.5747 | 3.5e-04 | 1.09 | 38.6K | 01:09:24 |  39.3%\n",
            "19650 | 4.5645 | 3.5e-04 | 0.94 | 38.6K | 01:09:26 |  39.3%\n",
            "19660 | 4.3529 | 3.5e-04 | 0.97 | 38.6K | 01:09:27 |  39.3%\n",
            "19670 | 4.4267 | 3.5e-04 | 0.96 | 38.6K | 01:09:29 |  39.3%\n",
            "19680 | 4.4971 | 3.5e-04 | 0.96 | 38.6K | 01:09:31 |  39.4%\n",
            "19690 | 4.4751 | 3.5e-04 | 0.95 | 38.7K | 01:09:33 |  39.4%\n",
            "19700 | 4.3692 | 3.5e-04 | 1.01 | 38.7K | 01:09:34 |  39.4%\n",
            "19710 | 4.5824 | 3.5e-04 | 0.93 | 38.7K | 01:09:36 |  39.4%\n",
            "19720 | 4.5207 | 3.5e-04 | 1.03 | 38.7K | 01:09:38 |  39.4%\n",
            "19730 | 4.6231 | 3.5e-04 | 0.97 | 38.7K | 01:09:39 |  39.5%\n",
            "19740 | 4.5802 | 3.5e-04 | 0.95 | 38.7K | 01:09:41 |  39.5%\n",
            "19750 | 4.6598 | 3.5e-04 | 0.97 | 38.7K | 01:09:43 |  39.5%\n",
            "19760 | 4.6686 | 3.5e-04 | 0.93 | 38.7K | 01:09:45 |  39.5%\n",
            "19770 | 4.6914 | 3.5e-04 | 1.04 | 38.7K | 01:09:46 |  39.5%\n",
            "19780 | 4.3564 | 3.5e-04 | 0.99 | 38.7K | 01:09:48 |  39.6%\n",
            "19790 | 4.5676 | 3.5e-04 | 0.98 | 38.7K | 01:09:50 |  39.6%\n",
            "19800 | 4.8913 | 3.5e-04 | 0.94 | 38.7K | 01:09:51 |  39.6%\n",
            "19810 | 4.5123 | 3.5e-04 | 0.95 | 38.7K | 01:09:53 |  39.6%\n",
            "19820 | 4.8238 | 3.5e-04 | 0.94 | 38.7K | 01:09:55 |  39.6%\n",
            "19830 | 4.3311 | 3.5e-04 | 0.97 | 38.7K | 01:09:57 |  39.7%\n",
            "19840 | 4.5474 | 3.5e-04 | 0.93 | 38.7K | 01:09:58 |  39.7%\n",
            "19850 | 4.2846 | 3.5e-04 | 1.07 | 38.7K | 01:10:00 |  39.7%\n",
            "19860 | 4.2742 | 3.5e-04 | 0.96 | 38.7K | 01:10:02 |  39.7%\n",
            "19870 | 4.8332 | 3.5e-04 | 0.97 | 38.7K | 01:10:03 |  39.7%\n",
            "19880 | 4.2203 | 3.5e-04 | 0.96 | 38.7K | 01:10:05 |  39.8%\n",
            "19890 | 4.5275 | 3.5e-04 | 0.99 | 38.7K | 01:10:07 |  39.8%\n",
            "19900 | 4.4681 | 3.5e-04 | 0.97 | 38.7K | 01:10:09 |  39.8%\n",
            "19910 | 4.5928 | 3.5e-04 | 0.98 | 38.7K | 01:10:10 |  39.8%\n",
            "19920 | 4.4612 | 3.5e-04 | 0.96 | 38.7K | 01:10:12 |  39.8%\n",
            "19930 | 4.5914 | 3.5e-04 | 1.02 | 38.7K | 01:10:14 |  39.9%\n",
            "19940 | 4.6670 | 3.5e-04 | 1.00 | 38.7K | 01:10:15 |  39.9%\n",
            "19950 | 4.2972 | 3.5e-04 | 1.02 | 38.7K | 01:10:17 |  39.9%\n",
            "19960 | 4.5296 | 3.5e-04 | 0.97 | 38.8K | 01:10:19 |  39.9%\n",
            "19970 | 4.8010 | 3.5e-04 | 0.98 | 38.8K | 01:10:21 |  39.9%\n",
            "19980 | 4.6874 | 3.5e-04 | 0.95 | 38.8K | 01:10:22 |  40.0%\n",
            "19990 | 4.7444 | 3.5e-04 | 0.97 | 38.8K | 01:10:24 |  40.0%\n",
            "20000 | 4.5636 | 3.5e-04 | 0.97 | 38.8K | 01:10:26 |  40.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 20000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.5430\n",
            "  Perplexity: 93.98\n",
            "  Train loss (avg): 4.5460\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        durumu iyi durumda ve dış politikadaki yavaşlamalarla birlikte Türkiye’de ekonomi, endüstri, otomotiv sektöründen kalma ve sosyal güvenlik, endüstri, endüstri, tasarım ve teknoloji sektöründen kalma turizm sektörü ve bu\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        olan San Francisco’nun en büyük şehri konumunda bulunan San Francisco, 2200 yıl sonra dünyanın en büyük şehri konumunda. San Francisco’nun başkenti San Francisco’nun en büyük şehri diyebiliriz. San Francisco’\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        yapay zeka teknolojileri, bir çok farklı alanda en çok tercih edilen tercih edilen bilgisayarlerden biridir. Teknoloji devi yapay zeka teknolojisi için yapay zeka sistemleri geliştirilmiş bir akıllı telefondır. Yapay zeka teknolojisinin gelişmesi ile akıllı telefon\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.71\n",
            "     ETA: 01:46:05\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "💾 Checkpoint kaydediliyor: /content/drive/MyDrive/turkish_llm/checkpoints//checkpoint_step_20000.pt\n",
            "  ✅ Checkpoint kaydedildi!\n",
            "\n",
            "20010 | 4.5963 | 3.5e-04 | 0.99 | 38.6K | 01:10:48 |  40.0%\n",
            "20020 | 4.4982 | 3.5e-04 | 0.98 | 38.6K | 01:10:50 |  40.0%\n",
            "20030 | 4.6342 | 3.5e-04 | 0.97 | 38.6K | 01:10:51 |  40.1%\n",
            "20040 | 4.6591 | 3.5e-04 | 0.94 | 38.6K | 01:10:53 |  40.1%\n",
            "20050 | 4.5571 | 3.4e-04 | 0.96 | 38.6K | 01:10:55 |  40.1%\n",
            "20060 | 4.2798 | 3.4e-04 | 1.04 | 38.6K | 01:10:57 |  40.1%\n",
            "20070 | 4.7420 | 3.4e-04 | 0.95 | 38.6K | 01:10:58 |  40.1%\n",
            "20080 | 4.5448 | 3.4e-04 | 0.94 | 38.6K | 01:11:00 |  40.2%\n",
            "20090 | 4.6083 | 3.4e-04 | 0.93 | 38.6K | 01:11:02 |  40.2%\n",
            "20100 | 4.3115 | 3.4e-04 | 1.15 | 38.6K | 01:11:04 |  40.2%\n",
            "20110 | 4.6177 | 3.4e-04 | 1.01 | 38.6K | 01:11:05 |  40.2%\n",
            "20120 | 4.6460 | 3.4e-04 | 0.98 | 38.6K | 01:11:07 |  40.2%\n",
            "20130 | 4.4085 | 3.4e-04 | 1.05 | 38.6K | 01:11:09 |  40.3%\n",
            "20140 | 4.7725 | 3.4e-04 | 0.99 | 38.6K | 01:11:10 |  40.3%\n",
            "20150 | 4.5956 | 3.4e-04 | 0.99 | 38.6K | 01:11:12 |  40.3%\n",
            "20160 | 4.3586 | 3.4e-04 | 0.95 | 38.6K | 01:11:14 |  40.3%\n",
            "20170 | 4.5741 | 3.4e-04 | 0.98 | 38.6K | 01:11:16 |  40.3%\n",
            "20180 | 4.8436 | 3.4e-04 | 0.96 | 38.6K | 01:11:17 |  40.4%\n",
            "20190 | 4.5322 | 3.4e-04 | 1.01 | 38.6K | 01:11:19 |  40.4%\n",
            "20200 | 4.5482 | 3.4e-04 | 0.97 | 38.7K | 01:11:21 |  40.4%\n",
            "20210 | 4.6339 | 3.4e-04 | 1.01 | 38.7K | 01:11:22 |  40.4%\n",
            "20220 | 4.3230 | 3.4e-04 | 1.20 | 38.7K | 01:11:24 |  40.4%\n",
            "20230 | 4.5662 | 3.4e-04 | 1.03 | 38.7K | 01:11:26 |  40.5%\n",
            "20240 | 4.1178 | 3.4e-04 | 1.01 | 38.7K | 01:11:28 |  40.5%\n",
            "20250 | 4.6816 | 3.4e-04 | 1.00 | 38.7K | 01:11:29 |  40.5%\n",
            "20260 | 4.3913 | 3.4e-04 | 1.01 | 38.7K | 01:11:31 |  40.5%\n",
            "20270 | 4.6810 | 3.4e-04 | 0.97 | 38.7K | 01:11:33 |  40.5%\n",
            "20280 | 4.6413 | 3.4e-04 | 0.98 | 38.7K | 01:11:34 |  40.6%\n",
            "20290 | 4.5785 | 3.4e-04 | 0.98 | 38.7K | 01:11:36 |  40.6%\n",
            "20300 | 4.7393 | 3.4e-04 | 0.97 | 38.7K | 01:11:38 |  40.6%\n",
            "20310 | 4.7395 | 3.4e-04 | 0.97 | 38.7K | 01:11:40 |  40.6%\n",
            "20320 | 4.4079 | 3.4e-04 | 0.98 | 38.7K | 01:11:41 |  40.6%\n",
            "20330 | 4.4807 | 3.4e-04 | 0.99 | 38.7K | 01:11:43 |  40.7%\n",
            "20340 | 4.6444 | 3.4e-04 | 0.95 | 38.7K | 01:11:45 |  40.7%\n",
            "20350 | 4.6618 | 3.4e-04 | 0.95 | 38.7K | 01:11:46 |  40.7%\n",
            "20360 | 4.6180 | 3.4e-04 | 0.98 | 38.7K | 01:11:48 |  40.7%\n",
            "20370 | 4.4944 | 3.4e-04 | 1.01 | 38.7K | 01:11:50 |  40.7%\n",
            "20380 | 4.2053 | 3.4e-04 | 0.97 | 38.7K | 01:11:52 |  40.8%\n",
            "20390 | 4.9442 | 3.4e-04 | 1.00 | 38.7K | 01:11:53 |  40.8%\n",
            "20400 | 4.7358 | 3.4e-04 | 1.04 | 38.7K | 01:11:55 |  40.8%\n",
            "20410 | 4.6043 | 3.4e-04 | 0.95 | 38.7K | 01:11:57 |  40.8%\n",
            "20420 | 4.4548 | 3.4e-04 | 1.02 | 38.7K | 01:11:58 |  40.8%\n",
            "20430 | 4.8124 | 3.4e-04 | 1.06 | 38.7K | 01:12:00 |  40.9%\n",
            "20440 | 4.5598 | 3.4e-04 | 0.98 | 38.7K | 01:12:02 |  40.9%\n",
            "20450 | 4.2559 | 3.4e-04 | 1.05 | 38.7K | 01:12:03 |  40.9%\n",
            "20460 | 4.6076 | 3.4e-04 | 0.95 | 38.7K | 01:12:05 |  40.9%\n",
            "20470 | 4.6086 | 3.4e-04 | 1.05 | 38.8K | 01:12:07 |  40.9%\n",
            "20480 | 4.6799 | 3.4e-04 | 0.97 | 38.8K | 01:12:09 |  41.0%\n",
            "20490 | 4.6034 | 3.4e-04 | 1.03 | 38.8K | 01:12:10 |  41.0%\n",
            "20500 | 4.6781 | 3.4e-04 | 0.97 | 38.8K | 01:12:12 |  41.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 20500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.5113\n",
            "  Perplexity: 91.04\n",
            "  Train loss (avg): 4.5553\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        durumu dün hava durumu ile dün hava durumu pek çok kişinin gözleriniÜlteledi. Bugün hava durumu bugün hava durumu yarın hava durumu ise hava durumu dün hava durumu bugün hava durumu bugün hava durumu yarın hava\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        ve dünyanın en büyük ikinci şehri, \"Çiftlik, Bin yılın yorgunluğu, yorgunluğu, yorgunluğu\" filmi  ⁇ Maçta huzur  ⁇ Türkiye'nin en büyük ikinci şehri,\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        günümüzde insanlar tarafından bile yapılmıyor. Fakat günümüzde bir çok teknolojik ve teknolojik gelişmelerin olduğu, sanal gerçekliklerin, teknolojik çözümlerin ve hatta yapay zeka teknolojisi ile yapay zekanın yaratıldığı bir sektör. Bu alanda\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.5113)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.71\n",
            "     ETA: 01:44:24\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "20510 | 4.3896 | 3.4e-04 | 1.20 | 38.6K | 01:12:35 |  41.0%\n",
            "20520 | 4.6140 | 3.4e-04 | 0.97 | 38.6K | 01:12:36 |  41.0%\n",
            "20530 | 4.7421 | 3.4e-04 | 0.96 | 38.6K | 01:12:38 |  41.1%\n",
            "20540 | 4.5875 | 3.4e-04 | 0.96 | 38.6K | 01:12:40 |  41.1%\n",
            "20550 | 4.3817 | 3.4e-04 | 2.50 | 38.6K | 01:12:41 |  41.1%\n",
            "20560 | 4.6000 | 3.4e-04 | 1.03 | 38.6K | 01:12:43 |  41.1%\n",
            "20570 | 4.6106 | 3.4e-04 | 1.00 | 38.6K | 01:12:45 |  41.1%\n",
            "20580 | 4.7316 | 3.4e-04 | 0.95 | 38.6K | 01:12:47 |  41.2%\n",
            "20590 | 4.0638 | 3.4e-04 | 0.97 | 38.6K | 01:12:48 |  41.2%\n",
            "20600 | 4.3662 | 3.4e-04 | 0.95 | 38.6K | 01:12:50 |  41.2%\n",
            "20610 | 4.3396 | 3.4e-04 | 1.10 | 38.6K | 01:12:52 |  41.2%\n",
            "20620 | 4.6885 | 3.4e-04 | 0.99 | 38.6K | 01:12:53 |  41.2%\n",
            "20630 | 4.2022 | 3.4e-04 | 1.05 | 38.6K | 01:12:55 |  41.3%\n",
            "20640 | 4.6061 | 3.4e-04 | 1.06 | 38.6K | 01:12:57 |  41.3%\n",
            "20650 | 4.2725 | 3.4e-04 | 0.95 | 38.6K | 01:12:59 |  41.3%\n",
            "20660 | 4.7255 | 3.4e-04 | 0.91 | 38.6K | 01:13:00 |  41.3%\n",
            "20670 | 4.7929 | 3.4e-04 | 0.97 | 38.6K | 01:13:02 |  41.3%\n",
            "20680 | 4.6056 | 3.4e-04 | 0.99 | 38.6K | 01:13:04 |  41.4%\n",
            "20690 | 4.6960 | 3.4e-04 | 0.99 | 38.6K | 01:13:05 |  41.4%\n",
            "20700 | 4.7162 | 3.4e-04 | 0.98 | 38.6K | 01:13:07 |  41.4%\n",
            "20710 | 4.6260 | 3.3e-04 | 0.99 | 38.7K | 01:13:09 |  41.4%\n",
            "20720 | 4.5498 | 3.3e-04 | 0.98 | 38.7K | 01:13:11 |  41.4%\n",
            "20730 | 4.6541 | 3.3e-04 | 0.94 | 38.7K | 01:13:12 |  41.5%\n",
            "20740 | 4.4854 | 3.3e-04 | 1.00 | 38.7K | 01:13:14 |  41.5%\n",
            "20750 | 4.4126 | 3.3e-04 | 0.98 | 38.7K | 01:13:16 |  41.5%\n",
            "20760 | 4.1545 | 3.3e-04 | 1.07 | 38.7K | 01:13:17 |  41.5%\n",
            "20770 | 4.6250 | 3.3e-04 | 1.19 | 38.7K | 01:13:19 |  41.5%\n",
            "20780 | 4.8035 | 3.3e-04 | 1.00 | 38.7K | 01:13:21 |  41.6%\n",
            "20790 | 4.5342 | 3.3e-04 | 1.02 | 38.7K | 01:13:22 |  41.6%\n",
            "20800 | 4.3573 | 3.3e-04 | 1.07 | 38.7K | 01:13:24 |  41.6%\n",
            "20810 | 4.5923 | 3.3e-04 | 0.95 | 38.7K | 01:13:26 |  41.6%\n",
            "20820 | 4.4790 | 3.3e-04 | 1.07 | 38.7K | 01:13:28 |  41.6%\n",
            "20830 | 4.8632 | 3.3e-04 | 0.97 | 38.7K | 01:13:29 |  41.7%\n",
            "20840 | 4.7784 | 3.3e-04 | 1.01 | 38.7K | 01:13:31 |  41.7%\n",
            "20850 | 4.6555 | 3.3e-04 | 0.94 | 38.7K | 01:13:33 |  41.7%\n",
            "20860 | 4.3265 | 3.3e-04 | 0.99 | 38.7K | 01:13:34 |  41.7%\n",
            "20870 | 4.5567 | 3.3e-04 | 0.99 | 38.7K | 01:13:36 |  41.7%\n",
            "20880 | 4.7013 | 3.3e-04 | 0.97 | 38.7K | 01:13:38 |  41.8%\n",
            "20890 | 4.6222 | 3.3e-04 | 0.98 | 38.7K | 01:13:40 |  41.8%\n",
            "20900 | 4.5546 | 3.3e-04 | 0.95 | 38.7K | 01:13:41 |  41.8%\n",
            "20910 | 4.5317 | 3.3e-04 | 0.96 | 38.7K | 01:13:43 |  41.8%\n",
            "20920 | 4.7360 | 3.3e-04 | 1.07 | 38.7K | 01:13:45 |  41.8%\n",
            "20930 | 4.4781 | 3.3e-04 | 1.02 | 38.7K | 01:13:46 |  41.9%\n",
            "20940 | 4.6105 | 3.3e-04 | 0.97 | 38.7K | 01:13:48 |  41.9%\n",
            "20950 | 4.6042 | 3.3e-04 | 0.95 | 38.7K | 01:13:50 |  41.9%\n",
            "20960 | 4.4934 | 3.3e-04 | 1.07 | 38.7K | 01:13:52 |  41.9%\n",
            "20970 | 4.2548 | 3.3e-04 | 1.02 | 38.7K | 01:13:53 |  41.9%\n",
            "20980 | 4.7149 | 3.3e-04 | 0.94 | 38.7K | 01:13:55 |  42.0%\n",
            "20990 | 4.3999 | 3.3e-04 | 0.97 | 38.8K | 01:13:57 |  42.0%\n",
            "21000 | 4.6515 | 3.3e-04 | 0.98 | 38.8K | 01:13:58 |  42.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 21000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.4997\n",
            "  Perplexity: 89.99\n",
            "  Train loss (avg): 4.5574\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        sıcaklığındaki yükselişte gerileyen yeni gelişmeler yeni nesil yeni nesilleri daha önceki nesillerin aksine daha çok beğeneceğini ve bunun daha verimli olacağını düşünüyor ve yeni nesilleri daha çok terk edeceğimizi vurgulamaya çalışıyor\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        New York'taki I. Travel Otel'de gerçekleştirilen yangın sonucu hayatını kaybetti. İzmir'in Aliağa ilçesinde bazı semtlerde yangın çıktı. Edinilen bilgilere göre, vatandaşlarımızın daha sonra alevler içinde\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        ile üretilen yapay zeka, çok amaçlı, özel olarak üretilen yapay zeka ile geliştirilen yapay zeka ürünü ile üretilen yapay zeka, bu özellikleri ile de zengin bir kitleye hitap eden yapay zeka ve yapay zeka, bu özelliği\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.4997)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.71\n",
            "     ETA: 01:42:38\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "21010 | 4.5661 | 3.3e-04 | 1.02 | 38.6K | 01:14:21 |  42.0%\n",
            "21020 | 4.4187 | 3.3e-04 | 0.99 | 38.6K | 01:14:23 |  42.0%\n",
            "21030 | 4.6430 | 3.3e-04 | 0.96 | 38.6K | 01:14:24 |  42.1%\n",
            "21040 | 4.6827 | 3.3e-04 | 0.98 | 38.6K | 01:14:26 |  42.1%\n",
            "21050 | 4.5672 | 3.3e-04 | 0.99 | 38.6K | 01:14:28 |  42.1%\n",
            "21060 | 4.2675 | 3.3e-04 | 0.98 | 38.6K | 01:14:29 |  42.1%\n",
            "21070 | 4.4301 | 3.3e-04 | 1.03 | 38.6K | 01:14:31 |  42.1%\n",
            "21080 | 4.4418 | 3.3e-04 | 1.03 | 38.6K | 01:14:33 |  42.2%\n",
            "21090 | 4.5036 | 3.3e-04 | 0.99 | 38.6K | 01:14:35 |  42.2%\n",
            "21100 | 4.6554 | 3.3e-04 | 1.00 | 38.6K | 01:14:36 |  42.2%\n",
            "21110 | 4.4735 | 3.3e-04 | 0.98 | 38.6K | 01:14:38 |  42.2%\n",
            "21120 | 4.4373 | 3.3e-04 | 0.97 | 38.6K | 01:14:40 |  42.2%\n",
            "21130 | 4.4701 | 3.3e-04 | 0.96 | 38.6K | 01:14:41 |  42.3%\n",
            "21140 | 4.0759 | 3.3e-04 | 1.07 | 38.6K | 01:14:43 |  42.3%\n",
            "21150 | 4.4342 | 3.3e-04 | 1.03 | 38.6K | 01:14:45 |  42.3%\n",
            "21160 | 4.4433 | 3.3e-04 | 0.99 | 38.6K | 01:14:47 |  42.3%\n",
            "21170 | 4.7297 | 3.3e-04 | 0.96 | 38.6K | 01:14:48 |  42.3%\n",
            "21180 | 4.4641 | 3.3e-04 | 1.01 | 38.6K | 01:14:50 |  42.4%\n",
            "21190 | 4.6284 | 3.3e-04 | 1.03 | 38.6K | 01:14:52 |  42.4%\n",
            "21200 | 4.5812 | 3.3e-04 | 0.98 | 38.6K | 01:14:53 |  42.4%\n",
            "21210 | 4.6084 | 3.3e-04 | 1.05 | 38.6K | 01:14:55 |  42.4%\n",
            "21220 | 4.5248 | 3.3e-04 | 0.96 | 38.7K | 01:14:57 |  42.4%\n",
            "21230 | 4.6283 | 3.3e-04 | 1.01 | 38.7K | 01:14:59 |  42.5%\n",
            "21240 | 4.5278 | 3.3e-04 | 0.98 | 38.7K | 01:15:00 |  42.5%\n",
            "21250 | 4.4860 | 3.3e-04 | 1.02 | 38.7K | 01:15:02 |  42.5%\n",
            "21260 | 4.5968 | 3.3e-04 | 1.02 | 38.7K | 01:15:04 |  42.5%\n",
            "21270 | 4.3093 | 3.3e-04 | 1.05 | 38.7K | 01:15:05 |  42.5%\n",
            "21280 | 4.6974 | 3.3e-04 | 0.96 | 38.7K | 01:15:07 |  42.6%\n",
            "21290 | 4.5978 | 3.3e-04 | 0.95 | 38.7K | 01:15:09 |  42.6%\n",
            "21300 | 4.4728 | 3.3e-04 | 1.00 | 38.7K | 01:15:11 |  42.6%\n",
            "21310 | 4.6121 | 3.3e-04 | 1.01 | 38.7K | 01:15:12 |  42.6%\n",
            "21320 | 4.5909 | 3.3e-04 | 0.96 | 38.7K | 01:15:14 |  42.6%\n",
            "21330 | 4.7977 | 3.3e-04 | 0.99 | 38.7K | 01:15:16 |  42.7%\n",
            "21340 | 4.6734 | 3.3e-04 | 0.97 | 38.7K | 01:15:17 |  42.7%\n",
            "21350 | 4.4204 | 3.2e-04 | 0.98 | 38.7K | 01:15:19 |  42.7%\n",
            "21360 | 4.7178 | 3.2e-04 | 0.97 | 38.7K | 01:15:21 |  42.7%\n",
            "21370 | 4.3604 | 3.2e-04 | 1.00 | 38.7K | 01:15:23 |  42.7%\n",
            "21380 | 4.6598 | 3.2e-04 | 1.01 | 38.7K | 01:15:24 |  42.8%\n",
            "21390 | 4.4545 | 3.2e-04 | 1.02 | 38.7K | 01:15:26 |  42.8%\n",
            "21400 | 4.6657 | 3.2e-04 | 1.03 | 38.7K | 01:15:28 |  42.8%\n",
            "21410 | 4.7002 | 3.2e-04 | 0.97 | 38.7K | 01:15:29 |  42.8%\n",
            "21420 | 4.5741 | 3.2e-04 | 1.00 | 38.7K | 01:15:31 |  42.8%\n",
            "21430 | 4.4913 | 3.2e-04 | 0.96 | 38.7K | 01:15:33 |  42.9%\n",
            "21440 | 4.4138 | 3.2e-04 | 1.00 | 38.7K | 01:15:35 |  42.9%\n",
            "21450 | 4.7303 | 3.2e-04 | 0.96 | 38.7K | 01:15:36 |  42.9%\n",
            "21460 | 4.4514 | 3.2e-04 | 0.99 | 38.7K | 01:15:38 |  42.9%\n",
            "21470 | 4.3757 | 3.2e-04 | 1.04 | 38.7K | 01:15:40 |  42.9%\n",
            "21480 | 4.6076 | 3.2e-04 | 0.99 | 38.7K | 01:15:41 |  43.0%\n",
            "21490 | 4.5434 | 3.2e-04 | 0.98 | 38.7K | 01:15:43 |  43.0%\n",
            "21500 | 4.4512 | 3.2e-04 | 1.02 | 38.7K | 01:15:45 |  43.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 21500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.5129\n",
            "  Perplexity: 91.18\n",
            "  Train loss (avg): 4.5467\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        şartları ve hava durumu nedir? İnsan kaynakları yeterli düzeyde, her konuda yeterli bilgiye sahip değil, her zaman gerekli bilgileri veren bir kurumdur. Bu kurum; hem belli bir süre içinde, hem de bu süre\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        İstanbul'un sahilinden geçen ve dünyanın en büyük liman kenti olan Hadrianen, dünyanın en büyük liman kentidir. İstanbul'da Türkiye'nin en büyük liman kenti olan İstanbul'da şehrin en\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , davranışlarımıza özel bir yazılım geliştirmiştir. Hemen hemen her şeyi etkileyen ve olağanüstü bir işlem olan, temel olarak, o kadar çok şey üreten ve olmayan, o kadar çok şey öğreten bir yazılım geliştirmiştir\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.71\n",
            "     ETA: 01:40:48\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "21510 | 4.4039 | 3.2e-04 | 0.98 | 38.6K | 01:16:04 |  43.0%\n",
            "21520 | 4.7239 | 3.2e-04 | 0.97 | 38.6K | 01:16:06 |  43.0%\n",
            "21530 | 4.5021 | 3.2e-04 | 0.98 | 38.6K | 01:16:07 |  43.1%\n",
            "21540 | 4.3593 | 3.2e-04 | 1.01 | 38.6K | 01:16:09 |  43.1%\n",
            "21550 | 4.4262 | 3.2e-04 | 1.02 | 38.6K | 01:16:11 |  43.1%\n",
            "21560 | 4.5017 | 3.2e-04 | 0.99 | 38.6K | 01:16:12 |  43.1%\n",
            "21570 | 4.6788 | 3.2e-04 | 1.04 | 38.6K | 01:16:14 |  43.1%\n",
            "21580 | 4.5604 | 3.2e-04 | 1.00 | 38.6K | 01:16:16 |  43.2%\n",
            "21590 | 4.2296 | 3.2e-04 | 1.09 | 38.6K | 01:16:18 |  43.2%\n",
            "21600 | 4.4986 | 3.2e-04 | 0.99 | 38.6K | 01:16:19 |  43.2%\n",
            "21610 | 4.6355 | 3.2e-04 | 0.98 | 38.6K | 01:16:21 |  43.2%\n",
            "21620 | 4.4716 | 3.2e-04 | 1.04 | 38.6K | 01:16:23 |  43.2%\n",
            "21630 | 4.5037 | 3.2e-04 | 0.97 | 38.6K | 01:16:24 |  43.3%\n",
            "21640 | 4.3690 | 3.2e-04 | 1.02 | 38.7K | 01:16:26 |  43.3%\n",
            "21650 | 3.8976 | 3.2e-04 | 1.18 | 38.7K | 01:16:28 |  43.3%\n",
            "21660 | 4.4802 | 3.2e-04 | 0.96 | 38.7K | 01:16:30 |  43.3%\n",
            "21670 | 4.5901 | 3.2e-04 | 1.01 | 38.7K | 01:16:31 |  43.3%\n",
            "21680 | 4.6720 | 3.2e-04 | 1.00 | 38.7K | 01:16:33 |  43.4%\n",
            "21690 | 4.4542 | 3.2e-04 | 0.99 | 38.7K | 01:16:35 |  43.4%\n",
            "21700 | 4.3267 | 3.2e-04 | 1.03 | 38.7K | 01:16:36 |  43.4%\n",
            "21710 | 4.4819 | 3.2e-04 | 0.98 | 38.7K | 01:16:38 |  43.4%\n",
            "21720 | 4.7197 | 3.2e-04 | 1.00 | 38.7K | 01:16:40 |  43.4%\n",
            "21730 | 4.7587 | 3.2e-04 | 0.98 | 38.7K | 01:16:42 |  43.5%\n",
            "21740 | 4.6447 | 3.2e-04 | 1.04 | 38.7K | 01:16:43 |  43.5%\n",
            "21750 | 4.5184 | 3.2e-04 | 0.98 | 38.7K | 01:16:45 |  43.5%\n",
            "21760 | 4.6379 | 3.2e-04 | 1.07 | 38.7K | 01:16:47 |  43.5%\n",
            "21770 | 4.2771 | 3.2e-04 | 1.00 | 38.7K | 01:16:48 |  43.5%\n",
            "21780 | 4.4412 | 3.2e-04 | 1.05 | 38.7K | 01:16:50 |  43.6%\n",
            "21790 | 4.5610 | 3.2e-04 | 0.96 | 38.7K | 01:16:52 |  43.6%\n",
            "21800 | 4.5621 | 3.2e-04 | 0.99 | 38.7K | 01:16:54 |  43.6%\n",
            "21810 | 4.3961 | 3.2e-04 | 0.98 | 38.7K | 01:16:55 |  43.6%\n",
            "21820 | 4.6786 | 3.2e-04 | 0.98 | 38.7K | 01:16:57 |  43.6%\n",
            "21830 | 4.5236 | 3.2e-04 | 0.98 | 38.7K | 01:16:59 |  43.7%\n",
            "21840 | 4.5061 | 3.2e-04 | 1.00 | 38.7K | 01:17:00 |  43.7%\n",
            "21850 | 4.8195 | 3.2e-04 | 1.12 | 38.7K | 01:17:02 |  43.7%\n",
            "21860 | 4.7018 | 3.2e-04 | 0.99 | 38.7K | 01:17:04 |  43.7%\n",
            "21870 | 4.3978 | 3.2e-04 | 1.05 | 38.7K | 01:17:06 |  43.7%\n",
            "21880 | 4.6047 | 3.2e-04 | 1.01 | 38.7K | 01:17:07 |  43.8%\n",
            "21890 | 4.4518 | 3.2e-04 | 1.00 | 38.7K | 01:17:09 |  43.8%\n",
            "21900 | 4.6375 | 3.2e-04 | 0.95 | 38.7K | 01:17:11 |  43.8%\n",
            "21910 | 4.8322 | 3.2e-04 | 1.01 | 38.7K | 01:17:12 |  43.8%\n",
            "21920 | 4.2896 | 3.2e-04 | 0.96 | 38.7K | 01:17:14 |  43.8%\n",
            "21930 | 4.7722 | 3.2e-04 | 0.98 | 38.7K | 01:17:16 |  43.9%\n",
            "21940 | 4.4713 | 3.2e-04 | 0.99 | 38.8K | 01:17:17 |  43.9%\n",
            "21950 | 4.6905 | 3.2e-04 | 0.99 | 38.8K | 01:17:19 |  43.9%\n",
            "21960 | 4.7141 | 3.2e-04 | 0.98 | 38.8K | 01:17:21 |  43.9%\n",
            "21970 | 4.5670 | 3.2e-04 | 1.00 | 38.8K | 01:17:23 |  43.9%\n",
            "21980 | 4.4648 | 3.2e-04 | 0.99 | 38.8K | 01:17:24 |  44.0%\n",
            "21990 | 4.4843 | 3.1e-04 | 0.97 | 38.8K | 01:17:26 |  44.0%\n",
            "22000 | 4.6575 | 3.1e-04 | 1.02 | 38.8K | 01:17:28 |  44.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 22000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.5107\n",
            "  Perplexity: 90.99\n",
            "  Train loss (avg): 4.5226\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        , bir buçuk saat sürüyor. Hava hem de gece sıcaklıklarıyla birlikte bu güneşin ısınmasını zorlaştırıyor. Hava, rüzgar ve rüzgar gibi olumsuz hava koşulları sebebiyle de bu rüzgarın aşırı sıcak olduğunu gösteriyor. Öyle\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        İstanbul'da, bölgede ikamet eden yaklaşık 8 bin kişi yakalandı. A tipi 'Teknik Yapı'nın eylem alanı yaklaşık 10 bin kişilik grup tarafından saniye saniye saniye saniye saniye saniye kaydedildi. Türkiye'de\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        sayesinde öğrenme ve öğrenme ile ilgili bilgi sahibi olabilmenin sadece temel bir bilgiden ibaret olmadığını anlatan beyaz yakalı, bilgi, tutum, zeka, tutum, zihin ve mantık kavramlarını inceleyen bilim dalıdır\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:38:57\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "22010 | 4.6644 | 3.1e-04 | 0.99 | 38.6K | 01:17:47 |  44.0%\n",
            "22020 | 4.5621 | 3.1e-04 | 0.98 | 38.6K | 01:17:48 |  44.0%\n",
            "22030 | 4.4441 | 3.1e-04 | 1.03 | 38.6K | 01:17:50 |  44.1%\n",
            "22040 | 4.4347 | 3.1e-04 | 1.07 | 38.6K | 01:17:52 |  44.1%\n",
            "22050 | 4.6236 | 3.1e-04 | 0.98 | 38.6K | 01:17:54 |  44.1%\n",
            "22060 | 4.4621 | 3.1e-04 | 0.98 | 38.6K | 01:17:55 |  44.1%\n",
            "22070 | 4.2572 | 3.1e-04 | 1.07 | 38.7K | 01:17:57 |  44.1%\n",
            "22080 | 4.5890 | 3.1e-04 | 0.98 | 38.7K | 01:17:59 |  44.2%\n",
            "22090 | 4.5005 | 3.1e-04 | 0.97 | 38.7K | 01:18:00 |  44.2%\n",
            "22100 | 4.3961 | 3.1e-04 | 0.98 | 38.7K | 01:18:02 |  44.2%\n",
            "22110 | 4.3063 | 3.1e-04 | 0.96 | 38.7K | 01:18:04 |  44.2%\n",
            "22120 | 4.3368 | 3.1e-04 | 0.95 | 38.7K | 01:18:06 |  44.2%\n",
            "22130 | 4.7251 | 3.1e-04 | 1.03 | 38.7K | 01:18:07 |  44.3%\n",
            "22140 | 4.6588 | 3.1e-04 | 1.04 | 38.7K | 01:18:09 |  44.3%\n",
            "22150 | 4.7971 | 3.1e-04 | 1.00 | 38.7K | 01:18:11 |  44.3%\n",
            "22160 | 4.7030 | 3.1e-04 | 1.00 | 38.7K | 01:18:12 |  44.3%\n",
            "22170 | 4.6545 | 3.1e-04 | 0.98 | 38.7K | 01:18:14 |  44.3%\n",
            "22180 | 4.5396 | 3.1e-04 | 1.03 | 38.7K | 01:18:16 |  44.4%\n",
            "22190 | 4.4650 | 3.1e-04 | 1.08 | 38.7K | 01:18:18 |  44.4%\n",
            "22200 | 4.5378 | 3.1e-04 | 1.00 | 38.7K | 01:18:19 |  44.4%\n",
            "22210 | 4.3874 | 3.1e-04 | 1.01 | 38.7K | 01:18:21 |  44.4%\n",
            "22220 | 4.4248 | 3.1e-04 | 0.98 | 38.7K | 01:18:23 |  44.4%\n",
            "22230 | 4.1069 | 3.1e-04 | 1.06 | 38.7K | 01:18:24 |  44.5%\n",
            "22240 | 4.4247 | 3.1e-04 | 1.02 | 38.7K | 01:18:26 |  44.5%\n",
            "22250 | 4.6458 | 3.1e-04 | 0.98 | 38.7K | 01:18:28 |  44.5%\n",
            "22260 | 4.5328 | 3.1e-04 | 0.97 | 38.7K | 01:18:30 |  44.5%\n",
            "22270 | 4.6554 | 3.1e-04 | 1.07 | 38.7K | 01:18:31 |  44.5%\n",
            "22280 | 4.2987 | 3.1e-04 | 1.12 | 38.7K | 01:18:33 |  44.6%\n",
            "22290 | 4.4320 | 3.1e-04 | 1.00 | 38.7K | 01:18:35 |  44.6%\n",
            "22300 | 4.5617 | 3.1e-04 | 0.99 | 38.7K | 01:18:36 |  44.6%\n",
            "22310 | 4.5615 | 3.1e-04 | 0.99 | 38.7K | 01:18:38 |  44.6%\n",
            "22320 | 4.1275 | 3.1e-04 | 1.11 | 38.7K | 01:18:40 |  44.6%\n",
            "22330 | 4.7548 | 3.1e-04 | 1.02 | 38.7K | 01:18:42 |  44.7%\n",
            "22340 | 4.6639 | 3.1e-04 | 1.02 | 38.7K | 01:18:43 |  44.7%\n",
            "22350 | 4.5293 | 3.1e-04 | 1.01 | 38.7K | 01:18:45 |  44.7%\n",
            "22360 | 4.3343 | 3.1e-04 | 1.13 | 38.7K | 01:18:47 |  44.7%\n",
            "22370 | 4.5190 | 3.1e-04 | 0.98 | 38.8K | 01:18:48 |  44.7%\n",
            "22380 | 4.7005 | 3.1e-04 | 1.04 | 38.8K | 01:18:50 |  44.8%\n",
            "22390 | 4.4652 | 3.1e-04 | 1.00 | 38.8K | 01:18:52 |  44.8%\n",
            "22400 | 4.6717 | 3.1e-04 | 1.02 | 38.8K | 01:18:54 |  44.8%\n",
            "22410 | 4.3147 | 3.1e-04 | 0.98 | 38.8K | 01:18:55 |  44.8%\n",
            "22420 | 4.2634 | 3.1e-04 | 1.06 | 38.8K | 01:18:57 |  44.8%\n",
            "22430 | 4.4512 | 3.1e-04 | 1.01 | 38.8K | 01:18:59 |  44.9%\n",
            "22440 | 4.8528 | 3.1e-04 | 0.99 | 38.8K | 01:19:00 |  44.9%\n",
            "22450 | 4.4052 | 3.1e-04 | 1.00 | 38.8K | 01:19:02 |  44.9%\n",
            "22460 | 4.2086 | 3.1e-04 | 1.19 | 38.8K | 01:19:04 |  44.9%\n",
            "22470 | 4.3965 | 3.1e-04 | 0.99 | 38.8K | 01:19:06 |  44.9%\n",
            "22480 | 4.7352 | 3.1e-04 | 1.04 | 38.8K | 01:19:07 |  45.0%\n",
            "22490 | 4.5043 | 3.1e-04 | 1.03 | 38.8K | 01:19:09 |  45.0%\n",
            "22500 | 4.3546 | 3.1e-04 | 0.99 | 38.8K | 01:19:11 |  45.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 22500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.4843\n",
            "  Perplexity: 88.62\n",
            "  Train loss (avg): 4.5274\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        durumu da çok normal. Tabii ben de bu durumu daha çok anlıyorum. Bu, insanların yaşadığı durumu da yok. Şu anda durum çok farklı. Ama hava durumu pek öyle. Biz hava durumunu ne zaman göster\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Moskova'da yaşanan FETÖ/PDY operasyonunda teröristlere yönelik saldırılarda 23 kişi tutuklandı. Terör örgütü DEAŞ'ın adını taşıyan bir örgütten terör örgütü tarafından kabul edilen 6 kişi tutuklandı. Yapılan açıklamada,\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        tarafından geliştirilen sistemlerde yapay zekanın nasıl yapılacağına dair yeni bir imkanın ortaya çıkması için bu sistemlerde de hem yapay zeka hem de yapay zekanın nasıl kullanılacağına dair bir yenilik yer alıyor\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.4843)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:37:12\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "22510 | 4.5615 | 3.1e-04 | 1.00 | 38.6K | 01:19:33 |  45.0%\n",
            "22520 | 4.4360 | 3.1e-04 | 1.03 | 38.6K | 01:19:35 |  45.0%\n",
            "22530 | 4.7707 | 3.1e-04 | 1.01 | 38.6K | 01:19:37 |  45.1%\n",
            "22540 | 4.7901 | 3.1e-04 | 1.04 | 38.6K | 01:19:38 |  45.1%\n",
            "22550 | 4.6003 | 3.1e-04 | 0.97 | 38.6K | 01:19:40 |  45.1%\n",
            "22560 | 4.7267 | 3.1e-04 | 1.16 | 38.6K | 01:19:42 |  45.1%\n",
            "22570 | 4.1256 | 3.1e-04 | 1.05 | 38.6K | 01:19:43 |  45.1%\n",
            "22580 | 4.4633 | 3.1e-04 | 1.07 | 38.7K | 01:19:45 |  45.2%\n",
            "22590 | 4.2776 | 3.1e-04 | 1.04 | 38.7K | 01:19:47 |  45.2%\n",
            "22600 | 4.3801 | 3.1e-04 | 1.10 | 38.7K | 01:19:48 |  45.2%\n",
            "22610 | 4.6694 | 3.1e-04 | 1.03 | 38.7K | 01:19:50 |  45.2%\n",
            "22620 | 4.5465 | 3.0e-04 | 0.96 | 38.7K | 01:19:52 |  45.2%\n",
            "22630 | 4.1129 | 3.0e-04 | 1.08 | 38.7K | 01:19:54 |  45.3%\n",
            "22640 | 4.3767 | 3.0e-04 | 1.01 | 38.7K | 01:19:55 |  45.3%\n",
            "22650 | 4.5315 | 3.0e-04 | 1.01 | 38.7K | 01:19:57 |  45.3%\n",
            "22660 | 4.3745 | 3.0e-04 | 1.01 | 38.7K | 01:19:59 |  45.3%\n",
            "22670 | 4.2831 | 3.0e-04 | 1.01 | 38.7K | 01:20:00 |  45.3%\n",
            "22680 | 4.2973 | 3.0e-04 | 1.03 | 38.7K | 01:20:02 |  45.4%\n",
            "22690 | 4.5686 | 3.0e-04 | 0.99 | 38.7K | 01:20:04 |  45.4%\n",
            "22700 | 4.6905 | 3.0e-04 | 1.01 | 38.7K | 01:20:06 |  45.4%\n",
            "22710 | 4.1478 | 3.0e-04 | 1.11 | 38.7K | 01:20:07 |  45.4%\n",
            "22720 | 4.4931 | 3.0e-04 | 1.08 | 38.7K | 01:20:09 |  45.4%\n",
            "22730 | 4.5319 | 3.0e-04 | 0.99 | 38.7K | 01:20:11 |  45.5%\n",
            "22740 | 4.4981 | 3.0e-04 | 1.04 | 38.7K | 01:20:12 |  45.5%\n",
            "22750 | 4.5814 | 3.0e-04 | 1.05 | 38.7K | 01:20:14 |  45.5%\n",
            "22760 | 4.4826 | 3.0e-04 | 1.03 | 38.7K | 01:20:16 |  45.5%\n",
            "22770 | 4.7564 | 3.0e-04 | 0.99 | 38.7K | 01:20:18 |  45.5%\n",
            "22780 | 4.1194 | 3.0e-04 | 1.09 | 38.7K | 01:20:19 |  45.6%\n",
            "22790 | 4.5280 | 3.0e-04 | 0.98 | 38.7K | 01:20:21 |  45.6%\n",
            "22800 | 4.7264 | 3.0e-04 | 1.02 | 38.7K | 01:20:23 |  45.6%\n",
            "22810 | 4.4410 | 3.0e-04 | 1.04 | 38.7K | 01:20:24 |  45.6%\n",
            "22820 | 4.6758 | 3.0e-04 | 1.04 | 38.7K | 01:20:26 |  45.6%\n",
            "22830 | 4.6442 | 3.0e-04 | 1.01 | 38.7K | 01:20:28 |  45.7%\n",
            "22840 | 4.4499 | 3.0e-04 | 0.96 | 38.7K | 01:20:30 |  45.7%\n",
            "22850 | 4.2486 | 3.0e-04 | 1.00 | 38.7K | 01:20:31 |  45.7%\n",
            "22860 | 4.4014 | 3.0e-04 | 1.08 | 38.7K | 01:20:33 |  45.7%\n",
            "22870 | 4.5804 | 3.0e-04 | 0.98 | 38.7K | 01:20:35 |  45.7%\n",
            "22880 | 4.2613 | 3.0e-04 | 1.24 | 38.8K | 01:20:36 |  45.8%\n",
            "22890 | 4.4105 | 3.0e-04 | 1.08 | 38.8K | 01:20:38 |  45.8%\n",
            "22900 | 4.6678 | 3.0e-04 | 0.99 | 38.8K | 01:20:40 |  45.8%\n",
            "22910 | 4.0939 | 3.0e-04 | 1.03 | 38.8K | 01:20:42 |  45.8%\n",
            "22920 | 4.5444 | 3.0e-04 | 1.02 | 38.8K | 01:20:43 |  45.8%\n",
            "22930 | 4.3661 | 3.0e-04 | 1.02 | 38.8K | 01:20:45 |  45.9%\n",
            "22940 | 4.6095 | 3.0e-04 | 1.03 | 38.8K | 01:20:47 |  45.9%\n",
            "22950 | 4.6091 | 3.0e-04 | 1.47 | 38.8K | 01:20:48 |  45.9%\n",
            "22960 | 4.3832 | 3.0e-04 | 1.05 | 38.8K | 01:20:50 |  45.9%\n",
            "22970 | 4.2990 | 3.0e-04 | 1.01 | 38.8K | 01:20:52 |  45.9%\n",
            "22980 | 4.4604 | 3.0e-04 | 1.01 | 38.8K | 01:20:54 |  46.0%\n",
            "22990 | 4.2479 | 3.0e-04 | 1.02 | 38.8K | 01:20:55 |  46.0%\n",
            "23000 | 4.5342 | 3.0e-04 | 1.01 | 38.8K | 01:20:57 |  46.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 23000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.4371\n",
            "  Perplexity: 84.53\n",
            "  Train loss (avg): 4.5009\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        ısısı aşırı derecede göz göre 1.3.5 derece ila 1.9 derece arasında olacak. Bu arada hava, hava, hava ve hava saatlerinden dolayı daha fazla yağış bekleyebilir. Bunlar ise aşırı soğuktan\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Berlin'de yer alan ve Avrupa'nın en güzel şehirlerinden biri olan Berlin'de gezilecek pek çok yer var. Bu bölgeler en yakın olan şehirlerden olan Berlin'de, dünyanın en eski şehirlerinden biri\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , bu teknolojinin kullanımıyla ilgili daha detaylı bilgi edinmenizi sağlar. Bir ya da birkaç farklı akıllı teknoloji, özellikle Google tarafından yapılan bir araştırmaya göre, bir buluşun görevi, kurumdaki bir kurum veya bir\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.4371)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.71\n",
            "     ETA: 01:35:27\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "23010 | 4.6099 | 3.0e-04 | 0.97 | 38.6K | 01:21:20 |  46.0%\n",
            "23020 | 4.4063 | 3.0e-04 | 0.98 | 38.6K | 01:21:22 |  46.0%\n",
            "23030 | 4.5337 | 3.0e-04 | 1.07 | 38.6K | 01:21:23 |  46.1%\n",
            "23040 | 4.5382 | 3.0e-04 | 1.03 | 38.6K | 01:21:25 |  46.1%\n",
            "23050 | 4.6946 | 3.0e-04 | 1.02 | 38.6K | 01:21:27 |  46.1%\n",
            "23060 | 4.5823 | 3.0e-04 | 0.99 | 38.6K | 01:21:28 |  46.1%\n",
            "23070 | 4.5804 | 3.0e-04 | 1.04 | 38.6K | 01:21:30 |  46.1%\n",
            "23080 | 4.5364 | 3.0e-04 | 1.00 | 38.6K | 01:21:32 |  46.2%\n",
            "23090 | 4.6414 | 3.0e-04 | 1.02 | 38.6K | 01:21:34 |  46.2%\n",
            "23100 | 4.6109 | 3.0e-04 | 1.02 | 38.7K | 01:21:35 |  46.2%\n",
            "23110 | 4.5849 | 3.0e-04 | 1.03 | 38.7K | 01:21:37 |  46.2%\n",
            "23120 | 4.4431 | 3.0e-04 | 1.03 | 38.7K | 01:21:39 |  46.2%\n",
            "23130 | 4.5775 | 3.0e-04 | 1.08 | 38.7K | 01:21:40 |  46.3%\n",
            "23140 | 4.3705 | 3.0e-04 | 1.01 | 38.7K | 01:21:42 |  46.3%\n",
            "23150 | 4.5854 | 3.0e-04 | 1.02 | 38.7K | 01:21:44 |  46.3%\n",
            "23160 | 4.5075 | 3.0e-04 | 1.06 | 38.7K | 01:21:46 |  46.3%\n",
            "23170 | 4.4076 | 3.0e-04 | 1.04 | 38.7K | 01:21:47 |  46.3%\n",
            "23180 | 4.6966 | 3.0e-04 | 1.02 | 38.7K | 01:21:49 |  46.4%\n",
            "23190 | 4.4033 | 3.0e-04 | 1.01 | 38.7K | 01:21:51 |  46.4%\n",
            "23200 | 4.3786 | 3.0e-04 | 1.04 | 38.7K | 01:21:52 |  46.4%\n",
            "23210 | 4.6046 | 3.0e-04 | 1.00 | 38.7K | 01:21:54 |  46.4%\n",
            "23220 | 4.7823 | 3.0e-04 | 0.99 | 38.7K | 01:21:56 |  46.4%\n",
            "23230 | 4.5375 | 3.0e-04 | 1.01 | 38.7K | 01:21:58 |  46.5%\n",
            "23240 | 4.5984 | 2.9e-04 | 1.04 | 38.7K | 01:21:59 |  46.5%\n",
            "23250 | 4.2991 | 2.9e-04 | 1.06 | 38.7K | 01:22:01 |  46.5%\n",
            "23260 | 4.3426 | 2.9e-04 | 1.01 | 38.7K | 01:22:03 |  46.5%\n",
            "23270 | 4.1829 | 2.9e-04 | 1.13 | 38.7K | 01:22:04 |  46.5%\n",
            "23280 | 4.2124 | 2.9e-04 | 1.36 | 38.7K | 01:22:06 |  46.6%\n",
            "23290 | 4.2711 | 2.9e-04 | 0.98 | 38.7K | 01:22:08 |  46.6%\n",
            "23300 | 4.0095 | 2.9e-04 | 1.07 | 38.7K | 01:22:10 |  46.6%\n",
            "23310 | 4.4617 | 2.9e-04 | 0.99 | 38.7K | 01:22:11 |  46.6%\n",
            "23320 | 4.3148 | 2.9e-04 | 1.00 | 38.7K | 01:22:13 |  46.6%\n",
            "23330 | 4.4736 | 2.9e-04 | 1.00 | 38.7K | 01:22:15 |  46.7%\n",
            "23340 | 4.3537 | 2.9e-04 | 1.07 | 38.7K | 01:22:16 |  46.7%\n",
            "23350 | 4.6219 | 2.9e-04 | 1.00 | 38.7K | 01:22:18 |  46.7%\n",
            "23360 | 4.1893 | 2.9e-04 | 1.04 | 38.7K | 01:22:20 |  46.7%\n",
            "23370 | 4.5297 | 2.9e-04 | 1.07 | 38.7K | 01:22:21 |  46.7%\n",
            "23380 | 4.7370 | 2.9e-04 | 1.06 | 38.7K | 01:22:23 |  46.8%\n",
            "23390 | 4.4672 | 2.9e-04 | 1.06 | 38.7K | 01:22:25 |  46.8%\n",
            "23400 | 4.4162 | 2.9e-04 | 1.75 | 38.7K | 01:22:27 |  46.8%\n",
            "23410 | 4.4508 | 2.9e-04 | 1.08 | 38.8K | 01:22:28 |  46.8%\n",
            "23420 | 4.4790 | 2.9e-04 | 1.02 | 38.8K | 01:22:30 |  46.8%\n",
            "23430 | 4.5595 | 2.9e-04 | 1.02 | 38.8K | 01:22:32 |  46.9%\n",
            "23440 | 4.4615 | 2.9e-04 | 0.99 | 38.8K | 01:22:33 |  46.9%\n",
            "23450 | 4.4921 | 2.9e-04 | 1.00 | 38.8K | 01:22:35 |  46.9%\n",
            "23460 | 4.4637 | 2.9e-04 | 1.02 | 38.8K | 01:22:37 |  46.9%\n",
            "23470 | 4.4828 | 2.9e-04 | 0.99 | 38.8K | 01:22:39 |  46.9%\n",
            "23480 | 4.3647 | 2.9e-04 | 1.01 | 38.8K | 01:22:40 |  47.0%\n",
            "23490 | 4.3361 | 2.9e-04 | 1.10 | 38.8K | 01:22:42 |  47.0%\n",
            "23500 | 4.4267 | 2.9e-04 | 0.97 | 38.8K | 01:22:44 |  47.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 23500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.4759\n",
            "  Perplexity: 87.88\n",
            "  Train loss (avg): 4.5152\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        ların soğuk olmasına rağmen kar, yaz aylarında kar yağıyor. Ancak kar yağışı ile birlikte kar yağıyor. Kar yağışı ise kar yağışı için kar yağdı. Kar yağışı bu kadar etkili olmazken kar yağışı\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Ankara'da yapılan bir konuşmada, Ankara'da yapılan bir konuşmada, “Bunu ben asla kabul edemem” dedi. Bu açıklama, Ankara'da yapılan bir konuşmada, “Bizim başkent Ankara'da da\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        (M2, 3M2, 3M2, 3M2, 3M2, 3M2, 3M2, 4M2, 2M2, 3M2, 3M2, 3M2, 3M2, 2\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:33:37\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "23510 | 4.1628 | 2.9e-04 | 1.04 | 38.6K | 01:23:03 |  47.0%\n",
            "23520 | 4.4317 | 2.9e-04 | 1.05 | 38.7K | 01:23:04 |  47.0%\n",
            "23530 | 4.3081 | 2.9e-04 | 1.01 | 38.7K | 01:23:06 |  47.1%\n",
            "23540 | 4.5684 | 2.9e-04 | 1.04 | 38.7K | 01:23:08 |  47.1%\n",
            "23550 | 4.4366 | 2.9e-04 | 1.02 | 38.7K | 01:23:10 |  47.1%\n",
            "23560 | 4.4734 | 2.9e-04 | 1.00 | 38.7K | 01:23:11 |  47.1%\n",
            "23570 | 4.4544 | 2.9e-04 | 1.04 | 38.7K | 01:23:13 |  47.1%\n",
            "23580 | 4.6047 | 2.9e-04 | 1.07 | 38.7K | 01:23:15 |  47.2%\n",
            "23590 | 4.7487 | 2.9e-04 | 1.03 | 38.7K | 01:23:16 |  47.2%\n",
            "23600 | 4.5682 | 2.9e-04 | 0.99 | 38.7K | 01:23:18 |  47.2%\n",
            "23610 | 4.3364 | 2.9e-04 | 1.05 | 38.7K | 01:23:20 |  47.2%\n",
            "23620 | 4.5460 | 2.9e-04 | 0.98 | 38.7K | 01:23:22 |  47.2%\n",
            "23630 | 4.5816 | 2.9e-04 | 1.05 | 38.7K | 01:23:23 |  47.3%\n",
            "23640 | 4.4344 | 2.9e-04 | 1.07 | 38.7K | 01:23:25 |  47.3%\n",
            "23650 | 4.9031 | 2.9e-04 | 1.08 | 38.7K | 01:23:27 |  47.3%\n",
            "23660 | 4.4108 | 2.9e-04 | 0.98 | 38.7K | 01:23:28 |  47.3%\n",
            "23670 | 4.4108 | 2.9e-04 | 0.98 | 38.7K | 01:23:30 |  47.3%\n",
            "23680 | 4.5954 | 2.9e-04 | 1.01 | 38.7K | 01:23:32 |  47.4%\n",
            "23690 | 4.3378 | 2.9e-04 | 1.02 | 38.7K | 01:23:34 |  47.4%\n",
            "23700 | 4.5839 | 2.9e-04 | 1.05 | 38.7K | 01:23:35 |  47.4%\n",
            "23710 | 4.5437 | 2.9e-04 | 1.05 | 38.7K | 01:23:37 |  47.4%\n",
            "23720 | 4.4325 | 2.9e-04 | 1.27 | 38.7K | 01:23:39 |  47.4%\n",
            "23730 | 4.4255 | 2.9e-04 | 1.06 | 38.7K | 01:23:40 |  47.5%\n",
            "23740 | 4.2289 | 2.9e-04 | 1.07 | 38.7K | 01:23:42 |  47.5%\n",
            "23750 | 4.7978 | 2.9e-04 | 1.01 | 38.7K | 01:23:44 |  47.5%\n",
            "23760 | 4.6067 | 2.9e-04 | 0.99 | 38.7K | 01:23:46 |  47.5%\n",
            "23770 | 4.4209 | 2.9e-04 | 1.08 | 38.7K | 01:23:47 |  47.5%\n",
            "23780 | 4.7223 | 2.9e-04 | 1.03 | 38.7K | 01:23:49 |  47.6%\n",
            "23790 | 4.6637 | 2.9e-04 | 1.02 | 38.7K | 01:23:51 |  47.6%\n",
            "23800 | 4.2490 | 2.9e-04 | 1.01 | 38.7K | 01:23:52 |  47.6%\n",
            "23810 | 4.5839 | 2.9e-04 | 1.00 | 38.7K | 01:23:54 |  47.6%\n",
            "23820 | 4.6751 | 2.9e-04 | 1.01 | 38.7K | 01:23:56 |  47.6%\n",
            "23830 | 4.8057 | 2.9e-04 | 1.01 | 38.7K | 01:23:58 |  47.7%\n",
            "23840 | 4.3292 | 2.9e-04 | 0.99 | 38.8K | 01:23:59 |  47.7%\n",
            "23850 | 4.4520 | 2.9e-04 | 1.00 | 38.8K | 01:24:01 |  47.7%\n",
            "23860 | 4.5673 | 2.8e-04 | 1.00 | 38.8K | 01:24:03 |  47.7%\n",
            "23870 | 4.5987 | 2.8e-04 | 1.05 | 38.8K | 01:24:04 |  47.7%\n",
            "23880 | 4.5534 | 2.8e-04 | 1.04 | 38.8K | 01:24:06 |  47.8%\n",
            "23890 | 4.2676 | 2.8e-04 | 1.03 | 38.8K | 01:24:08 |  47.8%\n",
            "23900 | 4.4105 | 2.8e-04 | 1.01 | 38.8K | 01:24:10 |  47.8%\n",
            "23910 | 4.5720 | 2.8e-04 | 1.01 | 38.8K | 01:24:11 |  47.8%\n",
            "23920 | 4.5446 | 2.8e-04 | 1.05 | 38.8K | 01:24:13 |  47.8%\n",
            "23930 | 4.3822 | 2.8e-04 | 1.03 | 38.8K | 01:24:15 |  47.9%\n",
            "23940 | 4.3582 | 2.8e-04 | 1.03 | 38.8K | 01:24:16 |  47.9%\n",
            "23950 | 4.7589 | 2.8e-04 | 1.02 | 38.8K | 01:24:18 |  47.9%\n",
            "23960 | 4.6426 | 2.8e-04 | 1.02 | 38.8K | 01:24:20 |  47.9%\n",
            "23970 | 4.3717 | 2.8e-04 | 0.98 | 38.8K | 01:24:22 |  47.9%\n",
            "23980 | 4.4628 | 2.8e-04 | 1.00 | 38.8K | 01:24:23 |  48.0%\n",
            "23990 | 4.7228 | 2.8e-04 | 1.04 | 38.8K | 01:24:25 |  48.0%\n",
            "24000 | 4.7840 | 2.8e-04 | 1.05 | 38.8K | 01:24:27 |  48.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 24000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.4364\n",
            "  Perplexity: 84.47\n",
            "  Train loss (avg): 4.5144\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        sıcaklığının büyük oranda azalmasına neden olan önemli bir faktör olan kol saati, yol boyunca uzanan bir hızla hareket etmeye başlar. Bu sebeple sırt kısmında uzun uzun sapmaları yoksa, ya da uzun uzun sapmaları\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        ve Türkiye'nin merkez ilçelerinden birisi olan ve Türkiye'nin en büyük ve en büyük kenti olarak kabul edilen Gazi Mustafa Kemal Atatürk'ün \"Muğrideler\" dediği \"Hocam\"\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        ve yapay zeka teknolojilerini destekleyerek, yapay zekada yaşananların önüne geçilebilir. Bu teknolojiler, yapay zeka ile ilgilenen insanların tüm bilgiye erişimini sağlar ve hatta biz onları nasıl kullandığımız konusunda bilgilendirir.\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.4364)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:31:51\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "24010 | 4.3795 | 2.8e-04 | 1.00 | 38.6K | 01:24:49 |  48.0%\n",
            "24020 | 4.7696 | 2.8e-04 | 1.03 | 38.6K | 01:24:51 |  48.0%\n",
            "24030 | 4.7189 | 2.8e-04 | 1.03 | 38.7K | 01:24:53 |  48.1%\n",
            "24040 | 4.3344 | 2.8e-04 | 1.09 | 38.7K | 01:24:54 |  48.1%\n",
            "24050 | 4.3578 | 2.8e-04 | 1.02 | 38.7K | 01:24:56 |  48.1%\n",
            "24060 | 4.4709 | 2.8e-04 | 1.01 | 38.7K | 01:24:58 |  48.1%\n",
            "24070 | 4.3022 | 2.8e-04 | 1.07 | 38.7K | 01:24:59 |  48.1%\n",
            "24080 | 4.4613 | 2.8e-04 | 0.99 | 38.7K | 01:25:01 |  48.2%\n",
            "24090 | 4.8824 | 2.8e-04 | 1.02 | 38.7K | 01:25:03 |  48.2%\n",
            "24100 | 4.4441 | 2.8e-04 | 1.00 | 38.7K | 01:25:05 |  48.2%\n",
            "24110 | 4.3427 | 2.8e-04 | 1.09 | 38.7K | 01:25:06 |  48.2%\n",
            "24120 | 4.3904 | 2.8e-04 | 1.01 | 38.7K | 01:25:08 |  48.2%\n",
            "24130 | 4.4755 | 2.8e-04 | 1.00 | 38.7K | 01:25:10 |  48.3%\n",
            "24140 | 4.4675 | 2.8e-04 | 1.06 | 38.7K | 01:25:11 |  48.3%\n",
            "24150 | 4.5876 | 2.8e-04 | 1.04 | 38.7K | 01:25:13 |  48.3%\n",
            "24160 | 4.5376 | 2.8e-04 | 1.07 | 38.7K | 01:25:15 |  48.3%\n",
            "24170 | 4.6843 | 2.8e-04 | 1.02 | 38.7K | 01:25:17 |  48.3%\n",
            "24180 | 4.6066 | 2.8e-04 | 0.99 | 38.7K | 01:25:18 |  48.4%\n",
            "24190 | 4.6334 | 2.8e-04 | 1.03 | 38.7K | 01:25:20 |  48.4%\n",
            "24200 | 4.3233 | 2.8e-04 | 1.02 | 38.7K | 01:25:22 |  48.4%\n",
            "24210 | 4.4207 | 2.8e-04 | 1.13 | 38.7K | 01:25:23 |  48.4%\n",
            "24220 | 4.4880 | 2.8e-04 | 1.03 | 38.7K | 01:25:25 |  48.4%\n",
            "24230 | 4.5393 | 2.8e-04 | 1.09 | 38.7K | 01:25:27 |  48.5%\n",
            "24240 | 4.3364 | 2.8e-04 | 1.00 | 38.7K | 01:25:29 |  48.5%\n",
            "24250 | 4.1187 | 2.8e-04 | 1.12 | 38.7K | 01:25:30 |  48.5%\n",
            "24260 | 4.3758 | 2.8e-04 | 1.03 | 38.7K | 01:25:32 |  48.5%\n",
            "24270 | 4.5493 | 2.8e-04 | 1.05 | 38.7K | 01:25:34 |  48.5%\n",
            "24280 | 4.3550 | 2.8e-04 | 1.00 | 38.7K | 01:25:35 |  48.6%\n",
            "24290 | 4.6451 | 2.8e-04 | 1.13 | 38.7K | 01:25:37 |  48.6%\n",
            "24300 | 4.5456 | 2.8e-04 | 1.07 | 38.7K | 01:25:39 |  48.6%\n",
            "24310 | 4.4951 | 2.8e-04 | 1.05 | 38.7K | 01:25:41 |  48.6%\n",
            "24320 | 4.5642 | 2.8e-04 | 1.04 | 38.7K | 01:25:42 |  48.6%\n",
            "24330 | 4.6380 | 2.8e-04 | 1.05 | 38.7K | 01:25:44 |  48.7%\n",
            "24340 | 4.3406 | 2.8e-04 | 1.06 | 38.7K | 01:25:46 |  48.7%\n",
            "24350 | 4.4673 | 2.8e-04 | 1.07 | 38.7K | 01:25:47 |  48.7%\n",
            "24360 | 4.3458 | 2.8e-04 | 1.03 | 38.8K | 01:25:49 |  48.7%\n",
            "24370 | 4.2877 | 2.8e-04 | 1.10 | 38.8K | 01:25:51 |  48.7%\n",
            "24380 | 4.2748 | 2.8e-04 | 1.10 | 38.8K | 01:25:53 |  48.8%\n",
            "24390 | 4.7743 | 2.8e-04 | 0.99 | 38.8K | 01:25:54 |  48.8%\n",
            "24400 | 4.4533 | 2.8e-04 | 1.05 | 38.8K | 01:25:56 |  48.8%\n",
            "24410 | 4.6154 | 2.8e-04 | 1.06 | 38.8K | 01:25:58 |  48.8%\n",
            "24420 | 4.5792 | 2.8e-04 | 1.03 | 38.8K | 01:25:59 |  48.8%\n",
            "24430 | 4.6660 | 2.8e-04 | 1.02 | 38.8K | 01:26:01 |  48.9%\n",
            "24440 | 4.5399 | 2.8e-04 | 1.03 | 38.8K | 01:26:03 |  48.9%\n",
            "24450 | 4.5049 | 2.8e-04 | 1.01 | 38.8K | 01:26:05 |  48.9%\n",
            "24460 | 4.3247 | 2.8e-04 | 1.06 | 38.8K | 01:26:06 |  48.9%\n",
            "24470 | 4.6039 | 2.8e-04 | 1.05 | 38.8K | 01:26:08 |  48.9%\n",
            "24480 | 4.2164 | 2.7e-04 | 1.12 | 38.8K | 01:26:10 |  49.0%\n",
            "24490 | 4.5017 | 2.7e-04 | 1.12 | 38.8K | 01:26:11 |  49.0%\n",
            "24500 | 4.4236 | 2.7e-04 | 1.05 | 38.8K | 01:26:13 |  49.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 24500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.4180\n",
            "  Perplexity: 82.93\n",
            "  Train loss (avg): 4.4658\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        koşullarına karşı duyarlı olan herkes, her şeyi çözecek bir şeyler arar. Derhal bir kadın olan herkesin niyetinde tek bir şey yoktur. Çaresiz ve karamsar olan herkesin hayatın planlarını bilmeniz, asla kabul etmeniz\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Ankara'da yaşayan Türk vatandaşları, yaşadıkları tehdit, yabancı uyruklularla da karşı karşıyalar. Türkiye'nin vize serbestliği konusundaki taleplerinin başında Suriye. Türkiye ile yapılan anlaşmalarda, Türkiye'nin vize\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , yapay zeka ile çalışmaya devam ediyor. Yapay zeka, yapay zeka ile çalışmaya devam ediyor. Yapay zeka ile çalışmanın dijital dünyada çok daha kolay olacağını belirten Yapay Zeka, yapay zeka ile çalışmanın daha kolay olacağını belirtiyor\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.4180)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:30:06\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "24510 | 4.4122 | 2.7e-04 | 1.10 | 38.6K | 01:26:36 |  49.0%\n",
            "24520 | 4.5520 | 2.7e-04 | 1.03 | 38.6K | 01:26:37 |  49.0%\n",
            "24530 | 4.5924 | 2.7e-04 | 1.04 | 38.6K | 01:26:39 |  49.1%\n",
            "24540 | 4.7534 | 2.7e-04 | 1.04 | 38.7K | 01:26:41 |  49.1%\n",
            "24550 | 4.8397 | 2.7e-04 | 1.02 | 38.7K | 01:26:43 |  49.1%\n",
            "24560 | 4.2924 | 2.7e-04 | 1.04 | 38.7K | 01:26:44 |  49.1%\n",
            "24570 | 4.5454 | 2.7e-04 | 1.03 | 38.7K | 01:26:46 |  49.1%\n",
            "24580 | 4.3247 | 2.7e-04 | 1.02 | 38.7K | 01:26:48 |  49.2%\n",
            "24590 | 4.4107 | 2.7e-04 | 1.01 | 38.7K | 01:26:49 |  49.2%\n",
            "24600 | 4.3235 | 2.7e-04 | 1.03 | 38.7K | 01:26:51 |  49.2%\n",
            "24610 | 4.6227 | 2.7e-04 | 1.04 | 38.7K | 01:26:53 |  49.2%\n",
            "24620 | 4.3354 | 2.7e-04 | 0.99 | 38.7K | 01:26:55 |  49.2%\n",
            "24630 | 4.1744 | 2.7e-04 | 1.03 | 38.7K | 01:26:56 |  49.3%\n",
            "24640 | 4.2232 | 2.7e-04 | 1.05 | 38.7K | 01:26:58 |  49.3%\n",
            "24650 | 4.3845 | 2.7e-04 | 1.04 | 38.7K | 01:27:00 |  49.3%\n",
            "24660 | 4.6275 | 2.7e-04 | 1.05 | 38.7K | 01:27:01 |  49.3%\n",
            "24670 | 4.4615 | 2.7e-04 | 1.21 | 38.7K | 01:27:03 |  49.3%\n",
            "24680 | 4.6800 | 2.7e-04 | 1.01 | 38.7K | 01:27:05 |  49.4%\n",
            "24690 | 4.3467 | 2.7e-04 | 1.02 | 38.7K | 01:27:07 |  49.4%\n",
            "24700 | 4.4895 | 2.7e-04 | 1.05 | 38.7K | 01:27:08 |  49.4%\n",
            "24710 | 4.5545 | 2.7e-04 | 1.04 | 38.7K | 01:27:10 |  49.4%\n",
            "24720 | 4.5838 | 2.7e-04 | 1.01 | 38.7K | 01:27:12 |  49.4%\n",
            "24730 | 4.3064 | 2.7e-04 | 1.05 | 38.7K | 01:27:13 |  49.5%\n",
            "24740 | 4.4321 | 2.7e-04 | 1.02 | 38.7K | 01:27:15 |  49.5%\n",
            "24750 | 4.6012 | 2.7e-04 | 1.00 | 38.7K | 01:27:17 |  49.5%\n",
            "24760 | 4.2952 | 2.7e-04 | 1.04 | 38.7K | 01:27:19 |  49.5%\n",
            "24770 | 4.5882 | 2.7e-04 | 1.06 | 38.7K | 01:27:20 |  49.5%\n",
            "24780 | 4.1810 | 2.7e-04 | 1.02 | 38.7K | 01:27:22 |  49.6%\n",
            "24790 | 4.4807 | 2.7e-04 | 1.06 | 38.7K | 01:27:24 |  49.6%\n",
            "24800 | 4.3776 | 2.7e-04 | 1.03 | 38.7K | 01:27:25 |  49.6%\n",
            "24810 | 4.4651 | 2.7e-04 | 1.11 | 38.7K | 01:27:27 |  49.6%\n",
            "24820 | 4.5489 | 2.7e-04 | 1.66 | 38.7K | 01:27:29 |  49.6%\n",
            "24830 | 4.6013 | 2.7e-04 | 1.03 | 38.7K | 01:27:30 |  49.7%\n",
            "24840 | 4.3641 | 2.7e-04 | 1.19 | 38.7K | 01:27:32 |  49.7%\n",
            "24850 | 4.4005 | 2.7e-04 | 1.06 | 38.7K | 01:27:34 |  49.7%\n",
            "24860 | 4.2218 | 2.7e-04 | 1.05 | 38.7K | 01:27:36 |  49.7%\n",
            "24870 | 4.5249 | 2.7e-04 | 1.06 | 38.7K | 01:27:37 |  49.7%\n",
            "24880 | 4.3978 | 2.7e-04 | 1.05 | 38.8K | 01:27:39 |  49.8%\n",
            "24890 | 4.4080 | 2.7e-04 | 1.10 | 38.8K | 01:27:41 |  49.8%\n",
            "24900 | 4.5893 | 2.7e-04 | 1.00 | 38.8K | 01:27:42 |  49.8%\n",
            "24910 | 4.0391 | 2.7e-04 | 1.10 | 38.8K | 01:27:44 |  49.8%\n",
            "24920 | 4.6697 | 2.7e-04 | 1.03 | 38.8K | 01:27:46 |  49.8%\n",
            "24930 | 4.5538 | 2.7e-04 | 1.04 | 38.8K | 01:27:48 |  49.9%\n",
            "24940 | 4.4941 | 2.7e-04 | 1.05 | 38.8K | 01:27:49 |  49.9%\n",
            "24950 | 4.4626 | 2.7e-04 | 1.03 | 38.8K | 01:27:51 |  49.9%\n",
            "24960 | 4.6441 | 2.7e-04 | 1.05 | 38.8K | 01:27:53 |  49.9%\n",
            "24970 | 4.4653 | 2.7e-04 | 1.02 | 38.8K | 01:27:54 |  49.9%\n",
            "24980 | 4.6102 | 2.7e-04 | 1.05 | 38.8K | 01:27:56 |  50.0%\n",
            "24990 | 4.5981 | 2.7e-04 | 1.02 | 38.8K | 01:27:58 |  50.0%\n",
            "25000 | 4.3208 | 2.7e-04 | 1.02 | 38.8K | 01:28:00 |  50.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 25000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.4063\n",
            "  Perplexity: 81.97\n",
            "  Train loss (avg): 4.4603\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        ların çok yavaş ilerlediği ve fırtınaların büyük etkisi olduğu bir ortamda, aşırı derecede sıcaklıkların bir miktar yükselmesine sebep olacağı, bu da çok geç bir derecede yağa dönüşebilir. Yağmura bile karış\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        olan İstanbul, özellikle İstanbul, Ankara, İstanbul, Ankara ve Ankara gibi birçok farklı lokasyonda hizmet veriyor. Ankara'nın bir diğer özelliği de İstanbul, Ankara, İstanbul ve İzmir gibi birçok farklı lokasyonda\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , bilim ve teknoloji dünyasında kullanılan sanal robotlar gibi, insanların zeka ile olan ilişkilerini oldukça karmaşık bir hale getirmiştir. Bu sayede insanların beyinlerine olan merakı azalmış ve çok da ilginç bir yöntem haline gelmiştir\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.4063)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:28:20\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "💾 Checkpoint kaydediliyor: /content/drive/MyDrive/turkish_llm/checkpoints//checkpoint_step_25000.pt\n",
            "  ✅ Checkpoint kaydedildi!\n",
            "\n",
            "25010 | 4.0557 | 2.7e-04 | 1.13 | 38.6K | 01:28:25 |  50.0%\n",
            "25020 | 4.5594 | 2.7e-04 | 1.05 | 38.6K | 01:28:27 |  50.0%\n",
            "25030 | 4.5558 | 2.7e-04 | 1.02 | 38.6K | 01:28:29 |  50.1%\n",
            "25040 | 4.5460 | 2.7e-04 | 1.06 | 38.6K | 01:28:30 |  50.1%\n",
            "25050 | 4.2729 | 2.7e-04 | 1.06 | 38.6K | 01:28:32 |  50.1%\n",
            "25060 | 4.6313 | 2.7e-04 | 1.08 | 38.6K | 01:28:34 |  50.1%\n",
            "25070 | 4.3422 | 2.7e-04 | 1.11 | 38.6K | 01:28:36 |  50.1%\n",
            "25080 | 4.3165 | 2.7e-04 | 1.02 | 38.6K | 01:28:37 |  50.2%\n",
            "25090 | 4.5483 | 2.6e-04 | 1.02 | 38.6K | 01:28:39 |  50.2%\n",
            "25100 | 4.2404 | 2.6e-04 | 1.07 | 38.6K | 01:28:41 |  50.2%\n",
            "25110 | 4.3481 | 2.6e-04 | 1.05 | 38.6K | 01:28:42 |  50.2%\n",
            "25120 | 4.4636 | 2.6e-04 | 1.05 | 38.6K | 01:28:44 |  50.2%\n",
            "25130 | 4.8048 | 2.6e-04 | 1.02 | 38.6K | 01:28:46 |  50.3%\n",
            "25140 | 4.3667 | 2.6e-04 | 1.02 | 38.7K | 01:28:48 |  50.3%\n",
            "25150 | 4.2737 | 2.6e-04 | 1.20 | 38.7K | 01:28:49 |  50.3%\n",
            "25160 | 4.6139 | 2.6e-04 | 1.01 | 38.7K | 01:28:51 |  50.3%\n",
            "25170 | 4.3292 | 2.6e-04 | 1.00 | 38.7K | 01:28:53 |  50.3%\n",
            "25180 | 4.4264 | 2.6e-04 | 1.08 | 38.7K | 01:28:54 |  50.4%\n",
            "25190 | 4.3159 | 2.6e-04 | 1.08 | 38.7K | 01:28:56 |  50.4%\n",
            "25200 | 4.5756 | 2.6e-04 | 1.06 | 38.7K | 01:28:58 |  50.4%\n",
            "25210 | 4.3621 | 2.6e-04 | 1.03 | 38.7K | 01:29:00 |  50.4%\n",
            "25220 | 4.5878 | 2.6e-04 | 1.04 | 38.7K | 01:29:01 |  50.4%\n",
            "25230 | 4.5065 | 2.6e-04 | 1.05 | 38.7K | 01:29:03 |  50.5%\n",
            "25240 | 4.4741 | 2.6e-04 | 1.05 | 38.7K | 01:29:05 |  50.5%\n",
            "25250 | 4.5063 | 2.6e-04 | 1.03 | 38.7K | 01:29:06 |  50.5%\n",
            "25260 | 4.3001 | 2.6e-04 | 1.02 | 38.7K | 01:29:08 |  50.5%\n",
            "25270 | 4.3672 | 2.6e-04 | 1.07 | 38.7K | 01:29:10 |  50.5%\n",
            "25280 | 4.3464 | 2.6e-04 | 1.07 | 38.7K | 01:29:12 |  50.6%\n",
            "25290 | 4.4102 | 2.6e-04 | 1.04 | 38.7K | 01:29:13 |  50.6%\n",
            "25300 | 4.6300 | 2.6e-04 | 1.03 | 38.7K | 01:29:15 |  50.6%\n",
            "25310 | 4.5816 | 2.6e-04 | 1.02 | 38.7K | 01:29:17 |  50.6%\n",
            "25320 | 4.4138 | 2.6e-04 | 1.01 | 38.7K | 01:29:18 |  50.6%\n",
            "25330 | 4.4503 | 2.6e-04 | 1.06 | 38.7K | 01:29:20 |  50.7%\n",
            "25340 | 4.2702 | 2.6e-04 | 1.04 | 38.7K | 01:29:22 |  50.7%\n",
            "25350 | 4.5454 | 2.6e-04 | 1.04 | 38.7K | 01:29:24 |  50.7%\n",
            "25360 | 4.5223 | 2.6e-04 | 1.01 | 38.7K | 01:29:25 |  50.7%\n",
            "25370 | 4.2396 | 2.6e-04 | 1.04 | 38.7K | 01:29:27 |  50.7%\n",
            "25380 | 4.4186 | 2.6e-04 | 1.04 | 38.7K | 01:29:29 |  50.8%\n",
            "25390 | 4.5627 | 2.6e-04 | 1.03 | 38.7K | 01:29:30 |  50.8%\n",
            "25400 | 4.5978 | 2.6e-04 | 1.08 | 38.7K | 01:29:32 |  50.8%\n",
            "25410 | 4.7149 | 2.6e-04 | 1.02 | 38.7K | 01:29:34 |  50.8%\n",
            "25420 | 4.4791 | 2.6e-04 | 1.03 | 38.7K | 01:29:36 |  50.8%\n",
            "25430 | 4.4416 | 2.6e-04 | 1.09 | 38.7K | 01:29:37 |  50.9%\n",
            "25440 | 4.4962 | 2.6e-04 | 1.04 | 38.7K | 01:29:39 |  50.9%\n",
            "25450 | 4.5475 | 2.6e-04 | 1.00 | 38.7K | 01:29:41 |  50.9%\n",
            "25460 | 4.5813 | 2.6e-04 | 1.06 | 38.7K | 01:29:42 |  50.9%\n",
            "25470 | 4.0552 | 2.6e-04 | 1.24 | 38.7K | 01:29:44 |  50.9%\n",
            "25480 | 4.3325 | 2.6e-04 | 1.09 | 38.8K | 01:29:46 |  51.0%\n",
            "25490 | 4.3559 | 2.6e-04 | 1.12 | 38.8K | 01:29:48 |  51.0%\n",
            "25500 | 4.5432 | 2.6e-04 | 1.05 | 38.8K | 01:29:49 |  51.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 25500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.4170\n",
            "  Perplexity: 82.85\n",
            "  Train loss (avg): 4.4895\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        şartlarından daha tehlikeler var. Biz de bu tehlikeleri fırsata dönüştürmeyi hedefliyoruz. Vatandaşın isteği doğrultusunda hava koşulları uygun olacak. Bakanlar Kurulu da bu sebeple kararını açıklayacağı zaman buyursun ki bu\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Ankara'da ortaya çıkan nükleer santralin en büyük kısmı Türkiye'ye geliyor. Ankara'ya başka bir ülkeye gitmek isteyen Türkiye'nin, nükleer santralin daha da güzelleşmesini sağlayan bir diğer faktör\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        kullanılıyor. Günümüzde insanlar artık bu yazılımlarla (gözleme ve öğrenme amaçlı) gözlemleniyor. Her ne kadar da dijital ortamda yapılan bir araştırmaya göre, sanal gerçeklik, bir sanal gerçeklik, sanal gerçeklik, yapay\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:26:35\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "25510 | 4.5360 | 2.6e-04 | 1.03 | 38.6K | 01:30:08 |  51.0%\n",
            "25520 | 4.4037 | 2.6e-04 | 1.04 | 38.6K | 01:30:10 |  51.0%\n",
            "25530 | 4.6170 | 2.6e-04 | 1.03 | 38.6K | 01:30:12 |  51.1%\n",
            "25540 | 4.4021 | 2.6e-04 | 1.10 | 38.6K | 01:30:13 |  51.1%\n",
            "25550 | 4.3833 | 2.6e-04 | 1.10 | 38.6K | 01:30:15 |  51.1%\n",
            "25560 | 4.1835 | 2.6e-04 | 1.05 | 38.7K | 01:30:17 |  51.1%\n",
            "25570 | 4.5816 | 2.6e-04 | 1.02 | 38.7K | 01:30:19 |  51.1%\n",
            "25580 | 4.5319 | 2.6e-04 | 1.04 | 38.7K | 01:30:20 |  51.2%\n",
            "25590 | 4.4519 | 2.6e-04 | 1.04 | 38.7K | 01:30:22 |  51.2%\n",
            "25600 | 4.2558 | 2.6e-04 | 1.07 | 38.7K | 01:30:24 |  51.2%\n",
            "25610 | 4.5048 | 2.6e-04 | 1.03 | 38.7K | 01:30:25 |  51.2%\n",
            "25620 | 4.6581 | 2.6e-04 | 1.03 | 38.7K | 01:30:27 |  51.2%\n",
            "25630 | 4.5813 | 2.6e-04 | 1.08 | 38.7K | 01:30:29 |  51.3%\n",
            "25640 | 4.4677 | 2.6e-04 | 1.03 | 38.7K | 01:30:31 |  51.3%\n",
            "25650 | 4.5887 | 2.6e-04 | 1.03 | 38.7K | 01:30:32 |  51.3%\n",
            "25660 | 4.3682 | 2.6e-04 | 1.04 | 38.7K | 01:30:34 |  51.3%\n",
            "25670 | 4.7123 | 2.6e-04 | 1.04 | 38.7K | 01:30:36 |  51.3%\n",
            "25680 | 4.4956 | 2.6e-04 | 1.02 | 38.7K | 01:30:37 |  51.4%\n",
            "25690 | 4.4649 | 2.6e-04 | 1.03 | 38.7K | 01:30:39 |  51.4%\n",
            "25700 | 4.4180 | 2.5e-04 | 1.10 | 38.7K | 01:30:41 |  51.4%\n",
            "25710 | 4.6021 | 2.5e-04 | 1.00 | 38.7K | 01:30:43 |  51.4%\n",
            "25720 | 4.4406 | 2.5e-04 | 1.14 | 38.7K | 01:30:44 |  51.4%\n",
            "25730 | 4.5144 | 2.5e-04 | 1.14 | 38.7K | 01:30:46 |  51.5%\n",
            "25740 | 4.5114 | 2.5e-04 | 1.03 | 38.7K | 01:30:48 |  51.5%\n",
            "25750 | 4.5773 | 2.5e-04 | 1.05 | 38.7K | 01:30:49 |  51.5%\n",
            "25760 | 4.4538 | 2.5e-04 | 1.06 | 38.7K | 01:30:51 |  51.5%\n",
            "25770 | 4.4770 | 2.5e-04 | 1.01 | 38.7K | 01:30:53 |  51.5%\n",
            "25780 | 4.3854 | 2.5e-04 | 1.04 | 38.7K | 01:30:55 |  51.6%\n",
            "25790 | 4.5822 | 2.5e-04 | 1.07 | 38.7K | 01:30:56 |  51.6%\n",
            "25800 | 4.5247 | 2.5e-04 | 1.08 | 38.7K | 01:30:58 |  51.6%\n",
            "25810 | 4.3434 | 2.5e-04 | 1.10 | 38.7K | 01:31:00 |  51.6%\n",
            "25820 | 4.5227 | 2.5e-04 | 1.12 | 38.7K | 01:31:01 |  51.6%\n",
            "25830 | 4.0954 | 2.5e-04 | 1.12 | 38.7K | 01:31:03 |  51.7%\n",
            "25840 | 4.7705 | 2.5e-04 | 1.00 | 38.7K | 01:31:05 |  51.7%\n",
            "25850 | 4.2648 | 2.5e-04 | 1.05 | 38.7K | 01:31:07 |  51.7%\n",
            "25860 | 4.2607 | 2.5e-04 | 1.06 | 38.7K | 01:31:08 |  51.7%\n",
            "25870 | 4.6235 | 2.5e-04 | 1.08 | 38.7K | 01:31:10 |  51.7%\n",
            "25880 | 4.4825 | 2.5e-04 | 1.02 | 38.7K | 01:31:12 |  51.8%\n",
            "25890 | 4.7892 | 2.5e-04 | 1.07 | 38.7K | 01:31:14 |  51.8%\n",
            "25900 | 4.4459 | 2.5e-04 | 1.02 | 38.7K | 01:31:15 |  51.8%\n",
            "25910 | 4.3940 | 2.5e-04 | 1.03 | 38.8K | 01:31:17 |  51.8%\n",
            "25920 | 4.4225 | 2.5e-04 | 1.04 | 38.8K | 01:31:19 |  51.8%\n",
            "25930 | 4.4057 | 2.5e-04 | 1.11 | 38.8K | 01:31:20 |  51.9%\n",
            "25940 | 4.4503 | 2.5e-04 | 1.01 | 38.8K | 01:31:22 |  51.9%\n",
            "25950 | 4.3804 | 2.5e-04 | 1.02 | 38.8K | 01:31:24 |  51.9%\n",
            "25960 | 4.3160 | 2.5e-04 | 1.23 | 38.8K | 01:31:26 |  51.9%\n",
            "25970 | 4.4209 | 2.5e-04 | 1.01 | 38.8K | 01:31:27 |  51.9%\n",
            "25980 | 4.1912 | 2.5e-04 | 1.18 | 38.8K | 01:31:29 |  52.0%\n",
            "25990 | 4.2733 | 2.5e-04 | 1.09 | 38.8K | 01:31:31 |  52.0%\n",
            "26000 | 4.4628 | 2.5e-04 | 1.04 | 38.8K | 01:31:32 |  52.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 26000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.4134\n",
            "  Perplexity: 82.55\n",
            "  Train loss (avg): 4.4012\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        durumunu kontrol altında tutan ve dolayısıyla yoğunlaşan havaların etkisiyle, hava çok şiddetli olup, hava sıcaklığı hemen ölçülemeyecek kadar yüksek ve; hava sıcaklığı yaklaşık 0’a kadar inmektedir. Yoğun olan hava\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Düsek'in doğusunda bulunan Büyük Selçuklu, Osmanlı ve Cumhuriyet'in ilk Müslüman halifesi olan Şeyh Said'in, halifelikten sonra tahttan indirilmesine karar vermiştir. Bu durum, yeni\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , bu teknolojinin, özellikle teknolojiyi kullanan kişilerin, kazandıkları, kazandıkları veya kazandıkları ürünlerin, ürün ve donanımlarından, maliyetlerinden, maliyetlerinden, maliyetlerinden ve maliyetlerinden etkilenerek etkilenip etkilen\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:24:46\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "26010 | 4.6071 | 2.5e-04 | 1.05 | 38.7K | 01:31:51 |  52.0%\n",
            "26020 | 4.7394 | 2.5e-04 | 1.06 | 38.7K | 01:31:53 |  52.0%\n",
            "26030 | 4.5876 | 2.5e-04 | 1.05 | 38.7K | 01:31:55 |  52.1%\n",
            "26040 | 4.7789 | 2.5e-04 | 1.02 | 38.7K | 01:31:56 |  52.1%\n",
            "26050 | 4.2973 | 2.5e-04 | 1.04 | 38.7K | 01:31:58 |  52.1%\n",
            "26060 | 4.3097 | 2.5e-04 | 1.06 | 38.7K | 01:32:00 |  52.1%\n",
            "26070 | 4.3521 | 2.5e-04 | 1.08 | 38.7K | 01:32:02 |  52.1%\n",
            "26080 | 4.0336 | 2.5e-04 | 1.28 | 38.7K | 01:32:03 |  52.2%\n",
            "26090 | 4.5311 | 2.5e-04 | 1.04 | 38.7K | 01:32:05 |  52.2%\n",
            "26100 | 4.3178 | 2.5e-04 | 1.08 | 38.7K | 01:32:07 |  52.2%\n",
            "26110 | 4.3711 | 2.5e-04 | 1.05 | 38.7K | 01:32:08 |  52.2%\n",
            "26120 | 4.8370 | 2.5e-04 | 1.03 | 38.7K | 01:32:10 |  52.2%\n",
            "26130 | 4.1596 | 2.5e-04 | 1.11 | 38.7K | 01:32:12 |  52.3%\n",
            "26140 | 3.9635 | 2.5e-04 | 1.08 | 38.7K | 01:32:14 |  52.3%\n",
            "26150 | 3.9417 | 2.5e-04 | 1.17 | 38.7K | 01:32:15 |  52.3%\n",
            "26160 | 4.6737 | 2.5e-04 | 1.06 | 38.7K | 01:32:17 |  52.3%\n",
            "26170 | 4.4043 | 2.5e-04 | 1.05 | 38.7K | 01:32:19 |  52.3%\n",
            "26180 | 4.4938 | 2.5e-04 | 1.06 | 38.7K | 01:32:20 |  52.4%\n",
            "26190 | 4.4504 | 2.5e-04 | 1.06 | 38.7K | 01:32:22 |  52.4%\n",
            "26200 | 4.4309 | 2.5e-04 | 1.03 | 38.7K | 01:32:24 |  52.4%\n",
            "26210 | 4.5863 | 2.5e-04 | 1.06 | 38.7K | 01:32:26 |  52.4%\n",
            "26220 | 4.2892 | 2.5e-04 | 1.77 | 38.7K | 01:32:27 |  52.4%\n",
            "26230 | 4.4046 | 2.5e-04 | 1.10 | 38.7K | 01:32:29 |  52.5%\n",
            "26240 | 4.3906 | 2.5e-04 | 1.03 | 38.7K | 01:32:31 |  52.5%\n",
            "26250 | 4.3372 | 2.5e-04 | 1.04 | 38.7K | 01:32:32 |  52.5%\n",
            "26260 | 4.6262 | 2.5e-04 | 1.08 | 38.7K | 01:32:34 |  52.5%\n",
            "26270 | 4.6262 | 2.5e-04 | 1.05 | 38.7K | 01:32:36 |  52.5%\n",
            "26280 | 4.0202 | 2.5e-04 | 1.07 | 38.7K | 01:32:38 |  52.6%\n",
            "26290 | 4.6872 | 2.5e-04 | 1.05 | 38.7K | 01:32:39 |  52.6%\n",
            "26300 | 4.7608 | 2.5e-04 | 1.05 | 38.7K | 01:32:41 |  52.6%\n",
            "26310 | 4.6281 | 2.4e-04 | 1.02 | 38.7K | 01:32:43 |  52.6%\n",
            "26320 | 4.4458 | 2.4e-04 | 1.04 | 38.7K | 01:32:44 |  52.6%\n",
            "26330 | 4.2716 | 2.4e-04 | 1.06 | 38.7K | 01:32:46 |  52.7%\n",
            "26340 | 4.5004 | 2.4e-04 | 1.08 | 38.8K | 01:32:48 |  52.7%\n",
            "26350 | 4.3078 | 2.4e-04 | inf | 38.8K | 01:32:50 |  52.7%\n",
            "26360 | 4.7239 | 2.4e-04 | 1.05 | 38.8K | 01:32:51 |  52.7%\n",
            "26370 | 4.4127 | 2.4e-04 | 1.04 | 38.8K | 01:32:53 |  52.7%\n",
            "26380 | 4.2429 | 2.4e-04 | 1.09 | 38.8K | 01:32:55 |  52.8%\n",
            "26390 | 4.6812 | 2.4e-04 | 1.07 | 38.8K | 01:32:56 |  52.8%\n",
            "26400 | 4.5632 | 2.4e-04 | 1.05 | 38.8K | 01:32:58 |  52.8%\n",
            "26410 | 4.2747 | 2.4e-04 | 1.09 | 38.8K | 01:33:00 |  52.8%\n",
            "26420 | 4.3136 | 2.4e-04 | 1.01 | 38.8K | 01:33:02 |  52.8%\n",
            "26430 | 4.4112 | 2.4e-04 | 1.17 | 38.8K | 01:33:03 |  52.9%\n",
            "26440 | 4.7032 | 2.4e-04 | 1.05 | 38.8K | 01:33:05 |  52.9%\n",
            "26450 | 4.5790 | 2.4e-04 | 1.05 | 38.8K | 01:33:07 |  52.9%\n",
            "26460 | 4.6230 | 2.4e-04 | 1.06 | 38.8K | 01:33:08 |  52.9%\n",
            "26470 | 4.0945 | 2.4e-04 | 1.03 | 38.8K | 01:33:10 |  52.9%\n",
            "26480 | 4.4008 | 2.4e-04 | 1.08 | 38.8K | 01:33:12 |  53.0%\n",
            "26490 | 4.5046 | 2.4e-04 | 1.07 | 38.8K | 01:33:14 |  53.0%\n",
            "26500 | 4.9096 | 2.4e-04 | 1.03 | 38.8K | 01:33:15 |  53.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 26500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.3809\n",
            "  Perplexity: 79.91\n",
            "  Train loss (avg): 4.4266\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        ların soğumaya başladığı bugünlerde, hava sıcaklığının en düşük seviyede olduğu; hava sıcaklığının en yüksek olduğu alanlar; hava sıcaklıklarının en yüksek olduğu alanlar; hava sıcaklığının en yüksek olduğu alanlar; hava sıcak\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        İstanbul'da, Türkiye'nin en çok ziyaret edilen ilçesi İzmir oldu. İzmir'de Atatürk Havalimanı'nın açılış töreni yapıldı. Türkiye'nin en büyük kentlerinden İzmir'in en büyük kenti İzmir\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        üzerine yapay zekanın kullanımı hakkında daha fazla bilgi vereceğiz. Yapay zekanın nasıl kullanıldığı konusu; Yapay zeka sistemlerinin insan zekasının nasıl ve nasıl kullanılacağı; Yapay zeka sistemlerinin insan zekasını nasıl kullanacağı;\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.3809)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:23:01\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "26510 | 4.4685 | 2.4e-04 | 1.03 | 38.6K | 01:33:38 |  53.0%\n",
            "26520 | 4.2007 | 2.4e-04 | 1.07 | 38.7K | 01:33:40 |  53.0%\n",
            "26530 | 4.4616 | 2.4e-04 | 1.04 | 38.7K | 01:33:42 |  53.1%\n",
            "26540 | 4.3625 | 2.4e-04 | 1.04 | 38.7K | 01:33:44 |  53.1%\n",
            "26550 | 4.4910 | 2.4e-04 | 1.04 | 38.7K | 01:33:45 |  53.1%\n",
            "26560 | 4.3125 | 2.4e-04 | 1.10 | 38.7K | 01:33:47 |  53.1%\n",
            "26570 | 4.6984 | 2.4e-04 | 1.09 | 38.7K | 01:33:49 |  53.1%\n",
            "26580 | 4.5687 | 2.4e-04 | 1.04 | 38.7K | 01:33:50 |  53.2%\n",
            "26590 | 4.4274 | 2.4e-04 | 1.08 | 38.7K | 01:33:52 |  53.2%\n",
            "26600 | 4.4058 | 2.4e-04 | 1.12 | 38.7K | 01:33:54 |  53.2%\n",
            "26610 | 4.3997 | 2.4e-04 | 1.05 | 38.7K | 01:33:56 |  53.2%\n",
            "26620 | 4.3545 | 2.4e-04 | 1.06 | 38.7K | 01:33:57 |  53.2%\n",
            "26630 | 4.4922 | 2.4e-04 | 1.17 | 38.7K | 01:33:59 |  53.3%\n",
            "26640 | 4.6459 | 2.4e-04 | 1.01 | 38.7K | 01:34:01 |  53.3%\n",
            "26650 | 4.6611 | 2.4e-04 | 1.03 | 38.7K | 01:34:02 |  53.3%\n",
            "26660 | 4.2754 | 2.4e-04 | 1.04 | 38.7K | 01:34:04 |  53.3%\n",
            "26670 | 4.6516 | 2.4e-04 | 1.05 | 38.7K | 01:34:06 |  53.3%\n",
            "26680 | 4.2850 | 2.4e-04 | 1.05 | 38.7K | 01:34:08 |  53.4%\n",
            "26690 | 4.3983 | 2.4e-04 | 1.06 | 38.7K | 01:34:09 |  53.4%\n",
            "26700 | 4.4790 | 2.4e-04 | 1.05 | 38.7K | 01:34:11 |  53.4%\n",
            "26710 | 4.2005 | 2.4e-04 | 1.30 | 38.7K | 01:34:13 |  53.4%\n",
            "26720 | 4.4759 | 2.4e-04 | 1.09 | 38.7K | 01:34:14 |  53.4%\n",
            "26730 | 4.1553 | 2.4e-04 | 1.09 | 38.7K | 01:34:16 |  53.5%\n",
            "26740 | 4.3243 | 2.4e-04 | 1.06 | 38.7K | 01:34:18 |  53.5%\n",
            "26750 | 4.6505 | 2.4e-04 | 1.11 | 38.7K | 01:34:20 |  53.5%\n",
            "26760 | 4.4899 | 2.4e-04 | 1.05 | 38.7K | 01:34:21 |  53.5%\n",
            "26770 | 4.6099 | 2.4e-04 | 1.05 | 38.7K | 01:34:23 |  53.5%\n",
            "26780 | 4.7675 | 2.4e-04 | 1.05 | 38.7K | 01:34:25 |  53.6%\n",
            "26790 | 4.5377 | 2.4e-04 | 1.04 | 38.7K | 01:34:26 |  53.6%\n",
            "26800 | 4.4142 | 2.4e-04 | 1.02 | 38.7K | 01:34:28 |  53.6%\n",
            "26810 | 4.0552 | 2.4e-04 | 1.18 | 38.7K | 01:34:30 |  53.6%\n",
            "26820 | 4.4081 | 2.4e-04 | 1.06 | 38.7K | 01:34:32 |  53.6%\n",
            "26830 | 4.5344 | 2.4e-04 | 1.13 | 38.7K | 01:34:33 |  53.7%\n",
            "26840 | 4.4313 | 2.4e-04 | 1.06 | 38.7K | 01:34:35 |  53.7%\n",
            "26850 | 4.5340 | 2.4e-04 | 1.05 | 38.7K | 01:34:37 |  53.7%\n",
            "26860 | 4.4468 | 2.4e-04 | 1.12 | 38.7K | 01:34:38 |  53.7%\n",
            "26870 | 4.1389 | 2.4e-04 | 1.01 | 38.7K | 01:34:40 |  53.7%\n",
            "26880 | 4.1820 | 2.4e-04 | 1.04 | 38.8K | 01:34:42 |  53.8%\n",
            "26890 | 4.3684 | 2.4e-04 | 1.06 | 38.8K | 01:34:44 |  53.8%\n",
            "26900 | 4.5434 | 2.4e-04 | 1.05 | 38.8K | 01:34:45 |  53.8%\n",
            "26910 | 4.2145 | 2.4e-04 | 1.08 | 38.8K | 01:34:47 |  53.8%\n",
            "26920 | 4.5478 | 2.3e-04 | 1.05 | 38.8K | 01:34:49 |  53.8%\n",
            "26930 | 4.5672 | 2.3e-04 | 1.06 | 38.8K | 01:34:50 |  53.9%\n",
            "26940 | 4.1442 | 2.3e-04 | 1.31 | 38.8K | 01:34:52 |  53.9%\n",
            "26950 | 4.3847 | 2.3e-04 | 1.07 | 38.8K | 01:34:54 |  53.9%\n",
            "26960 | 4.2845 | 2.3e-04 | 1.16 | 38.8K | 01:34:56 |  53.9%\n",
            "26970 | 4.4144 | 2.3e-04 | 1.07 | 38.8K | 01:34:57 |  53.9%\n",
            "26980 | 4.5813 | 2.3e-04 | 1.10 | 38.8K | 01:34:59 |  54.0%\n",
            "26990 | 4.6563 | 2.3e-04 | 1.08 | 38.8K | 01:35:01 |  54.0%\n",
            "27000 | 4.3758 | 2.3e-04 | 1.05 | 38.8K | 01:35:02 |  54.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 27000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.4084\n",
            "  Perplexity: 82.14\n",
            "  Train loss (avg): 4.4218\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        durumu ve ilk yardımlar ne zaman? Hava durumu ve hava durumu tahmin ediliyor. Hava durumu tahminleri belli oluyor. Hava durumu tahminleri belli oluyor. Hava durumu tahminleri belli oluyor. Hava durumu tahmin\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        olan İstanbul'da 11 Eylül Perşembe günü başlayan sağanak yağışla birlikte, İstanbul'da da İstanbul'da da hissedilecek sağanak yağışla birlikte, İstanbul'un ... Türkiye'nin ilk ve tek kuruluş\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        en büyük güçler ve dünya liderlerinin dünya pazarları ve küresel pazara verdiği önemin bir sonucu olarak, ülkelerin başarıyla uluslararası pazarda yer almasını sağlayacak bir sistem kurmak ve geliştirmek ve ticaret için gereken teknolojik imkan ve kapasit\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:21:12\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "27010 | 4.3542 | 2.3e-04 | 1.14 | 38.7K | 01:35:21 |  54.0%\n",
            "27020 | 4.4864 | 2.3e-04 | 1.05 | 38.7K | 01:35:23 |  54.0%\n",
            "27030 | 4.3664 | 2.3e-04 | 1.05 | 38.7K | 01:35:25 |  54.1%\n",
            "27040 | 4.5579 | 2.3e-04 | 1.07 | 38.7K | 01:35:27 |  54.1%\n",
            "27050 | 4.6841 | 2.3e-04 | 1.07 | 38.7K | 01:35:28 |  54.1%\n",
            "27060 | 4.0402 | 2.3e-04 | 1.02 | 38.7K | 01:35:30 |  54.1%\n",
            "27070 | 4.5767 | 2.3e-04 | 1.07 | 38.7K | 01:35:32 |  54.1%\n",
            "27080 | 4.3971 | 2.3e-04 | 1.05 | 38.7K | 01:35:33 |  54.2%\n",
            "27090 | 4.2397 | 2.3e-04 | 1.07 | 38.7K | 01:35:35 |  54.2%\n",
            "27100 | 4.0494 | 2.3e-04 | 1.12 | 38.7K | 01:35:37 |  54.2%\n",
            "27110 | 4.4306 | 2.3e-04 | 1.07 | 38.7K | 01:35:39 |  54.2%\n",
            "27120 | 4.6121 | 2.3e-04 | 1.04 | 38.7K | 01:35:40 |  54.2%\n",
            "27130 | 4.5370 | 2.3e-04 | 1.10 | 38.7K | 01:35:42 |  54.3%\n",
            "27140 | 4.3212 | 2.3e-04 | 1.06 | 38.7K | 01:35:44 |  54.3%\n",
            "27150 | 4.5467 | 2.3e-04 | 1.06 | 38.7K | 01:35:45 |  54.3%\n",
            "27160 | 4.1922 | 2.3e-04 | 1.09 | 38.7K | 01:35:47 |  54.3%\n",
            "27170 | 4.2918 | 2.3e-04 | 1.03 | 38.7K | 01:35:49 |  54.3%\n",
            "27180 | 4.5409 | 2.3e-04 | 1.06 | 38.7K | 01:35:51 |  54.4%\n",
            "27190 | 4.3314 | 2.3e-04 | 1.09 | 38.7K | 01:35:52 |  54.4%\n",
            "27200 | 4.5300 | 2.3e-04 | 1.03 | 38.7K | 01:35:54 |  54.4%\n",
            "27210 | 4.7729 | 2.3e-04 | 1.09 | 38.7K | 01:35:56 |  54.4%\n",
            "27220 | 4.4151 | 2.3e-04 | 1.06 | 38.7K | 01:35:57 |  54.4%\n",
            "27230 | 4.5606 | 2.3e-04 | 1.08 | 38.7K | 01:35:59 |  54.5%\n",
            "27240 | 4.2502 | 2.3e-04 | 1.05 | 38.7K | 01:36:01 |  54.5%\n",
            "27250 | 4.0978 | 2.3e-04 | 1.08 | 38.7K | 01:36:02 |  54.5%\n",
            "27260 | 4.5887 | 2.3e-04 | 1.08 | 38.7K | 01:36:04 |  54.5%\n",
            "27270 | 4.4770 | 2.3e-04 | 1.11 | 38.7K | 01:36:06 |  54.5%\n",
            "27280 | 4.0643 | 2.3e-04 | 1.10 | 38.7K | 01:36:08 |  54.6%\n",
            "27290 | 4.1851 | 2.3e-04 | 1.09 | 38.7K | 01:36:09 |  54.6%\n",
            "27300 | 4.6204 | 2.3e-04 | 1.07 | 38.7K | 01:36:11 |  54.6%\n",
            "27310 | 4.3611 | 2.3e-04 | 1.22 | 38.8K | 01:36:13 |  54.6%\n",
            "27320 | 4.3750 | 2.3e-04 | 1.06 | 38.8K | 01:36:14 |  54.6%\n",
            "27330 | 4.7436 | 2.3e-04 | 1.04 | 38.8K | 01:36:16 |  54.7%\n",
            "27340 | 4.3679 | 2.3e-04 | 1.07 | 38.8K | 01:36:18 |  54.7%\n",
            "27350 | 4.5385 | 2.3e-04 | 1.07 | 38.8K | 01:36:20 |  54.7%\n",
            "27360 | 4.6232 | 2.3e-04 | 1.08 | 38.8K | 01:36:21 |  54.7%\n",
            "27370 | 4.4698 | 2.3e-04 | 1.04 | 38.8K | 01:36:23 |  54.7%\n",
            "27380 | 4.4231 | 2.3e-04 | 1.06 | 38.8K | 01:36:25 |  54.8%\n",
            "27390 | 4.3634 | 2.3e-04 | 1.10 | 38.8K | 01:36:26 |  54.8%\n",
            "27400 | 4.5302 | 2.3e-04 | 1.06 | 38.8K | 01:36:28 |  54.8%\n",
            "27410 | 4.1306 | 2.3e-04 | 1.04 | 38.8K | 01:36:30 |  54.8%\n",
            "27420 | 4.1475 | 2.3e-04 | 1.17 | 38.8K | 01:36:32 |  54.8%\n",
            "27430 | 4.5225 | 2.3e-04 | 1.11 | 38.8K | 01:36:33 |  54.9%\n",
            "27440 | 4.3497 | 2.3e-04 | 1.05 | 38.8K | 01:36:35 |  54.9%\n",
            "27450 | 4.8504 | 2.3e-04 | 1.07 | 38.8K | 01:36:37 |  54.9%\n",
            "27460 | 4.4637 | 2.3e-04 | 1.07 | 38.8K | 01:36:38 |  54.9%\n",
            "27470 | 4.5468 | 2.3e-04 | 1.07 | 38.8K | 01:36:40 |  54.9%\n",
            "27480 | 4.1757 | 2.3e-04 | 1.05 | 38.8K | 01:36:42 |  55.0%\n",
            "27490 | 4.2084 | 2.3e-04 | 1.07 | 38.8K | 01:36:44 |  55.0%\n",
            "27500 | 4.3143 | 2.3e-04 | 1.09 | 38.8K | 01:36:45 |  55.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 27500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.3565\n",
            "  Perplexity: 77.99\n",
            "  Train loss (avg): 4.3854\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        ların ısınmasıyla beraber, havaların soğuk olması ve su emiliminin artması nedeniyle kış aylarında soğuk hava almaya ve kış aylarında soğuk hava ile içildikleri için soğuk hava dalgasını engellemeye devam ederken,\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        dir. Bu ülkede yaşayan, üreten, üreten, üreten, üreten, üreten, büyüyen bir millet yoktur. Bizim derdimiz de burası. Bunun için her türlü yolu tercih ettik. Yıllardır terör örgütü ile mücadele\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        artık robotlar, robotlar, robotlar ve robotlar üzerinde çalışabilecek. Yapay zeka teknolojisi artık robotlar ve robotlar üzerinde çalışabilecek. Yapay zekalı robotlar, robotlar ve robotlar\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.3565)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:19:27\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "27510 | 4.2125 | 2.3e-04 | 1.05 | 38.7K | 01:37:08 |  55.0%\n",
            "27520 | 4.4141 | 2.3e-04 | 1.13 | 38.7K | 01:37:09 |  55.0%\n",
            "27530 | 4.2854 | 2.3e-04 | 1.14 | 38.7K | 01:37:11 |  55.1%\n",
            "27540 | 4.3136 | 2.2e-04 | 1.09 | 38.7K | 01:37:13 |  55.1%\n",
            "27550 | 4.3519 | 2.2e-04 | 1.12 | 38.7K | 01:37:14 |  55.1%\n",
            "27560 | 4.4450 | 2.2e-04 | 1.08 | 38.7K | 01:37:16 |  55.1%\n",
            "27570 | 4.0077 | 2.2e-04 | 1.08 | 38.7K | 01:37:18 |  55.1%\n",
            "27580 | 4.3320 | 2.2e-04 | 1.15 | 38.7K | 01:37:20 |  55.2%\n",
            "27590 | 4.4343 | 2.2e-04 | 1.05 | 38.7K | 01:37:21 |  55.2%\n",
            "27600 | 4.5971 | 2.2e-04 | 1.09 | 38.7K | 01:37:23 |  55.2%\n",
            "27610 | 4.1517 | 2.2e-04 | 1.10 | 38.7K | 01:37:25 |  55.2%\n",
            "27620 | 4.7222 | 2.2e-04 | 1.09 | 38.7K | 01:37:26 |  55.2%\n",
            "27630 | 4.3565 | 2.2e-04 | 1.10 | 38.7K | 01:37:28 |  55.3%\n",
            "27640 | 4.3519 | 2.2e-04 | 1.08 | 38.7K | 01:37:30 |  55.3%\n",
            "27650 | 4.4694 | 2.2e-04 | 1.07 | 38.7K | 01:37:32 |  55.3%\n",
            "27660 | 4.5186 | 2.2e-04 | 1.09 | 38.7K | 01:37:33 |  55.3%\n",
            "27670 | 3.9868 | 2.2e-04 | 1.14 | 38.7K | 01:37:35 |  55.3%\n",
            "27680 | 4.5449 | 2.2e-04 | 1.07 | 38.7K | 01:37:37 |  55.4%\n",
            "27690 | 4.4005 | 2.2e-04 | 1.12 | 38.7K | 01:37:38 |  55.4%\n",
            "27700 | 4.1424 | 2.2e-04 | 1.12 | 38.7K | 01:37:40 |  55.4%\n",
            "27710 | 4.5009 | 2.2e-04 | 1.08 | 38.7K | 01:37:42 |  55.4%\n",
            "27720 | 4.3996 | 2.2e-04 | 1.10 | 38.7K | 01:37:44 |  55.4%\n",
            "27730 | 4.2814 | 2.2e-04 | 1.16 | 38.7K | 01:37:45 |  55.5%\n",
            "27740 | 4.1813 | 2.2e-04 | 1.09 | 38.7K | 01:37:47 |  55.5%\n",
            "27750 | 4.3236 | 2.2e-04 | 1.08 | 38.7K | 01:37:49 |  55.5%\n",
            "27760 | 4.6989 | 2.2e-04 | 1.06 | 38.7K | 01:37:50 |  55.5%\n",
            "27770 | 4.3123 | 2.2e-04 | 1.08 | 38.7K | 01:37:52 |  55.5%\n",
            "27780 | 4.2333 | 2.2e-04 | 1.09 | 38.7K | 01:37:54 |  55.6%\n",
            "27790 | 4.4881 | 2.2e-04 | 1.09 | 38.7K | 01:37:56 |  55.6%\n",
            "27800 | 4.3456 | 2.2e-04 | 1.09 | 38.7K | 01:37:57 |  55.6%\n",
            "27810 | 4.5264 | 2.2e-04 | 1.08 | 38.7K | 01:37:59 |  55.6%\n",
            "27820 | 4.1783 | 2.2e-04 | 1.08 | 38.8K | 01:38:01 |  55.6%\n",
            "27830 | 4.5626 | 2.2e-04 | 1.08 | 38.8K | 01:38:02 |  55.7%\n",
            "27840 | 4.4974 | 2.2e-04 | 1.10 | 38.8K | 01:38:04 |  55.7%\n",
            "27850 | 4.6005 | 2.2e-04 | 1.07 | 38.8K | 01:38:06 |  55.7%\n",
            "27860 | 4.3858 | 2.2e-04 | 1.06 | 38.8K | 01:38:08 |  55.7%\n",
            "27870 | 4.2982 | 2.2e-04 | 1.14 | 38.8K | 01:38:09 |  55.7%\n",
            "27880 | 4.2890 | 2.2e-04 | 1.08 | 38.8K | 01:38:11 |  55.8%\n",
            "27890 | 4.6054 | 2.2e-04 | 1.08 | 38.8K | 01:38:13 |  55.8%\n",
            "27900 | 4.6497 | 2.2e-04 | 1.10 | 38.8K | 01:38:14 |  55.8%\n",
            "27910 | 4.5458 | 2.2e-04 | 1.07 | 38.8K | 01:38:16 |  55.8%\n",
            "27920 | 4.5774 | 2.2e-04 | 1.06 | 38.8K | 01:38:18 |  55.8%\n",
            "27930 | 4.6642 | 2.2e-04 | 1.14 | 38.8K | 01:38:20 |  55.9%\n",
            "27940 | 4.4224 | 2.2e-04 | 1.10 | 38.8K | 01:38:21 |  55.9%\n",
            "27950 | 4.6081 | 2.2e-04 | 1.11 | 38.8K | 01:38:23 |  55.9%\n",
            "27960 | 4.4019 | 2.2e-04 | 1.07 | 38.8K | 01:38:25 |  55.9%\n",
            "27970 | 4.2718 | 2.2e-04 | 1.09 | 38.8K | 01:38:26 |  55.9%\n",
            "27980 | 4.5962 | 2.2e-04 | 1.10 | 38.8K | 01:38:28 |  56.0%\n",
            "27990 | 4.4450 | 2.2e-04 | 1.10 | 38.8K | 01:38:30 |  56.0%\n",
            "28000 | 4.4702 | 2.2e-04 | 1.07 | 38.8K | 01:38:31 |  56.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 28000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.3496\n",
            "  Perplexity: 77.45\n",
            "  Train loss (avg): 4.4150\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        ların da parçalı bulutlu olması nedeniyle sabah saat 18.00 sıralarında devam eden orman yangınında yaşamını yitirdi. Atiker Konyaspor'da arama ve bankalara saldırı! Dünyada 400 milyon kişi hayatını kaybetti Atik\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        olan İstanbul'un coğrafi konumu itibariyle dünyanın en büyük kenti olan İstanbul'un tarihi konumunu göstermektedir. İstanbul, Osmanlı’nın ilk başkenti olma özelliğini kaybetmesine rağmen, İstanbul’un tarihi açıdan en zengin kenti\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , bilimsel veri ve yapay zeka işlemleriyle doğrudan işlem yapılabilen bir teknolojidir. Temel ihtiyaç olan akıllı bilgisayarlar, akıllı telefonlar ve tabletlerin ekranları, net veya net olarak net olarak görebilmektedir. S\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.3496)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:17:41\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "28010 | 4.3299 | 2.2e-04 | 1.06 | 38.7K | 01:38:54 |  56.0%\n",
            "28020 | 4.4673 | 2.2e-04 | 1.11 | 38.7K | 01:38:56 |  56.0%\n",
            "28030 | 4.4206 | 2.2e-04 | 1.14 | 38.7K | 01:38:57 |  56.1%\n",
            "28040 | 4.4577 | 2.2e-04 | 1.07 | 38.7K | 01:38:59 |  56.1%\n",
            "28050 | 4.4322 | 2.2e-04 | 1.07 | 38.7K | 01:39:01 |  56.1%\n",
            "28060 | 4.4835 | 2.2e-04 | 1.10 | 38.7K | 01:39:02 |  56.1%\n",
            "28070 | 4.2852 | 2.2e-04 | 1.08 | 38.7K | 01:39:04 |  56.1%\n",
            "28080 | 4.2009 | 2.2e-04 | 1.11 | 38.7K | 01:39:06 |  56.2%\n",
            "28090 | 4.4297 | 2.2e-04 | 1.08 | 38.7K | 01:39:08 |  56.2%\n",
            "28100 | 4.4969 | 2.2e-04 | 1.09 | 38.7K | 01:39:09 |  56.2%\n",
            "28110 | 4.5265 | 2.2e-04 | 1.09 | 38.7K | 01:39:11 |  56.2%\n",
            "28120 | 4.3723 | 2.2e-04 | 1.12 | 38.7K | 01:39:13 |  56.2%\n",
            "28130 | 4.2510 | 2.2e-04 | 1.11 | 38.7K | 01:39:14 |  56.3%\n",
            "28140 | 4.2755 | 2.2e-04 | 1.09 | 38.7K | 01:39:16 |  56.3%\n",
            "28150 | 4.1501 | 2.1e-04 | 1.05 | 38.7K | 01:39:18 |  56.3%\n",
            "28160 | 4.5018 | 2.1e-04 | 1.08 | 38.7K | 01:39:20 |  56.3%\n",
            "28170 | 4.5858 | 2.1e-04 | 1.08 | 38.7K | 01:39:21 |  56.3%\n",
            "28180 | 3.9864 | 2.1e-04 | 1.16 | 38.7K | 01:39:23 |  56.4%\n",
            "28190 | 4.6536 | 2.1e-04 | 1.13 | 38.7K | 01:39:25 |  56.4%\n",
            "28200 | 4.4664 | 2.1e-04 | 1.11 | 38.7K | 01:39:26 |  56.4%\n",
            "28210 | 4.4279 | 2.1e-04 | 1.06 | 38.7K | 01:39:28 |  56.4%\n",
            "28220 | 4.6039 | 2.1e-04 | 1.10 | 38.7K | 01:39:30 |  56.4%\n",
            "28230 | 4.0997 | 2.1e-04 | 1.15 | 38.7K | 01:39:32 |  56.5%\n",
            "28240 | 4.3326 | 2.1e-04 | 1.07 | 38.7K | 01:39:33 |  56.5%\n",
            "28250 | 4.0617 | 2.1e-04 | 1.17 | 38.7K | 01:39:35 |  56.5%\n",
            "28260 | 4.5421 | 2.1e-04 | 1.10 | 38.7K | 01:39:37 |  56.5%\n",
            "28270 | 4.5992 | 2.1e-04 | 1.16 | 38.7K | 01:39:38 |  56.5%\n",
            "28280 | 4.2637 | 2.1e-04 | 1.07 | 38.7K | 01:39:40 |  56.6%\n",
            "28290 | 4.1698 | 2.1e-04 | 1.09 | 38.7K | 01:39:42 |  56.6%\n",
            "28300 | 4.5883 | 2.1e-04 | 1.11 | 38.7K | 01:39:43 |  56.6%\n",
            "28310 | 4.6175 | 2.1e-04 | 1.13 | 38.7K | 01:39:45 |  56.6%\n",
            "28320 | 4.4297 | 2.1e-04 | 1.08 | 38.7K | 01:39:47 |  56.6%\n",
            "28330 | 4.7020 | 2.1e-04 | 1.11 | 38.8K | 01:39:49 |  56.7%\n",
            "28340 | 4.0984 | 2.1e-04 | 1.07 | 38.8K | 01:39:50 |  56.7%\n",
            "28350 | 4.4577 | 2.1e-04 | 1.10 | 38.8K | 01:39:52 |  56.7%\n",
            "28360 | 4.4787 | 2.1e-04 | 1.06 | 38.8K | 01:39:54 |  56.7%\n",
            "28370 | 4.6230 | 2.1e-04 | 1.14 | 38.8K | 01:39:55 |  56.7%\n",
            "28380 | 4.0736 | 2.1e-04 | 1.10 | 38.8K | 01:39:57 |  56.8%\n",
            "28390 | 4.5204 | 2.1e-04 | 1.09 | 38.8K | 01:39:59 |  56.8%\n",
            "28400 | 4.4640 | 2.1e-04 | 1.11 | 38.8K | 01:40:01 |  56.8%\n",
            "28410 | 4.4275 | 2.1e-04 | 1.11 | 38.8K | 01:40:02 |  56.8%\n",
            "28420 | 4.2439 | 2.1e-04 | 1.11 | 38.8K | 01:40:04 |  56.8%\n",
            "28430 | 4.4443 | 2.1e-04 | 1.04 | 38.8K | 01:40:06 |  56.9%\n",
            "28440 | 4.4549 | 2.1e-04 | 1.06 | 38.8K | 01:40:07 |  56.9%\n",
            "28450 | 4.4655 | 2.1e-04 | 1.08 | 38.8K | 01:40:09 |  56.9%\n",
            "28460 | 4.3259 | 2.1e-04 | 1.10 | 38.8K | 01:40:11 |  56.9%\n",
            "28470 | 4.3634 | 2.1e-04 | 1.09 | 38.8K | 01:40:13 |  56.9%\n",
            "28480 | 4.4128 | 2.1e-04 | 1.07 | 38.8K | 01:40:14 |  57.0%\n",
            "28490 | 4.3736 | 2.1e-04 | 1.08 | 38.8K | 01:40:16 |  57.0%\n",
            "28500 | 4.3781 | 2.1e-04 | 1.12 | 38.8K | 01:40:18 |  57.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 28500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.3624\n",
            "  Perplexity: 78.44\n",
            "  Train loss (avg): 4.4049\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        ların ısınmasıyla birlikte havaların ısınmasıyla birlikte hava sıcaklığının yükselmesi bu yolla da gerçekleşti. Peki hava sıcaklıklarının bir çok nedeni olabilir? Bilemiyorum. Bazı ülkeler hava sıcaklıkları sebebiyle hava sıcaklıklarında artış\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        olan Sabiha Gökçen Havalimanı'na Türk hava araçlarıyla ulaşım sağlanabiliyor. Havalimanında saat 19:30'da Atatürk Havalimanı'nda saat 19.00'da Atatürk Havalimanı'na gelen yolculardan bir tanesi saat 19\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , teknolojinin kolay ve ucuz olduğu dönemde insanların bir araya gelişinden çok daha ileri yaşlarda kullanabilecekleri bir teknoloji haline gelmişti. Türkiye’de bu teknolojinin aslında bilgisayarlara göre çok daha hızlı olduğu ve cihazlara göre\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:15:53\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "28510 | 4.4004 | 2.1e-04 | 1.07 | 38.7K | 01:40:37 |  57.0%\n",
            "28520 | 4.4015 | 2.1e-04 | 1.09 | 38.7K | 01:40:38 |  57.0%\n",
            "28530 | 4.4915 | 2.1e-04 | 1.07 | 38.7K | 01:40:40 |  57.1%\n",
            "28540 | 4.4874 | 2.1e-04 | 1.14 | 38.7K | 01:40:42 |  57.1%\n",
            "28550 | 4.5499 | 2.1e-04 | 1.06 | 38.7K | 01:40:44 |  57.1%\n",
            "28560 | 4.5785 | 2.1e-04 | 1.07 | 38.7K | 01:40:45 |  57.1%\n",
            "28570 | 4.5574 | 2.1e-04 | 1.07 | 38.7K | 01:40:47 |  57.1%\n",
            "28580 | 4.3316 | 2.1e-04 | 1.15 | 38.7K | 01:40:49 |  57.2%\n",
            "28590 | 4.3888 | 2.1e-04 | 1.32 | 38.7K | 01:40:50 |  57.2%\n",
            "28600 | 4.4752 | 2.1e-04 | 1.05 | 38.7K | 01:40:52 |  57.2%\n",
            "28610 | 4.4082 | 2.1e-04 | 1.07 | 38.7K | 01:40:54 |  57.2%\n",
            "28620 | 4.6260 | 2.1e-04 | 1.08 | 38.7K | 01:40:56 |  57.2%\n",
            "28630 | 4.2715 | 2.1e-04 | 1.08 | 38.7K | 01:40:57 |  57.3%\n",
            "28640 | 4.4811 | 2.1e-04 | 1.10 | 38.7K | 01:40:59 |  57.3%\n",
            "28650 | 4.3569 | 2.1e-04 | 1.08 | 38.7K | 01:41:01 |  57.3%\n",
            "28660 | 4.5119 | 2.1e-04 | 1.17 | 38.7K | 01:41:02 |  57.3%\n",
            "28670 | 4.4954 | 2.1e-04 | 1.11 | 38.7K | 01:41:04 |  57.3%\n",
            "28680 | 3.9993 | 2.1e-04 | 1.15 | 38.7K | 01:41:06 |  57.4%\n",
            "28690 | 4.4974 | 2.1e-04 | 1.08 | 38.7K | 01:41:08 |  57.4%\n",
            "28700 | 4.3855 | 2.1e-04 | 1.18 | 38.7K | 01:41:09 |  57.4%\n",
            "28710 | 4.4323 | 2.1e-04 | 1.12 | 38.7K | 01:41:11 |  57.4%\n",
            "28720 | 4.5345 | 2.1e-04 | 1.08 | 38.7K | 01:41:13 |  57.4%\n",
            "28730 | 4.2679 | 2.1e-04 | 1.10 | 38.7K | 01:41:14 |  57.5%\n",
            "28740 | 4.5319 | 2.1e-04 | 1.06 | 38.7K | 01:41:16 |  57.5%\n",
            "28750 | 4.2380 | 2.1e-04 | 1.06 | 38.7K | 01:41:18 |  57.5%\n",
            "28760 | 4.2934 | 2.1e-04 | 1.11 | 38.8K | 01:41:19 |  57.5%\n",
            "28770 | 4.2176 | 2.0e-04 | 1.09 | 38.8K | 01:41:21 |  57.5%\n",
            "28780 | 4.6593 | 2.0e-04 | 1.10 | 38.8K | 01:41:23 |  57.6%\n",
            "28790 | 4.5403 | 2.0e-04 | 1.06 | 38.8K | 01:41:25 |  57.6%\n",
            "28800 | 4.3027 | 2.0e-04 | 1.12 | 38.8K | 01:41:26 |  57.6%\n",
            "28810 | 4.4477 | 2.0e-04 | 1.08 | 38.8K | 01:41:28 |  57.6%\n",
            "28820 | 4.2132 | 2.0e-04 | 1.11 | 38.8K | 01:41:30 |  57.6%\n",
            "28830 | 4.2576 | 2.0e-04 | 1.14 | 38.8K | 01:41:31 |  57.7%\n",
            "28840 | 4.3327 | 2.0e-04 | 1.46 | 38.8K | 01:41:33 |  57.7%\n",
            "28850 | 4.2319 | 2.0e-04 | 1.06 | 38.8K | 01:41:35 |  57.7%\n",
            "28860 | 4.2109 | 2.0e-04 | 1.11 | 38.8K | 01:41:37 |  57.7%\n",
            "28870 | 4.6300 | 2.0e-04 | 1.09 | 38.8K | 01:41:38 |  57.7%\n",
            "28880 | 4.0845 | 2.0e-04 | 1.18 | 38.8K | 01:41:40 |  57.8%\n",
            "28890 | 4.4777 | 2.0e-04 | 1.15 | 38.8K | 01:41:42 |  57.8%\n",
            "28900 | 4.1114 | 2.0e-04 | 1.17 | 38.8K | 01:41:43 |  57.8%\n",
            "28910 | 4.5255 | 2.0e-04 | 1.11 | 38.8K | 01:41:45 |  57.8%\n",
            "28920 | 4.4597 | 2.0e-04 | 1.06 | 38.8K | 01:41:47 |  57.8%\n",
            "28930 | 4.3859 | 2.0e-04 | 1.11 | 38.8K | 01:41:49 |  57.9%\n",
            "28940 | 4.3524 | 2.0e-04 | 1.10 | 38.8K | 01:41:50 |  57.9%\n",
            "28950 | 4.3344 | 2.0e-04 | 1.14 | 38.8K | 01:41:52 |  57.9%\n",
            "28960 | 4.2173 | 2.0e-04 | 1.39 | 38.8K | 01:41:54 |  57.9%\n",
            "28970 | 4.6315 | 2.0e-04 | 1.10 | 38.8K | 01:41:55 |  57.9%\n",
            "28980 | 4.2686 | 2.0e-04 | 1.11 | 38.8K | 01:41:57 |  58.0%\n",
            "28990 | 4.3475 | 2.0e-04 | 1.15 | 38.8K | 01:41:59 |  58.0%\n",
            "29000 | 4.5084 | 2.0e-04 | 1.06 | 38.8K | 01:42:01 |  58.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 29000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.3386\n",
            "  Perplexity: 76.60\n",
            "  Train loss (avg): 4.3875\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        ile ilgili bazı şeylerden uzak duruyorum. Alcantara mı, nerelerden nereye giderseniz gidin, kaybolmadınız. Bu yüzden yürüyüş yolları tercih ediyorum. Fakat groteskler ile ilgili\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        olan Ankara'da, bir dönem ev sahibi olan Kemal Kılıçdaroğlu'nun siyaset üzerinden kurduğu \"Sanal Haklar\" isimli dava nedeniyle dava açıldı. İzmir'de, \"Sanal Haklar\" adlı\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        ile bu teknolojiyi bir arada kullanan yapay zeka bu işletim sistemi ile yapay zeka için çok iyi bir teknoloji. Yapay zeka ve yapay zeka ve yapay zekayı da içeren yapay zeka, yapay zeka ile yapay zekanın\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.3386)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:14:07\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "29010 | 4.4722 | 2.0e-04 | 1.06 | 38.7K | 01:42:23 |  58.0%\n",
            "29020 | 4.3587 | 2.0e-04 | 1.12 | 38.7K | 01:42:25 |  58.0%\n",
            "29030 | 4.4067 | 2.0e-04 | 1.05 | 38.7K | 01:42:26 |  58.1%\n",
            "29040 | 4.4085 | 2.0e-04 | 1.14 | 38.7K | 01:42:28 |  58.1%\n",
            "29050 | 4.3226 | 2.0e-04 | 1.10 | 38.7K | 01:42:30 |  58.1%\n",
            "29060 | 4.4863 | 2.0e-04 | 1.11 | 38.7K | 01:42:31 |  58.1%\n",
            "29070 | 4.4072 | 2.0e-04 | 1.07 | 38.7K | 01:42:33 |  58.1%\n",
            "29080 | 4.5283 | 2.0e-04 | 1.09 | 38.7K | 01:42:35 |  58.2%\n",
            "29090 | 4.3500 | 2.0e-04 | 1.07 | 38.7K | 01:42:37 |  58.2%\n",
            "29100 | 4.3602 | 2.0e-04 | 1.12 | 38.7K | 01:42:38 |  58.2%\n",
            "29110 | 4.4449 | 2.0e-04 | 1.11 | 38.7K | 01:42:40 |  58.2%\n",
            "29120 | 4.3002 | 2.0e-04 | 1.18 | 38.7K | 01:42:42 |  58.2%\n",
            "29130 | 4.4559 | 2.0e-04 | 1.09 | 38.7K | 01:42:43 |  58.3%\n",
            "29140 | 4.5722 | 2.0e-04 | 1.14 | 38.7K | 01:42:45 |  58.3%\n",
            "29150 | 4.1397 | 2.0e-04 | 1.11 | 38.7K | 01:42:47 |  58.3%\n",
            "29160 | 4.3906 | 2.0e-04 | 1.13 | 38.7K | 01:42:49 |  58.3%\n",
            "29170 | 4.2117 | 2.0e-04 | 1.12 | 38.7K | 01:42:50 |  58.3%\n",
            "29180 | 4.6144 | 2.0e-04 | 1.10 | 38.7K | 01:42:52 |  58.4%\n",
            "29190 | 4.4748 | 2.0e-04 | 1.09 | 38.7K | 01:42:54 |  58.4%\n",
            "29200 | 4.3803 | 2.0e-04 | 1.12 | 38.7K | 01:42:55 |  58.4%\n",
            "29210 | 4.3174 | 2.0e-04 | 1.10 | 38.7K | 01:42:57 |  58.4%\n",
            "29220 | 4.2355 | 2.0e-04 | 1.16 | 38.7K | 01:42:59 |  58.4%\n",
            "29230 | 3.9920 | 2.0e-04 | 1.17 | 38.7K | 01:43:01 |  58.5%\n",
            "29240 | 4.2648 | 2.0e-04 | 1.13 | 38.7K | 01:43:02 |  58.5%\n",
            "29250 | 4.4587 | 2.0e-04 | 1.09 | 38.7K | 01:43:04 |  58.5%\n",
            "29260 | 4.4960 | 2.0e-04 | 1.09 | 38.7K | 01:43:06 |  58.5%\n",
            "29270 | 4.4074 | 2.0e-04 | 1.10 | 38.7K | 01:43:07 |  58.5%\n",
            "29280 | 4.6807 | 2.0e-04 | 1.11 | 38.8K | 01:43:09 |  58.6%\n",
            "29290 | 4.4409 | 2.0e-04 | 1.10 | 38.8K | 01:43:11 |  58.6%\n",
            "29300 | 4.4344 | 2.0e-04 | 1.12 | 38.8K | 01:43:13 |  58.6%\n",
            "29310 | 4.4763 | 2.0e-04 | 1.11 | 38.8K | 01:43:14 |  58.6%\n",
            "29320 | 4.2114 | 2.0e-04 | 1.09 | 38.8K | 01:43:16 |  58.6%\n",
            "29330 | 4.3583 | 2.0e-04 | 1.09 | 38.8K | 01:43:18 |  58.7%\n",
            "29340 | 4.1734 | 2.0e-04 | 1.10 | 38.8K | 01:43:19 |  58.7%\n",
            "29350 | 4.5802 | 2.0e-04 | 1.06 | 38.8K | 01:43:21 |  58.7%\n",
            "29360 | 4.0966 | 2.0e-04 | 1.08 | 38.8K | 01:43:23 |  58.7%\n",
            "29370 | 4.3963 | 2.0e-04 | 1.08 | 38.8K | 01:43:25 |  58.7%\n",
            "29380 | 4.7470 | 2.0e-04 | 1.10 | 38.8K | 01:43:26 |  58.8%\n",
            "29390 | 4.3479 | 2.0e-04 | 1.13 | 38.8K | 01:43:28 |  58.8%\n",
            "29400 | 4.2589 | 1.9e-04 | 1.10 | 38.8K | 01:43:30 |  58.8%\n",
            "29410 | 4.4168 | 1.9e-04 | 1.12 | 38.8K | 01:43:31 |  58.8%\n",
            "29420 | 4.3150 | 1.9e-04 | 1.12 | 38.8K | 01:43:33 |  58.8%\n",
            "29430 | 4.5878 | 1.9e-04 | 1.12 | 38.8K | 01:43:35 |  58.9%\n",
            "29440 | 4.4813 | 1.9e-04 | 1.12 | 38.8K | 01:43:37 |  58.9%\n",
            "29450 | 4.3646 | 1.9e-04 | 1.07 | 38.8K | 01:43:38 |  58.9%\n",
            "29460 | 4.4496 | 1.9e-04 | 1.07 | 38.8K | 01:43:40 |  58.9%\n",
            "29470 | 4.2092 | 1.9e-04 | 1.08 | 38.8K | 01:43:42 |  58.9%\n",
            "29480 | 4.1964 | 1.9e-04 | 1.12 | 38.8K | 01:43:43 |  59.0%\n",
            "29490 | 4.3344 | 1.9e-04 | 1.11 | 38.8K | 01:43:45 |  59.0%\n",
            "29500 | 4.4086 | 1.9e-04 | 1.08 | 38.8K | 01:43:47 |  59.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 29500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.3211\n",
            "  Perplexity: 75.27\n",
            "  Train loss (avg): 4.3933\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        koşulları nedeniyle 2020 yılına kadar ülkeler, hava koşulları nedeniyle yabancı ülke konumunda bulunuyor. Türkiye’nin Rusya ile ilgili en önemli sorunu, Rusya’nın Karadeniz Bölgesi’nde yaşadığı. Ancak Rusya’nın Karadeniz Bölgesi\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        İstanbul'da bir çok tarihi bölgeye ev sahipliği yapan güzel ve tarihi atmosferin yanı sıra şehrin her noktasında tarihi yapılar, tarihi yerleri gezip görmeniz mümkün. En güzel rotalardan birisi de tarihi bir gün geçirmek.\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        sayesinde, insanların %99’u ev ve iş yerinde rahat rahat konuşabiliyor, karşıdan gelen bir sese, ev ve iş yerinde sakin kalabiliyor ve yalnızlaşabiliyor. Aynı zamanda, sürekli çalışma\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.3211)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:12:21\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "29510 | 4.2877 | 1.9e-04 | 1.07 | 38.7K | 01:44:09 |  59.0%\n",
            "29520 | 4.4000 | 1.9e-04 | 1.10 | 38.7K | 01:44:11 |  59.0%\n",
            "29530 | 4.1803 | 1.9e-04 | 1.26 | 38.7K | 01:44:13 |  59.1%\n",
            "29540 | 4.3776 | 1.9e-04 | 1.07 | 38.7K | 01:44:14 |  59.1%\n",
            "29550 | 4.3802 | 1.9e-04 | 1.11 | 38.7K | 01:44:16 |  59.1%\n",
            "29560 | 4.4481 | 1.9e-04 | 1.09 | 38.7K | 01:44:18 |  59.1%\n",
            "29570 | 4.4616 | 1.9e-04 | 1.11 | 38.7K | 01:44:20 |  59.1%\n",
            "29580 | 4.4250 | 1.9e-04 | 1.09 | 38.7K | 01:44:21 |  59.2%\n",
            "29590 | 4.1818 | 1.9e-04 | 1.08 | 38.7K | 01:44:23 |  59.2%\n",
            "29600 | 4.3229 | 1.9e-04 | 1.11 | 38.7K | 01:44:25 |  59.2%\n",
            "29610 | 4.0889 | 1.9e-04 | 1.09 | 38.7K | 01:44:26 |  59.2%\n",
            "29620 | 4.7807 | 1.9e-04 | 1.14 | 38.7K | 01:44:28 |  59.2%\n",
            "29630 | 4.3663 | 1.9e-04 | 1.05 | 38.7K | 01:44:30 |  59.3%\n",
            "29640 | 4.5296 | 1.9e-04 | 1.12 | 38.7K | 01:44:31 |  59.3%\n",
            "29650 | 4.4948 | 1.9e-04 | 1.09 | 38.7K | 01:44:33 |  59.3%\n",
            "29660 | 4.4244 | 1.9e-04 | 1.09 | 38.7K | 01:44:35 |  59.3%\n",
            "29670 | 4.4300 | 1.9e-04 | 1.09 | 38.7K | 01:44:37 |  59.3%\n",
            "29680 | 4.5784 | 1.9e-04 | 1.17 | 38.7K | 01:44:38 |  59.4%\n",
            "29690 | 4.2627 | 1.9e-04 | 1.40 | 38.7K | 01:44:40 |  59.4%\n",
            "29700 | 4.4752 | 1.9e-04 | 1.12 | 38.7K | 01:44:42 |  59.4%\n",
            "29710 | 4.3992 | 1.9e-04 | 1.10 | 38.7K | 01:44:43 |  59.4%\n",
            "29720 | 4.4149 | 1.9e-04 | 1.13 | 38.7K | 01:44:45 |  59.4%\n",
            "29730 | 4.3205 | 1.9e-04 | 1.09 | 38.7K | 01:44:47 |  59.5%\n",
            "29740 | 4.4675 | 1.9e-04 | 1.16 | 38.7K | 01:44:49 |  59.5%\n",
            "29750 | 4.6212 | 1.9e-04 | 1.11 | 38.7K | 01:44:50 |  59.5%\n",
            "29760 | 4.1202 | 1.9e-04 | 1.09 | 38.7K | 01:44:52 |  59.5%\n",
            "29770 | 4.4166 | 1.9e-04 | 1.17 | 38.7K | 01:44:54 |  59.5%\n",
            "29780 | 4.3414 | 1.9e-04 | 1.12 | 38.7K | 01:44:55 |  59.6%\n",
            "29790 | 4.4278 | 1.9e-04 | 1.11 | 38.8K | 01:44:57 |  59.6%\n",
            "29800 | 4.2335 | 1.9e-04 | 1.10 | 38.8K | 01:44:59 |  59.6%\n",
            "29810 | 4.4270 | 1.9e-04 | 1.15 | 38.8K | 01:45:01 |  59.6%\n",
            "29820 | 4.3103 | 1.9e-04 | 1.09 | 38.8K | 01:45:02 |  59.6%\n",
            "29830 | 4.6672 | 1.9e-04 | 1.09 | 38.8K | 01:45:04 |  59.7%\n",
            "29840 | 4.2594 | 1.9e-04 | 1.13 | 38.8K | 01:45:06 |  59.7%\n",
            "29850 | 4.4466 | 1.9e-04 | 1.09 | 38.8K | 01:45:07 |  59.7%\n",
            "29860 | 4.3849 | 1.9e-04 | 1.08 | 38.8K | 01:45:09 |  59.7%\n",
            "29870 | 4.1396 | 1.9e-04 | 1.16 | 38.8K | 01:45:11 |  59.7%\n",
            "29880 | 4.2981 | 1.9e-04 | 1.41 | 38.8K | 01:45:13 |  59.8%\n",
            "29890 | 4.1751 | 1.9e-04 | 1.16 | 38.8K | 01:45:14 |  59.8%\n",
            "29900 | 4.7683 | 1.9e-04 | 1.08 | 38.8K | 01:45:16 |  59.8%\n",
            "29910 | 4.5355 | 1.9e-04 | 1.09 | 38.8K | 01:45:18 |  59.8%\n",
            "29920 | 4.5262 | 1.9e-04 | 1.10 | 38.8K | 01:45:19 |  59.8%\n",
            "29930 | 4.5118 | 1.9e-04 | 1.07 | 38.8K | 01:45:21 |  59.9%\n",
            "29940 | 4.3082 | 1.9e-04 | 1.11 | 38.8K | 01:45:23 |  59.9%\n",
            "29950 | 4.2146 | 1.9e-04 | 1.13 | 38.8K | 01:45:25 |  59.9%\n",
            "29960 | 4.3558 | 1.9e-04 | 1.11 | 38.8K | 01:45:26 |  59.9%\n",
            "29970 | 4.5977 | 1.9e-04 | 1.12 | 38.8K | 01:45:28 |  59.9%\n",
            "29980 | 4.3565 | 1.9e-04 | 1.20 | 38.8K | 01:45:30 |  60.0%\n",
            "29990 | 4.1924 | 1.9e-04 | 1.12 | 38.8K | 01:45:31 |  60.0%\n",
            "30000 | 4.5681 | 1.9e-04 | 1.10 | 38.8K | 01:45:33 |  60.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 30000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.3041\n",
            "  Perplexity: 74.00\n",
            "  Train loss (avg): 4.3720\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        sıcaklığının azaldığını, büyük bir ihtimalle batık havaların ısınması ile birlikte yağan yağmur nedeniyle buzlanma şeklinde devam ettiğini anlatan Gülşah, “Özellikle çok sıcak olan sıcaklarda buzlanma şeklinde devam\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        olan İstanbul'da altı gün boyunca, dost ve akrabalarla birlikte serin, huzurlu, mesut bir gün geçireceğiz. İstanbul'da, bir çok şehirde, bu şehirde, yeni arkadaşlar, yeni arkadaş\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        sayesinde, gelecek yıl öğrenme ve uygulama alanında kendinizi geliştirmek üzere çok daha fazla zaman ayırmayı amaçlayan bir girişimi daha; bu sayede hem zeka üzerinde hem de yenilikçilik konusunda daha fazla bilgi sahibi olacağınızı kaydeden Prof\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.3041)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:10:36\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "💾 Checkpoint kaydediliyor: /content/drive/MyDrive/turkish_llm/checkpoints//checkpoint_step_30000.pt\n",
            "  ✅ Checkpoint kaydedildi!\n",
            "\n",
            "30010 | 4.0440 | 1.9e-04 | 1.12 | 38.7K | 01:45:59 |  60.0%\n",
            "30020 | 4.2383 | 1.8e-04 | 1.12 | 38.7K | 01:46:00 |  60.0%\n",
            "30030 | 4.6060 | 1.8e-04 | 1.09 | 38.7K | 01:46:02 |  60.1%\n",
            "30040 | 4.5426 | 1.8e-04 | 1.11 | 38.7K | 01:46:04 |  60.1%\n",
            "30050 | 4.3690 | 1.8e-04 | 1.08 | 38.7K | 01:46:06 |  60.1%\n",
            "30060 | 4.0060 | 1.8e-04 | 1.12 | 38.7K | 01:46:07 |  60.1%\n",
            "30070 | 4.5575 | 1.8e-04 | 1.09 | 38.7K | 01:46:09 |  60.1%\n",
            "30080 | 4.3827 | 1.8e-04 | 1.10 | 38.7K | 01:46:11 |  60.2%\n",
            "30090 | 4.4537 | 1.8e-04 | 1.13 | 38.7K | 01:46:12 |  60.2%\n",
            "30100 | 4.1387 | 1.8e-04 | 1.22 | 38.7K | 01:46:14 |  60.2%\n",
            "30110 | 4.5401 | 1.8e-04 | 1.10 | 38.7K | 01:46:16 |  60.2%\n",
            "30120 | 4.4438 | 1.8e-04 | 1.13 | 38.7K | 01:46:18 |  60.2%\n",
            "30130 | 4.2095 | 1.8e-04 | 1.10 | 38.7K | 01:46:19 |  60.3%\n",
            "30140 | 4.5301 | 1.8e-04 | 1.13 | 38.7K | 01:46:21 |  60.3%\n",
            "30150 | 4.5653 | 1.8e-04 | 1.10 | 38.7K | 01:46:23 |  60.3%\n",
            "30160 | 4.5430 | 1.8e-04 | 1.13 | 38.7K | 01:46:24 |  60.3%\n",
            "30170 | 4.2418 | 1.8e-04 | 1.13 | 38.7K | 01:46:26 |  60.3%\n",
            "30180 | 4.3277 | 1.8e-04 | 1.18 | 38.7K | 01:46:28 |  60.4%\n",
            "30190 | 4.4629 | 1.8e-04 | 1.10 | 38.7K | 01:46:30 |  60.4%\n",
            "30200 | 4.2872 | 1.8e-04 | 1.12 | 38.7K | 01:46:31 |  60.4%\n",
            "30210 | 4.3645 | 1.8e-04 | 1.08 | 38.7K | 01:46:33 |  60.4%\n",
            "30220 | 4.4393 | 1.8e-04 | 1.23 | 38.7K | 01:46:35 |  60.4%\n",
            "30230 | 4.5245 | 1.8e-04 | 1.12 | 38.7K | 01:46:36 |  60.5%\n",
            "30240 | 4.4790 | 1.8e-04 | 1.12 | 38.7K | 01:46:38 |  60.5%\n",
            "30250 | 4.5447 | 1.8e-04 | 1.12 | 38.7K | 01:46:40 |  60.5%\n",
            "30260 | 4.4191 | 1.8e-04 | 1.11 | 38.7K | 01:46:42 |  60.5%\n",
            "30270 | 4.5118 | 1.8e-04 | 1.12 | 38.7K | 01:46:43 |  60.5%\n",
            "30280 | 4.1452 | 1.8e-04 | 1.08 | 38.7K | 01:46:45 |  60.6%\n",
            "30290 | 4.5705 | 1.8e-04 | 1.13 | 38.7K | 01:46:47 |  60.6%\n",
            "30300 | 4.4690 | 1.8e-04 | 1.14 | 38.7K | 01:46:48 |  60.6%\n",
            "30310 | 4.4353 | 1.8e-04 | 1.09 | 38.7K | 01:46:50 |  60.6%\n",
            "30320 | 4.4077 | 1.8e-04 | 1.12 | 38.7K | 01:46:52 |  60.6%\n",
            "30330 | 4.1506 | 1.8e-04 | 1.28 | 38.7K | 01:46:54 |  60.7%\n",
            "30340 | 4.4051 | 1.8e-04 | 1.11 | 38.7K | 01:46:55 |  60.7%\n",
            "30350 | 4.2033 | 1.8e-04 | 1.13 | 38.7K | 01:46:57 |  60.7%\n",
            "30360 | 4.4480 | 1.8e-04 | 1.09 | 38.7K | 01:46:59 |  60.7%\n",
            "30370 | 4.3051 | 1.8e-04 | 1.11 | 38.7K | 01:47:00 |  60.7%\n",
            "30380 | 4.5726 | 1.8e-04 | 1.15 | 38.7K | 01:47:02 |  60.8%\n",
            "30390 | 3.8685 | 1.8e-04 | 1.10 | 38.8K | 01:47:04 |  60.8%\n",
            "30400 | 4.3149 | 1.8e-04 | 1.24 | 38.8K | 01:47:06 |  60.8%\n",
            "30410 | 4.4192 | 1.8e-04 | 1.12 | 38.8K | 01:47:07 |  60.8%\n",
            "30420 | 4.5003 | 1.8e-04 | 1.13 | 38.8K | 01:47:09 |  60.8%\n",
            "30430 | 4.5187 | 1.8e-04 | 1.12 | 38.8K | 01:47:11 |  60.9%\n",
            "30440 | 4.4319 | 1.8e-04 | 1.11 | 38.8K | 01:47:12 |  60.9%\n",
            "30450 | 4.2214 | 1.8e-04 | 1.16 | 38.8K | 01:47:14 |  60.9%\n",
            "30460 | 4.3662 | 1.8e-04 | 1.14 | 38.8K | 01:47:16 |  60.9%\n",
            "30470 | 4.0117 | 1.8e-04 | 1.12 | 38.8K | 01:47:18 |  60.9%\n",
            "30480 | 4.5187 | 1.8e-04 | 1.19 | 38.8K | 01:47:19 |  61.0%\n",
            "30490 | 4.4263 | 1.8e-04 | 1.13 | 38.8K | 01:47:21 |  61.0%\n",
            "30500 | 4.2350 | 1.8e-04 | 1.13 | 38.8K | 01:47:23 |  61.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 30500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.3021\n",
            "  Perplexity: 73.85\n",
            "  Train loss (avg): 4.3278\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        şartları açısından etkili olan kar yağışının ardından bölgede ciddi bir iyileşme sürecine girilirken, kar yağışının ardından bölgede hava şartları açısından etkili olan kar yağışının ardından bölgede soğuk hava nedeniyle, bu durumun da yaşanması muhtemel\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Bakü'ye giden yaklaşık 60 bin kişi, Türkiye'nin çeşitli illerinde çay ve kahve içerek, çay ve kahve içiyor. Çay, kahvenin tadı damağınızda kalacak. Cumhurbaşkanı Recep Tayyip\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        ile birçok insan, biyolog, doktorlar ve psikologların de yer aldığı etkinlikte, bilim insanları, psikolo-Medical Parker, psikolo-Medical Parker, eğitmenlerin yanı\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.3021)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:08:52\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "30510 | 4.3889 | 1.8e-04 | 1.12 | 38.7K | 01:47:45 |  61.0%\n",
            "30520 | 4.1207 | 1.8e-04 | 1.15 | 38.7K | 01:47:47 |  61.0%\n",
            "30530 | 4.4644 | 1.8e-04 | 1.11 | 38.7K | 01:47:49 |  61.1%\n",
            "30540 | 4.5076 | 1.8e-04 | 1.11 | 38.7K | 01:47:50 |  61.1%\n",
            "30550 | 4.3339 | 1.8e-04 | 1.12 | 38.7K | 01:47:52 |  61.1%\n",
            "30560 | 4.3590 | 1.8e-04 | 1.09 | 38.7K | 01:47:54 |  61.1%\n",
            "30570 | 4.2845 | 1.8e-04 | 1.10 | 38.7K | 01:47:55 |  61.1%\n",
            "30580 | 4.5757 | 1.8e-04 | 1.23 | 38.7K | 01:47:57 |  61.2%\n",
            "30590 | 4.2581 | 1.8e-04 | 1.09 | 38.7K | 01:47:59 |  61.2%\n",
            "30600 | 4.4200 | 1.8e-04 | 1.10 | 38.7K | 01:48:00 |  61.2%\n",
            "30610 | 4.4220 | 1.8e-04 | 1.15 | 38.7K | 01:48:02 |  61.2%\n",
            "30620 | 4.2836 | 1.8e-04 | 1.22 | 38.7K | 01:48:04 |  61.2%\n",
            "30630 | 4.2437 | 1.8e-04 | 1.12 | 38.7K | 01:48:06 |  61.3%\n",
            "30640 | 4.6234 | 1.8e-04 | 1.10 | 38.7K | 01:48:07 |  61.3%\n",
            "30650 | 4.2642 | 1.8e-04 | 1.16 | 38.7K | 01:48:09 |  61.3%\n",
            "30660 | 4.2086 | 1.7e-04 | 1.14 | 38.7K | 01:48:11 |  61.3%\n",
            "30670 | 4.1694 | 1.7e-04 | 1.10 | 38.7K | 01:48:12 |  61.3%\n",
            "30680 | 4.4308 | 1.7e-04 | 1.11 | 38.7K | 01:48:14 |  61.4%\n",
            "30690 | 4.5437 | 1.7e-04 | 1.12 | 38.7K | 01:48:16 |  61.4%\n",
            "30700 | 4.4647 | 1.7e-04 | 1.18 | 38.7K | 01:48:18 |  61.4%\n",
            "30710 | 4.2520 | 1.7e-04 | 1.12 | 38.7K | 01:48:19 |  61.4%\n",
            "30720 | 4.4173 | 1.7e-04 | 1.12 | 38.7K | 01:48:21 |  61.4%\n",
            "30730 | 4.4274 | 1.7e-04 | 1.14 | 38.7K | 01:48:23 |  61.5%\n",
            "30740 | 4.2773 | 1.7e-04 | 1.14 | 38.7K | 01:48:24 |  61.5%\n",
            "30750 | 4.0057 | 1.7e-04 | 1.66 | 38.7K | 01:48:26 |  61.5%\n",
            "30760 | 4.4537 | 1.7e-04 | 1.14 | 38.7K | 01:48:28 |  61.5%\n",
            "30770 | 4.3182 | 1.7e-04 | 1.11 | 38.7K | 01:48:30 |  61.5%\n",
            "30780 | 4.2272 | 1.7e-04 | 1.14 | 38.7K | 01:48:31 |  61.6%\n",
            "30790 | 4.3809 | 1.7e-04 | 1.13 | 38.7K | 01:48:33 |  61.6%\n",
            "30800 | 4.2069 | 1.7e-04 | 1.21 | 38.7K | 01:48:35 |  61.6%\n",
            "30810 | 4.2050 | 1.7e-04 | 1.16 | 38.7K | 01:48:36 |  61.6%\n",
            "30820 | 4.2322 | 1.7e-04 | 1.10 | 38.7K | 01:48:38 |  61.6%\n",
            "30830 | 4.3781 | 1.7e-04 | 1.11 | 38.7K | 01:48:40 |  61.7%\n",
            "30840 | 4.2855 | 1.7e-04 | 1.09 | 38.7K | 01:48:42 |  61.7%\n",
            "30850 | 4.6592 | 1.7e-04 | 1.12 | 38.7K | 01:48:43 |  61.7%\n",
            "30860 | 4.2932 | 1.7e-04 | 1.14 | 38.7K | 01:48:45 |  61.7%\n",
            "30870 | 4.0085 | 1.7e-04 | 1.19 | 38.7K | 01:48:47 |  61.7%\n",
            "30880 | 4.2232 | 1.7e-04 | 1.11 | 38.7K | 01:48:48 |  61.8%\n",
            "30890 | 4.5221 | 1.7e-04 | 1.13 | 38.7K | 01:48:50 |  61.8%\n",
            "30900 | 4.3649 | 1.7e-04 | 1.10 | 38.8K | 01:48:52 |  61.8%\n",
            "30910 | 4.1241 | 1.7e-04 | 1.10 | 38.8K | 01:48:54 |  61.8%\n",
            "30920 | 4.4772 | 1.7e-04 | 1.12 | 38.8K | 01:48:55 |  61.8%\n",
            "30930 | 4.5898 | 1.7e-04 | 1.12 | 38.8K | 01:48:57 |  61.9%\n",
            "30940 | 4.4917 | 1.7e-04 | 1.15 | 38.8K | 01:48:59 |  61.9%\n",
            "30950 | 4.3114 | 1.7e-04 | 1.15 | 38.8K | 01:49:00 |  61.9%\n",
            "30960 | 4.2595 | 1.7e-04 | 1.13 | 38.8K | 01:49:02 |  61.9%\n",
            "30970 | 4.2901 | 1.7e-04 | 1.07 | 38.8K | 01:49:04 |  61.9%\n",
            "30980 | 4.2854 | 1.7e-04 | 1.09 | 38.8K | 01:49:06 |  62.0%\n",
            "30990 | 4.5433 | 1.7e-04 | 1.16 | 38.8K | 01:49:07 |  62.0%\n",
            "31000 | 4.4548 | 1.7e-04 | 1.08 | 38.8K | 01:49:09 |  62.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 31000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.3315\n",
            "  Perplexity: 76.06\n",
            "  Train loss (avg): 4.3275\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        durumu iyi ancak, tatilin zorluğunu aşmış durumdayız. Lakin, son derece uygun fiyatlı ve uygun fiyatlı oteller bulunamadı. Ev sahibinin durumu da bu. Yemek için az zaman ayırabilir, ancak\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Ankara'da hizmet veren Türkiye'nin önde gelen ofislerinden birisi olan Türkiye'nin ilk profesyonel ofis taşıma şirketi olan Ankara'da hizmet veren bir firmadır. Ankara'da bulunan Ankara İstanbul ofis taşıma\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , insan ve çevreyle bağlantılı olarak, her iki sinir ağı üzerinde de öncü bir uygulama olarak kullanılmaktadır. Bu uygulama, insan ve çevre arasındaki iletişimi güçlendirmek için büyük önem taşımaktadır. Aşağıda belirtilen bilgiler, kişilerin\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:07:04\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "31010 | 4.4866 | 1.7e-04 | 1.14 | 38.7K | 01:49:28 |  62.0%\n",
            "31020 | 4.3972 | 1.7e-04 | 1.19 | 38.7K | 01:49:30 |  62.0%\n",
            "31030 | 4.3357 | 1.7e-04 | 1.10 | 38.7K | 01:49:31 |  62.1%\n",
            "31040 | 4.3016 | 1.7e-04 | 1.12 | 38.7K | 01:49:33 |  62.1%\n",
            "31050 | 4.3162 | 1.7e-04 | 1.10 | 38.7K | 01:49:35 |  62.1%\n",
            "31060 | 4.3172 | 1.7e-04 | 1.12 | 38.7K | 01:49:36 |  62.1%\n",
            "31070 | 4.0366 | 1.7e-04 | 1.27 | 38.7K | 01:49:38 |  62.1%\n",
            "31080 | 4.3235 | 1.7e-04 | 1.17 | 38.7K | 01:49:40 |  62.2%\n",
            "31090 | 4.3665 | 1.7e-04 | 1.11 | 38.7K | 01:49:42 |  62.2%\n",
            "31100 | 4.5795 | 1.7e-04 | 1.20 | 38.7K | 01:49:43 |  62.2%\n",
            "31110 | 4.1667 | 1.7e-04 | 1.18 | 38.7K | 01:49:45 |  62.2%\n",
            "31120 | 4.5387 | 1.7e-04 | 1.11 | 38.7K | 01:49:47 |  62.2%\n",
            "31130 | 4.1626 | 1.7e-04 | 1.15 | 38.7K | 01:49:48 |  62.3%\n",
            "31140 | 4.2968 | 1.7e-04 | 1.09 | 38.7K | 01:49:50 |  62.3%\n",
            "31150 | 4.3659 | 1.7e-04 | 1.13 | 38.7K | 01:49:52 |  62.3%\n",
            "31160 | 4.4406 | 1.7e-04 | 1.13 | 38.7K | 01:49:54 |  62.3%\n",
            "31170 | 4.3204 | 1.7e-04 | 1.06 | 38.7K | 01:49:55 |  62.3%\n",
            "31180 | 4.1121 | 1.7e-04 | 1.19 | 38.7K | 01:49:57 |  62.4%\n",
            "31190 | 3.9156 | 1.7e-04 | 1.12 | 38.7K | 01:49:59 |  62.4%\n",
            "31200 | 4.1871 | 1.7e-04 | 1.15 | 38.7K | 01:50:00 |  62.4%\n",
            "31210 | 4.3692 | 1.7e-04 | 1.16 | 38.7K | 01:50:02 |  62.4%\n",
            "31220 | 4.4112 | 1.7e-04 | 1.12 | 38.7K | 01:50:04 |  62.4%\n",
            "31230 | 4.3578 | 1.7e-04 | 1.15 | 38.7K | 01:50:06 |  62.5%\n",
            "31240 | 4.5361 | 1.7e-04 | 1.13 | 38.7K | 01:50:07 |  62.5%\n",
            "31250 | 4.4659 | 1.7e-04 | 1.12 | 38.7K | 01:50:09 |  62.5%\n",
            "31260 | 4.3645 | 1.7e-04 | 1.11 | 38.7K | 01:50:11 |  62.5%\n",
            "31270 | 4.4252 | 1.7e-04 | 1.13 | 38.7K | 01:50:12 |  62.5%\n",
            "31280 | 4.1610 | 1.7e-04 | 1.16 | 38.7K | 01:50:14 |  62.6%\n",
            "31290 | 3.9659 | 1.7e-04 | 1.15 | 38.7K | 01:50:16 |  62.6%\n",
            "31300 | 4.1798 | 1.7e-04 | 1.12 | 38.7K | 01:50:18 |  62.6%\n",
            "31310 | 4.2239 | 1.6e-04 | 1.12 | 38.7K | 01:50:19 |  62.6%\n",
            "31320 | 4.2272 | 1.6e-04 | 1.17 | 38.7K | 01:50:21 |  62.6%\n",
            "31330 | 3.8525 | 1.6e-04 | 1.09 | 38.8K | 01:50:23 |  62.7%\n",
            "31340 | 4.6016 | 1.6e-04 | 1.15 | 38.8K | 01:50:24 |  62.7%\n",
            "31350 | 4.3817 | 1.6e-04 | 1.11 | 38.8K | 01:50:26 |  62.7%\n",
            "31360 | 4.2998 | 1.6e-04 | 1.11 | 38.8K | 01:50:28 |  62.7%\n",
            "31370 | 4.6027 | 1.6e-04 | 1.21 | 38.8K | 01:50:30 |  62.7%\n",
            "31380 | 4.4595 | 1.6e-04 | 1.10 | 38.8K | 01:50:31 |  62.8%\n",
            "31390 | 4.5597 | 1.6e-04 | 1.10 | 38.8K | 01:50:33 |  62.8%\n",
            "31400 | 4.3396 | 1.6e-04 | 1.14 | 38.8K | 01:50:35 |  62.8%\n",
            "31410 | 4.2203 | 1.6e-04 | 1.12 | 38.8K | 01:50:36 |  62.8%\n",
            "31420 | 4.8337 | 1.6e-04 | 1.15 | 38.8K | 01:50:38 |  62.8%\n",
            "31430 | 4.3355 | 1.6e-04 | 1.12 | 38.8K | 01:50:40 |  62.9%\n",
            "31440 | 3.8720 | 1.6e-04 | 1.14 | 38.8K | 01:50:41 |  62.9%\n",
            "31450 | 4.5693 | 1.6e-04 | 1.17 | 38.8K | 01:50:43 |  62.9%\n",
            "31460 | 4.3102 | 1.6e-04 | 1.15 | 38.8K | 01:50:45 |  62.9%\n",
            "31470 | 4.4861 | 1.6e-04 | 1.12 | 38.8K | 01:50:47 |  62.9%\n",
            "31480 | 4.2232 | 1.6e-04 | 1.11 | 38.8K | 01:50:48 |  63.0%\n",
            "31490 | 4.4220 | 1.6e-04 | 1.21 | 38.8K | 01:50:50 |  63.0%\n",
            "31500 | 4.5279 | 1.6e-04 | 1.09 | 38.8K | 01:50:52 |  63.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 31500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.2617\n",
            "  Perplexity: 70.93\n",
            "  Train loss (avg): 4.3145\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        durumu nedeniyle elektronik ortamdaki hava durumu verileri ve hava durumu verileri de etkilenmektedir. Her iki durumda da hava durumu bilgileri ve hava durumu durumu rapor edilmesi gerekir. Elektriklerin duyulması için yapılması gereken hava durumu\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        olan Ankara, Türkiye'nin en büyük turizm kuruluşlarından biridir. Ankara'nın başlıca turizm merkezlerinden birisi olan Ankara'nın en büyük turizm kuruluşlarındandır. Ankara'nın en büyük turizm kuruluşlarından birisi olan\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        her zaman en yüksek teknolojiye sahip ve teknoloji alanındaki yeniliklere, yeniliklere ve teknolojilere sahip. CADI için son derece başarılı bir teknoloji. Dijital teknoloji, markalar ve teknoloji konularını inceleyerek, farklı farklı\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.2617)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:05:19\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "31510 | 4.5417 | 1.6e-04 | 1.13 | 38.7K | 01:51:14 |  63.0%\n",
            "31520 | 4.5881 | 1.6e-04 | 1.13 | 38.7K | 01:51:16 |  63.0%\n",
            "31530 | 4.5225 | 1.6e-04 | 1.12 | 38.7K | 01:51:18 |  63.1%\n",
            "31540 | 4.0425 | 1.6e-04 | 1.11 | 38.7K | 01:51:19 |  63.1%\n",
            "31550 | 4.3199 | 1.6e-04 | 1.10 | 38.7K | 01:51:21 |  63.1%\n",
            "31560 | 3.9865 | 1.6e-04 | 1.16 | 38.7K | 01:51:23 |  63.1%\n",
            "31570 | 4.3282 | 1.6e-04 | 1.13 | 38.7K | 01:51:24 |  63.1%\n",
            "31580 | 4.3419 | 1.6e-04 | 1.21 | 38.7K | 01:51:26 |  63.2%\n",
            "31590 | 4.2635 | 1.6e-04 | 1.11 | 38.7K | 01:51:28 |  63.2%\n",
            "31600 | 4.4724 | 1.6e-04 | 1.12 | 38.7K | 01:51:30 |  63.2%\n",
            "31610 | 3.9877 | 1.6e-04 | 1.16 | 38.7K | 01:51:31 |  63.2%\n",
            "31620 | 4.2466 | 1.6e-04 | 1.14 | 38.7K | 01:51:33 |  63.2%\n",
            "31630 | 4.4418 | 1.6e-04 | 1.11 | 38.7K | 01:51:35 |  63.3%\n",
            "31640 | 4.2092 | 1.6e-04 | 1.14 | 38.7K | 01:51:36 |  63.3%\n",
            "31650 | 4.2535 | 1.6e-04 | 1.08 | 38.7K | 01:51:38 |  63.3%\n",
            "31660 | 4.4202 | 1.6e-04 | 1.11 | 38.7K | 01:51:40 |  63.3%\n",
            "31670 | 4.3633 | 1.6e-04 | 1.15 | 38.7K | 01:51:42 |  63.3%\n",
            "31680 | 4.5544 | 1.6e-04 | 1.16 | 38.7K | 01:51:43 |  63.4%\n",
            "31690 | 4.4953 | 1.6e-04 | 1.13 | 38.7K | 01:51:45 |  63.4%\n",
            "31700 | 4.5075 | 1.6e-04 | 1.17 | 38.7K | 01:51:47 |  63.4%\n",
            "31710 | 4.2924 | 1.6e-04 | 1.10 | 38.7K | 01:51:48 |  63.4%\n",
            "31720 | 4.4926 | 1.6e-04 | 1.18 | 38.7K | 01:51:50 |  63.4%\n",
            "31730 | 4.2695 | 1.6e-04 | 1.11 | 38.7K | 01:51:52 |  63.5%\n",
            "31740 | 4.3493 | 1.6e-04 | 1.11 | 38.7K | 01:51:54 |  63.5%\n",
            "31750 | 4.2136 | 1.6e-04 | 1.14 | 38.7K | 01:51:55 |  63.5%\n",
            "31760 | 4.4387 | 1.6e-04 | 1.18 | 38.7K | 01:51:57 |  63.5%\n",
            "31770 | 3.6059 | 1.6e-04 | 1.16 | 38.7K | 01:51:59 |  63.5%\n",
            "31780 | 4.4064 | 1.6e-04 | 1.10 | 38.7K | 01:52:00 |  63.6%\n",
            "31790 | 4.1649 | 1.6e-04 | 1.08 | 38.7K | 01:52:02 |  63.6%\n",
            "31800 | 4.2494 | 1.6e-04 | 1.20 | 38.7K | 01:52:04 |  63.6%\n",
            "31810 | 4.5245 | 1.6e-04 | 1.15 | 38.7K | 01:52:06 |  63.6%\n",
            "31820 | 4.5547 | 1.6e-04 | 1.14 | 38.7K | 01:52:07 |  63.6%\n",
            "31830 | 4.5188 | 1.6e-04 | 1.11 | 38.7K | 01:52:09 |  63.7%\n",
            "31840 | 4.1130 | 1.6e-04 | 1.21 | 38.8K | 01:52:11 |  63.7%\n",
            "31850 | 4.5788 | 1.6e-04 | 1.14 | 38.8K | 01:52:12 |  63.7%\n",
            "31860 | 4.1486 | 1.6e-04 | 1.14 | 38.8K | 01:52:14 |  63.7%\n",
            "31870 | 4.4766 | 1.6e-04 | 1.11 | 38.8K | 01:52:16 |  63.7%\n",
            "31880 | 4.4088 | 1.6e-04 | 1.11 | 38.8K | 01:52:18 |  63.8%\n",
            "31890 | 4.4585 | 1.6e-04 | 1.11 | 38.8K | 01:52:19 |  63.8%\n",
            "31900 | 4.3990 | 1.6e-04 | 1.19 | 38.8K | 01:52:21 |  63.8%\n",
            "31910 | 4.2972 | 1.6e-04 | 1.13 | 38.8K | 01:52:23 |  63.8%\n",
            "31920 | 4.4136 | 1.6e-04 | 1.15 | 38.8K | 01:52:24 |  63.8%\n",
            "31930 | 4.5993 | 1.6e-04 | 1.11 | 38.8K | 01:52:26 |  63.9%\n",
            "31940 | 4.5226 | 1.6e-04 | 1.17 | 38.8K | 01:52:28 |  63.9%\n",
            "31950 | 4.3363 | 1.6e-04 | 1.09 | 38.8K | 01:52:29 |  63.9%\n",
            "31960 | 4.1246 | 1.5e-04 | 1.17 | 38.8K | 01:52:31 |  63.9%\n",
            "31970 | 4.1876 | 1.5e-04 | 1.17 | 38.8K | 01:52:33 |  63.9%\n",
            "31980 | 4.5569 | 1.5e-04 | 1.16 | 38.8K | 01:52:35 |  64.0%\n",
            "31990 | 4.2202 | 1.5e-04 | 1.14 | 38.8K | 01:52:36 |  64.0%\n",
            "32000 | 4.3670 | 1.5e-04 | 1.13 | 38.8K | 01:52:38 |  64.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 32000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.3061\n",
            "  Perplexity: 74.15\n",
            "  Train loss (avg): 4.3216\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        ların çok iyi ve yoğun olduğu bir gündü. Neden bu kadar soğuk bir günün getirdiklerini merak ettiğim bir durumdu. Nitekim her iki taraf çok sıcak ve serin bir günün getirildiğini biliyorduk. Bir\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Washington'da bulunan Güney Amerika Uluslararası Boris... Dünyanın en pahalı ve en pahalı yolcu taşıyan ülkesi olan Güney Amerika, Doğu Avrupa'da en pahalı ve en pahalı kir... Dünya nüfusla bir diğer önemli\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , dijital bilim insanlarını daha güçlü bir şekilde yansıtacak, yeni iş imkanları yaratarak iş dünyasında ve vizyonlarda yer alacağız. Etkin bir şekilde iş dünyasında ve vizyonlarda yer alabilecek, iş dünyasında da iy\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:03:31\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "32010 | 4.4435 | 1.5e-04 | 1.12 | 38.7K | 01:52:57 |  64.0%\n",
            "32020 | 4.3000 | 1.5e-04 | 1.10 | 38.7K | 01:52:59 |  64.0%\n",
            "32030 | 4.4608 | 1.5e-04 | 1.13 | 38.7K | 01:53:00 |  64.1%\n",
            "32040 | 4.1795 | 1.5e-04 | 1.15 | 38.7K | 01:53:02 |  64.1%\n",
            "32050 | 3.9890 | 1.5e-04 | 1.11 | 38.7K | 01:53:04 |  64.1%\n",
            "32060 | 4.3454 | 1.5e-04 | 1.13 | 38.7K | 01:53:06 |  64.1%\n",
            "32070 | 4.2967 | 1.5e-04 | 1.21 | 38.7K | 01:53:07 |  64.1%\n",
            "32080 | 4.4365 | 1.5e-04 | 1.10 | 38.7K | 01:53:09 |  64.2%\n",
            "32090 | 4.4194 | 1.5e-04 | 1.12 | 38.7K | 01:53:11 |  64.2%\n",
            "32100 | 4.0430 | 1.5e-04 | 1.16 | 38.7K | 01:53:12 |  64.2%\n",
            "32110 | 4.3609 | 1.5e-04 | 1.15 | 38.7K | 01:53:14 |  64.2%\n",
            "32120 | 4.5276 | 1.5e-04 | 1.14 | 38.7K | 01:53:16 |  64.2%\n",
            "32130 | 4.1820 | 1.5e-04 | 1.15 | 38.7K | 01:53:18 |  64.3%\n",
            "32140 | 4.3816 | 1.5e-04 | 1.13 | 38.7K | 01:53:19 |  64.3%\n",
            "32150 | 4.3572 | 1.5e-04 | 1.15 | 38.7K | 01:53:21 |  64.3%\n",
            "32160 | 4.0565 | 1.5e-04 | 1.12 | 38.7K | 01:53:23 |  64.3%\n",
            "32170 | 4.0301 | 1.5e-04 | 1.13 | 38.7K | 01:53:24 |  64.3%\n",
            "32180 | 4.2327 | 1.5e-04 | 1.15 | 38.7K | 01:53:26 |  64.4%\n",
            "32190 | 4.0994 | 1.5e-04 | 1.11 | 38.7K | 01:53:28 |  64.4%\n",
            "32200 | 4.2427 | 1.5e-04 | 1.14 | 38.7K | 01:53:30 |  64.4%\n",
            "32210 | 4.4657 | 1.5e-04 | 1.15 | 38.7K | 01:53:31 |  64.4%\n",
            "32220 | 4.4634 | 1.5e-04 | 1.10 | 38.7K | 01:53:33 |  64.4%\n",
            "32230 | 3.9936 | 1.5e-04 | 1.17 | 38.7K | 01:53:35 |  64.5%\n",
            "32240 | 4.0169 | 1.5e-04 | 1.16 | 38.7K | 01:53:36 |  64.5%\n",
            "32250 | 4.0719 | 1.5e-04 | 1.11 | 38.7K | 01:53:38 |  64.5%\n",
            "32260 | 4.3609 | 1.5e-04 | 1.14 | 38.7K | 01:53:40 |  64.5%\n",
            "32270 | 4.4871 | 1.5e-04 | 1.17 | 38.8K | 01:53:42 |  64.5%\n",
            "32280 | 4.1862 | 1.5e-04 | 1.18 | 38.8K | 01:53:43 |  64.6%\n",
            "32290 | 4.4520 | 1.5e-04 | 1.12 | 38.8K | 01:53:45 |  64.6%\n",
            "32300 | 4.2065 | 1.5e-04 | 1.12 | 38.8K | 01:53:47 |  64.6%\n",
            "32310 | 4.1621 | 1.5e-04 | 1.12 | 38.8K | 01:53:48 |  64.6%\n",
            "32320 | 4.5319 | 1.5e-04 | 1.12 | 38.8K | 01:53:50 |  64.6%\n",
            "32330 | 4.4557 | 1.5e-04 | 1.11 | 38.8K | 01:53:52 |  64.7%\n",
            "32340 | 4.5910 | 1.5e-04 | 1.23 | 38.8K | 01:53:54 |  64.7%\n",
            "32350 | 4.3160 | 1.5e-04 | 1.13 | 38.8K | 01:53:55 |  64.7%\n",
            "32360 | 4.0423 | 1.5e-04 | 1.17 | 38.8K | 01:53:57 |  64.7%\n",
            "32370 | 4.5499 | 1.5e-04 | 1.12 | 38.8K | 01:53:59 |  64.7%\n",
            "32380 | 4.2674 | 1.5e-04 | 1.12 | 38.8K | 01:54:00 |  64.8%\n",
            "32390 | 4.3782 | 1.5e-04 | 1.14 | 38.8K | 01:54:02 |  64.8%\n",
            "32400 | 4.1852 | 1.5e-04 | 1.15 | 38.8K | 01:54:04 |  64.8%\n",
            "32410 | 4.5108 | 1.5e-04 | 1.13 | 38.8K | 01:54:05 |  64.8%\n",
            "32420 | 4.4879 | 1.5e-04 | 1.10 | 38.8K | 01:54:07 |  64.8%\n",
            "32430 | 4.3413 | 1.5e-04 | 1.16 | 38.8K | 01:54:09 |  64.9%\n",
            "32440 | 4.2567 | 1.5e-04 | 1.11 | 38.8K | 01:54:11 |  64.9%\n",
            "32450 | 4.4236 | 1.5e-04 | 1.16 | 38.8K | 01:54:12 |  64.9%\n",
            "32460 | 4.2514 | 1.5e-04 | 1.10 | 38.8K | 01:54:14 |  64.9%\n",
            "32470 | 4.2549 | 1.5e-04 | 1.16 | 38.8K | 01:54:16 |  64.9%\n",
            "32480 | 4.2271 | 1.5e-04 | 1.19 | 38.8K | 01:54:17 |  65.0%\n",
            "32490 | 4.4005 | 1.5e-04 | 1.11 | 38.8K | 01:54:19 |  65.0%\n",
            "32500 | 4.7731 | 1.5e-04 | 1.18 | 38.8K | 01:54:21 |  65.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 32500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.2568\n",
            "  Perplexity: 70.58\n",
            "  Train loss (avg): 4.3139\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        kararan hangi bölge olursa olsun, bir bölge olursa olsun, bütün bölge için hazırlıklı olmak lazım. Bölgenin kalbi, çevre temizliği, havza ve çevre temizliği, çevreye duyarlılık, çevre koruma, doğaya\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        İstanbul'da yer alan Mimar Sinan Üniversitesi, ayrıca kendi mimarisi ile dikkat çeken ve Türkiye'nin en büyük mimarlarından biri olan Mimar Sinan Üniversitesi, mimarlığı ile dikkat çeken mimarları ile oldukça iyi\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , her zaman yapay zeka ve yapay zeka teknolojisi ile iş adamları ve çalışanlar tarafından kullanılmaktadır. Bu teknolojinin tüm sistemleri sadece sosyal zekalar ve kararsızlıklara açık olan yapay zekalar, iş kazaları ve\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.2568)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:01:45\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "32510 | 4.4650 | 1.5e-04 | 1.16 | 38.7K | 01:54:43 |  65.0%\n",
            "32520 | 4.1448 | 1.5e-04 | 1.28 | 38.7K | 01:54:45 |  65.0%\n",
            "32530 | 4.3622 | 1.5e-04 | 1.15 | 38.7K | 01:54:47 |  65.1%\n",
            "32540 | 4.2422 | 1.5e-04 | 1.14 | 38.7K | 01:54:48 |  65.1%\n",
            "32550 | 4.4627 | 1.5e-04 | 1.16 | 38.7K | 01:54:50 |  65.1%\n",
            "32560 | 4.3649 | 1.5e-04 | 1.11 | 38.7K | 01:54:52 |  65.1%\n",
            "32570 | 4.0955 | 1.5e-04 | 1.16 | 38.7K | 01:54:54 |  65.1%\n",
            "32580 | 4.5072 | 1.5e-04 | 1.13 | 38.7K | 01:54:55 |  65.2%\n",
            "32590 | 4.4890 | 1.5e-04 | 1.11 | 38.7K | 01:54:57 |  65.2%\n",
            "32600 | 4.2212 | 1.5e-04 | 1.14 | 38.7K | 01:54:59 |  65.2%\n",
            "32610 | 4.6833 | 1.5e-04 | 1.13 | 38.7K | 01:55:00 |  65.2%\n",
            "32620 | 4.4283 | 1.5e-04 | 1.18 | 38.7K | 01:55:02 |  65.2%\n",
            "32630 | 4.4089 | 1.4e-04 | 1.14 | 38.7K | 01:55:04 |  65.3%\n",
            "32640 | 4.1850 | 1.4e-04 | 1.38 | 38.7K | 01:55:05 |  65.3%\n",
            "32650 | 4.1975 | 1.4e-04 | 1.11 | 38.7K | 01:55:07 |  65.3%\n",
            "32660 | 4.4618 | 1.4e-04 | 1.13 | 38.7K | 01:55:09 |  65.3%\n",
            "32670 | 4.4306 | 1.4e-04 | 1.12 | 38.7K | 01:55:11 |  65.3%\n",
            "32680 | 4.1887 | 1.4e-04 | 1.13 | 38.7K | 01:55:12 |  65.4%\n",
            "32690 | 4.2051 | 1.4e-04 | 1.15 | 38.7K | 01:55:14 |  65.4%\n",
            "32700 | 4.2084 | 1.4e-04 | 1.26 | 38.7K | 01:55:16 |  65.4%\n",
            "32710 | 4.2904 | 1.4e-04 | 1.10 | 38.7K | 01:55:17 |  65.4%\n",
            "32720 | 4.2600 | 1.4e-04 | 1.09 | 38.7K | 01:55:19 |  65.4%\n",
            "32730 | 4.3539 | 1.4e-04 | 1.16 | 38.7K | 01:55:21 |  65.5%\n",
            "32740 | 4.3789 | 1.4e-04 | 1.13 | 38.7K | 01:55:23 |  65.5%\n",
            "32750 | 4.4305 | 1.4e-04 | 1.16 | 38.7K | 01:55:24 |  65.5%\n",
            "32760 | 4.1855 | 1.4e-04 | 1.30 | 38.7K | 01:55:26 |  65.5%\n",
            "32770 | 4.2292 | 1.4e-04 | 1.20 | 38.7K | 01:55:28 |  65.5%\n",
            "32780 | 4.4900 | 1.4e-04 | 1.16 | 38.7K | 01:55:29 |  65.6%\n",
            "32790 | 4.3499 | 1.4e-04 | 1.10 | 38.8K | 01:55:31 |  65.6%\n",
            "32800 | 4.2800 | 1.4e-04 | 1.13 | 38.8K | 01:55:33 |  65.6%\n",
            "32810 | 4.1594 | 1.4e-04 | 1.20 | 38.8K | 01:55:35 |  65.6%\n",
            "32820 | 4.1981 | 1.4e-04 | 1.10 | 38.8K | 01:55:36 |  65.6%\n",
            "32830 | 4.3600 | 1.4e-04 | 1.11 | 38.8K | 01:55:38 |  65.7%\n",
            "32840 | 4.6265 | 1.4e-04 | 1.13 | 38.8K | 01:55:40 |  65.7%\n",
            "32850 | 4.1705 | 1.4e-04 | 1.13 | 38.8K | 01:55:41 |  65.7%\n",
            "32860 | 4.5591 | 1.4e-04 | 1.17 | 38.8K | 01:55:43 |  65.7%\n",
            "32870 | 4.1792 | 1.4e-04 | 1.21 | 38.8K | 01:55:45 |  65.7%\n",
            "32880 | 4.1466 | 1.4e-04 | 1.11 | 38.8K | 01:55:47 |  65.8%\n",
            "32890 | 4.1670 | 1.4e-04 | 1.14 | 38.8K | 01:55:48 |  65.8%\n",
            "32900 | 4.2517 | 1.4e-04 | 1.09 | 38.8K | 01:55:50 |  65.8%\n",
            "32910 | 4.0365 | 1.4e-04 | 1.11 | 38.8K | 01:55:52 |  65.8%\n",
            "32920 | 4.3650 | 1.4e-04 | 1.12 | 38.8K | 01:55:53 |  65.8%\n",
            "32930 | 4.4185 | 1.4e-04 | 1.14 | 38.8K | 01:55:55 |  65.9%\n",
            "32940 | 4.2834 | 1.4e-04 | 1.20 | 38.8K | 01:55:57 |  65.9%\n",
            "32950 | 4.2604 | 1.4e-04 | 1.39 | 38.8K | 01:55:59 |  65.9%\n",
            "32960 | 4.1464 | 1.4e-04 | 1.34 | 38.8K | 01:56:00 |  65.9%\n",
            "32970 | 4.3446 | 1.4e-04 | 1.11 | 38.8K | 01:56:02 |  65.9%\n",
            "32980 | 4.3199 | 1.4e-04 | 1.18 | 38.8K | 01:56:04 |  66.0%\n",
            "32990 | 4.2938 | 1.4e-04 | 1.12 | 38.8K | 01:56:05 |  66.0%\n",
            "33000 | 4.5415 | 1.4e-04 | 1.16 | 38.8K | 01:56:07 |  66.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 33000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.2513\n",
            "  Perplexity: 70.19\n",
            "  Train loss (avg): 4.3492\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        sıcaklığını en yüksek seviyeye çıkarmayı hedefleyen ve hava sıcaklığını en yüksek seviyeye çıkartmayı hedefleyen bir sistem olarak, hem daha hızlı hem de daha verimli bir şekilde kullanılabilme olanağı ve yüksek kaliteli hava depoları\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Ankara'da bulunan MHP Genel Merkezi'nin genel başkanı Muharrem İnce, partisinin genel başkanı Kemal Kılıçdaroğlu'nun moderatörlüğünde yaptığı konuşmada, Türkiye'nin gündemini şu sözlerle anlattı: \"Hatta tek\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        sayesinde insan vücudu ciddi bir çaba olarak bile karşı karşıya kalabilir. Bundan dolayı insan vücudu için gerekli olan bilgiyi ve bilgileri elde etmenin önemli olduğu bir gerçek. Bu durum insan vücudu için gerekli olan bilgiyi üreterek elde\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.2513)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:00:00\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "33010 | 4.2435 | 1.4e-04 | 1.17 | 38.7K | 01:56:30 |  66.0%\n",
            "33020 | 4.3322 | 1.4e-04 | 1.16 | 38.7K | 01:56:31 |  66.0%\n",
            "33030 | 4.4587 | 1.4e-04 | 1.13 | 38.7K | 01:56:33 |  66.1%\n",
            "33040 | 4.4200 | 1.4e-04 | 1.16 | 38.7K | 01:56:35 |  66.1%\n",
            "33050 | 4.2246 | 1.4e-04 | 1.17 | 38.7K | 01:56:37 |  66.1%\n",
            "33060 | 4.0828 | 1.4e-04 | 1.27 | 38.7K | 01:56:38 |  66.1%\n",
            "33070 | 4.2902 | 1.4e-04 | 1.17 | 38.7K | 01:56:40 |  66.1%\n",
            "33080 | 4.4968 | 1.4e-04 | 1.17 | 38.7K | 01:56:42 |  66.2%\n",
            "33090 | 4.1419 | 1.4e-04 | 1.19 | 38.7K | 01:56:43 |  66.2%\n",
            "33100 | 4.3015 | 1.4e-04 | 1.21 | 38.7K | 01:56:45 |  66.2%\n",
            "33110 | 4.4103 | 1.4e-04 | 1.12 | 38.7K | 01:56:47 |  66.2%\n",
            "33120 | 4.4088 | 1.4e-04 | 1.10 | 38.7K | 01:56:49 |  66.2%\n",
            "33130 | 4.1609 | 1.4e-04 | 1.18 | 38.7K | 01:56:50 |  66.3%\n",
            "33140 | 4.4114 | 1.4e-04 | 1.21 | 38.7K | 01:56:52 |  66.3%\n",
            "33150 | 4.3231 | 1.4e-04 | 1.16 | 38.7K | 01:56:54 |  66.3%\n",
            "33160 | 4.4262 | 1.4e-04 | 1.14 | 38.7K | 01:56:55 |  66.3%\n",
            "33170 | 4.5332 | 1.4e-04 | 1.11 | 38.7K | 01:56:57 |  66.3%\n",
            "33180 | 4.1927 | 1.4e-04 | 1.18 | 38.7K | 01:56:59 |  66.4%\n",
            "33190 | 4.3592 | 1.4e-04 | 1.24 | 38.7K | 01:57:00 |  66.4%\n",
            "33200 | 4.3745 | 1.4e-04 | 1.12 | 38.7K | 01:57:02 |  66.4%\n",
            "33210 | 4.4133 | 1.4e-04 | 1.14 | 38.7K | 01:57:04 |  66.4%\n",
            "33220 | 3.8238 | 1.4e-04 | 1.28 | 38.7K | 01:57:06 |  66.4%\n",
            "33230 | 4.3715 | 1.4e-04 | 1.16 | 38.7K | 01:57:07 |  66.5%\n",
            "33240 | 4.2597 | 1.4e-04 | 1.19 | 38.7K | 01:57:09 |  66.5%\n",
            "33250 | 4.4998 | 1.4e-04 | 1.17 | 38.7K | 01:57:11 |  66.5%\n",
            "33260 | 4.4739 | 1.4e-04 | 1.11 | 38.7K | 01:57:12 |  66.5%\n",
            "33270 | 4.3594 | 1.4e-04 | 1.12 | 38.7K | 01:57:14 |  66.5%\n",
            "33280 | 3.9478 | 1.4e-04 | 1.19 | 38.7K | 01:57:16 |  66.6%\n",
            "33290 | 4.2492 | 1.4e-04 | 1.14 | 38.7K | 01:57:18 |  66.6%\n",
            "33300 | 4.3305 | 1.4e-04 | 1.14 | 38.8K | 01:57:19 |  66.6%\n",
            "33310 | 4.2282 | 1.3e-04 | 1.14 | 38.8K | 01:57:21 |  66.6%\n",
            "33320 | 4.0578 | 1.3e-04 | 1.16 | 38.8K | 01:57:23 |  66.6%\n",
            "33330 | 4.6048 | 1.3e-04 | 1.14 | 38.8K | 01:57:24 |  66.7%\n",
            "33340 | 4.3348 | 1.3e-04 | 1.18 | 38.8K | 01:57:26 |  66.7%\n",
            "33350 | 4.5909 | 1.3e-04 | 1.15 | 38.8K | 01:57:28 |  66.7%\n",
            "33360 | 4.4630 | 1.3e-04 | 1.19 | 38.8K | 01:57:30 |  66.7%\n",
            "33370 | 4.5414 | 1.3e-04 | 1.13 | 38.8K | 01:57:31 |  66.7%\n",
            "33380 | 4.3382 | 1.3e-04 | 1.19 | 38.8K | 01:57:33 |  66.8%\n",
            "33390 | 4.0173 | 1.3e-04 | 1.13 | 38.8K | 01:57:35 |  66.8%\n",
            "33400 | 4.1365 | 1.3e-04 | 1.14 | 38.8K | 01:57:36 |  66.8%\n",
            "33410 | 4.2785 | 1.3e-04 | 1.12 | 38.8K | 01:57:38 |  66.8%\n",
            "33420 | 4.5069 | 1.3e-04 | 1.17 | 38.8K | 01:57:40 |  66.8%\n",
            "33430 | 4.3840 | 1.3e-04 | 1.11 | 38.8K | 01:57:42 |  66.9%\n",
            "33440 | 4.2323 | 1.3e-04 | 1.15 | 38.8K | 01:57:43 |  66.9%\n",
            "33450 | 4.3550 | 1.3e-04 | 1.15 | 38.8K | 01:57:45 |  66.9%\n",
            "33460 | 4.2126 | 1.3e-04 | 1.20 | 38.8K | 01:57:47 |  66.9%\n",
            "33470 | 4.2124 | 1.3e-04 | 1.17 | 38.8K | 01:57:48 |  66.9%\n",
            "33480 | 4.3925 | 1.3e-04 | 1.17 | 38.8K | 01:57:50 |  67.0%\n",
            "33490 | 4.1313 | 1.3e-04 | 1.17 | 38.8K | 01:57:52 |  67.0%\n",
            "33500 | 4.1973 | 1.3e-04 | 1.23 | 38.8K | 01:57:54 |  67.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 33500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.2581\n",
            "  Perplexity: 70.68\n",
            "  Train loss (avg): 4.2899\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        durumu çok kötü bir şey değil. Çünkü gündüz kuşağı gibi bir ortam vardı. Sıcakta bir hava vardı. Soğuklar soğuktu, sıcakta bir şeyler vardı, sisler, yükseklik, bu\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        İstanbul'da bulunan Evoles bölgesindeki Özel kaldımealı alışveriş merkezi İstanbul'da açıldı. İstanbul'da mağaza açarak, 300'den fazla mağaza satın aldım. İstanbul'da bulunan mağazalardaki\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , yapay zeka teknolojisinin tamamlayıcısı olarak bilgisayar teknolojisinin bir parçası haline geliyor. Yapay zeka teknolojisinin kullanımına açık bir teknoloji olarak akıllı telefonlar ve tabletler arasındaki bağlantı her geçen gün artıyor. Yapay zekanın yapay zeka ile\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 00:58:12\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "33510 | 4.3127 | 1.3e-04 | 1.12 | 38.7K | 01:58:13 |  67.0%\n",
            "33520 | 4.3005 | 1.3e-04 | 1.14 | 38.7K | 01:58:14 |  67.0%\n",
            "33530 | 4.4716 | 1.3e-04 | 1.10 | 38.7K | 01:58:16 |  67.1%\n",
            "33540 | 4.3756 | 1.3e-04 | 1.21 | 38.7K | 01:58:18 |  67.1%\n",
            "33550 | 4.1296 | 1.3e-04 | 1.17 | 38.7K | 01:58:19 |  67.1%\n",
            "33560 | 4.4133 | 1.3e-04 | 1.16 | 38.7K | 01:58:21 |  67.1%\n",
            "33570 | 4.2922 | 1.3e-04 | 1.13 | 38.7K | 01:58:23 |  67.1%\n",
            "33580 | 4.3732 | 1.3e-04 | 1.11 | 38.7K | 01:58:25 |  67.2%\n",
            "33590 | 4.5417 | 1.3e-04 | 1.15 | 38.7K | 01:58:26 |  67.2%\n",
            "33600 | 4.1700 | 1.3e-04 | 1.14 | 38.7K | 01:58:28 |  67.2%\n",
            "33610 | 4.2716 | 1.3e-04 | 1.12 | 38.7K | 01:58:30 |  67.2%\n",
            "33620 | 4.3545 | 1.3e-04 | 1.14 | 38.7K | 01:58:31 |  67.2%\n",
            "33630 | 4.4526 | 1.3e-04 | 1.17 | 38.7K | 01:58:33 |  67.3%\n",
            "33640 | 4.3087 | 1.3e-04 | 1.14 | 38.7K | 01:58:35 |  67.3%\n",
            "33650 | 4.2404 | 1.3e-04 | 1.16 | 38.7K | 01:58:36 |  67.3%\n",
            "33660 | 4.1721 | 1.3e-04 | 1.20 | 38.7K | 01:58:38 |  67.3%\n",
            "33670 | 4.2831 | 1.3e-04 | 1.11 | 38.7K | 01:58:40 |  67.3%\n",
            "33680 | 4.3087 | 1.3e-04 | 1.11 | 38.7K | 01:58:42 |  67.4%\n",
            "33690 | 4.3582 | 1.3e-04 | 1.15 | 38.7K | 01:58:43 |  67.4%\n",
            "33700 | 4.1318 | 1.3e-04 | 1.15 | 38.7K | 01:58:45 |  67.4%\n",
            "33710 | 4.3397 | 1.3e-04 | 1.22 | 38.7K | 01:58:47 |  67.4%\n",
            "33720 | 4.4837 | 1.3e-04 | 1.14 | 38.7K | 01:58:48 |  67.4%\n",
            "33730 | 4.0708 | 1.3e-04 | 1.13 | 38.8K | 01:58:50 |  67.5%\n",
            "33740 | 4.1316 | 1.3e-04 | 1.16 | 38.8K | 01:58:52 |  67.5%\n",
            "33750 | 4.2426 | 1.3e-04 | 1.13 | 38.8K | 01:58:54 |  67.5%\n",
            "33760 | 4.2716 | 1.3e-04 | 1.23 | 38.8K | 01:58:55 |  67.5%\n",
            "33770 | 4.4056 | 1.3e-04 | 1.15 | 38.8K | 01:58:57 |  67.5%\n",
            "33780 | 4.0839 | 1.3e-04 | 1.22 | 38.8K | 01:58:59 |  67.6%\n",
            "33790 | 4.5802 | 1.3e-04 | 1.19 | 38.8K | 01:59:00 |  67.6%\n",
            "33800 | 4.5056 | 1.3e-04 | 1.41 | 38.8K | 01:59:02 |  67.6%\n",
            "33810 | 4.1166 | 1.3e-04 | 1.14 | 38.8K | 01:59:04 |  67.6%\n",
            "33820 | 4.5638 | 1.3e-04 | 1.14 | 38.8K | 01:59:06 |  67.6%\n",
            "33830 | 4.3758 | 1.3e-04 | 1.16 | 38.8K | 01:59:07 |  67.7%\n",
            "33840 | 4.4544 | 1.3e-04 | 1.14 | 38.8K | 01:59:09 |  67.7%\n",
            "33850 | 4.5486 | 1.3e-04 | 1.15 | 38.8K | 01:59:11 |  67.7%\n",
            "33860 | 4.1775 | 1.3e-04 | 1.23 | 38.8K | 01:59:12 |  67.7%\n",
            "33870 | 4.3255 | 1.3e-04 | 1.17 | 38.8K | 01:59:14 |  67.7%\n",
            "33880 | 4.3981 | 1.3e-04 | 1.20 | 38.8K | 01:59:16 |  67.8%\n",
            "33890 | 4.3837 | 1.3e-04 | 1.12 | 38.8K | 01:59:18 |  67.8%\n",
            "33900 | 4.0664 | 1.3e-04 | 1.42 | 38.8K | 01:59:19 |  67.8%\n",
            "33910 | 4.4377 | 1.3e-04 | 1.25 | 38.8K | 01:59:21 |  67.8%\n",
            "33920 | 4.3857 | 1.3e-04 | 1.13 | 38.8K | 01:59:23 |  67.8%\n",
            "33930 | 4.5083 | 1.3e-04 | 1.19 | 38.8K | 01:59:24 |  67.9%\n",
            "33940 | 3.9729 | 1.3e-04 | 1.19 | 38.8K | 01:59:26 |  67.9%\n",
            "33950 | 4.3648 | 1.3e-04 | 1.18 | 38.8K | 01:59:28 |  67.9%\n",
            "33960 | 4.0566 | 1.3e-04 | 1.10 | 38.8K | 01:59:30 |  67.9%\n",
            "33970 | 4.4977 | 1.3e-04 | 1.14 | 38.8K | 01:59:31 |  67.9%\n",
            "33980 | 4.2387 | 1.3e-04 | 1.16 | 38.8K | 01:59:33 |  68.0%\n",
            "33990 | 4.2352 | 1.3e-04 | 1.18 | 38.8K | 01:59:35 |  68.0%\n",
            "34000 | 4.2356 | 1.3e-04 | 1.14 | 38.8K | 01:59:36 |  68.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 34000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.2491\n",
            "  Perplexity: 70.04\n",
            "  Train loss (avg): 4.2984\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        nasıldı? Nasıldı? Neden mi? Neden? Neden? Neden? Neden? Neden? Neden? Neden? Neden? Neden? Neden? Neden? Neden? Neden? Neden? Neden? Neden\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Ankara'da gerçekleştirilen DYP İstanbul Avrupa Markaları Zirvesi'ne, Türkiye'nin önde gelen özel sektör temsilcileri ve basın mensupları katıldı. İstanbul Teknik Üniversitesi'nde düzenlenen Türkiye'nin 500,\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        sayesinde, süreç içerisindeki en büyük rekabet avantajı (en iyi teknoloji) yüksek performanslı bir sistem üretildi. Yeni nesil teknolojiyle, en çok kullanılan ve en çok kullanılan teknolojilerin en çok da daha fazla\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.2491)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 00:56:27\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "34010 | 4.2632 | 1.2e-04 | 1.15 | 38.7K | 01:59:59 |  68.0%\n",
            "34020 | 3.9736 | 1.2e-04 | 1.12 | 38.7K | 02:00:00 |  68.0%\n",
            "34030 | 4.2492 | 1.2e-04 | 1.11 | 38.7K | 02:00:02 |  68.1%\n",
            "34040 | 4.3415 | 1.2e-04 | 1.18 | 38.7K | 02:00:04 |  68.1%\n",
            "34050 | 4.4503 | 1.2e-04 | 1.13 | 38.7K | 02:00:06 |  68.1%\n",
            "34060 | 4.0155 | 1.2e-04 | 1.13 | 38.7K | 02:00:07 |  68.1%\n",
            "34070 | 4.3763 | 1.2e-04 | 1.12 | 38.7K | 02:00:09 |  68.1%\n",
            "34080 | 4.3367 | 1.2e-04 | 1.16 | 38.7K | 02:00:11 |  68.2%\n",
            "34090 | 4.3124 | 1.2e-04 | 1.19 | 38.7K | 02:00:12 |  68.2%\n",
            "34100 | 3.9973 | 1.2e-04 | 1.18 | 38.7K | 02:00:14 |  68.2%\n",
            "34110 | 4.3240 | 1.2e-04 | 1.32 | 38.7K | 02:00:16 |  68.2%\n",
            "34120 | 4.3635 | 1.2e-04 | 1.12 | 38.7K | 02:00:18 |  68.2%\n",
            "34130 | 4.2383 | 1.2e-04 | 1.20 | 38.7K | 02:00:19 |  68.3%\n",
            "34140 | 4.3153 | 1.2e-04 | 1.14 | 38.7K | 02:00:21 |  68.3%\n",
            "34150 | 4.2177 | 1.2e-04 | 1.17 | 38.7K | 02:00:23 |  68.3%\n",
            "34160 | 4.3391 | 1.2e-04 | 1.13 | 38.7K | 02:00:24 |  68.3%\n",
            "34170 | 4.0643 | 1.2e-04 | 1.38 | 38.7K | 02:00:26 |  68.3%\n",
            "34180 | 3.8391 | 1.2e-04 | 1.12 | 38.7K | 02:00:28 |  68.4%\n",
            "34190 | 4.5510 | 1.2e-04 | 1.13 | 38.7K | 02:00:30 |  68.4%\n",
            "34200 | 4.2236 | 1.2e-04 | 1.20 | 38.7K | 02:00:31 |  68.4%\n",
            "34210 | 4.1739 | 1.2e-04 | 1.11 | 38.7K | 02:00:33 |  68.4%\n",
            "34220 | 4.0310 | 1.2e-04 | 1.15 | 38.7K | 02:00:35 |  68.4%\n",
            "34230 | 4.1676 | 1.2e-04 | 1.19 | 38.7K | 02:00:36 |  68.5%\n",
            "34240 | 4.3405 | 1.2e-04 | 1.18 | 38.7K | 02:00:38 |  68.5%\n",
            "34250 | 4.5126 | 1.2e-04 | 1.21 | 38.8K | 02:00:40 |  68.5%\n",
            "34260 | 4.3289 | 1.2e-04 | 1.13 | 38.8K | 02:00:42 |  68.5%\n",
            "34270 | 4.3192 | 1.2e-04 | 1.15 | 38.8K | 02:00:43 |  68.5%\n",
            "34280 | 4.4999 | 1.2e-04 | 1.15 | 38.8K | 02:00:45 |  68.6%\n",
            "34290 | 4.0379 | 1.2e-04 | 1.18 | 38.8K | 02:00:47 |  68.6%\n",
            "34300 | 4.3856 | 1.2e-04 | 1.18 | 38.8K | 02:00:48 |  68.6%\n",
            "34310 | 4.3467 | 1.2e-04 | 1.14 | 38.8K | 02:00:50 |  68.6%\n",
            "34320 | 4.4469 | 1.2e-04 | 1.18 | 38.8K | 02:00:52 |  68.6%\n",
            "34330 | 4.3264 | 1.2e-04 | 1.16 | 38.8K | 02:00:54 |  68.7%\n",
            "34340 | 4.3835 | 1.2e-04 | 1.14 | 38.8K | 02:00:55 |  68.7%\n",
            "34350 | 4.4467 | 1.2e-04 | 1.14 | 38.8K | 02:00:57 |  68.7%\n",
            "34360 | 4.5820 | 1.2e-04 | 1.27 | 38.8K | 02:00:59 |  68.7%\n",
            "34370 | 4.2464 | 1.2e-04 | 1.14 | 38.8K | 02:01:00 |  68.7%\n",
            "34380 | 4.5060 | 1.2e-04 | 1.15 | 38.8K | 02:01:02 |  68.8%\n",
            "34390 | 4.4074 | 1.2e-04 | 1.14 | 38.8K | 02:01:04 |  68.8%\n",
            "34400 | 4.2825 | 1.2e-04 | 1.41 | 38.8K | 02:01:05 |  68.8%\n",
            "34410 | 4.4428 | 1.2e-04 | 1.16 | 38.8K | 02:01:07 |  68.8%\n",
            "34420 | 4.2455 | 1.2e-04 | 1.16 | 38.8K | 02:01:09 |  68.8%\n",
            "34430 | 4.5171 | 1.2e-04 | 1.16 | 38.8K | 02:01:11 |  68.9%\n",
            "34440 | 4.3633 | 1.2e-04 | 1.17 | 38.8K | 02:01:12 |  68.9%\n",
            "34450 | 4.2086 | 1.2e-04 | 1.13 | 38.8K | 02:01:14 |  68.9%\n",
            "34460 | 4.6826 | 1.2e-04 | 1.15 | 38.8K | 02:01:16 |  68.9%\n",
            "34470 | 4.1951 | 1.2e-04 | 1.19 | 38.8K | 02:01:17 |  68.9%\n",
            "34480 | 4.2369 | 1.2e-04 | 1.11 | 38.8K | 02:01:19 |  69.0%\n",
            "34490 | 4.2956 | 1.2e-04 | 1.20 | 38.8K | 02:01:21 |  69.0%\n",
            "34500 | 4.2783 | 1.2e-04 | 1.12 | 38.8K | 02:01:23 |  69.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 34500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.2423\n",
            "  Perplexity: 69.57\n",
            "  Train loss (avg): 4.2909\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        , İstanbul’da kar yağışı ile birlikte parçalı ve zaman zaman kar yağışı ile birlikte etkili oldu. Yakın Doğu Anadolu Bölgesi’nde bazı bölgelerde kar yağışı devam ediyor. Bugün kar yağışı ve yağışı ile birlikte\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        olarak tanımlanan, merkeziyetçi, bölgesel bir güç olması, Türkiye'nin de yoğun bir yönetim ağı olması, ülkenin her türlü gelişmişliği ve mutluluğu ile AB'yi uzun süreli bir bağlılık sarfetmesi\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        sayesinde, çok fazla insan biyolojik olarak da üretilen tüm yapay zeka teknolojilerini kullanmak zorunda. Çevre dostu teknolojilerin kullanımı, daha az insan yaşam alanında daha fazla insana hizmet vermektedir. Dünya üzerindeki insanlarımızın da yaşam\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.2423)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 00:54:41\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "34510 | 4.0754 | 1.2e-04 | 1.25 | 38.7K | 02:01:45 |  69.0%\n",
            "34520 | 4.2388 | 1.2e-04 | 1.17 | 38.7K | 02:01:47 |  69.0%\n",
            "34530 | 4.1626 | 1.2e-04 | 1.15 | 38.7K | 02:01:48 |  69.1%\n",
            "34540 | 4.3850 | 1.2e-04 | 1.19 | 38.7K | 02:01:50 |  69.1%\n",
            "34550 | 4.3380 | 1.2e-04 | 1.19 | 38.7K | 02:01:52 |  69.1%\n",
            "34560 | 4.3376 | 1.2e-04 | 1.13 | 38.7K | 02:01:54 |  69.1%\n",
            "34570 | 4.1510 | 1.2e-04 | 1.14 | 38.7K | 02:01:55 |  69.1%\n",
            "34580 | 4.2558 | 1.2e-04 | 1.14 | 38.7K | 02:01:57 |  69.2%\n",
            "34590 | 4.2275 | 1.2e-04 | 1.14 | 38.7K | 02:01:59 |  69.2%\n",
            "34600 | 4.0588 | 1.2e-04 | 1.14 | 38.7K | 02:02:00 |  69.2%\n",
            "34610 | 4.1866 | 1.2e-04 | 1.21 | 38.7K | 02:02:02 |  69.2%\n",
            "34620 | 4.1432 | 1.2e-04 | 1.16 | 38.7K | 02:02:04 |  69.2%\n",
            "34630 | 4.2660 | 1.2e-04 | 1.13 | 38.7K | 02:02:06 |  69.3%\n",
            "34640 | 4.2116 | 1.2e-04 | 1.22 | 38.7K | 02:02:07 |  69.3%\n",
            "34650 | 4.3131 | 1.2e-04 | 1.17 | 38.7K | 02:02:09 |  69.3%\n",
            "34660 | 4.2786 | 1.2e-04 | 1.15 | 38.7K | 02:02:11 |  69.3%\n",
            "34670 | 4.3518 | 1.2e-04 | 1.16 | 38.7K | 02:02:12 |  69.3%\n",
            "34680 | 4.5526 | 1.2e-04 | 1.16 | 38.7K | 02:02:14 |  69.4%\n",
            "34690 | 4.2309 | 1.2e-04 | 1.12 | 38.7K | 02:02:16 |  69.4%\n",
            "34700 | 4.3255 | 1.2e-04 | 1.15 | 38.7K | 02:02:18 |  69.4%\n",
            "34710 | 4.0250 | 1.2e-04 | 1.18 | 38.7K | 02:02:19 |  69.4%\n",
            "34720 | 4.0092 | 1.1e-04 | 1.12 | 38.7K | 02:02:21 |  69.4%\n",
            "34730 | 4.3670 | 1.1e-04 | 1.13 | 38.7K | 02:02:23 |  69.5%\n",
            "34740 | 4.1507 | 1.1e-04 | 1.15 | 38.7K | 02:02:24 |  69.5%\n",
            "34750 | 4.3439 | 1.1e-04 | 1.16 | 38.7K | 02:02:26 |  69.5%\n",
            "34760 | 4.1927 | 1.1e-04 | 1.15 | 38.8K | 02:02:28 |  69.5%\n",
            "34770 | 4.1724 | 1.1e-04 | 1.16 | 38.8K | 02:02:30 |  69.5%\n",
            "34780 | 4.1338 | 1.1e-04 | 1.17 | 38.8K | 02:02:31 |  69.6%\n",
            "34790 | 4.2746 | 1.1e-04 | 1.15 | 38.8K | 02:02:33 |  69.6%\n",
            "34800 | 4.4542 | 1.1e-04 | 1.19 | 38.8K | 02:02:35 |  69.6%\n",
            "34810 | 4.2084 | 1.1e-04 | 1.15 | 38.8K | 02:02:36 |  69.6%\n",
            "34820 | 4.3285 | 1.1e-04 | 1.16 | 38.8K | 02:02:38 |  69.6%\n",
            "34830 | 4.4716 | 1.1e-04 | 1.17 | 38.8K | 02:02:40 |  69.7%\n",
            "34840 | 4.5969 | 1.1e-04 | 1.23 | 38.8K | 02:02:42 |  69.7%\n",
            "34850 | 4.6060 | 1.1e-04 | 1.13 | 38.8K | 02:02:43 |  69.7%\n",
            "34860 | 4.2335 | 1.1e-04 | 1.17 | 38.8K | 02:02:45 |  69.7%\n",
            "34870 | 4.2513 | 1.1e-04 | 1.14 | 38.8K | 02:02:47 |  69.7%\n",
            "34880 | 4.3416 | 1.1e-04 | 1.15 | 38.8K | 02:02:48 |  69.8%\n",
            "34890 | 3.9354 | 1.1e-04 | 1.13 | 38.8K | 02:02:50 |  69.8%\n",
            "34900 | 4.3496 | 1.1e-04 | 1.16 | 38.8K | 02:02:52 |  69.8%\n",
            "34910 | 4.2706 | 1.1e-04 | 1.16 | 38.8K | 02:02:54 |  69.8%\n",
            "34920 | 4.3843 | 1.1e-04 | 1.17 | 38.8K | 02:02:55 |  69.8%\n",
            "34930 | 3.5710 | 1.1e-04 | 1.27 | 38.8K | 02:02:57 |  69.9%\n",
            "34940 | 4.3649 | 1.1e-04 | 1.15 | 38.8K | 02:02:59 |  69.9%\n",
            "34950 | 4.5250 | 1.1e-04 | 1.17 | 38.8K | 02:03:00 |  69.9%\n",
            "34960 | 4.0962 | 1.1e-04 | 1.26 | 38.8K | 02:03:02 |  69.9%\n",
            "34970 | 4.0772 | 1.1e-04 | 1.26 | 38.8K | 02:03:04 |  69.9%\n",
            "34980 | 3.9849 | 1.1e-04 | 1.19 | 38.8K | 02:03:06 |  70.0%\n",
            "34990 | 4.3328 | 1.1e-04 | 1.18 | 38.8K | 02:03:07 |  70.0%\n",
            "35000 | 4.5387 | 1.1e-04 | 1.14 | 38.8K | 02:03:09 |  70.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 35000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.2472\n",
            "  Perplexity: 69.91\n",
            "  Train loss (avg): 4.2948\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        çok sıcak ve soğuk. Kış aylarının çok sıcak geçmesi ile, kışın, yazın donup, kışın da sıcak olacak. Kış geldi. Kış geldi. Kış geldi. Gün geldi. Kış geldi. Kış\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        ve en büyük şehri olan Türkiye, Avrupa'ya açık bir konuma sahiptir. Türkiye, Avrupa'nın en büyük şehri olan Avrupa'ya açılan kapısı olarak bilinen dünyanın en büyük şehridir. Türkiye'nin\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        günümüzde, akıllı cihazlara iyi gelebiliyor. Sizin de böyle bir şey yapmış olduğunuza inanmanız gerekiyor. Herhangi bir altyapıyı dağıttığınız ya da satın aldığınız marka, bir şey satmak ya da daha fazlasını\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:52:54\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "💾 Checkpoint kaydediliyor: /content/drive/MyDrive/turkish_llm/checkpoints//checkpoint_step_35000.pt\n",
            "  ✅ Checkpoint kaydedildi!\n",
            "\n",
            "35010 | 4.1172 | 1.1e-04 | 1.13 | 38.7K | 02:03:31 |  70.0%\n",
            "35020 | 4.2884 | 1.1e-04 | 1.13 | 38.7K | 02:03:33 |  70.0%\n",
            "35030 | 4.6304 | 1.1e-04 | 1.20 | 38.7K | 02:03:35 |  70.1%\n",
            "35040 | 4.5377 | 1.1e-04 | 1.18 | 38.7K | 02:03:36 |  70.1%\n",
            "35050 | 4.3489 | 1.1e-04 | 1.16 | 38.7K | 02:03:38 |  70.1%\n",
            "35060 | 3.7630 | 1.1e-04 | 1.27 | 38.7K | 02:03:40 |  70.1%\n",
            "35070 | 4.5015 | 1.1e-04 | 1.18 | 38.7K | 02:03:41 |  70.1%\n",
            "35080 | 4.2593 | 1.1e-04 | 1.15 | 38.7K | 02:03:43 |  70.2%\n",
            "35090 | 4.2757 | 1.1e-04 | 1.16 | 38.7K | 02:03:45 |  70.2%\n",
            "35100 | 4.2478 | 1.1e-04 | 1.13 | 38.7K | 02:03:47 |  70.2%\n",
            "35110 | 4.3042 | 1.1e-04 | 1.15 | 38.7K | 02:03:48 |  70.2%\n",
            "35120 | 4.4338 | 1.1e-04 | 1.16 | 38.7K | 02:03:50 |  70.2%\n",
            "35130 | 4.1874 | 1.1e-04 | 1.20 | 38.7K | 02:03:52 |  70.3%\n",
            "35140 | 4.3374 | 1.1e-04 | 1.21 | 38.7K | 02:03:53 |  70.3%\n",
            "35150 | 4.5744 | 1.1e-04 | 1.27 | 38.7K | 02:03:55 |  70.3%\n",
            "35160 | 4.4135 | 1.1e-04 | 1.13 | 38.7K | 02:03:57 |  70.3%\n",
            "35170 | 4.1813 | 1.1e-04 | 1.16 | 38.7K | 02:03:59 |  70.3%\n",
            "35180 | 4.2871 | 1.1e-04 | 1.16 | 38.7K | 02:04:00 |  70.4%\n",
            "35190 | 4.2418 | 1.1e-04 | 1.19 | 38.7K | 02:04:02 |  70.4%\n",
            "35200 | 4.4868 | 1.1e-04 | 1.17 | 38.7K | 02:04:04 |  70.4%\n",
            "35210 | 4.4765 | 1.1e-04 | 1.16 | 38.7K | 02:04:05 |  70.4%\n",
            "35220 | 4.5188 | 1.1e-04 | 1.16 | 38.7K | 02:04:07 |  70.4%\n",
            "35230 | 4.3822 | 1.1e-04 | 1.18 | 38.7K | 02:04:09 |  70.5%\n",
            "35240 | 4.3112 | 1.1e-04 | 1.17 | 38.7K | 02:04:11 |  70.5%\n",
            "35250 | 4.2723 | 1.1e-04 | 1.19 | 38.7K | 02:04:12 |  70.5%\n",
            "35260 | 4.1843 | 1.1e-04 | 1.19 | 38.7K | 02:04:14 |  70.5%\n",
            "35270 | 4.3190 | 1.1e-04 | 1.25 | 38.8K | 02:04:16 |  70.5%\n",
            "35280 | 4.1814 | 1.1e-04 | 1.21 | 38.8K | 02:04:17 |  70.6%\n",
            "35290 | 4.6401 | 1.1e-04 | 1.21 | 38.8K | 02:04:19 |  70.6%\n",
            "35300 | 4.3475 | 1.1e-04 | 1.20 | 38.8K | 02:04:21 |  70.6%\n",
            "35310 | 4.3349 | 1.1e-04 | 1.13 | 38.8K | 02:04:23 |  70.6%\n",
            "35320 | 3.7434 | 1.1e-04 | 1.20 | 38.8K | 02:04:24 |  70.6%\n",
            "35330 | 4.0958 | 1.1e-04 | 1.19 | 38.8K | 02:04:26 |  70.7%\n",
            "35340 | 4.6973 | 1.1e-04 | 1.12 | 38.8K | 02:04:28 |  70.7%\n",
            "35350 | 4.3994 | 1.1e-04 | 1.20 | 38.8K | 02:04:29 |  70.7%\n",
            "35360 | 4.4263 | 1.1e-04 | 1.15 | 38.8K | 02:04:31 |  70.7%\n",
            "35370 | 4.3124 | 1.1e-04 | 1.16 | 38.8K | 02:04:33 |  70.7%\n",
            "35380 | 4.1703 | 1.1e-04 | 1.16 | 38.8K | 02:04:34 |  70.8%\n",
            "35390 | 4.3015 | 1.1e-04 | 1.16 | 38.8K | 02:04:36 |  70.8%\n",
            "35400 | 4.0265 | 1.1e-04 | 1.15 | 38.8K | 02:04:38 |  70.8%\n",
            "35410 | 4.3114 | 1.1e-04 | 1.25 | 38.8K | 02:04:40 |  70.8%\n",
            "35420 | 4.1283 | 1.1e-04 | 1.15 | 38.8K | 02:04:41 |  70.8%\n",
            "35430 | 4.3487 | 1.1e-04 | 1.16 | 38.8K | 02:04:43 |  70.9%\n",
            "35440 | 4.3632 | 1.1e-04 | 1.13 | 38.8K | 02:04:45 |  70.9%\n",
            "35450 | 3.4797 | 1.1e-04 | 1.23 | 38.8K | 02:04:46 |  70.9%\n",
            "35460 | 4.1995 | 1.0e-04 | 1.19 | 38.8K | 02:04:48 |  70.9%\n",
            "35470 | 4.4189 | 1.0e-04 | 1.18 | 38.8K | 02:04:50 |  70.9%\n",
            "35480 | 4.3836 | 1.0e-04 | 1.18 | 38.8K | 02:04:52 |  71.0%\n",
            "35490 | 4.0369 | 1.0e-04 | 1.15 | 38.8K | 02:04:53 |  71.0%\n",
            "35500 | 4.1093 | 1.0e-04 | 1.14 | 38.8K | 02:04:55 |  71.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 35500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.2304\n",
            "  Perplexity: 68.75\n",
            "  Train loss (avg): 4.2843\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        şartları ne olursa olsun hava şartları su ve toprak ısısı ile sabittir. Hava koşulları hava şartları hava şartlarının uygunluğuna göre değişiklik göstermektedir. Ancak hava şartları, hava şartları ve hava şartları bu belgeler üzerinde\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Ankara'da, Ankara merkezli çok sayıda STK ve çeşitli meslek kuruluşu vardır. Bunlardan bazıları: Ankara, İzmir, İzmir, İzmir, Eskişehir, İzmir, Antalya, Diyarbakır, Samsun, Antalya, İzmir,\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        sayesinde dijital uygulamalar daha az enerji tüketimine olanak sağlar. Aslında bu, bir bilgisayar tarafından yönlendirilir. Ve neredeyse hiç tek bir özelliği yoktur. Eğer bilgisayarınız bu konuda bir çok konuda bilgi sahibi ve yetkin\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.2304)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 00:51:09\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "35510 | 4.1242 | 1.0e-04 | 1.15 | 38.7K | 02:05:17 |  71.0%\n",
            "35520 | 4.0997 | 1.0e-04 | 1.17 | 38.7K | 02:05:19 |  71.0%\n",
            "35530 | 4.3703 | 1.0e-04 | 1.16 | 38.7K | 02:05:21 |  71.1%\n",
            "35540 | 4.2852 | 1.0e-04 | 1.18 | 38.7K | 02:05:22 |  71.1%\n",
            "35550 | 4.3566 | 1.0e-04 | 1.15 | 38.7K | 02:05:24 |  71.1%\n",
            "35560 | 4.3132 | 1.0e-04 | 1.15 | 38.7K | 02:05:26 |  71.1%\n",
            "35570 | 4.4356 | 1.0e-04 | 1.19 | 38.7K | 02:05:28 |  71.1%\n",
            "35580 | 4.1503 | 1.0e-04 | 1.17 | 38.7K | 02:05:29 |  71.2%\n",
            "35590 | 4.1346 | 1.0e-04 | 1.25 | 38.7K | 02:05:31 |  71.2%\n",
            "35600 | 4.5042 | 1.0e-04 | 1.18 | 38.7K | 02:05:33 |  71.2%\n",
            "35610 | 4.3319 | 1.0e-04 | 1.18 | 38.7K | 02:05:34 |  71.2%\n",
            "35620 | 4.2539 | 1.0e-04 | 1.12 | 38.7K | 02:05:36 |  71.2%\n",
            "35630 | 4.3146 | 1.0e-04 | 1.16 | 38.7K | 02:05:38 |  71.3%\n",
            "35640 | 4.2118 | 1.0e-04 | 1.14 | 38.7K | 02:05:40 |  71.3%\n",
            "35650 | 4.4843 | 1.0e-04 | 1.17 | 38.7K | 02:05:41 |  71.3%\n",
            "35660 | 4.3039 | 1.0e-04 | 1.19 | 38.7K | 02:05:43 |  71.3%\n",
            "35670 | 4.7122 | 1.0e-04 | 1.20 | 38.7K | 02:05:45 |  71.3%\n",
            "35680 | 4.3794 | 1.0e-04 | 1.17 | 38.7K | 02:05:46 |  71.4%\n",
            "35690 | 4.2791 | 1.0e-04 | 1.21 | 38.7K | 02:05:48 |  71.4%\n",
            "35700 | 4.2941 | 1.0e-04 | 1.14 | 38.7K | 02:05:50 |  71.4%\n",
            "35710 | 4.2276 | 1.0e-04 | 1.33 | 38.7K | 02:05:52 |  71.4%\n",
            "35720 | 4.3256 | 1.0e-04 | 1.16 | 38.7K | 02:05:53 |  71.4%\n",
            "35730 | 4.1620 | 1.0e-04 | 1.12 | 38.7K | 02:05:55 |  71.5%\n",
            "35740 | 4.1244 | 1.0e-04 | 1.17 | 38.7K | 02:05:57 |  71.5%\n",
            "35750 | 4.3131 | 1.0e-04 | 1.18 | 38.7K | 02:05:58 |  71.5%\n",
            "35760 | 3.9916 | 1.0e-04 | 1.16 | 38.7K | 02:06:00 |  71.5%\n",
            "35770 | 4.2227 | 1.0e-04 | 1.17 | 38.7K | 02:06:02 |  71.5%\n",
            "35780 | 4.4829 | 1.0e-04 | 1.17 | 38.8K | 02:06:04 |  71.6%\n",
            "35790 | 4.3549 | 1.0e-04 | 1.15 | 38.8K | 02:06:05 |  71.6%\n",
            "35800 | 4.2126 | 1.0e-04 | 1.15 | 38.8K | 02:06:07 |  71.6%\n",
            "35810 | 4.2044 | 1.0e-04 | 1.18 | 38.8K | 02:06:09 |  71.6%\n",
            "35820 | 4.0546 | 1.0e-04 | 1.13 | 38.8K | 02:06:10 |  71.6%\n",
            "35830 | 4.2943 | 1.0e-04 | 1.13 | 38.8K | 02:06:12 |  71.7%\n",
            "35840 | 4.1629 | 1.0e-04 | 1.19 | 38.8K | 02:06:14 |  71.7%\n",
            "35850 | 4.3926 | 1.0e-04 | 1.18 | 38.8K | 02:06:16 |  71.7%\n",
            "35860 | 4.1515 | 1.0e-04 | 1.19 | 38.8K | 02:06:17 |  71.7%\n",
            "35870 | 4.4432 | 1.0e-04 | 1.19 | 38.8K | 02:06:19 |  71.7%\n",
            "35880 | 4.3464 | 9.9e-05 | 1.14 | 38.8K | 02:06:21 |  71.8%\n",
            "35890 | 4.4980 | 9.9e-05 | 1.20 | 38.8K | 02:06:22 |  71.8%\n",
            "35900 | 4.3239 | 9.9e-05 | 1.20 | 38.8K | 02:06:24 |  71.8%\n",
            "35910 | 4.1055 | 9.9e-05 | 1.19 | 38.8K | 02:06:26 |  71.8%\n",
            "35920 | 4.5209 | 9.9e-05 | 1.17 | 38.8K | 02:06:28 |  71.8%\n",
            "35930 | 4.4250 | 9.9e-05 | 1.19 | 38.8K | 02:06:29 |  71.9%\n",
            "35940 | 4.6266 | 9.9e-05 | 1.14 | 38.8K | 02:06:31 |  71.9%\n",
            "35950 | 4.3022 | 9.8e-05 | 1.22 | 38.8K | 02:06:33 |  71.9%\n",
            "35960 | 4.2902 | 9.8e-05 | 1.14 | 38.8K | 02:06:34 |  71.9%\n",
            "35970 | 4.2400 | 9.8e-05 | 1.20 | 38.8K | 02:06:36 |  71.9%\n",
            "35980 | 4.3243 | 9.8e-05 | 1.18 | 38.8K | 02:06:38 |  72.0%\n",
            "35990 | 4.2916 | 9.8e-05 | 1.17 | 38.8K | 02:06:40 |  72.0%\n",
            "36000 | 4.3592 | 9.8e-05 | 1.19 | 38.8K | 02:06:41 |  72.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 36000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.2141\n",
            "  Perplexity: 67.63\n",
            "  Train loss (avg): 4.2743\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        nasıl? Karaciğer nedir? Karaciğer neden oluşur? Karaciğerin nasıl bir halde olduğu, nasıl geliştiği ve nasıl geliştiği hakkında bilgi verir. Karaciğer nasıl çalışır? Karaciğer ve deniz biy\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Ankara'da bulunan OMÜ'de, iki ayrı grup tarafından kurulan ve aralarında yaklaşık 20 kişinin çalıştığı bir kuruluş olan OMÜ'de, AK Parti ile CHP'nin Meclis'te temsil\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        ile pazarlama, pazarlama, sosyal medya ve satış ve satış gibi alanlarda çok geniş kapsamlı bir şekilde çalışan pazarlama ve tanıtım platformudur. Ayrıca dijital pazarlama alanında müşteri portföyüne yönelik en yeni teknolojilere ve yatırımlara\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.2141)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 00:49:24\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "36010 | 4.2662 | 9.8e-05 | 1.27 | 38.7K | 02:07:04 |  72.0%\n",
            "36020 | 4.4723 | 9.8e-05 | 1.13 | 38.7K | 02:07:05 |  72.0%\n",
            "36030 | 4.4907 | 9.7e-05 | 1.21 | 38.7K | 02:07:07 |  72.1%\n",
            "36040 | 4.2032 | 9.7e-05 | 1.16 | 38.7K | 02:07:09 |  72.1%\n",
            "36050 | 4.0850 | 9.7e-05 | 1.19 | 38.7K | 02:07:10 |  72.1%\n",
            "36060 | 4.2781 | 9.7e-05 | 1.13 | 38.7K | 02:07:12 |  72.1%\n",
            "36070 | 4.3791 | 9.7e-05 | 1.16 | 38.7K | 02:07:14 |  72.1%\n",
            "36080 | 4.2336 | 9.7e-05 | 1.15 | 38.7K | 02:07:16 |  72.2%\n",
            "36090 | 4.1313 | 9.7e-05 | 1.18 | 38.7K | 02:07:17 |  72.2%\n",
            "36100 | 4.0667 | 9.7e-05 | 1.17 | 38.7K | 02:07:19 |  72.2%\n",
            "36110 | 4.0964 | 9.6e-05 | 1.12 | 38.7K | 02:07:21 |  72.2%\n",
            "36120 | 4.4561 | 9.6e-05 | 1.19 | 38.7K | 02:07:22 |  72.2%\n",
            "36130 | 4.1863 | 9.6e-05 | 1.13 | 38.7K | 02:07:24 |  72.3%\n",
            "36140 | 4.3641 | 9.6e-05 | 1.17 | 38.7K | 02:07:26 |  72.3%\n",
            "36150 | 4.1467 | 9.6e-05 | 1.20 | 38.7K | 02:07:28 |  72.3%\n",
            "36160 | 4.2850 | 9.6e-05 | 1.18 | 38.7K | 02:07:29 |  72.3%\n",
            "36170 | 4.4549 | 9.6e-05 | 1.17 | 38.7K | 02:07:31 |  72.3%\n",
            "36180 | 4.4682 | 9.5e-05 | 1.14 | 38.7K | 02:07:33 |  72.4%\n",
            "36190 | 4.0600 | 9.5e-05 | 1.14 | 38.7K | 02:07:34 |  72.4%\n",
            "36200 | 4.2887 | 9.5e-05 | 1.15 | 38.7K | 02:07:36 |  72.4%\n",
            "36210 | 4.3030 | 9.5e-05 | 1.13 | 38.7K | 02:07:38 |  72.4%\n",
            "36220 | 4.3542 | 9.5e-05 | 1.16 | 38.7K | 02:07:40 |  72.4%\n",
            "36230 | 4.4598 | 9.5e-05 | 1.20 | 38.7K | 02:07:41 |  72.5%\n",
            "36240 | 4.2294 | 9.5e-05 | 1.17 | 38.7K | 02:07:43 |  72.5%\n",
            "36250 | 4.1516 | 9.5e-05 | 1.17 | 38.7K | 02:07:45 |  72.5%\n",
            "36260 | 4.3751 | 9.4e-05 | 1.15 | 38.7K | 02:07:46 |  72.5%\n",
            "36270 | 4.2285 | 9.4e-05 | 1.18 | 38.7K | 02:07:48 |  72.5%\n",
            "36280 | 4.3760 | 9.4e-05 | 1.19 | 38.7K | 02:07:50 |  72.6%\n",
            "36290 | 4.0091 | 9.4e-05 | 1.18 | 38.7K | 02:07:52 |  72.6%\n",
            "36300 | 4.5738 | 9.4e-05 | 1.18 | 38.8K | 02:07:53 |  72.6%\n",
            "36310 | 4.2870 | 9.4e-05 | 1.13 | 38.8K | 02:07:55 |  72.6%\n",
            "36320 | 4.3755 | 9.4e-05 | 1.18 | 38.8K | 02:07:57 |  72.6%\n",
            "36330 | 4.2109 | 9.4e-05 | 1.18 | 38.8K | 02:07:58 |  72.7%\n",
            "36340 | 4.2479 | 9.3e-05 | 1.15 | 38.8K | 02:08:00 |  72.7%\n",
            "36350 | 4.0767 | 9.3e-05 | 1.23 | 38.8K | 02:08:02 |  72.7%\n",
            "36360 | 4.0521 | 9.3e-05 | 1.21 | 38.8K | 02:08:04 |  72.7%\n",
            "36370 | 4.3254 | 9.3e-05 | 1.19 | 38.8K | 02:08:05 |  72.7%\n",
            "36380 | 3.9842 | 9.3e-05 | 1.19 | 38.8K | 02:08:07 |  72.8%\n",
            "36390 | 4.2263 | 9.3e-05 | 1.16 | 38.8K | 02:08:09 |  72.8%\n",
            "36400 | 4.0299 | 9.3e-05 | 1.16 | 38.8K | 02:08:10 |  72.8%\n",
            "36410 | 3.9180 | 9.3e-05 | 1.18 | 38.8K | 02:08:12 |  72.8%\n",
            "36420 | 4.2006 | 9.2e-05 | 1.12 | 38.8K | 02:08:14 |  72.8%\n",
            "36430 | 4.7768 | 9.2e-05 | 1.23 | 38.8K | 02:08:16 |  72.9%\n",
            "36440 | 4.3053 | 9.2e-05 | 1.15 | 38.8K | 02:08:17 |  72.9%\n",
            "36450 | 4.2443 | 9.2e-05 | 1.28 | 38.8K | 02:08:19 |  72.9%\n",
            "36460 | 4.2808 | 9.2e-05 | 1.19 | 38.8K | 02:08:21 |  72.9%\n",
            "36470 | 4.2815 | 9.2e-05 | 1.16 | 38.8K | 02:08:22 |  72.9%\n",
            "36480 | 4.1069 | 9.2e-05 | 1.22 | 38.8K | 02:08:24 |  73.0%\n",
            "36490 | 4.0680 | 9.2e-05 | 1.20 | 38.8K | 02:08:26 |  73.0%\n",
            "36500 | 4.2256 | 9.1e-05 | 1.18 | 38.8K | 02:08:28 |  73.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 36500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.2066\n",
            "  Perplexity: 67.13\n",
            "  Train loss (avg): 4.2431\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        parçalı ve vahşi ormanlarda can verme hareketi, daha sonra tüm ormanlar, daha sonra tüm ormanlar, daha sonra ise çok daha büyük bir ormanda ve daha sonra da uzun yıllardır var olan orman\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Birgün'de bir araya gelen ve iki ülke arasındaki dış ticaret anlaşmasını da içeren, Türkiye, yüzde 17'lik bir oranda dış ticaret hacmiyle ilgili reformlar yapmaya başladı. Uluslararası ticaret anlaş\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , insanların kafasının kesilmesini önlemek için daha fazla potansiyel enerji tasarrufu sağlıyor. 16 yaşındaki bir çocuk, artık kendi kendine düşünmeli ve bunları öğrendikten sonra önce kendi kendine düşünmelidir. Çünkü, bilişsel ve\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.2066)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 00:47:38\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "36510 | 4.3598 | 9.1e-05 | 1.23 | 38.7K | 02:08:50 |  73.0%\n",
            "36520 | 4.5252 | 9.1e-05 | 1.23 | 38.7K | 02:08:52 |  73.0%\n",
            "36530 | 4.2525 | 9.1e-05 | 1.18 | 38.7K | 02:08:53 |  73.1%\n",
            "36540 | 3.9535 | 9.1e-05 | 1.17 | 38.7K | 02:08:55 |  73.1%\n",
            "36550 | 4.2324 | 9.1e-05 | 1.17 | 38.7K | 02:08:57 |  73.1%\n",
            "36560 | 4.4490 | 9.1e-05 | 1.16 | 38.7K | 02:08:58 |  73.1%\n",
            "36570 | 4.4160 | 9.1e-05 | 1.14 | 38.7K | 02:09:00 |  73.1%\n",
            "36580 | 4.0199 | 9.0e-05 | 1.26 | 38.7K | 02:09:02 |  73.2%\n",
            "36590 | 3.9843 | 9.0e-05 | 1.18 | 38.7K | 02:09:04 |  73.2%\n",
            "36600 | 4.0816 | 9.0e-05 | 1.28 | 38.7K | 02:09:05 |  73.2%\n",
            "36610 | 4.2973 | 9.0e-05 | 1.26 | 38.7K | 02:09:07 |  73.2%\n",
            "36620 | 4.2443 | 9.0e-05 | 1.19 | 38.7K | 02:09:09 |  73.2%\n",
            "36630 | 4.3423 | 9.0e-05 | 1.18 | 38.7K | 02:09:10 |  73.3%\n",
            "36640 | 4.2326 | 9.0e-05 | 1.18 | 38.7K | 02:09:12 |  73.3%\n",
            "36650 | 4.1439 | 9.0e-05 | 1.19 | 38.7K | 02:09:14 |  73.3%\n",
            "36660 | 4.3015 | 8.9e-05 | 1.16 | 38.7K | 02:09:16 |  73.3%\n",
            "36670 | 4.5912 | 8.9e-05 | 1.17 | 38.7K | 02:09:17 |  73.3%\n",
            "36680 | 4.3475 | 8.9e-05 | 1.18 | 38.7K | 02:09:19 |  73.4%\n",
            "36690 | 4.0860 | 8.9e-05 | 1.15 | 38.7K | 02:09:21 |  73.4%\n",
            "36700 | 4.3372 | 8.9e-05 | 1.15 | 38.7K | 02:09:22 |  73.4%\n",
            "36710 | 4.1087 | 8.9e-05 | 1.31 | 38.7K | 02:09:24 |  73.4%\n",
            "36720 | 4.2719 | 8.9e-05 | 1.16 | 38.7K | 02:09:26 |  73.4%\n",
            "36730 | 4.6025 | 8.9e-05 | 1.16 | 38.7K | 02:09:28 |  73.5%\n",
            "36740 | 4.0786 | 8.8e-05 | 1.18 | 38.7K | 02:09:29 |  73.5%\n",
            "36750 | 4.4705 | 8.8e-05 | inf | 38.7K | 02:09:31 |  73.5%\n",
            "36760 | 4.3805 | 8.8e-05 | 1.25 | 38.7K | 02:09:33 |  73.5%\n",
            "36770 | 4.2332 | 8.8e-05 | 1.19 | 38.7K | 02:09:34 |  73.5%\n",
            "36780 | 4.0695 | 8.8e-05 | 1.13 | 38.7K | 02:09:36 |  73.6%\n",
            "36790 | 4.2221 | 8.8e-05 | 1.17 | 38.7K | 02:09:38 |  73.6%\n",
            "36800 | 4.2470 | 8.8e-05 | 1.17 | 38.7K | 02:09:40 |  73.6%\n",
            "36810 | 4.1916 | 8.8e-05 | 1.23 | 38.8K | 02:09:41 |  73.6%\n",
            "36820 | 3.9965 | 8.7e-05 | 1.16 | 38.8K | 02:09:43 |  73.6%\n",
            "36830 | 4.2609 | 8.7e-05 | 1.19 | 38.8K | 02:09:45 |  73.7%\n",
            "36840 | 4.2983 | 8.7e-05 | 1.21 | 38.8K | 02:09:46 |  73.7%\n",
            "36850 | 4.2930 | 8.7e-05 | 1.22 | 38.8K | 02:09:48 |  73.7%\n",
            "36860 | 4.2951 | 8.7e-05 | 1.17 | 38.8K | 02:09:50 |  73.7%\n",
            "36870 | 4.2694 | 8.7e-05 | 1.20 | 38.8K | 02:09:52 |  73.7%\n",
            "36880 | 4.3169 | 8.7e-05 | 1.19 | 38.8K | 02:09:53 |  73.8%\n",
            "36890 | 4.5107 | 8.7e-05 | 1.25 | 38.8K | 02:09:55 |  73.8%\n",
            "36900 | 4.2465 | 8.6e-05 | 1.22 | 38.8K | 02:09:57 |  73.8%\n",
            "36910 | 4.4554 | 8.6e-05 | 1.19 | 38.8K | 02:09:58 |  73.8%\n",
            "36920 | 4.1332 | 8.6e-05 | 1.18 | 38.8K | 02:10:00 |  73.8%\n",
            "36930 | 4.2936 | 8.6e-05 | 1.17 | 38.8K | 02:10:02 |  73.9%\n",
            "36940 | 4.3670 | 8.6e-05 | 1.17 | 38.8K | 02:10:04 |  73.9%\n",
            "36950 | 4.4245 | 8.6e-05 | 1.16 | 38.8K | 02:10:05 |  73.9%\n",
            "36960 | 4.4462 | 8.6e-05 | 1.16 | 38.8K | 02:10:07 |  73.9%\n",
            "36970 | 4.3342 | 8.6e-05 | 1.16 | 38.8K | 02:10:09 |  73.9%\n",
            "36980 | 4.2840 | 8.5e-05 | 1.22 | 38.8K | 02:10:10 |  74.0%\n",
            "36990 | 4.4428 | 8.5e-05 | 1.18 | 38.8K | 02:10:12 |  74.0%\n",
            "37000 | 4.2466 | 8.5e-05 | 1.31 | 38.8K | 02:10:14 |  74.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 37000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.2072\n",
            "  Perplexity: 67.17\n",
            "  Train loss (avg): 4.2809\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        kapalıyken, bir anda baktıkça, hava iyice soğumaya başladı. Güneş Sistemini açın, ona doğru sürükleyin. Kendinize iyi bakın, bir iyi gün geçireceksiniz. Bir hata yapmış gibi görünmeyin\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        İstanbul'da kalan Türk Milli Birliği, Türkiye'nin güneyinde hem ekonomik hem de politik olarak barınan ve uluslararası alanda faaliyet gösteren yabancı sermayenin faaliyetlerine devam ediyor. AB, Türkiye'nin kuzeyinde de dış\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        sayesinde, beyin ve sinir sistemlerindeki performansa paralel olarak, insan sinir sistemi savunma sistemlerindeki algıyı ifade edebilmektedir. Sonuç olarak, beyinde sinir sisteminin gerçek düşünme yeteneği, beynin enerji ve sinir sistem\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 00:45:51\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "37010 | 4.0325 | 8.5e-05 | 1.15 | 38.7K | 02:10:33 |  74.0%\n",
            "37020 | 4.4097 | 8.5e-05 | 1.16 | 38.7K | 02:10:35 |  74.0%\n",
            "37030 | 3.9336 | 8.5e-05 | 1.27 | 38.7K | 02:10:36 |  74.1%\n",
            "37040 | 4.0194 | 8.5e-05 | 1.23 | 38.7K | 02:10:38 |  74.1%\n",
            "37050 | 4.1889 | 8.5e-05 | 1.20 | 38.7K | 02:10:40 |  74.1%\n",
            "37060 | 4.2664 | 8.4e-05 | 1.20 | 38.7K | 02:10:41 |  74.1%\n",
            "37070 | 4.1409 | 8.4e-05 | 1.18 | 38.7K | 02:10:43 |  74.1%\n",
            "37080 | 4.5291 | 8.4e-05 | 1.22 | 38.7K | 02:10:45 |  74.2%\n",
            "37090 | 4.1710 | 8.4e-05 | 1.17 | 38.7K | 02:10:47 |  74.2%\n",
            "37100 | 4.1366 | 8.4e-05 | 1.15 | 38.7K | 02:10:48 |  74.2%\n",
            "37110 | 4.4840 | 8.4e-05 | 1.20 | 38.7K | 02:10:50 |  74.2%\n",
            "37120 | 4.2495 | 8.4e-05 | 1.16 | 38.7K | 02:10:52 |  74.2%\n",
            "37130 | 4.2995 | 8.4e-05 | 1.17 | 38.7K | 02:10:53 |  74.3%\n",
            "37140 | 4.4617 | 8.3e-05 | 1.24 | 38.7K | 02:10:55 |  74.3%\n",
            "37150 | 4.3654 | 8.3e-05 | 1.17 | 38.7K | 02:10:57 |  74.3%\n",
            "37160 | 4.4197 | 8.3e-05 | 1.16 | 38.7K | 02:10:58 |  74.3%\n",
            "37170 | 4.2719 | 8.3e-05 | 1.17 | 38.7K | 02:11:00 |  74.3%\n",
            "37180 | 4.3227 | 8.3e-05 | 1.20 | 38.7K | 02:11:02 |  74.4%\n",
            "37190 | 4.2102 | 8.3e-05 | 1.17 | 38.7K | 02:11:04 |  74.4%\n",
            "37200 | 4.1567 | 8.3e-05 | 1.22 | 38.7K | 02:11:05 |  74.4%\n",
            "37210 | 4.2558 | 8.3e-05 | 1.19 | 38.7K | 02:11:07 |  74.4%\n",
            "37220 | 4.1483 | 8.2e-05 | 1.17 | 38.7K | 02:11:09 |  74.4%\n",
            "37230 | 4.1196 | 8.2e-05 | 1.15 | 38.7K | 02:11:10 |  74.5%\n",
            "37240 | 4.1315 | 8.2e-05 | 1.22 | 38.8K | 02:11:12 |  74.5%\n",
            "37250 | 3.8368 | 8.2e-05 | 1.28 | 38.8K | 02:11:14 |  74.5%\n",
            "37260 | 4.3260 | 8.2e-05 | 1.29 | 38.8K | 02:11:16 |  74.5%\n",
            "37270 | 4.3471 | 8.2e-05 | 1.17 | 38.8K | 02:11:17 |  74.5%\n",
            "37280 | 4.1632 | 8.2e-05 | 1.15 | 38.8K | 02:11:19 |  74.6%\n",
            "37290 | 4.0192 | 8.2e-05 | 1.21 | 38.8K | 02:11:21 |  74.6%\n",
            "37300 | 3.9811 | 8.2e-05 | 1.18 | 38.8K | 02:11:22 |  74.6%\n",
            "37310 | 4.4077 | 8.1e-05 | 1.15 | 38.8K | 02:11:24 |  74.6%\n",
            "37320 | 4.4213 | 8.1e-05 | 1.20 | 38.8K | 02:11:26 |  74.6%\n",
            "37330 | 4.0866 | 8.1e-05 | 1.26 | 38.8K | 02:11:28 |  74.7%\n",
            "37340 | 3.9554 | 8.1e-05 | 1.16 | 38.8K | 02:11:29 |  74.7%\n",
            "37350 | 4.1424 | 8.1e-05 | 1.19 | 38.8K | 02:11:31 |  74.7%\n",
            "37360 | 4.2086 | 8.1e-05 | 1.24 | 38.8K | 02:11:33 |  74.7%\n",
            "37370 | 4.2031 | 8.1e-05 | 1.14 | 38.8K | 02:11:34 |  74.7%\n",
            "37380 | 4.3659 | 8.1e-05 | 1.18 | 38.8K | 02:11:36 |  74.8%\n",
            "37390 | 4.3849 | 8.0e-05 | 1.24 | 38.8K | 02:11:38 |  74.8%\n",
            "37400 | 4.3341 | 8.0e-05 | 1.23 | 38.8K | 02:11:40 |  74.8%\n",
            "37410 | 4.4023 | 8.0e-05 | 1.16 | 38.8K | 02:11:41 |  74.8%\n",
            "37420 | 3.8670 | 8.0e-05 | 1.21 | 38.8K | 02:11:43 |  74.8%\n",
            "37430 | 4.3510 | 8.0e-05 | 1.16 | 38.8K | 02:11:45 |  74.9%\n",
            "37440 | 4.4033 | 8.0e-05 | 1.16 | 38.8K | 02:11:46 |  74.9%\n",
            "37450 | 4.4802 | 8.0e-05 | 1.16 | 38.8K | 02:11:48 |  74.9%\n",
            "37460 | 4.3934 | 8.0e-05 | 1.21 | 38.8K | 02:11:50 |  74.9%\n",
            "37470 | 4.3294 | 7.9e-05 | 1.17 | 38.8K | 02:11:51 |  74.9%\n",
            "37480 | 4.2171 | 7.9e-05 | 1.16 | 38.8K | 02:11:53 |  75.0%\n",
            "37490 | 4.1612 | 7.9e-05 | 1.18 | 38.8K | 02:11:55 |  75.0%\n",
            "37500 | 4.2088 | 7.9e-05 | 1.21 | 38.8K | 02:11:57 |  75.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 37500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1663\n",
            "  Perplexity: 64.48\n",
            "  Train loss (avg): 4.2537\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        durumu tahminleri, hava durumu tahminleri, hava durumu tahminleri ve hava durumu tahminleri olarak bilinmektedir. Eğer hava durumu tahminleri tahminleri ile birlikte hava durumu tahminleri tahminleri ile birlikte yer almak\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        olan İstanbul'a uzaklığı 5 km. mesafededir. Ankara'nın en yüksek noktası olan Ankara, aynı zamanda çok daha güzel bir çevre kampı ve de bir eğitim merkezidir. Ankara'nın\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        sayesinde de robotların gerçek zamanlı bilgi ve deneyimlerini elde edebilmesi, özel bilgisayarlardan bilgi edinilmesi ve gerçek zamanlı bilgi edinme gibi basit ve hızlı bilgi teknolojilerini geliştirmek mümkün. Bu bağlamda robotların ma\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.1663)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 00:44:05\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "37510 | 4.1389 | 7.9e-05 | 1.19 | 38.7K | 02:12:19 |  75.0%\n",
            "37520 | 4.4416 | 7.9e-05 | 1.16 | 38.7K | 02:12:21 |  75.0%\n",
            "37530 | 4.2162 | 7.9e-05 | 1.19 | 38.7K | 02:12:22 |  75.1%\n",
            "37540 | 4.5333 | 7.9e-05 | 1.19 | 38.7K | 02:12:24 |  75.1%\n",
            "37550 | 4.1015 | 7.9e-05 | 1.18 | 38.7K | 02:12:26 |  75.1%\n",
            "37560 | 4.0577 | 7.8e-05 | 1.16 | 38.7K | 02:12:28 |  75.1%\n",
            "37570 | 4.1224 | 7.8e-05 | 1.24 | 38.7K | 02:12:29 |  75.1%\n",
            "37580 | 4.1679 | 7.8e-05 | 1.20 | 38.7K | 02:12:31 |  75.2%\n",
            "37590 | 4.3557 | 7.8e-05 | 1.16 | 38.7K | 02:12:33 |  75.2%\n",
            "37600 | 4.3886 | 7.8e-05 | 1.20 | 38.7K | 02:12:34 |  75.2%\n",
            "37610 | 4.2917 | 7.8e-05 | 1.20 | 38.7K | 02:12:36 |  75.2%\n",
            "37620 | 4.3850 | 7.8e-05 | 1.23 | 38.7K | 02:12:38 |  75.2%\n",
            "37630 | 4.0354 | 7.8e-05 | 1.18 | 38.7K | 02:12:40 |  75.3%\n",
            "37640 | 3.9313 | 7.7e-05 | 1.23 | 38.7K | 02:12:41 |  75.3%\n",
            "37650 | 4.1104 | 7.7e-05 | 1.21 | 38.7K | 02:12:43 |  75.3%\n",
            "37660 | 4.0890 | 7.7e-05 | 1.17 | 38.7K | 02:12:45 |  75.3%\n",
            "37670 | 4.1311 | 7.7e-05 | 1.20 | 38.7K | 02:12:46 |  75.3%\n",
            "37680 | 4.2156 | 7.7e-05 | 1.15 | 38.7K | 02:12:48 |  75.4%\n",
            "37690 | 4.1567 | 7.7e-05 | 1.21 | 38.7K | 02:12:50 |  75.4%\n",
            "37700 | 3.9444 | 7.7e-05 | 1.13 | 38.7K | 02:12:52 |  75.4%\n",
            "37710 | 4.1229 | 7.7e-05 | 1.19 | 38.7K | 02:12:53 |  75.4%\n",
            "37720 | 4.3967 | 7.7e-05 | 1.27 | 38.7K | 02:12:55 |  75.4%\n",
            "37730 | 4.1613 | 7.6e-05 | 1.25 | 38.7K | 02:12:57 |  75.5%\n",
            "37740 | 4.2351 | 7.6e-05 | 1.18 | 38.7K | 02:12:58 |  75.5%\n",
            "37750 | 4.2165 | 7.6e-05 | 1.14 | 38.7K | 02:13:00 |  75.5%\n",
            "37760 | 4.1993 | 7.6e-05 | 1.17 | 38.8K | 02:13:02 |  75.5%\n",
            "37770 | 4.2046 | 7.6e-05 | 1.28 | 38.8K | 02:13:04 |  75.5%\n",
            "37780 | 4.2581 | 7.6e-05 | 1.17 | 38.8K | 02:13:05 |  75.6%\n",
            "37790 | 4.0751 | 7.6e-05 | 1.17 | 38.8K | 02:13:07 |  75.6%\n",
            "37800 | 3.9955 | 7.6e-05 | 1.19 | 38.8K | 02:13:09 |  75.6%\n",
            "37810 | 4.5040 | 7.5e-05 | 1.17 | 38.8K | 02:13:10 |  75.6%\n",
            "37820 | 3.9632 | 7.5e-05 | 1.19 | 38.8K | 02:13:12 |  75.6%\n",
            "37830 | 4.3175 | 7.5e-05 | 1.18 | 38.8K | 02:13:14 |  75.7%\n",
            "37840 | 4.1862 | 7.5e-05 | 1.18 | 38.8K | 02:13:16 |  75.7%\n",
            "37850 | 4.2748 | 7.5e-05 | 1.20 | 38.8K | 02:13:17 |  75.7%\n",
            "37860 | 4.4077 | 7.5e-05 | 1.16 | 38.8K | 02:13:19 |  75.7%\n",
            "37870 | 4.4141 | 7.5e-05 | 1.20 | 38.8K | 02:13:21 |  75.7%\n",
            "37880 | 4.2357 | 7.5e-05 | 1.19 | 38.8K | 02:13:22 |  75.8%\n",
            "37890 | 4.5800 | 7.5e-05 | 1.21 | 38.8K | 02:13:24 |  75.8%\n",
            "37900 | 4.4861 | 7.4e-05 | 1.19 | 38.8K | 02:13:26 |  75.8%\n",
            "37910 | 4.5167 | 7.4e-05 | 1.18 | 38.8K | 02:13:28 |  75.8%\n",
            "37920 | 4.4767 | 7.4e-05 | 1.23 | 38.8K | 02:13:29 |  75.8%\n",
            "37930 | 4.1059 | 7.4e-05 | 1.23 | 38.8K | 02:13:31 |  75.9%\n",
            "37940 | 4.1453 | 7.4e-05 | 1.17 | 38.8K | 02:13:33 |  75.9%\n",
            "37950 | 3.8704 | 7.4e-05 | 1.24 | 38.8K | 02:13:34 |  75.9%\n",
            "37960 | 4.0663 | 7.4e-05 | 1.15 | 38.8K | 02:13:36 |  75.9%\n",
            "37970 | 4.2817 | 7.4e-05 | 1.20 | 38.8K | 02:13:38 |  75.9%\n",
            "37980 | 4.1765 | 7.3e-05 | 1.18 | 38.8K | 02:13:40 |  76.0%\n",
            "37990 | 3.9950 | 7.3e-05 | 1.15 | 38.8K | 02:13:41 |  76.0%\n",
            "38000 | 4.3859 | 7.3e-05 | 1.16 | 38.8K | 02:13:43 |  76.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 38000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1769\n",
            "  Perplexity: 65.16\n",
            "  Train loss (avg): 4.2415\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        sıcaklıklarında genel olarak 35-45 derecelik bir yağış var. Bu yağışların çok düşük olduğu bir dönemde olan yağışlar, soğuk havalarda bile hava sıcaklığı azaltıyor. Yeni kurulan okullara, yeni yapılan okul\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Ankara'da yerel televizyonlarda ve gazetelerde siyaset yapan gazeteci ve gazeteci Ali Tülay'ın \"Ben böyle bir şey yapabileceğimi sanmıyorum. Çünkü bu durum Türkiye'nin geleceğini tehlikeye atıyor. Çünkü\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        sayesinde, robotlar, robotların zarar görmesini engelliyor. Arızalı robotlar robotlara nasıl bakılıyor? Robotların yapay zekadan nasıl etkilendiği ve robotların yapay zekayla nasıl değiştir\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:42:19\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "38010 | 4.2291 | 7.3e-05 | 1.16 | 38.7K | 02:14:02 |  76.0%\n",
            "38020 | 4.1455 | 7.3e-05 | 1.22 | 38.7K | 02:14:04 |  76.0%\n",
            "38030 | 4.5168 | 7.3e-05 | 1.18 | 38.7K | 02:14:05 |  76.1%\n",
            "38040 | 4.3807 | 7.3e-05 | 1.19 | 38.7K | 02:14:07 |  76.1%\n",
            "38050 | 3.9217 | 7.3e-05 | 1.17 | 38.7K | 02:14:09 |  76.1%\n",
            "38060 | 4.4206 | 7.3e-05 | 1.19 | 38.7K | 02:14:10 |  76.1%\n",
            "38070 | 4.3997 | 7.2e-05 | 1.24 | 38.7K | 02:14:12 |  76.1%\n",
            "38080 | 4.0949 | 7.2e-05 | 1.20 | 38.7K | 02:14:14 |  76.2%\n",
            "38090 | 3.8573 | 7.2e-05 | 1.19 | 38.7K | 02:14:16 |  76.2%\n",
            "38100 | 4.1233 | 7.2e-05 | 1.19 | 38.7K | 02:14:17 |  76.2%\n",
            "38110 | 4.2916 | 7.2e-05 | 1.16 | 38.7K | 02:14:19 |  76.2%\n",
            "38120 | 4.4043 | 7.2e-05 | 1.16 | 38.7K | 02:14:21 |  76.2%\n",
            "38130 | 4.3096 | 7.2e-05 | 1.16 | 38.7K | 02:14:22 |  76.3%\n",
            "38140 | 4.3352 | 7.2e-05 | 1.19 | 38.7K | 02:14:24 |  76.3%\n",
            "38150 | 4.2909 | 7.2e-05 | 1.25 | 38.7K | 02:14:26 |  76.3%\n",
            "38160 | 4.1633 | 7.1e-05 | 1.15 | 38.7K | 02:14:28 |  76.3%\n",
            "38170 | 4.0171 | 7.1e-05 | 1.19 | 38.7K | 02:14:29 |  76.3%\n",
            "38180 | 3.8009 | 7.1e-05 | 1.20 | 38.7K | 02:14:31 |  76.4%\n",
            "38190 | 4.3456 | 7.1e-05 | 1.21 | 38.8K | 02:14:33 |  76.4%\n",
            "38200 | 4.8255 | 7.1e-05 | 1.24 | 38.8K | 02:14:34 |  76.4%\n",
            "38210 | 4.1749 | 7.1e-05 | 1.25 | 38.8K | 02:14:36 |  76.4%\n",
            "38220 | 4.3223 | 7.1e-05 | 1.20 | 38.8K | 02:14:38 |  76.4%\n",
            "38230 | 4.0079 | 7.1e-05 | 1.22 | 38.8K | 02:14:40 |  76.5%\n",
            "38240 | 4.3196 | 7.0e-05 | 1.16 | 38.8K | 02:14:41 |  76.5%\n",
            "38250 | 4.3987 | 7.0e-05 | 1.22 | 38.8K | 02:14:43 |  76.5%\n",
            "38260 | 4.3599 | 7.0e-05 | 1.19 | 38.8K | 02:14:45 |  76.5%\n",
            "38270 | 3.8963 | 7.0e-05 | 1.14 | 38.8K | 02:14:46 |  76.5%\n",
            "38280 | 4.0319 | 7.0e-05 | 1.22 | 38.8K | 02:14:48 |  76.6%\n",
            "38290 | 4.1944 | 7.0e-05 | 1.18 | 38.8K | 02:14:50 |  76.6%\n",
            "38300 | 4.1913 | 7.0e-05 | 1.22 | 38.8K | 02:14:52 |  76.6%\n",
            "38310 | 4.2334 | 7.0e-05 | 1.16 | 38.8K | 02:14:53 |  76.6%\n",
            "38320 | 4.4139 | 7.0e-05 | 1.18 | 38.8K | 02:14:55 |  76.6%\n",
            "38330 | 4.1055 | 6.9e-05 | 1.21 | 38.8K | 02:14:57 |  76.7%\n",
            "38340 | 4.2749 | 6.9e-05 | 1.23 | 38.8K | 02:14:58 |  76.7%\n",
            "38350 | 4.2399 | 6.9e-05 | 1.19 | 38.8K | 02:15:00 |  76.7%\n",
            "38360 | 4.1568 | 6.9e-05 | 1.19 | 38.8K | 02:15:02 |  76.7%\n",
            "38370 | 4.1469 | 6.9e-05 | 1.17 | 38.8K | 02:15:04 |  76.7%\n",
            "38380 | 4.3690 | 6.9e-05 | 1.16 | 38.8K | 02:15:05 |  76.8%\n",
            "38390 | 3.6167 | 6.9e-05 | 1.18 | 38.8K | 02:15:07 |  76.8%\n",
            "38400 | 4.1355 | 6.9e-05 | 1.17 | 38.8K | 02:15:09 |  76.8%\n",
            "38410 | 4.3570 | 6.9e-05 | 1.19 | 38.8K | 02:15:10 |  76.8%\n",
            "38420 | 4.2507 | 6.8e-05 | 1.16 | 38.8K | 02:15:12 |  76.8%\n",
            "38430 | 4.4346 | 6.8e-05 | 1.22 | 38.8K | 02:15:14 |  76.9%\n",
            "38440 | 4.4405 | 6.8e-05 | 1.23 | 38.8K | 02:15:16 |  76.9%\n",
            "38450 | 4.1330 | 6.8e-05 | 1.17 | 38.8K | 02:15:17 |  76.9%\n",
            "38460 | 4.0688 | 6.8e-05 | 1.19 | 38.8K | 02:15:19 |  76.9%\n",
            "38470 | 4.1781 | 6.8e-05 | 1.19 | 38.8K | 02:15:21 |  76.9%\n",
            "38480 | 4.2970 | 6.8e-05 | 1.20 | 38.8K | 02:15:22 |  77.0%\n",
            "38490 | 4.3022 | 6.8e-05 | 1.21 | 38.8K | 02:15:24 |  77.0%\n",
            "38500 | 4.3373 | 6.8e-05 | 1.17 | 38.8K | 02:15:26 |  77.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 38500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1586\n",
            "  Perplexity: 63.98\n",
            "  Train loss (avg): 4.2329\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        sıcaklığının daha yüksek olduğu ve nem oranının da yüksek olduğu, daha yüksek nem oranına sahip bir yağmur yağına sahip olduğundan her birinizin ısının düşük olması mümkün. Hava sıcaklığının ise çok yüksek olduğu,\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        olan İstanbul'un en kalabalık ve en kalabalık şehri olan İstanbul'da, her yıl dünyanın dört bir yanından birçok ülkeye bu beldelerin tatil merkezi olan İstanbul'un en kalabalık şehri olan İstanbul'un\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        günümüzde son derece popüler hale geldi. Uzun yıllar yıllar önce inovatif projeler üreten ABD’de, Michael Sidney’nin geliştirdiği bir yapay zeka teknolojisi sayesinde yapay zekanın bir araya gelmesi ve yapay\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.1586)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:40:33\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "38510 | 4.1411 | 6.7e-05 | 1.17 | 38.7K | 02:15:48 |  77.0%\n",
            "38520 | 3.7439 | 6.7e-05 | 1.24 | 38.7K | 02:15:50 |  77.0%\n",
            "38530 | 4.2081 | 6.7e-05 | 1.24 | 38.7K | 02:15:52 |  77.1%\n",
            "38540 | 4.4207 | 6.7e-05 | 1.20 | 38.7K | 02:15:53 |  77.1%\n",
            "38550 | 3.9585 | 6.7e-05 | 1.19 | 38.7K | 02:15:55 |  77.1%\n",
            "38560 | 4.2214 | 6.7e-05 | 1.17 | 38.7K | 02:15:57 |  77.1%\n",
            "38570 | 4.3533 | 6.7e-05 | 1.21 | 38.7K | 02:15:58 |  77.1%\n",
            "38580 | 3.9130 | 6.7e-05 | 1.24 | 38.7K | 02:16:00 |  77.2%\n",
            "38590 | 4.4643 | 6.7e-05 | 1.19 | 38.7K | 02:16:02 |  77.2%\n",
            "38600 | 4.2973 | 6.6e-05 | 1.21 | 38.7K | 02:16:04 |  77.2%\n",
            "38610 | 4.5772 | 6.6e-05 | 1.20 | 38.7K | 02:16:05 |  77.2%\n",
            "38620 | 4.0665 | 6.6e-05 | 1.18 | 38.7K | 02:16:07 |  77.2%\n",
            "38630 | 4.0145 | 6.6e-05 | 1.24 | 38.7K | 02:16:09 |  77.3%\n",
            "38640 | 4.3917 | 6.6e-05 | 1.17 | 38.7K | 02:16:10 |  77.3%\n",
            "38650 | 3.9702 | 6.6e-05 | 1.24 | 38.7K | 02:16:12 |  77.3%\n",
            "38660 | 3.9110 | 6.6e-05 | 1.17 | 38.7K | 02:16:14 |  77.3%\n",
            "38670 | 4.2695 | 6.6e-05 | 1.29 | 38.7K | 02:16:16 |  77.3%\n",
            "38680 | 4.0487 | 6.6e-05 | 1.21 | 38.7K | 02:16:17 |  77.4%\n",
            "38690 | 4.1782 | 6.5e-05 | 1.16 | 38.7K | 02:16:19 |  77.4%\n",
            "38700 | 4.1159 | 6.5e-05 | 1.20 | 38.8K | 02:16:21 |  77.4%\n",
            "38710 | 4.1905 | 6.5e-05 | 1.19 | 38.8K | 02:16:22 |  77.4%\n",
            "38720 | 4.5785 | 6.5e-05 | 1.21 | 38.8K | 02:16:24 |  77.4%\n",
            "38730 | 4.0759 | 6.5e-05 | 1.22 | 38.8K | 02:16:26 |  77.5%\n",
            "38740 | 4.1816 | 6.5e-05 | 1.22 | 38.8K | 02:16:28 |  77.5%\n",
            "38750 | 3.8759 | 6.5e-05 | 1.18 | 38.8K | 02:16:29 |  77.5%\n",
            "38760 | 4.6185 | 6.5e-05 | 1.14 | 38.8K | 02:16:31 |  77.5%\n",
            "38770 | 4.4700 | 6.5e-05 | 1.16 | 38.8K | 02:16:33 |  77.5%\n",
            "38780 | 4.3039 | 6.4e-05 | 1.19 | 38.8K | 02:16:34 |  77.6%\n",
            "38790 | 4.1278 | 6.4e-05 | 1.19 | 38.8K | 02:16:36 |  77.6%\n",
            "38800 | 4.1755 | 6.4e-05 | 1.20 | 38.8K | 02:16:38 |  77.6%\n",
            "38810 | 4.3870 | 6.4e-05 | 1.18 | 38.8K | 02:16:40 |  77.6%\n",
            "38820 | 4.3073 | 6.4e-05 | 1.20 | 38.8K | 02:16:41 |  77.6%\n",
            "38830 | 4.2135 | 6.4e-05 | 1.16 | 38.8K | 02:16:43 |  77.7%\n",
            "38840 | 3.9586 | 6.4e-05 | 1.15 | 38.8K | 02:16:45 |  77.7%\n",
            "38850 | 4.3094 | 6.4e-05 | 1.22 | 38.8K | 02:16:46 |  77.7%\n",
            "38860 | 3.9428 | 6.4e-05 | 1.24 | 38.8K | 02:16:48 |  77.7%\n",
            "38870 | 4.1995 | 6.3e-05 | 1.16 | 38.8K | 02:16:50 |  77.7%\n",
            "38880 | 3.9542 | 6.3e-05 | 1.41 | 38.8K | 02:16:52 |  77.8%\n",
            "38890 | 4.2427 | 6.3e-05 | 1.21 | 38.8K | 02:16:53 |  77.8%\n",
            "38900 | 4.2110 | 6.3e-05 | 1.18 | 38.8K | 02:16:55 |  77.8%\n",
            "38910 | 3.9752 | 6.3e-05 | 1.16 | 38.8K | 02:16:57 |  77.8%\n",
            "38920 | 4.1546 | 6.3e-05 | 1.29 | 38.8K | 02:16:58 |  77.8%\n",
            "38930 | 4.3865 | 6.3e-05 | 1.15 | 38.8K | 02:17:00 |  77.9%\n",
            "38940 | 3.7982 | 6.3e-05 | 1.18 | 38.8K | 02:17:02 |  77.9%\n",
            "38950 | 4.3748 | 6.3e-05 | 1.16 | 38.8K | 02:17:04 |  77.9%\n",
            "38960 | 4.3201 | 6.2e-05 | 1.19 | 38.8K | 02:17:05 |  77.9%\n",
            "38970 | 4.2703 | 6.2e-05 | 1.21 | 38.8K | 02:17:07 |  77.9%\n",
            "38980 | 4.2269 | 6.2e-05 | 1.15 | 38.8K | 02:17:09 |  78.0%\n",
            "38990 | 4.0315 | 6.2e-05 | 1.19 | 38.8K | 02:17:10 |  78.0%\n",
            "39000 | 4.2160 | 6.2e-05 | 1.23 | 38.8K | 02:17:12 |  78.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 39000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1749\n",
            "  Perplexity: 65.03\n",
            "  Train loss (avg): 4.2228\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        çok sıcak, dışarıda her yerde. Böyle güzel işler yapmak için uğraşıp duruyorum. Yaptığım bu güzel şeyleri çok seviyorum. Yaptığım bu güzel işler için çok mutluyum. Umarım bu güzel işler için güzel\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        olarak nitelendirdiği bu şehir, bizim en büyük şehir, bizim en büyük şehir. Çünkü şehrin en büyük şehri. Bu şehir aslında bir meydan. Dünyanın en büyük şehri olarak karşımıza çıkıyor. Şehrin en büyük şehri\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        bu yeni teknolojiyle birlikte giderek yaygınlaşıyor. Bilgisayarların karmaşık bir şekilde işlemesi ve yine bu algoritma sayesinde virüsler arası etkileşimi azaltma olanaklarını da sunuyor. Özellikle yeni nesil bilgisayarlarda\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:38:46\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "39010 | 4.4284 | 6.2e-05 | 1.17 | 38.7K | 02:17:31 |  78.0%\n",
            "39020 | 4.2127 | 6.2e-05 | 1.17 | 38.7K | 02:17:33 |  78.0%\n",
            "39030 | 4.3236 | 6.2e-05 | 1.18 | 38.7K | 02:17:35 |  78.1%\n",
            "39040 | 4.1656 | 6.2e-05 | 1.21 | 38.7K | 02:17:36 |  78.1%\n",
            "39050 | 4.1044 | 6.2e-05 | 1.17 | 38.7K | 02:17:38 |  78.1%\n",
            "39060 | 4.4188 | 6.1e-05 | 1.19 | 38.7K | 02:17:40 |  78.1%\n",
            "39070 | 4.2927 | 6.1e-05 | 1.20 | 38.7K | 02:17:41 |  78.1%\n",
            "39080 | 4.1554 | 6.1e-05 | 1.23 | 38.7K | 02:17:43 |  78.2%\n",
            "39090 | 4.0041 | 6.1e-05 | 1.20 | 38.7K | 02:17:45 |  78.2%\n",
            "39100 | 4.3355 | 6.1e-05 | 1.23 | 38.7K | 02:17:47 |  78.2%\n",
            "39110 | 4.4165 | 6.1e-05 | 1.22 | 38.7K | 02:17:48 |  78.2%\n",
            "39120 | 4.4085 | 6.1e-05 | 1.20 | 38.7K | 02:17:50 |  78.2%\n",
            "39130 | 4.2278 | 6.1e-05 | 1.29 | 38.8K | 02:17:52 |  78.3%\n",
            "39140 | 4.2657 | 6.1e-05 | 1.20 | 38.8K | 02:17:53 |  78.3%\n",
            "39150 | 4.2349 | 6.0e-05 | 1.20 | 38.8K | 02:17:55 |  78.3%\n",
            "39160 | 4.2173 | 6.0e-05 | 1.19 | 38.8K | 02:17:57 |  78.3%\n",
            "39170 | 4.4003 | 6.0e-05 | 1.23 | 38.8K | 02:17:58 |  78.3%\n",
            "39180 | 4.1684 | 6.0e-05 | 1.16 | 38.8K | 02:18:00 |  78.4%\n",
            "39190 | 4.5777 | 6.0e-05 | 1.22 | 38.8K | 02:18:02 |  78.4%\n",
            "39200 | 4.3955 | 6.0e-05 | 1.15 | 38.8K | 02:18:04 |  78.4%\n",
            "39210 | 4.3060 | 6.0e-05 | 1.18 | 38.8K | 02:18:05 |  78.4%\n",
            "39220 | 4.2850 | 6.0e-05 | 1.24 | 38.8K | 02:18:07 |  78.4%\n",
            "39230 | 4.3824 | 6.0e-05 | 1.17 | 38.8K | 02:18:09 |  78.5%\n",
            "39240 | 4.2565 | 5.9e-05 | 1.18 | 38.8K | 02:18:10 |  78.5%\n",
            "39250 | 4.4323 | 5.9e-05 | 1.16 | 38.8K | 02:18:12 |  78.5%\n",
            "39260 | 4.4259 | 5.9e-05 | 1.19 | 38.8K | 02:18:14 |  78.5%\n",
            "39270 | 4.1651 | 5.9e-05 | 1.24 | 38.8K | 02:18:16 |  78.5%\n",
            "39280 | 4.0999 | 5.9e-05 | 1.16 | 38.8K | 02:18:17 |  78.6%\n",
            "39290 | 4.2637 | 5.9e-05 | 1.25 | 38.8K | 02:18:19 |  78.6%\n",
            "39300 | 4.3086 | 5.9e-05 | 1.20 | 38.8K | 02:18:21 |  78.6%\n",
            "39310 | 4.4706 | 5.9e-05 | 1.18 | 38.8K | 02:18:22 |  78.6%\n",
            "39320 | 4.0978 | 5.9e-05 | 1.19 | 38.8K | 02:18:24 |  78.6%\n",
            "39330 | 3.9260 | 5.9e-05 | 1.19 | 38.8K | 02:18:26 |  78.7%\n",
            "39340 | 4.3162 | 5.8e-05 | 1.17 | 38.8K | 02:18:28 |  78.7%\n",
            "39350 | 4.2745 | 5.8e-05 | 1.18 | 38.8K | 02:18:29 |  78.7%\n",
            "39360 | 4.4291 | 5.8e-05 | 1.19 | 38.8K | 02:18:31 |  78.7%\n",
            "39370 | 4.3039 | 5.8e-05 | 1.17 | 38.8K | 02:18:33 |  78.7%\n",
            "39380 | 3.9150 | 5.8e-05 | 1.13 | 38.8K | 02:18:34 |  78.8%\n",
            "39390 | 4.4534 | 5.8e-05 | 1.19 | 38.8K | 02:18:36 |  78.8%\n",
            "39400 | 4.1976 | 5.8e-05 | 1.28 | 38.8K | 02:18:38 |  78.8%\n",
            "39410 | 4.4133 | 5.8e-05 | 1.21 | 38.8K | 02:18:40 |  78.8%\n",
            "39420 | 4.2622 | 5.8e-05 | 1.17 | 38.8K | 02:18:41 |  78.8%\n",
            "39430 | 3.7476 | 5.7e-05 | 1.10 | 38.8K | 02:18:43 |  78.9%\n",
            "39440 | 4.5554 | 5.7e-05 | 1.18 | 38.8K | 02:18:45 |  78.9%\n",
            "39450 | 4.1355 | 5.7e-05 | 1.21 | 38.8K | 02:18:46 |  78.9%\n",
            "39460 | 4.4918 | 5.7e-05 | 1.18 | 38.8K | 02:18:48 |  78.9%\n",
            "39470 | 4.2045 | 5.7e-05 | 1.19 | 38.8K | 02:18:50 |  78.9%\n",
            "39480 | 3.8632 | 5.7e-05 | 1.23 | 38.8K | 02:18:52 |  79.0%\n",
            "39490 | 4.1627 | 5.7e-05 | 1.23 | 38.8K | 02:18:53 |  79.0%\n",
            "39500 | 4.2892 | 5.7e-05 | 1.18 | 38.8K | 02:18:55 |  79.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 39500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1710\n",
            "  Perplexity: 64.78\n",
            "  Train loss (avg): 4.2377\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        güneşini iyice hissettirdiğine inananlara ilk olarak Aralık ayı içinde hava da pek çok yenilik getirdi. Hava genelinin sıcaklığın 12 ila 12 derece arasında olması bekleniyor. Hava sıcaklıklarının çok yüksek olması nedeniyle\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Washington'da düzenlenen \"Dördüncü Dünya Savaşı'nın ilanının hemen ardından Avrupa'nın birçok yerine gönderilmeye başlandı. Batı'nın dik duruşunun, savaşın Türkiye ile birlikte Türkiye arasındaki ilişkileri,\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        ile kodlanmış bir yapay zekaya sahipseniz, yapay zeka bu işe gerçekten karar verir. Facebook, bir grup ürünü alarak yapay zekanın ne olduğunu öğreniyor. Yapay zekayı nasıl geliştirirseniz, geliştir\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:37:00\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "39510 | 4.2567 | 5.7e-05 | 1.17 | 38.7K | 02:19:14 |  79.0%\n",
            "39520 | 4.2266 | 5.7e-05 | 1.22 | 38.7K | 02:19:16 |  79.0%\n",
            "39530 | 4.3336 | 5.6e-05 | 1.19 | 38.7K | 02:19:17 |  79.1%\n",
            "39540 | 4.3093 | 5.6e-05 | 1.19 | 38.7K | 02:19:19 |  79.1%\n",
            "39550 | 4.2481 | 5.6e-05 | 1.18 | 38.7K | 02:19:21 |  79.1%\n",
            "39560 | 4.3250 | 5.6e-05 | 1.21 | 38.8K | 02:19:23 |  79.1%\n",
            "39570 | 4.0399 | 5.6e-05 | 1.21 | 38.8K | 02:19:24 |  79.1%\n",
            "39580 | 4.2324 | 5.6e-05 | 1.18 | 38.8K | 02:19:26 |  79.2%\n",
            "39590 | 3.7439 | 5.6e-05 | 1.19 | 38.8K | 02:19:28 |  79.2%\n",
            "39600 | 4.2222 | 5.6e-05 | 1.27 | 38.8K | 02:19:29 |  79.2%\n",
            "39610 | 3.7772 | 5.6e-05 | 1.29 | 38.8K | 02:19:31 |  79.2%\n",
            "39620 | 4.0310 | 5.6e-05 | 1.20 | 38.8K | 02:19:33 |  79.2%\n",
            "39630 | 4.4291 | 5.5e-05 | 1.20 | 38.8K | 02:19:34 |  79.3%\n",
            "39640 | 4.2846 | 5.5e-05 | 1.15 | 38.8K | 02:19:36 |  79.3%\n",
            "39650 | 4.0765 | 5.5e-05 | 1.16 | 38.8K | 02:19:38 |  79.3%\n",
            "39660 | 4.3095 | 5.5e-05 | 1.20 | 38.8K | 02:19:40 |  79.3%\n",
            "39670 | 4.5471 | 5.5e-05 | 1.16 | 38.8K | 02:19:41 |  79.3%\n",
            "39680 | 4.3965 | 5.5e-05 | 1.21 | 38.8K | 02:19:43 |  79.4%\n",
            "39690 | 4.2083 | 5.5e-05 | 1.22 | 38.8K | 02:19:45 |  79.4%\n",
            "39700 | 4.2409 | 5.5e-05 | 1.17 | 38.8K | 02:19:46 |  79.4%\n",
            "39710 | 4.0800 | 5.5e-05 | 1.21 | 38.8K | 02:19:48 |  79.4%\n",
            "39720 | 4.3491 | 5.4e-05 | 1.27 | 38.8K | 02:19:50 |  79.4%\n",
            "39730 | 4.0695 | 5.4e-05 | 1.17 | 38.8K | 02:19:52 |  79.5%\n",
            "39740 | 4.3825 | 5.4e-05 | 1.21 | 38.8K | 02:19:53 |  79.5%\n",
            "39750 | 3.8303 | 5.4e-05 | 1.31 | 38.8K | 02:19:55 |  79.5%\n",
            "39760 | 4.4111 | 5.4e-05 | 1.20 | 38.8K | 02:19:57 |  79.5%\n",
            "39770 | 4.0879 | 5.4e-05 | 1.21 | 38.8K | 02:19:58 |  79.5%\n",
            "39780 | 3.9592 | 5.4e-05 | 1.18 | 38.8K | 02:20:00 |  79.6%\n",
            "39790 | 4.1325 | 5.4e-05 | 1.19 | 38.8K | 02:20:02 |  79.6%\n",
            "39800 | 4.3685 | 5.4e-05 | 1.19 | 38.8K | 02:20:04 |  79.6%\n",
            "39810 | 4.0040 | 5.4e-05 | 1.18 | 38.8K | 02:20:05 |  79.6%\n",
            "39820 | 4.2389 | 5.3e-05 | 1.19 | 38.8K | 02:20:07 |  79.6%\n",
            "39830 | 4.3136 | 5.3e-05 | 1.21 | 38.8K | 02:20:09 |  79.7%\n",
            "39840 | 4.2207 | 5.3e-05 | 1.18 | 38.8K | 02:20:10 |  79.7%\n",
            "39850 | 4.3446 | 5.3e-05 | 1.20 | 38.8K | 02:20:12 |  79.7%\n",
            "39860 | 4.1629 | 5.3e-05 | 1.19 | 38.8K | 02:20:14 |  79.7%\n",
            "39870 | 3.9365 | 5.3e-05 | 1.17 | 38.8K | 02:20:16 |  79.7%\n",
            "39880 | 4.3866 | 5.3e-05 | 1.17 | 38.8K | 02:20:17 |  79.8%\n",
            "39890 | 4.2142 | 5.3e-05 | 1.21 | 38.8K | 02:20:19 |  79.8%\n",
            "39900 | 4.0133 | 5.3e-05 | 1.15 | 38.8K | 02:20:21 |  79.8%\n",
            "39910 | 4.4898 | 5.3e-05 | 1.18 | 38.8K | 02:20:22 |  79.8%\n",
            "39920 | 4.4749 | 5.2e-05 | 1.25 | 38.8K | 02:20:24 |  79.8%\n",
            "39930 | 4.0792 | 5.2e-05 | 1.15 | 38.8K | 02:20:26 |  79.9%\n",
            "39940 | 4.2434 | 5.2e-05 | 1.17 | 38.8K | 02:20:28 |  79.9%\n",
            "39950 | 4.2029 | 5.2e-05 | 1.17 | 38.8K | 02:20:29 |  79.9%\n",
            "39960 | 4.1299 | 5.2e-05 | 1.20 | 38.8K | 02:20:31 |  79.9%\n",
            "39970 | 4.2105 | 5.2e-05 | 1.21 | 38.8K | 02:20:33 |  79.9%\n",
            "39980 | 4.3165 | 5.2e-05 | 1.28 | 38.8K | 02:20:34 |  80.0%\n",
            "39990 | 4.0808 | 5.2e-05 | 1.16 | 38.8K | 02:20:36 |  80.0%\n",
            "40000 | 4.6246 | 5.2e-05 | 1.22 | 38.8K | 02:20:38 |  80.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 40000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1307\n",
            "  Perplexity: 62.22\n",
            "  Train loss (avg): 4.2096\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        çok sıcak ve nemli. Bu hafta, oldukça sıcak. 20-25 dakika, 15-25 dakika, 20 dakika. Sanki bir başka hava daha var. Hava sıcak. Türkiye'de hava çok soğuk. Hava\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        çimen'de, Eskişehir'de bir iki kişi PKK'lı grup tarafından kaçırıldı. Kanlı saldırı sonrası düzenlenen saldırıda şehit olan Uzman Çavuş Mehmet Korkmaz'ın cenazesi, Eskişehir'e getirildi.\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , kendi kendini geliştirmeyi başarmış ve büyük ölçüde yeniden icat etmiştir. Bu iki tekniğin, yeni bir yeni teknoloji geliştirip, Türkiye'de de tek başlarına geliştirilen teknolojilere ulaşmalarına olanak tanıyacak şekilde\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.1307)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:35:14\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "💾 Checkpoint kaydediliyor: /content/drive/MyDrive/turkish_llm/checkpoints//checkpoint_step_40000.pt\n",
            "  ✅ Checkpoint kaydedildi!\n",
            "\n",
            "40010 | 4.2527 | 5.2e-05 | 1.16 | 38.7K | 02:21:04 |  80.0%\n",
            "40020 | 4.0898 | 5.1e-05 | 1.19 | 38.7K | 02:21:05 |  80.0%\n",
            "40030 | 4.4829 | 5.1e-05 | 1.22 | 38.7K | 02:21:07 |  80.1%\n",
            "40040 | 3.9109 | 5.1e-05 | 1.24 | 38.7K | 02:21:09 |  80.1%\n",
            "40050 | 3.9421 | 5.1e-05 | 1.21 | 38.7K | 02:21:10 |  80.1%\n",
            "40060 | 4.1487 | 5.1e-05 | 1.22 | 38.7K | 02:21:12 |  80.1%\n",
            "40070 | 3.9972 | 5.1e-05 | 1.15 | 38.7K | 02:21:14 |  80.1%\n",
            "40080 | 4.0710 | 5.1e-05 | 1.21 | 38.7K | 02:21:16 |  80.2%\n",
            "40090 | 4.0628 | 5.1e-05 | 1.20 | 38.7K | 02:21:17 |  80.2%\n",
            "40100 | 4.2720 | 5.1e-05 | 1.17 | 38.7K | 02:21:19 |  80.2%\n",
            "40110 | 4.1062 | 5.1e-05 | 1.17 | 38.7K | 02:21:21 |  80.2%\n",
            "40120 | 4.0950 | 5.0e-05 | 1.22 | 38.7K | 02:21:22 |  80.2%\n",
            "40130 | 4.1096 | 5.0e-05 | 1.22 | 38.7K | 02:21:24 |  80.3%\n",
            "40140 | 3.9039 | 5.0e-05 | 1.24 | 38.7K | 02:21:26 |  80.3%\n",
            "40150 | 4.1347 | 5.0e-05 | 1.19 | 38.7K | 02:21:27 |  80.3%\n",
            "40160 | 4.2026 | 5.0e-05 | 1.16 | 38.8K | 02:21:29 |  80.3%\n",
            "40170 | 4.3311 | 5.0e-05 | 1.19 | 38.8K | 02:21:31 |  80.3%\n",
            "40180 | 4.3213 | 5.0e-05 | 1.19 | 38.8K | 02:21:33 |  80.4%\n",
            "40190 | 4.0845 | 5.0e-05 | 1.18 | 38.8K | 02:21:34 |  80.4%\n",
            "40200 | 3.9984 | 5.0e-05 | 1.17 | 38.8K | 02:21:36 |  80.4%\n",
            "40210 | 4.2577 | 5.0e-05 | 1.20 | 38.8K | 02:21:38 |  80.4%\n",
            "40220 | 3.9369 | 5.0e-05 | 1.19 | 38.8K | 02:21:39 |  80.4%\n",
            "40230 | 4.0413 | 4.9e-05 | 1.17 | 38.8K | 02:21:41 |  80.5%\n",
            "40240 | 4.3608 | 4.9e-05 | 1.18 | 38.8K | 02:21:43 |  80.5%\n",
            "40250 | 3.9081 | 4.9e-05 | 1.20 | 38.8K | 02:21:45 |  80.5%\n",
            "40260 | 4.1634 | 4.9e-05 | 1.24 | 38.8K | 02:21:46 |  80.5%\n",
            "40270 | 4.1341 | 4.9e-05 | 1.28 | 38.8K | 02:21:48 |  80.5%\n",
            "40280 | 4.2360 | 4.9e-05 | 1.23 | 38.8K | 02:21:50 |  80.6%\n",
            "40290 | 4.4367 | 4.9e-05 | 1.16 | 38.8K | 02:21:51 |  80.6%\n",
            "40300 | 3.9848 | 4.9e-05 | 1.21 | 38.8K | 02:21:53 |  80.6%\n",
            "40310 | 4.4290 | 4.9e-05 | 1.25 | 38.8K | 02:21:55 |  80.6%\n",
            "40320 | 4.2991 | 4.9e-05 | 1.24 | 38.8K | 02:21:57 |  80.6%\n",
            "40330 | 4.2304 | 4.8e-05 | 1.23 | 38.8K | 02:21:58 |  80.7%\n",
            "40340 | 4.1534 | 4.8e-05 | 1.25 | 38.8K | 02:22:00 |  80.7%\n",
            "40350 | 4.4244 | 4.8e-05 | 1.19 | 38.8K | 02:22:02 |  80.7%\n",
            "40360 | 4.2894 | 4.8e-05 | 1.21 | 38.8K | 02:22:03 |  80.7%\n",
            "40370 | 4.0681 | 4.8e-05 | 1.18 | 38.8K | 02:22:05 |  80.7%\n",
            "40380 | 4.3420 | 4.8e-05 | 1.20 | 38.8K | 02:22:07 |  80.8%\n",
            "40390 | 4.0020 | 4.8e-05 | 1.20 | 38.8K | 02:22:09 |  80.8%\n",
            "40400 | 4.2453 | 4.8e-05 | 1.20 | 38.8K | 02:22:10 |  80.8%\n",
            "40410 | 4.0716 | 4.8e-05 | 1.18 | 38.8K | 02:22:12 |  80.8%\n",
            "40420 | 4.3291 | 4.8e-05 | 1.21 | 38.8K | 02:22:14 |  80.8%\n",
            "40430 | 4.5135 | 4.7e-05 | 1.18 | 38.8K | 02:22:15 |  80.9%\n",
            "40440 | 4.1305 | 4.7e-05 | 1.25 | 38.8K | 02:22:17 |  80.9%\n",
            "40450 | 4.2651 | 4.7e-05 | 1.23 | 38.8K | 02:22:19 |  80.9%\n",
            "40460 | 4.1019 | 4.7e-05 | 1.22 | 38.8K | 02:22:21 |  80.9%\n",
            "40470 | 4.2237 | 4.7e-05 | 1.20 | 38.8K | 02:22:22 |  80.9%\n",
            "40480 | 4.1747 | 4.7e-05 | 1.18 | 38.8K | 02:22:24 |  81.0%\n",
            "40490 | 3.9931 | 4.7e-05 | 1.20 | 38.8K | 02:22:26 |  81.0%\n",
            "40500 | 4.2386 | 4.7e-05 | 1.27 | 38.8K | 02:22:27 |  81.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 40500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1138\n",
            "  Perplexity: 61.18\n",
            "  Train loss (avg): 4.1952\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        sıcak, sıcak ve yağmurlu. Her sabah yağmurlu. Hava sıcak ve yağmurlu. Hava sıcak ve yağmurlu. Yağışların sıcak olması hava sıcak. Hava sıcak ve yağmurlu. Hava sıcak\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Ankara'nın Ankara Büyükelçisi Andriyoz Atay, \"Türkiye'nin barış ve istikrar için gelecek ilk ve tekeli açısından çok önemli bir adım olduğunu ve bunun da Türkiye'nin AB'ye\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        geliştirildi ve bu yeni teknoloji sayesinde çok daha başarılı bir iletişim biçimi elde edildi. Teknoloji ile iletişim de geliştirildi. Telepatik teknolojisi ile ilgili çalışmalar yapan ve veri sorumlusu olarak çalışan Prof. Dr.\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.1138)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:33:29\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "40510 | 4.2961 | 4.7e-05 | 1.20 | 38.7K | 02:22:50 |  81.0%\n",
            "40520 | 3.9697 | 4.7e-05 | 1.19 | 38.7K | 02:22:51 |  81.0%\n",
            "40530 | 4.1366 | 4.7e-05 | 1.19 | 38.7K | 02:22:53 |  81.1%\n",
            "40540 | 4.1553 | 4.6e-05 | 1.19 | 38.7K | 02:22:55 |  81.1%\n",
            "40550 | 4.1388 | 4.6e-05 | 1.18 | 38.7K | 02:22:57 |  81.1%\n",
            "40560 | 4.2063 | 4.6e-05 | 1.22 | 38.7K | 02:22:58 |  81.1%\n",
            "40570 | 4.2068 | 4.6e-05 | 1.23 | 38.7K | 02:23:00 |  81.1%\n",
            "40580 | 4.1276 | 4.6e-05 | 1.22 | 38.7K | 02:23:02 |  81.2%\n",
            "40590 | 4.4044 | 4.6e-05 | 1.26 | 38.7K | 02:23:03 |  81.2%\n",
            "40600 | 4.2896 | 4.6e-05 | 1.16 | 38.7K | 02:23:05 |  81.2%\n",
            "40610 | 4.2404 | 4.6e-05 | 1.24 | 38.7K | 02:23:07 |  81.2%\n",
            "40620 | 4.0481 | 4.6e-05 | 1.20 | 38.7K | 02:23:09 |  81.2%\n",
            "40630 | 4.3212 | 4.6e-05 | 1.21 | 38.7K | 02:23:10 |  81.3%\n",
            "40640 | 3.8384 | 4.5e-05 | 1.21 | 38.7K | 02:23:12 |  81.3%\n",
            "40650 | 4.2040 | 4.5e-05 | 1.17 | 38.7K | 02:23:14 |  81.3%\n",
            "40660 | 4.1806 | 4.5e-05 | 1.16 | 38.7K | 02:23:15 |  81.3%\n",
            "40670 | 4.3844 | 4.5e-05 | 1.17 | 38.8K | 02:23:17 |  81.3%\n",
            "40680 | 4.1472 | 4.5e-05 | 1.20 | 38.8K | 02:23:19 |  81.4%\n",
            "40690 | 3.9651 | 4.5e-05 | 1.30 | 38.8K | 02:23:21 |  81.4%\n",
            "40700 | 4.3952 | 4.5e-05 | 1.21 | 38.8K | 02:23:22 |  81.4%\n",
            "40710 | 3.9202 | 4.5e-05 | 1.23 | 38.8K | 02:23:24 |  81.4%\n",
            "40720 | 4.0356 | 4.5e-05 | 1.19 | 38.8K | 02:23:26 |  81.4%\n",
            "40730 | 4.0785 | 4.5e-05 | 1.18 | 38.8K | 02:23:27 |  81.5%\n",
            "40740 | 4.1279 | 4.5e-05 | 1.19 | 38.8K | 02:23:29 |  81.5%\n",
            "40750 | 4.1612 | 4.4e-05 | 1.22 | 38.8K | 02:23:31 |  81.5%\n",
            "40760 | 4.2874 | 4.4e-05 | 1.26 | 38.8K | 02:23:33 |  81.5%\n",
            "40770 | 4.3734 | 4.4e-05 | 1.21 | 38.8K | 02:23:34 |  81.5%\n",
            "40780 | 4.2707 | 4.4e-05 | 1.19 | 38.8K | 02:23:36 |  81.6%\n",
            "40790 | 4.1932 | 4.4e-05 | 1.19 | 38.8K | 02:23:38 |  81.6%\n",
            "40800 | 4.1695 | 4.4e-05 | 1.20 | 38.8K | 02:23:39 |  81.6%\n",
            "40810 | 4.0453 | 4.4e-05 | 1.22 | 38.8K | 02:23:41 |  81.6%\n",
            "40820 | 4.3582 | 4.4e-05 | 1.18 | 38.8K | 02:23:43 |  81.6%\n",
            "40830 | 4.3738 | 4.4e-05 | 1.19 | 38.8K | 02:23:45 |  81.7%\n",
            "40840 | 4.1296 | 4.4e-05 | 1.19 | 38.8K | 02:23:46 |  81.7%\n",
            "40850 | 4.3279 | 4.4e-05 | 1.20 | 38.8K | 02:23:48 |  81.7%\n",
            "40860 | 4.2788 | 4.3e-05 | 1.21 | 38.8K | 02:23:50 |  81.7%\n",
            "40870 | 4.2286 | 4.3e-05 | 1.18 | 38.8K | 02:23:51 |  81.7%\n",
            "40880 | 4.0957 | 4.3e-05 | 1.17 | 38.8K | 02:23:53 |  81.8%\n",
            "40890 | 4.5789 | 4.3e-05 | 1.20 | 38.8K | 02:23:55 |  81.8%\n",
            "40900 | 4.2403 | 4.3e-05 | 1.18 | 38.8K | 02:23:57 |  81.8%\n",
            "40910 | 4.1957 | 4.3e-05 | 1.17 | 38.8K | 02:23:58 |  81.8%\n",
            "40920 | 4.0551 | 4.3e-05 | 1.23 | 38.8K | 02:24:00 |  81.8%\n",
            "40930 | 3.9915 | 4.3e-05 | 1.22 | 38.8K | 02:24:02 |  81.9%\n",
            "40940 | 3.9868 | 4.3e-05 | 1.20 | 38.8K | 02:24:03 |  81.9%\n",
            "40950 | 4.1042 | 4.3e-05 | 1.21 | 38.8K | 02:24:05 |  81.9%\n",
            "40960 | 4.3454 | 4.3e-05 | 1.29 | 38.8K | 02:24:07 |  81.9%\n",
            "40970 | 4.3739 | 4.2e-05 | 1.19 | 38.8K | 02:24:09 |  81.9%\n",
            "40980 | 4.1953 | 4.2e-05 | 1.22 | 38.8K | 02:24:10 |  82.0%\n",
            "40990 | 4.2325 | 4.2e-05 | 1.20 | 38.8K | 02:24:12 |  82.0%\n",
            "41000 | 4.3171 | 4.2e-05 | 1.22 | 38.8K | 02:24:14 |  82.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 41000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1224\n",
            "  Perplexity: 61.71\n",
            "  Train loss (avg): 4.2014\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        soğuksa ya da yağmur yağsa, kuraklığa dayanamazsak, kurda yağa yakmaya kalkarız. Yer yer yağmur yağsa, nem konusunda da çok dikkatli olmamız gerekir. Eğer yağmur yağ\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Ankara'da, 39 ülke arasında 22 ayrı kategoride toplam 218 ülke bulunuyor. Türkiye'de toplam 18 farklı kategoride toplam 208 ülke arasında toplam 227 ülke bulunuyor. Türkiye, ilk 500'e\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        sayesinde tüm akıllı telefonlara uygulama imkanı elde edilir. Akıllı telefonların yaygın kullanımı ise tercih edilmesi gereken bir teknolojidir. Yine akıllı telefonlarda daha çok mobil cihazlara uygulama imkanı elde edilir. Bunun için sistem\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:31:43\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "41010 | 4.0766 | 4.2e-05 | 1.23 | 38.7K | 02:24:33 |  82.0%\n",
            "41020 | 4.3743 | 4.2e-05 | 1.23 | 38.7K | 02:24:34 |  82.0%\n",
            "41030 | 4.1742 | 4.2e-05 | 1.21 | 38.7K | 02:24:36 |  82.1%\n",
            "41040 | 4.2282 | 4.2e-05 | 1.24 | 38.7K | 02:24:38 |  82.1%\n",
            "41050 | 4.3624 | 4.2e-05 | 1.17 | 38.7K | 02:24:39 |  82.1%\n",
            "41060 | 4.2182 | 4.2e-05 | 1.24 | 38.7K | 02:24:41 |  82.1%\n",
            "41070 | 4.3697 | 4.2e-05 | 1.18 | 38.7K | 02:24:43 |  82.1%\n",
            "41080 | 3.9576 | 4.1e-05 | 1.21 | 38.7K | 02:24:45 |  82.2%\n",
            "41090 | 4.0319 | 4.1e-05 | 1.16 | 38.7K | 02:24:46 |  82.2%\n",
            "41100 | 4.0544 | 4.1e-05 | 1.18 | 38.8K | 02:24:48 |  82.2%\n",
            "41110 | 4.3629 | 4.1e-05 | 1.21 | 38.8K | 02:24:50 |  82.2%\n",
            "41120 | 4.3795 | 4.1e-05 | 1.21 | 38.8K | 02:24:51 |  82.2%\n",
            "41130 | 4.2377 | 4.1e-05 | 1.26 | 38.8K | 02:24:53 |  82.3%\n",
            "41140 | 4.2128 | 4.1e-05 | 1.23 | 38.8K | 02:24:55 |  82.3%\n",
            "41150 | 4.0356 | 4.1e-05 | 1.16 | 38.8K | 02:24:57 |  82.3%\n",
            "41160 | 4.3243 | 4.1e-05 | 1.20 | 38.8K | 02:24:58 |  82.3%\n",
            "41170 | 4.2537 | 4.1e-05 | 1.24 | 38.8K | 02:25:00 |  82.3%\n",
            "41180 | 4.2045 | 4.1e-05 | 1.17 | 38.8K | 02:25:02 |  82.4%\n",
            "41190 | 4.3460 | 4.0e-05 | 1.17 | 38.8K | 02:25:03 |  82.4%\n",
            "41200 | 4.3350 | 4.0e-05 | 1.21 | 38.8K | 02:25:05 |  82.4%\n",
            "41210 | 4.3075 | 4.0e-05 | 1.18 | 38.8K | 02:25:07 |  82.4%\n",
            "41220 | 4.3764 | 4.0e-05 | 1.27 | 38.8K | 02:25:09 |  82.4%\n",
            "41230 | 4.2251 | 4.0e-05 | 1.22 | 38.8K | 02:25:10 |  82.5%\n",
            "41240 | 4.1749 | 4.0e-05 | 1.15 | 38.8K | 02:25:12 |  82.5%\n",
            "41250 | 4.4519 | 4.0e-05 | 1.20 | 38.8K | 02:25:14 |  82.5%\n",
            "41260 | 4.3360 | 4.0e-05 | 1.18 | 38.8K | 02:25:15 |  82.5%\n",
            "41270 | 4.2142 | 4.0e-05 | 1.20 | 38.8K | 02:25:17 |  82.5%\n",
            "41280 | 4.2048 | 4.0e-05 | 1.19 | 38.8K | 02:25:19 |  82.6%\n",
            "41290 | 4.2257 | 4.0e-05 | 1.23 | 38.8K | 02:25:21 |  82.6%\n",
            "41300 | 4.1757 | 3.9e-05 | 1.19 | 38.8K | 02:25:22 |  82.6%\n",
            "41310 | 4.1680 | 3.9e-05 | 1.21 | 38.8K | 02:25:24 |  82.6%\n",
            "41320 | 4.4206 | 3.9e-05 | 1.21 | 38.8K | 02:25:26 |  82.6%\n",
            "41330 | 4.1511 | 3.9e-05 | 1.19 | 38.8K | 02:25:27 |  82.7%\n",
            "41340 | 4.4057 | 3.9e-05 | 1.22 | 38.8K | 02:25:29 |  82.7%\n",
            "41350 | 4.2041 | 3.9e-05 | 1.20 | 38.8K | 02:25:31 |  82.7%\n",
            "41360 | 4.0344 | 3.9e-05 | 1.18 | 38.8K | 02:25:32 |  82.7%\n",
            "41370 | 4.2768 | 3.9e-05 | 1.23 | 38.8K | 02:25:34 |  82.7%\n",
            "41380 | 4.3087 | 3.9e-05 | 1.18 | 38.8K | 02:25:36 |  82.8%\n",
            "41390 | 4.3130 | 3.9e-05 | 1.22 | 38.8K | 02:25:38 |  82.8%\n",
            "41400 | 4.0724 | 3.9e-05 | 1.23 | 38.8K | 02:25:39 |  82.8%\n",
            "41410 | 4.2601 | 3.8e-05 | 1.17 | 38.8K | 02:25:41 |  82.8%\n",
            "41420 | 4.4524 | 3.8e-05 | 1.19 | 38.8K | 02:25:43 |  82.8%\n",
            "41430 | 4.0373 | 3.8e-05 | 1.16 | 38.8K | 02:25:44 |  82.9%\n",
            "41440 | 3.9971 | 3.8e-05 | 1.31 | 38.8K | 02:25:46 |  82.9%\n",
            "41450 | 3.7524 | 3.8e-05 | 1.17 | 38.8K | 02:25:48 |  82.9%\n",
            "41460 | 4.1153 | 3.8e-05 | 1.21 | 38.8K | 02:25:50 |  82.9%\n",
            "41470 | 4.0940 | 3.8e-05 | 1.25 | 38.8K | 02:25:51 |  82.9%\n",
            "41480 | 4.2261 | 3.8e-05 | 1.24 | 38.8K | 02:25:53 |  83.0%\n",
            "41490 | 3.8088 | 3.8e-05 | 1.18 | 38.8K | 02:25:55 |  83.0%\n",
            "41500 | 4.1345 | 3.8e-05 | 1.22 | 38.8K | 02:25:56 |  83.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 41500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1283\n",
            "  Perplexity: 62.07\n",
            "  Train loss (avg): 4.2048\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        tahminimce % 25'e yakındı. Bu tahminim, % 45'e yakındı. Ve bu tahminim tahminimce % 25'e yakındı. Bu tahminim, tahmin\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        İstanbul'da bulunan ve İstanbul-Akdeniz-İzmir arasındaki Kızıldeniz-Eminovo-Governo-Governo-Governo-Governo-\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        ile fark ediliyor ve bir sonraki aşamada da artık zamanı çabuk durduruyor. Günümüzde en önemli şey bir insansız bir dünyadır. Bu teknoloji oldukça yaygın ve yenilikçi bir araçtır. Bununla birlikte, insanlar bir\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:29:57\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "41510 | 4.1564 | 3.8e-05 | 1.25 | 38.7K | 02:26:15 |  83.0%\n",
            "41520 | 4.1325 | 3.8e-05 | 1.25 | 38.7K | 02:26:17 |  83.0%\n",
            "41530 | 4.2318 | 3.7e-05 | 1.15 | 38.8K | 02:26:19 |  83.1%\n",
            "41540 | 4.3034 | 3.7e-05 | 1.21 | 38.8K | 02:26:21 |  83.1%\n",
            "41550 | 4.0258 | 3.7e-05 | 1.33 | 38.8K | 02:26:22 |  83.1%\n",
            "41560 | 4.1862 | 3.7e-05 | 1.21 | 38.8K | 02:26:24 |  83.1%\n",
            "41570 | 4.1310 | 3.7e-05 | 1.18 | 38.8K | 02:26:26 |  83.1%\n",
            "41580 | 4.0807 | 3.7e-05 | 1.21 | 38.8K | 02:26:27 |  83.2%\n",
            "41590 | 4.4093 | 3.7e-05 | 1.17 | 38.8K | 02:26:29 |  83.2%\n",
            "41600 | 4.3402 | 3.7e-05 | 1.20 | 38.8K | 02:26:31 |  83.2%\n",
            "41610 | 4.0677 | 3.7e-05 | 1.23 | 38.8K | 02:26:33 |  83.2%\n",
            "41620 | 4.1895 | 3.7e-05 | 1.17 | 38.8K | 02:26:34 |  83.2%\n",
            "41630 | 4.2572 | 3.7e-05 | 1.19 | 38.8K | 02:26:36 |  83.3%\n",
            "41640 | 3.8487 | 3.7e-05 | 1.24 | 38.8K | 02:26:38 |  83.3%\n",
            "41650 | 4.5330 | 3.6e-05 | 1.26 | 38.8K | 02:26:39 |  83.3%\n",
            "41660 | 4.1734 | 3.6e-05 | 1.18 | 38.8K | 02:26:41 |  83.3%\n",
            "41670 | 4.0488 | 3.6e-05 | 1.18 | 38.8K | 02:26:43 |  83.3%\n",
            "41680 | 4.1448 | 3.6e-05 | 1.21 | 38.8K | 02:26:45 |  83.4%\n",
            "41690 | 4.3156 | 3.6e-05 | 1.20 | 38.8K | 02:26:46 |  83.4%\n",
            "41700 | 4.0988 | 3.6e-05 | 1.19 | 38.8K | 02:26:48 |  83.4%\n",
            "41710 | 4.0025 | 3.6e-05 | 1.20 | 38.8K | 02:26:50 |  83.4%\n",
            "41720 | 4.1052 | 3.6e-05 | 1.23 | 38.8K | 02:26:51 |  83.4%\n",
            "41730 | 4.1577 | 3.6e-05 | 1.25 | 38.8K | 02:26:53 |  83.5%\n",
            "41740 | 3.9325 | 3.6e-05 | 1.22 | 38.8K | 02:26:55 |  83.5%\n",
            "41750 | 4.3666 | 3.6e-05 | 1.20 | 38.8K | 02:26:57 |  83.5%\n",
            "41760 | 4.0476 | 3.5e-05 | 1.21 | 38.8K | 02:26:58 |  83.5%\n",
            "41770 | 4.0626 | 3.5e-05 | 1.20 | 38.8K | 02:27:00 |  83.5%\n",
            "41780 | 4.1761 | 3.5e-05 | 1.17 | 38.8K | 02:27:02 |  83.6%\n",
            "41790 | 4.0910 | 3.5e-05 | 1.23 | 38.8K | 02:27:03 |  83.6%\n",
            "41800 | 4.0785 | 3.5e-05 | 1.20 | 38.8K | 02:27:05 |  83.6%\n",
            "41810 | 4.1656 | 3.5e-05 | 1.19 | 38.8K | 02:27:07 |  83.6%\n",
            "41820 | 4.5877 | 3.5e-05 | 1.20 | 38.8K | 02:27:09 |  83.6%\n",
            "41830 | 3.9979 | 3.5e-05 | 1.19 | 38.8K | 02:27:10 |  83.7%\n",
            "41840 | 4.2378 | 3.5e-05 | 1.18 | 38.8K | 02:27:12 |  83.7%\n",
            "41850 | 4.0208 | 3.5e-05 | 1.20 | 38.8K | 02:27:14 |  83.7%\n",
            "41860 | 4.1734 | 3.5e-05 | 1.17 | 38.8K | 02:27:15 |  83.7%\n",
            "41870 | 4.3887 | 3.5e-05 | 1.27 | 38.8K | 02:27:17 |  83.7%\n",
            "41880 | 4.0951 | 3.4e-05 | 1.15 | 38.8K | 02:27:19 |  83.8%\n",
            "41890 | 4.1936 | 3.4e-05 | 1.21 | 38.8K | 02:27:21 |  83.8%\n",
            "41900 | 4.2257 | 3.4e-05 | 1.19 | 38.8K | 02:27:22 |  83.8%\n",
            "41910 | 4.4172 | 3.4e-05 | 1.19 | 38.8K | 02:27:24 |  83.8%\n",
            "41920 | 4.2066 | 3.4e-05 | 1.23 | 38.8K | 02:27:26 |  83.8%\n",
            "41930 | 3.9004 | 3.4e-05 | 1.19 | 38.8K | 02:27:27 |  83.9%\n",
            "41940 | 4.3212 | 3.4e-05 | 1.20 | 38.8K | 02:27:29 |  83.9%\n",
            "41950 | 4.3966 | 3.4e-05 | 1.19 | 38.8K | 02:27:31 |  83.9%\n",
            "41960 | 4.2777 | 3.4e-05 | 1.20 | 38.8K | 02:27:33 |  83.9%\n",
            "41970 | 4.2812 | 3.4e-05 | 1.31 | 38.8K | 02:27:34 |  83.9%\n",
            "41980 | 4.1664 | 3.4e-05 | 1.23 | 38.8K | 02:27:36 |  84.0%\n",
            "41990 | 3.9774 | 3.4e-05 | 1.26 | 38.8K | 02:27:38 |  84.0%\n",
            "42000 | 3.9850 | 3.4e-05 | 1.23 | 38.8K | 02:27:39 |  84.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 42000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1467\n",
            "  Perplexity: 63.22\n",
            "  Train loss (avg): 4.1978\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        durumu hakkında herhangi bir açıklama yapılmadı ancak özel eğitim kurumunun uçuş eğitimlerini de desteklemesi bekleniyor. Neden? Çünkü kar nedeniyle uçaklarda hava durumu düzenlenmemişken uçaklarda yolcu olarak bir miktar uçak düşmesi\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        ve en büyük kenti olan Yeşiller, Türkiye’nin en büyük şehridir. Yeşiller, Türkiye’nin en büyük şehridir. Yeşiller şehri, İstanbul’un yüzölçümünün 172\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , oldukça zeki bir yetenektir. Bu teknolojinin ülkemizde oldukça popüler olması, herkesin kullanabileceği bir teknoloji olması gibi özellikler öne çıkmaktadır. Dünyanın en büyük teknoloji şirketleri arasında yer alan ve dünyada ilk 10'a giren işletmeler\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:28:10\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "42010 | 4.2271 | 3.3e-05 | 1.19 | 38.8K | 02:27:58 |  84.0%\n",
            "42020 | 4.4124 | 3.3e-05 | 1.28 | 38.8K | 02:28:00 |  84.0%\n",
            "42030 | 4.3541 | 3.3e-05 | 1.22 | 38.8K | 02:28:02 |  84.1%\n",
            "42040 | 4.1493 | 3.3e-05 | 1.18 | 38.8K | 02:28:03 |  84.1%\n",
            "42050 | 4.0246 | 3.3e-05 | 1.26 | 38.8K | 02:28:05 |  84.1%\n",
            "42060 | 4.3384 | 3.3e-05 | 1.19 | 38.8K | 02:28:07 |  84.1%\n",
            "42070 | 4.2835 | 3.3e-05 | 1.19 | 38.8K | 02:28:09 |  84.1%\n",
            "42080 | 4.4242 | 3.3e-05 | 1.18 | 38.8K | 02:28:10 |  84.2%\n",
            "42090 | 4.1863 | 3.3e-05 | 1.20 | 38.8K | 02:28:12 |  84.2%\n",
            "42100 | 4.3612 | 3.3e-05 | 1.22 | 38.8K | 02:28:14 |  84.2%\n",
            "42110 | 4.2094 | 3.3e-05 | 1.18 | 38.8K | 02:28:15 |  84.2%\n",
            "42120 | 3.9725 | 3.3e-05 | 1.19 | 38.8K | 02:28:17 |  84.2%\n",
            "42130 | 4.0765 | 3.2e-05 | 1.15 | 38.8K | 02:28:19 |  84.3%\n",
            "42140 | 4.2242 | 3.2e-05 | 1.17 | 38.8K | 02:28:21 |  84.3%\n",
            "42150 | 4.3712 | 3.2e-05 | 1.20 | 38.8K | 02:28:22 |  84.3%\n",
            "42160 | 4.1305 | 3.2e-05 | 1.19 | 38.8K | 02:28:24 |  84.3%\n",
            "42170 | 4.1885 | 3.2e-05 | 1.21 | 38.8K | 02:28:26 |  84.3%\n",
            "42180 | 4.3178 | 3.2e-05 | 1.19 | 38.8K | 02:28:27 |  84.4%\n",
            "42190 | 3.7286 | 3.2e-05 | 1.16 | 38.8K | 02:28:29 |  84.4%\n",
            "42200 | 4.1294 | 3.2e-05 | 1.21 | 38.8K | 02:28:31 |  84.4%\n",
            "42210 | 4.2849 | 3.2e-05 | 1.23 | 38.8K | 02:28:33 |  84.4%\n",
            "42220 | 4.3523 | 3.2e-05 | 1.17 | 38.8K | 02:28:34 |  84.4%\n",
            "42230 | 4.2104 | 3.2e-05 | 1.19 | 38.8K | 02:28:36 |  84.5%\n",
            "42240 | 4.3527 | 3.2e-05 | 1.23 | 38.8K | 02:28:38 |  84.5%\n",
            "42250 | 4.2728 | 3.1e-05 | 1.23 | 38.8K | 02:28:39 |  84.5%\n",
            "42260 | 4.2615 | 3.1e-05 | 1.17 | 38.8K | 02:28:41 |  84.5%\n",
            "42270 | 4.2216 | 3.1e-05 | 1.19 | 38.8K | 02:28:43 |  84.5%\n",
            "42280 | 4.1024 | 3.1e-05 | 1.18 | 38.8K | 02:28:45 |  84.6%\n",
            "42290 | 4.2283 | 3.1e-05 | 1.19 | 38.8K | 02:28:46 |  84.6%\n",
            "42300 | 3.9497 | 3.1e-05 | 1.16 | 38.8K | 02:28:48 |  84.6%\n",
            "42310 | 4.1032 | 3.1e-05 | 1.25 | 38.8K | 02:28:50 |  84.6%\n",
            "42320 | 4.4322 | 3.1e-05 | 1.20 | 38.8K | 02:28:51 |  84.6%\n",
            "42330 | 3.8609 | 3.1e-05 | 1.16 | 38.8K | 02:28:53 |  84.7%\n",
            "42340 | 4.1485 | 3.1e-05 | 1.22 | 38.8K | 02:28:55 |  84.7%\n",
            "42350 | 4.2368 | 3.1e-05 | 1.22 | 38.8K | 02:28:57 |  84.7%\n",
            "42360 | 4.0846 | 3.1e-05 | 1.16 | 38.8K | 02:28:58 |  84.7%\n",
            "42370 | 4.2419 | 3.1e-05 | 1.22 | 38.8K | 02:29:00 |  84.7%\n",
            "42380 | 4.1256 | 3.0e-05 | 1.20 | 38.8K | 02:29:02 |  84.8%\n",
            "42390 | 4.0672 | 3.0e-05 | 1.28 | 38.8K | 02:29:03 |  84.8%\n",
            "42400 | 4.1530 | 3.0e-05 | 1.20 | 38.8K | 02:29:05 |  84.8%\n",
            "42410 | 4.2456 | 3.0e-05 | 1.22 | 38.8K | 02:29:07 |  84.8%\n",
            "42420 | 4.2545 | 3.0e-05 | 1.22 | 38.8K | 02:29:09 |  84.8%\n",
            "42430 | 4.3285 | 3.0e-05 | 1.20 | 38.8K | 02:29:10 |  84.9%\n",
            "42440 | 3.6659 | 3.0e-05 | 1.19 | 38.8K | 02:29:12 |  84.9%\n",
            "42450 | 4.2723 | 3.0e-05 | 1.22 | 38.8K | 02:29:14 |  84.9%\n",
            "42460 | 4.0389 | 3.0e-05 | 1.18 | 38.8K | 02:29:15 |  84.9%\n",
            "42470 | 4.3972 | 3.0e-05 | 1.19 | 38.8K | 02:29:17 |  84.9%\n",
            "42480 | 4.3304 | 3.0e-05 | 1.23 | 38.8K | 02:29:19 |  85.0%\n",
            "42490 | 4.3509 | 3.0e-05 | 1.20 | 38.8K | 02:29:21 |  85.0%\n",
            "42500 | 4.3755 | 3.0e-05 | 1.20 | 38.8K | 02:29:22 |  85.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 42500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1320\n",
            "  Perplexity: 62.30\n",
            "  Train loss (avg): 4.1920\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        sıcaklıklarının aşırı, orta ve yüksek olduğu, subtropikal havaların ve deniz işgalinin en yoğun olduğu günler. Hava sıcaklıklarının düşük olması da en büyük hava boşluğu olabilir. Ayrıca hava sıcaklığının\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Berlin'de bulunan Berlin'in en büyük şehri olan Berlin, İstanbul'a bir çok il ve seçenekle geliyor. Berlin'in en ünlü tarihi bölgeleri arasında yer alan Berlin, Berlin'in en\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , daha fazla bilgi ve deneyimle bir araya getiren bir yazılımdır. Bilgi bilimlerinin ortaya koyduğu veri ve teknolojisi için bilgiye ihtiyaç duyulur. Araştırmacılar, bilginin büyük bir bölümü, bilgiyi karmaşık hale getiriyor\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:26:24\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "42510 | 4.3140 | 2.9e-05 | 1.19 | 38.8K | 02:29:41 |  85.0%\n",
            "42520 | 4.0823 | 2.9e-05 | 1.14 | 38.8K | 02:29:43 |  85.0%\n",
            "42530 | 4.3232 | 2.9e-05 | 1.18 | 38.8K | 02:29:45 |  85.1%\n",
            "42540 | 4.2324 | 2.9e-05 | 1.20 | 38.8K | 02:29:46 |  85.1%\n",
            "42550 | 4.2710 | 2.9e-05 | 1.19 | 38.8K | 02:29:48 |  85.1%\n",
            "42560 | 3.8263 | 2.9e-05 | 1.15 | 38.8K | 02:29:50 |  85.1%\n",
            "42570 | 4.2639 | 2.9e-05 | 1.19 | 38.8K | 02:29:52 |  85.1%\n",
            "42580 | 4.4594 | 2.9e-05 | 1.19 | 38.8K | 02:29:53 |  85.2%\n",
            "42590 | 4.2128 | 2.9e-05 | 1.20 | 38.8K | 02:29:55 |  85.2%\n",
            "42600 | 4.4863 | 2.9e-05 | 1.23 | 38.8K | 02:29:57 |  85.2%\n",
            "42610 | 4.1289 | 2.9e-05 | 1.22 | 38.8K | 02:29:58 |  85.2%\n",
            "42620 | 3.9618 | 2.9e-05 | 1.18 | 38.8K | 02:30:00 |  85.2%\n",
            "42630 | 4.1861 | 2.9e-05 | 1.19 | 38.8K | 02:30:02 |  85.3%\n",
            "42640 | 4.0141 | 2.8e-05 | 1.22 | 38.8K | 02:30:04 |  85.3%\n",
            "42650 | 4.3093 | 2.8e-05 | 1.20 | 38.8K | 02:30:05 |  85.3%\n",
            "42660 | 4.3872 | 2.8e-05 | 1.20 | 38.8K | 02:30:07 |  85.3%\n",
            "42670 | 4.3273 | 2.8e-05 | 1.21 | 38.8K | 02:30:09 |  85.3%\n",
            "42680 | 4.1191 | 2.8e-05 | 1.22 | 38.8K | 02:30:10 |  85.4%\n",
            "42690 | 4.1602 | 2.8e-05 | 1.23 | 38.8K | 02:30:12 |  85.4%\n",
            "42700 | 4.1968 | 2.8e-05 | 1.19 | 38.8K | 02:30:14 |  85.4%\n",
            "42710 | 4.1870 | 2.8e-05 | 1.17 | 38.8K | 02:30:16 |  85.4%\n",
            "42720 | 4.3464 | 2.8e-05 | 1.17 | 38.8K | 02:30:17 |  85.4%\n",
            "42730 | 3.9048 | 2.8e-05 | 1.15 | 38.8K | 02:30:19 |  85.5%\n",
            "42740 | 4.1552 | 2.8e-05 | 1.22 | 38.8K | 02:30:21 |  85.5%\n",
            "42750 | 3.8792 | 2.8e-05 | 1.21 | 38.8K | 02:30:22 |  85.5%\n",
            "42760 | 4.0629 | 2.8e-05 | 1.22 | 38.8K | 02:30:24 |  85.5%\n",
            "42770 | 4.5381 | 2.7e-05 | 1.23 | 38.8K | 02:30:26 |  85.5%\n",
            "42780 | 4.3646 | 2.7e-05 | 1.31 | 38.8K | 02:30:28 |  85.6%\n",
            "42790 | 4.1117 | 2.7e-05 | 1.18 | 38.8K | 02:30:29 |  85.6%\n",
            "42800 | 4.1069 | 2.7e-05 | 1.18 | 38.8K | 02:30:31 |  85.6%\n",
            "42810 | 4.2323 | 2.7e-05 | 1.19 | 38.8K | 02:30:33 |  85.6%\n",
            "42820 | 3.9554 | 2.7e-05 | 1.17 | 38.8K | 02:30:34 |  85.6%\n",
            "42830 | 4.0745 | 2.7e-05 | 1.19 | 38.8K | 02:30:36 |  85.7%\n",
            "42840 | 4.1108 | 2.7e-05 | 1.20 | 38.8K | 02:30:38 |  85.7%\n",
            "42850 | 4.3338 | 2.7e-05 | 1.27 | 38.8K | 02:30:40 |  85.7%\n",
            "42860 | 4.5386 | 2.7e-05 | 1.18 | 38.8K | 02:30:41 |  85.7%\n",
            "42870 | 4.0168 | 2.7e-05 | 1.17 | 38.8K | 02:30:43 |  85.7%\n",
            "42880 | 4.0792 | 2.7e-05 | 1.16 | 38.8K | 02:30:45 |  85.8%\n",
            "42890 | 4.2993 | 2.7e-05 | 1.25 | 38.8K | 02:30:46 |  85.8%\n",
            "42900 | 4.1449 | 2.7e-05 | 1.21 | 38.8K | 02:30:48 |  85.8%\n",
            "42910 | 4.1896 | 2.6e-05 | 1.18 | 38.8K | 02:30:50 |  85.8%\n",
            "42920 | 4.0111 | 2.6e-05 | 1.22 | 38.8K | 02:30:51 |  85.8%\n",
            "42930 | 3.4173 | 2.6e-05 | 1.17 | 38.8K | 02:30:53 |  85.9%\n",
            "42940 | 3.9059 | 2.6e-05 | 1.23 | 38.8K | 02:30:55 |  85.9%\n",
            "42950 | 4.3716 | 2.6e-05 | 1.22 | 38.8K | 02:30:57 |  85.9%\n",
            "42960 | 4.1079 | 2.6e-05 | 1.21 | 38.8K | 02:30:58 |  85.9%\n",
            "42970 | 4.4587 | 2.6e-05 | 1.20 | 38.9K | 02:31:00 |  85.9%\n",
            "42980 | 4.3622 | 2.6e-05 | 1.24 | 38.9K | 02:31:02 |  86.0%\n",
            "42990 | 4.3699 | 2.6e-05 | 1.18 | 38.9K | 02:31:03 |  86.0%\n",
            "43000 | 4.2711 | 2.6e-05 | 1.23 | 38.9K | 02:31:05 |  86.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 43000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.0995\n",
            "  Perplexity: 60.31\n",
            "  Train loss (avg): 4.1748\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        durumu ne olursa olsun böyle değil. Ne kadar kötü hava var, ne kadar kişi hava şartları uygun olursa olsun soğuk hava, çok sıcak değil. Hava ne kadar soğuksa o kadar soğuk olacak. Hava yağışlı\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        olan Antalya'da, seçmenlerinin büyük çoğunluğu oy kullanabilecek. Antalya'da seçmenlerin çoğu oy kullanmayacak. Ayrıca Antalya, Türkiye'nin dört bir yanından seçmenlerin yüzde 10'u oy kullanacak\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , korku ve korku ile savaşmayı öğreniyor. ABD’de ekip, bilim insanları ve bilim adamları, süper kahramanlar gibi yeni bilim adamları ve bilim adamlarının bir araya gelip, yeni bir uzay aracı geliştir\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.0995)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:24:39\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "43010 | 4.3080 | 2.6e-05 | 1.27 | 38.8K | 02:31:30 |  86.0%\n",
            "43020 | 3.8790 | 2.6e-05 | 1.17 | 38.8K | 02:31:32 |  86.0%\n",
            "43030 | 4.1775 | 2.6e-05 | 1.21 | 38.8K | 02:31:34 |  86.1%\n",
            "43040 | 4.4308 | 2.6e-05 | 1.20 | 38.8K | 02:31:35 |  86.1%\n",
            "43050 | 4.4571 | 2.5e-05 | 1.24 | 38.8K | 02:31:37 |  86.1%\n",
            "43060 | 4.2377 | 2.5e-05 | 1.21 | 38.8K | 02:31:39 |  86.1%\n",
            "43070 | 4.1611 | 2.5e-05 | 1.21 | 38.8K | 02:31:40 |  86.1%\n",
            "43080 | 4.1910 | 2.5e-05 | 1.23 | 38.8K | 02:31:42 |  86.2%\n",
            "43090 | 4.2242 | 2.5e-05 | 1.21 | 38.8K | 02:31:44 |  86.2%\n",
            "43100 | 4.2229 | 2.5e-05 | 1.17 | 38.8K | 02:31:46 |  86.2%\n",
            "43110 | 4.0368 | 2.5e-05 | 1.20 | 38.8K | 02:31:47 |  86.2%\n",
            "43120 | 4.2474 | 2.5e-05 | 1.19 | 38.8K | 02:31:49 |  86.2%\n",
            "43130 | 4.0239 | 2.5e-05 | 1.28 | 38.8K | 02:31:51 |  86.3%\n",
            "43140 | 4.3564 | 2.5e-05 | 1.23 | 38.8K | 02:31:52 |  86.3%\n",
            "43150 | 4.1175 | 2.5e-05 | 1.20 | 38.8K | 02:31:54 |  86.3%\n",
            "43160 | 4.0341 | 2.5e-05 | 1.18 | 38.8K | 02:31:56 |  86.3%\n",
            "43170 | 4.2497 | 2.5e-05 | 1.20 | 38.8K | 02:31:58 |  86.3%\n",
            "43180 | 4.1510 | 2.5e-05 | 1.17 | 38.8K | 02:31:59 |  86.4%\n",
            "43190 | 4.2160 | 2.4e-05 | 1.21 | 38.8K | 02:32:01 |  86.4%\n",
            "43200 | 4.3573 | 2.4e-05 | 1.22 | 38.8K | 02:32:03 |  86.4%\n",
            "43210 | 4.2973 | 2.4e-05 | 1.22 | 38.8K | 02:32:04 |  86.4%\n",
            "43220 | 4.2032 | 2.4e-05 | 1.19 | 38.8K | 02:32:06 |  86.4%\n",
            "43230 | 3.8631 | 2.4e-05 | 1.23 | 38.8K | 02:32:08 |  86.5%\n",
            "43240 | 4.1248 | 2.4e-05 | 1.16 | 38.8K | 02:32:09 |  86.5%\n",
            "43250 | 4.1538 | 2.4e-05 | 1.24 | 38.8K | 02:32:11 |  86.5%\n",
            "43260 | 3.9799 | 2.4e-05 | 1.31 | 38.8K | 02:32:13 |  86.5%\n",
            "43270 | 4.0383 | 2.4e-05 | 1.15 | 38.8K | 02:32:15 |  86.5%\n",
            "43280 | 4.2831 | 2.4e-05 | 1.18 | 38.8K | 02:32:16 |  86.6%\n",
            "43290 | 4.2699 | 2.4e-05 | 1.23 | 38.8K | 02:32:18 |  86.6%\n",
            "43300 | 4.1255 | 2.4e-05 | 1.24 | 38.8K | 02:32:20 |  86.6%\n",
            "43310 | 4.1918 | 2.4e-05 | 1.19 | 38.8K | 02:32:21 |  86.6%\n",
            "43320 | 4.4084 | 2.4e-05 | 1.19 | 38.8K | 02:32:23 |  86.6%\n",
            "43330 | 4.4532 | 2.3e-05 | 1.26 | 38.8K | 02:32:25 |  86.7%\n",
            "43340 | 4.4704 | 2.3e-05 | 1.23 | 38.8K | 02:32:27 |  86.7%\n",
            "43350 | 4.2847 | 2.3e-05 | 1.19 | 38.8K | 02:32:28 |  86.7%\n",
            "43360 | 4.0134 | 2.3e-05 | 1.23 | 38.8K | 02:32:30 |  86.7%\n",
            "43370 | 3.6506 | 2.3e-05 | 1.19 | 38.8K | 02:32:32 |  86.7%\n",
            "43380 | 4.2095 | 2.3e-05 | 1.19 | 38.8K | 02:32:33 |  86.8%\n",
            "43390 | 4.0956 | 2.3e-05 | 1.23 | 38.8K | 02:32:35 |  86.8%\n",
            "43400 | 4.3115 | 2.3e-05 | 1.19 | 38.8K | 02:32:37 |  86.8%\n",
            "43410 | 4.2161 | 2.3e-05 | 1.17 | 38.8K | 02:32:39 |  86.8%\n",
            "43420 | 4.4108 | 2.3e-05 | 1.20 | 38.8K | 02:32:40 |  86.8%\n",
            "43430 | 4.3105 | 2.3e-05 | 1.21 | 38.8K | 02:32:42 |  86.9%\n",
            "43440 | 3.7063 | 2.3e-05 | 1.17 | 38.8K | 02:32:44 |  86.9%\n",
            "43450 | 4.2299 | 2.3e-05 | 1.20 | 38.8K | 02:32:45 |  86.9%\n",
            "43460 | 4.0294 | 2.3e-05 | 1.27 | 38.8K | 02:32:47 |  86.9%\n",
            "43470 | 4.4379 | 2.2e-05 | 1.20 | 38.8K | 02:32:49 |  86.9%\n",
            "43480 | 4.2214 | 2.2e-05 | 1.17 | 38.8K | 02:32:51 |  87.0%\n",
            "43490 | 4.1934 | 2.2e-05 | 1.21 | 38.8K | 02:32:52 |  87.0%\n",
            "43500 | 4.2128 | 2.2e-05 | 1.21 | 38.8K | 02:32:54 |  87.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 43500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1171\n",
            "  Perplexity: 61.38\n",
            "  Train loss (avg): 4.1806\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        sıcaklığının, pek çok kişinin üzerindedir. Hava sıcaklığının, havanın sıcaklığının arttığı bir ortamda, hava sıcaklığının sandığınızdan çok daha fazla olduğunu söyleyebilir, ama sıcaklık, bu sıcaklığın yaşandığı\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        olarak bilinen en büyük şehri haline gelen İstanbul, tarihiyle de en çok ilgi çeken kentlerden biri. Tarihi ve doğal güzellikleri ile dikkat çeken İstanbul, eski yapılarıyla da dikkat çekiyor. İstanbul'un en\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , yapay zeka ve yapay zekanın kazandırdığı birçok yeniliği üretti. Yapay zeka teknolojilerine karşı yeni bir eğilim daha ve yapay zekayı geliştiriyor. Yapay zeka, yapay zeka ve yapay zeka teknoloj\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:22:53\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "43510 | 4.2459 | 2.2e-05 | 1.22 | 38.8K | 02:33:13 |  87.0%\n",
            "43520 | 4.2840 | 2.2e-05 | 1.20 | 38.8K | 02:33:15 |  87.0%\n",
            "43530 | 4.2348 | 2.2e-05 | 1.18 | 38.8K | 02:33:16 |  87.1%\n",
            "43540 | 4.2950 | 2.2e-05 | 1.20 | 38.8K | 02:33:18 |  87.1%\n",
            "43550 | 4.0484 | 2.2e-05 | 1.21 | 38.8K | 02:33:20 |  87.1%\n",
            "43560 | 4.1595 | 2.2e-05 | 1.22 | 38.8K | 02:33:22 |  87.1%\n",
            "43570 | 4.2532 | 2.2e-05 | 1.21 | 38.8K | 02:33:23 |  87.1%\n",
            "43580 | 4.1825 | 2.2e-05 | 1.19 | 38.8K | 02:33:25 |  87.2%\n",
            "43590 | 4.3231 | 2.2e-05 | 1.22 | 38.8K | 02:33:27 |  87.2%\n",
            "43600 | 4.1548 | 2.2e-05 | 1.19 | 38.8K | 02:33:28 |  87.2%\n",
            "43610 | 4.3159 | 2.2e-05 | 1.24 | 38.8K | 02:33:30 |  87.2%\n",
            "43620 | 4.2594 | 2.1e-05 | 1.22 | 38.8K | 02:33:32 |  87.2%\n",
            "43630 | 4.2207 | 2.1e-05 | 1.18 | 38.8K | 02:33:34 |  87.3%\n",
            "43640 | 4.0473 | 2.1e-05 | 1.20 | 38.8K | 02:33:35 |  87.3%\n",
            "43650 | 4.3506 | 2.1e-05 | 1.26 | 38.8K | 02:33:37 |  87.3%\n",
            "43660 | 4.1090 | 2.1e-05 | 1.24 | 38.8K | 02:33:39 |  87.3%\n",
            "43670 | 4.2422 | 2.1e-05 | 1.23 | 38.8K | 02:33:40 |  87.3%\n",
            "43680 | 4.4093 | 2.1e-05 | 1.19 | 38.8K | 02:33:42 |  87.4%\n",
            "43690 | 4.3417 | 2.1e-05 | 1.22 | 38.8K | 02:33:44 |  87.4%\n",
            "43700 | 3.9710 | 2.1e-05 | 1.23 | 38.8K | 02:33:46 |  87.4%\n",
            "43710 | 4.2761 | 2.1e-05 | 1.20 | 38.8K | 02:33:47 |  87.4%\n",
            "43720 | 4.0410 | 2.1e-05 | 1.20 | 38.8K | 02:33:49 |  87.4%\n",
            "43730 | 4.1073 | 2.1e-05 | 1.23 | 38.8K | 02:33:51 |  87.5%\n",
            "43740 | 4.1027 | 2.1e-05 | 1.23 | 38.8K | 02:33:52 |  87.5%\n",
            "43750 | 4.0380 | 2.1e-05 | 1.22 | 38.8K | 02:33:54 |  87.5%\n",
            "43760 | 4.1057 | 2.1e-05 | 1.24 | 38.8K | 02:33:56 |  87.5%\n",
            "43770 | 4.1124 | 2.1e-05 | 1.24 | 38.8K | 02:33:58 |  87.5%\n",
            "43780 | 4.0588 | 2.0e-05 | 1.22 | 38.8K | 02:33:59 |  87.6%\n",
            "43790 | 4.1013 | 2.0e-05 | 1.17 | 38.8K | 02:34:01 |  87.6%\n",
            "43800 | 4.2311 | 2.0e-05 | 1.17 | 38.8K | 02:34:03 |  87.6%\n",
            "43810 | 4.2157 | 2.0e-05 | 1.24 | 38.8K | 02:34:04 |  87.6%\n",
            "43820 | 3.9614 | 2.0e-05 | 1.25 | 38.8K | 02:34:06 |  87.6%\n",
            "43830 | 3.8415 | 2.0e-05 | 1.21 | 38.8K | 02:34:08 |  87.7%\n",
            "43840 | 4.3705 | 2.0e-05 | 1.19 | 38.8K | 02:34:10 |  87.7%\n",
            "43850 | 4.3461 | 2.0e-05 | 1.21 | 38.8K | 02:34:11 |  87.7%\n",
            "43860 | 4.2225 | 2.0e-05 | 1.22 | 38.8K | 02:34:13 |  87.7%\n",
            "43870 | 4.1511 | 2.0e-05 | 1.20 | 38.8K | 02:34:15 |  87.7%\n",
            "43880 | 4.1893 | 2.0e-05 | 1.18 | 38.8K | 02:34:16 |  87.8%\n",
            "43890 | 4.1932 | 2.0e-05 | 1.20 | 38.8K | 02:34:18 |  87.8%\n",
            "43900 | 4.1982 | 2.0e-05 | 1.20 | 38.8K | 02:34:20 |  87.8%\n",
            "43910 | 4.0821 | 2.0e-05 | 1.21 | 38.8K | 02:34:21 |  87.8%\n",
            "43920 | 4.2649 | 2.0e-05 | 1.20 | 38.8K | 02:34:23 |  87.8%\n",
            "43930 | 4.2006 | 1.9e-05 | 1.19 | 38.8K | 02:34:25 |  87.9%\n",
            "43940 | 4.3699 | 1.9e-05 | 1.18 | 38.8K | 02:34:27 |  87.9%\n",
            "43950 | 4.1016 | 1.9e-05 | 1.18 | 38.8K | 02:34:28 |  87.9%\n",
            "43960 | 4.2265 | 1.9e-05 | 1.18 | 38.8K | 02:34:30 |  87.9%\n",
            "43970 | 4.3259 | 1.9e-05 | 1.21 | 38.8K | 02:34:32 |  87.9%\n",
            "43980 | 4.2984 | 1.9e-05 | 1.22 | 38.8K | 02:34:33 |  88.0%\n",
            "43990 | 3.8999 | 1.9e-05 | 1.16 | 38.9K | 02:34:35 |  88.0%\n",
            "44000 | 4.1408 | 1.9e-05 | 1.19 | 38.9K | 02:34:37 |  88.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 44000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1278\n",
            "  Perplexity: 62.04\n",
            "  Train loss (avg): 4.1717\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        ve deniz seviyelerinin aynı olması nedeniyle iki ülkenin iç ve dış politikasında belirleyici olacak olan ekonomi, politika ve politikaların yanı sıra, dış politikanın iç politikada da etki etmesini sağlayacak. En azından Türkiye\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Moskova'da düzenlenen 2. Dünya Savaşı'na katılanlar arasında Sovyetler Birliği'nin dışında kalan Putin'in kendisine soru sorması üzerine Moskova'da bulunan Prof. Dr. Alberta Von Ver\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , insanın yaşamsal gelişiminin anahtarını oluşturuyor. Bir bilim insanı, günlük yaşamla ilgili eksikleri, problemleri, başarısızlıkları ve kusurları tespit etmek için karmaşık çözümler sunuyor. Anasayfa > Ürün &\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:21:07\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "44010 | 4.4707 | 1.9e-05 | 1.21 | 38.8K | 02:34:56 |  88.0%\n",
            "44020 | 4.4252 | 1.9e-05 | 1.24 | 38.8K | 02:34:58 |  88.0%\n",
            "44030 | 4.3678 | 1.9e-05 | 1.18 | 38.8K | 02:34:59 |  88.1%\n",
            "44040 | 4.3997 | 1.9e-05 | 1.20 | 38.8K | 02:35:01 |  88.1%\n",
            "44050 | 4.0411 | 1.9e-05 | 1.27 | 38.8K | 02:35:03 |  88.1%\n",
            "44060 | 4.1459 | 1.9e-05 | 1.17 | 38.8K | 02:35:04 |  88.1%\n",
            "44070 | 4.1652 | 1.9e-05 | 1.21 | 38.8K | 02:35:06 |  88.1%\n",
            "44080 | 4.3966 | 1.9e-05 | 1.18 | 38.8K | 02:35:08 |  88.2%\n",
            "44090 | 4.0337 | 1.8e-05 | 1.21 | 38.8K | 02:35:10 |  88.2%\n",
            "44100 | 4.0078 | 1.8e-05 | 1.22 | 38.8K | 02:35:11 |  88.2%\n",
            "44110 | 4.3396 | 1.8e-05 | 1.21 | 38.8K | 02:35:13 |  88.2%\n",
            "44120 | 4.2635 | 1.8e-05 | 1.21 | 38.8K | 02:35:15 |  88.2%\n",
            "44130 | 4.5740 | 1.8e-05 | 1.25 | 38.8K | 02:35:16 |  88.3%\n",
            "44140 | 3.8597 | 1.8e-05 | 1.47 | 38.8K | 02:35:18 |  88.3%\n",
            "44150 | 4.2475 | 1.8e-05 | 1.20 | 38.8K | 02:35:20 |  88.3%\n",
            "44160 | 4.0466 | 1.8e-05 | 1.21 | 38.8K | 02:35:22 |  88.3%\n",
            "44170 | 4.1573 | 1.8e-05 | 1.20 | 38.8K | 02:35:23 |  88.3%\n",
            "44180 | 4.2714 | 1.8e-05 | 1.18 | 38.8K | 02:35:25 |  88.4%\n",
            "44190 | 4.2500 | 1.8e-05 | 1.22 | 38.8K | 02:35:27 |  88.4%\n",
            "44200 | 4.0255 | 1.8e-05 | 1.23 | 38.8K | 02:35:28 |  88.4%\n",
            "44210 | 3.8596 | 1.8e-05 | 1.18 | 38.8K | 02:35:30 |  88.4%\n",
            "44220 | 4.2403 | 1.8e-05 | 1.20 | 38.8K | 02:35:32 |  88.4%\n",
            "44230 | 4.1001 | 1.8e-05 | 1.23 | 38.8K | 02:35:34 |  88.5%\n",
            "44240 | 4.0771 | 1.8e-05 | 1.17 | 38.8K | 02:35:35 |  88.5%\n",
            "44250 | 4.2234 | 1.8e-05 | 1.24 | 38.8K | 02:35:37 |  88.5%\n",
            "44260 | 4.2654 | 1.7e-05 | 1.20 | 38.8K | 02:35:39 |  88.5%\n",
            "44270 | 4.1186 | 1.7e-05 | 1.18 | 38.8K | 02:35:40 |  88.5%\n",
            "44280 | 4.2886 | 1.7e-05 | 1.21 | 38.8K | 02:35:42 |  88.6%\n",
            "44290 | 4.0350 | 1.7e-05 | 1.20 | 38.8K | 02:35:44 |  88.6%\n",
            "44300 | 3.9652 | 1.7e-05 | 1.23 | 38.8K | 02:35:45 |  88.6%\n",
            "44310 | 3.8846 | 1.7e-05 | 1.24 | 38.8K | 02:35:47 |  88.6%\n",
            "44320 | 4.3041 | 1.7e-05 | 1.20 | 38.8K | 02:35:49 |  88.6%\n",
            "44330 | 4.3461 | 1.7e-05 | 1.20 | 38.8K | 02:35:51 |  88.7%\n",
            "44340 | 4.0148 | 1.7e-05 | 1.22 | 38.8K | 02:35:52 |  88.7%\n",
            "44350 | 4.2141 | 1.7e-05 | 1.21 | 38.8K | 02:35:54 |  88.7%\n",
            "44360 | 3.7641 | 1.7e-05 | 1.24 | 38.8K | 02:35:56 |  88.7%\n",
            "44370 | 4.0873 | 1.7e-05 | 1.27 | 38.8K | 02:35:57 |  88.7%\n",
            "44380 | 4.4406 | 1.7e-05 | 1.20 | 38.8K | 02:35:59 |  88.8%\n",
            "44390 | 4.4119 | 1.7e-05 | 1.20 | 38.8K | 02:36:01 |  88.8%\n",
            "44400 | 4.1117 | 1.7e-05 | 1.23 | 38.8K | 02:36:03 |  88.8%\n",
            "44410 | 4.1938 | 1.7e-05 | 1.26 | 38.8K | 02:36:04 |  88.8%\n",
            "44420 | 4.2238 | 1.6e-05 | 1.21 | 38.8K | 02:36:06 |  88.8%\n",
            "44430 | 4.4053 | 1.6e-05 | 1.23 | 38.9K | 02:36:08 |  88.9%\n",
            "44440 | 4.3458 | 1.6e-05 | 1.16 | 38.9K | 02:36:09 |  88.9%\n",
            "44450 | 4.4319 | 1.6e-05 | 1.28 | 38.9K | 02:36:11 |  88.9%\n",
            "44460 | 4.2694 | 1.6e-05 | 1.22 | 38.9K | 02:36:13 |  88.9%\n",
            "44470 | 4.3650 | 1.6e-05 | 1.21 | 38.9K | 02:36:15 |  88.9%\n",
            "44480 | 4.0591 | 1.6e-05 | 1.23 | 38.9K | 02:36:16 |  89.0%\n",
            "44490 | 4.5197 | 1.6e-05 | 1.21 | 38.9K | 02:36:18 |  89.0%\n",
            "44500 | 4.2240 | 1.6e-05 | 1.22 | 38.9K | 02:36:20 |  89.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 44500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1539\n",
            "  Perplexity: 63.68\n",
            "  Train loss (avg): 4.2032\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        sıcaklıklarının geldiğini görmek beni çok mutlu ediyor. Bu yüzden pek çok yerde bu sıcakta hava sıcaklığı çok iyi geliyor. Hava sıcaklıklarının iç sıcaklığının yüksek olması nedeniyle insanlar kendi aralarında çok iyi anlaşıyor.\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Mara'da, aralarında ABD Başkanı Donald Trump'ın da bulunduğu 40 kişilik bir grup, \"Para krizi, ülke için bir felakettir\" diyerek, \"birileri iç savaşa sokuyor\"\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        kullanılarak geliştirilecek olan bir oyunun ve bu oyunun ileri yaşta diğer oyunlardan farkı ise oyunun donma ve donma hızlarına göre farklı bir şekilde oynanmasıdır. Üstelik oyun dünyanın en hızlı oyunu olarak kabul edilir\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.74\n",
            "     ETA: 00:19:21\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "44510 | 4.1552 | 1.6e-05 | 1.24 | 38.8K | 02:36:39 |  89.0%\n",
            "44520 | 4.2859 | 1.6e-05 | 1.24 | 38.8K | 02:36:40 |  89.0%\n",
            "44530 | 3.9635 | 1.6e-05 | 1.22 | 38.8K | 02:36:42 |  89.1%\n",
            "44540 | 4.2857 | 1.6e-05 | 1.25 | 38.8K | 02:36:44 |  89.1%\n",
            "44550 | 4.1181 | 1.6e-05 | 1.19 | 38.8K | 02:36:46 |  89.1%\n",
            "44560 | 4.1550 | 1.6e-05 | 1.20 | 38.8K | 02:36:47 |  89.1%\n",
            "44570 | 3.8829 | 1.6e-05 | 1.21 | 38.8K | 02:36:49 |  89.1%\n",
            "44580 | 4.2647 | 1.6e-05 | 1.19 | 38.8K | 02:36:51 |  89.2%\n",
            "44590 | 4.3732 | 1.6e-05 | 1.23 | 38.8K | 02:36:52 |  89.2%\n",
            "44600 | 3.9905 | 1.5e-05 | 1.21 | 38.8K | 02:36:54 |  89.2%\n",
            "44610 | 4.2043 | 1.5e-05 | 1.18 | 38.8K | 02:36:56 |  89.2%\n",
            "44620 | 4.1131 | 1.5e-05 | 1.18 | 38.8K | 02:36:58 |  89.2%\n",
            "44630 | 4.4288 | 1.5e-05 | 1.19 | 38.8K | 02:36:59 |  89.3%\n",
            "44640 | 4.4084 | 1.5e-05 | 1.19 | 38.8K | 02:37:01 |  89.3%\n",
            "44650 | 4.3600 | 1.5e-05 | 1.21 | 38.8K | 02:37:03 |  89.3%\n",
            "44660 | 4.4217 | 1.5e-05 | 1.21 | 38.8K | 02:37:04 |  89.3%\n",
            "44670 | 4.3260 | 1.5e-05 | 1.20 | 38.8K | 02:37:06 |  89.3%\n",
            "44680 | 4.2425 | 1.5e-05 | 1.24 | 38.8K | 02:37:08 |  89.4%\n",
            "44690 | 3.9245 | 1.5e-05 | 1.21 | 38.8K | 02:37:10 |  89.4%\n",
            "44700 | 4.0001 | 1.5e-05 | 1.19 | 38.8K | 02:37:11 |  89.4%\n",
            "44710 | 4.1232 | 1.5e-05 | 1.19 | 38.8K | 02:37:13 |  89.4%\n",
            "44720 | 3.8539 | 1.5e-05 | 1.20 | 38.8K | 02:37:15 |  89.4%\n",
            "44730 | 4.2158 | 1.5e-05 | 1.17 | 38.8K | 02:37:16 |  89.5%\n",
            "44740 | 3.8923 | 1.5e-05 | 1.16 | 38.8K | 02:37:18 |  89.5%\n",
            "44750 | 4.0720 | 1.5e-05 | 1.30 | 38.8K | 02:37:20 |  89.5%\n",
            "44760 | 4.2436 | 1.5e-05 | 1.21 | 38.8K | 02:37:22 |  89.5%\n",
            "44770 | 4.2464 | 1.5e-05 | 1.25 | 38.8K | 02:37:23 |  89.5%\n",
            "44780 | 4.0268 | 1.4e-05 | 1.20 | 38.8K | 02:37:25 |  89.6%\n",
            "44790 | 3.8857 | 1.4e-05 | 1.19 | 38.8K | 02:37:27 |  89.6%\n",
            "44800 | 4.1645 | 1.4e-05 | 1.20 | 38.8K | 02:37:28 |  89.6%\n",
            "44810 | 4.1437 | 1.4e-05 | 1.21 | 38.8K | 02:37:30 |  89.6%\n",
            "44820 | 4.0811 | 1.4e-05 | 1.17 | 38.8K | 02:37:32 |  89.6%\n",
            "44830 | 4.3421 | 1.4e-05 | 1.21 | 38.8K | 02:37:34 |  89.7%\n",
            "44840 | 4.2050 | 1.4e-05 | 1.21 | 38.8K | 02:37:35 |  89.7%\n",
            "44850 | 4.3611 | 1.4e-05 | 1.23 | 38.8K | 02:37:37 |  89.7%\n",
            "44860 | 4.0268 | 1.4e-05 | 1.19 | 38.9K | 02:37:39 |  89.7%\n",
            "44870 | 4.0827 | 1.4e-05 | 1.27 | 38.9K | 02:37:40 |  89.7%\n",
            "44880 | 4.1304 | 1.4e-05 | 1.22 | 38.9K | 02:37:42 |  89.8%\n",
            "44890 | 4.4083 | 1.4e-05 | 1.23 | 38.9K | 02:37:44 |  89.8%\n",
            "44900 | 3.9998 | 1.4e-05 | 1.24 | 38.9K | 02:37:46 |  89.8%\n",
            "44910 | 4.0504 | 1.4e-05 | 1.21 | 38.9K | 02:37:47 |  89.8%\n",
            "44920 | 4.1804 | 1.4e-05 | 1.22 | 38.9K | 02:37:49 |  89.8%\n",
            "44930 | 4.0684 | 1.4e-05 | 1.22 | 38.9K | 02:37:51 |  89.9%\n",
            "44940 | 4.1822 | 1.4e-05 | 1.24 | 38.9K | 02:37:52 |  89.9%\n",
            "44950 | 4.2793 | 1.4e-05 | 1.17 | 38.9K | 02:37:54 |  89.9%\n",
            "44960 | 4.2592 | 1.3e-05 | 1.23 | 38.9K | 02:37:56 |  89.9%\n",
            "44970 | 4.2508 | 1.3e-05 | 1.21 | 38.9K | 02:37:58 |  89.9%\n",
            "44980 | 4.1779 | 1.3e-05 | 1.20 | 38.9K | 02:37:59 |  90.0%\n",
            "44990 | 4.2457 | 1.3e-05 | 1.19 | 38.9K | 02:38:01 |  90.0%\n",
            "45000 | 4.2479 | 1.3e-05 | 1.22 | 38.9K | 02:38:03 |  90.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 45000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.0716\n",
            "  Perplexity: 58.65\n",
            "  Train loss (avg): 4.1761\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        ların soğumasıyla beraber bazı hava şartları da değişerek yerini de bıraktı. Hava şartlarının meydana geldiği yer de “zehirli” hava da diyebiliriz. Hava şartları da oldukça uygun. Hava şartları da elverişli\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Ankara'da Türk Telekom'un aboneleri, kendi ülkelerinde iken, Türk Telekom, uluslararası alanda 3 yıl görev yapmış Türk Telekom ile sözleşme imzaladı. Yeni anlaşma ile Türk Telekom'un abonelerine mevcut fatura\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , insan biyolojisi ve doğanın ihtiyaç duyduğu dejenerasyona bağlı olarak, ‘kara delikler’ olarak adlandırılan, milyonlarca yıl önce tamamlandığında, vücudun canlılığını ve dokusunu alıp bu konudaki en\n",
            "\n",
            "  🏆 Yeni en iyi model! (loss: 4.0716)\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:17:35\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "💾 Checkpoint kaydediliyor: /content/drive/MyDrive/turkish_llm/checkpoints//checkpoint_step_45000.pt\n",
            "  ✅ Checkpoint kaydedildi!\n",
            "\n",
            "45010 | 4.2918 | 1.3e-05 | 1.19 | 38.8K | 02:38:28 |  90.0%\n",
            "45020 | 4.3647 | 1.3e-05 | 1.22 | 38.8K | 02:38:30 |  90.0%\n",
            "45030 | 4.2132 | 1.3e-05 | 1.22 | 38.8K | 02:38:32 |  90.1%\n",
            "45040 | 4.4248 | 1.3e-05 | 1.22 | 38.8K | 02:38:34 |  90.1%\n",
            "45050 | 4.2824 | 1.3e-05 | 1.18 | 38.8K | 02:38:35 |  90.1%\n",
            "45060 | 4.1765 | 1.3e-05 | 1.19 | 38.8K | 02:38:37 |  90.1%\n",
            "45070 | 4.1361 | 1.3e-05 | 1.19 | 38.8K | 02:38:39 |  90.1%\n",
            "45080 | 4.2895 | 1.3e-05 | 1.22 | 38.8K | 02:38:40 |  90.2%\n",
            "45090 | 4.0855 | 1.3e-05 | 1.18 | 38.8K | 02:38:42 |  90.2%\n",
            "45100 | 4.2344 | 1.3e-05 | 1.19 | 38.8K | 02:38:44 |  90.2%\n",
            "45110 | 4.1776 | 1.3e-05 | 1.22 | 38.8K | 02:38:46 |  90.2%\n",
            "45120 | 4.0848 | 1.3e-05 | 1.18 | 38.8K | 02:38:47 |  90.2%\n",
            "45130 | 4.1196 | 1.3e-05 | 1.19 | 38.8K | 02:38:49 |  90.3%\n",
            "45140 | 4.3721 | 1.3e-05 | 1.20 | 38.8K | 02:38:51 |  90.3%\n",
            "45150 | 4.1850 | 1.2e-05 | 1.25 | 38.8K | 02:38:52 |  90.3%\n",
            "45160 | 4.1827 | 1.2e-05 | 1.22 | 38.8K | 02:38:54 |  90.3%\n",
            "45170 | 4.1391 | 1.2e-05 | 1.30 | 38.8K | 02:38:56 |  90.3%\n",
            "45180 | 4.2133 | 1.2e-05 | 1.19 | 38.8K | 02:38:58 |  90.4%\n",
            "45190 | 4.1193 | 1.2e-05 | 1.20 | 38.8K | 02:38:59 |  90.4%\n",
            "45200 | 4.1712 | 1.2e-05 | 1.23 | 38.8K | 02:39:01 |  90.4%\n",
            "45210 | 4.2496 | 1.2e-05 | 1.21 | 38.8K | 02:39:03 |  90.4%\n",
            "45220 | 4.4418 | 1.2e-05 | 1.20 | 38.8K | 02:39:04 |  90.4%\n",
            "45230 | 3.9243 | 1.2e-05 | 1.23 | 38.8K | 02:39:06 |  90.5%\n",
            "45240 | 4.0449 | 1.2e-05 | 1.23 | 38.8K | 02:39:08 |  90.5%\n",
            "45250 | 4.3864 | 1.2e-05 | 1.20 | 38.8K | 02:39:10 |  90.5%\n",
            "45260 | 4.2003 | 1.2e-05 | 1.22 | 38.8K | 02:39:11 |  90.5%\n",
            "45270 | 4.1052 | 1.2e-05 | 1.19 | 38.8K | 02:39:13 |  90.5%\n",
            "45280 | 4.1124 | 1.2e-05 | 1.18 | 38.8K | 02:39:15 |  90.6%\n",
            "45290 | 4.2958 | 1.2e-05 | 1.23 | 38.8K | 02:39:16 |  90.6%\n",
            "45300 | 4.1553 | 1.2e-05 | 1.18 | 38.8K | 02:39:18 |  90.6%\n",
            "45310 | 4.2233 | 1.2e-05 | 1.19 | 38.8K | 02:39:20 |  90.6%\n",
            "45320 | 4.2672 | 1.2e-05 | 1.22 | 38.8K | 02:39:22 |  90.6%\n",
            "45330 | 4.1862 | 1.2e-05 | 1.24 | 38.8K | 02:39:23 |  90.7%\n",
            "45340 | 4.1017 | 1.2e-05 | 1.23 | 38.8K | 02:39:25 |  90.7%\n",
            "45350 | 3.7544 | 1.1e-05 | 1.22 | 38.8K | 02:39:27 |  90.7%\n",
            "45360 | 3.8041 | 1.1e-05 | 1.25 | 38.8K | 02:39:28 |  90.7%\n",
            "45370 | 4.3059 | 1.1e-05 | 1.21 | 38.8K | 02:39:30 |  90.7%\n",
            "45380 | 4.2880 | 1.1e-05 | 1.19 | 38.8K | 02:39:32 |  90.8%\n",
            "45390 | 4.2507 | 1.1e-05 | 1.23 | 38.8K | 02:39:34 |  90.8%\n",
            "45400 | 4.5418 | 1.1e-05 | 1.20 | 38.8K | 02:39:35 |  90.8%\n",
            "45410 | 4.3438 | 1.1e-05 | 1.21 | 38.8K | 02:39:37 |  90.8%\n",
            "45420 | 4.3408 | 1.1e-05 | 1.24 | 38.8K | 02:39:39 |  90.8%\n",
            "45430 | 4.0955 | 1.1e-05 | 1.18 | 38.8K | 02:39:40 |  90.9%\n",
            "45440 | 4.1164 | 1.1e-05 | 1.21 | 38.8K | 02:39:42 |  90.9%\n",
            "45450 | 4.2795 | 1.1e-05 | 1.22 | 38.8K | 02:39:44 |  90.9%\n",
            "45460 | 4.1567 | 1.1e-05 | 1.20 | 38.8K | 02:39:46 |  90.9%\n",
            "45470 | 4.2348 | 1.1e-05 | 1.21 | 38.9K | 02:39:47 |  90.9%\n",
            "45480 | 4.0809 | 1.1e-05 | 1.19 | 38.9K | 02:39:49 |  91.0%\n",
            "45490 | 4.3230 | 1.1e-05 | 1.21 | 38.9K | 02:39:51 |  91.0%\n",
            "45500 | 4.0940 | 1.1e-05 | 1.21 | 38.9K | 02:39:52 |  91.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 45500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.0948\n",
            "  Perplexity: 60.03\n",
            "  Train loss (avg): 4.1499\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        durumu iyi, hava sıcaklığı iyi, yağmurda yağan yağmur nedeniyle çok sıcak. Çünkü bir çok sebebi var. Her sene yağmur yağıyor. Aldığımızdan beri hava çok soğuk. Hava bu sıcaklardan\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Ankara'da bulunan ve son bir yıl içerisinde yaşanan trafik kazaları ve kazaların azaldığı bildirildi. Peki, Ankara'da bu kazalar ne oldu? Ankara'da son bir yıl içerisinde yaşanan trafik\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , ‘en eski çağlardan günümüze, ‘en eski çağlardan günümüze’ ve ‘en eski çağlardan bugüne’ kadar pek çok alanında başarılı olmuş ve birçok alanda başarılı çalışmalara imza atmış oldu. Bu sayede\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:15:50\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "45510 | 3.9215 | 1.1e-05 | 1.20 | 38.8K | 02:40:11 |  91.0%\n",
            "45520 | 4.3178 | 1.1e-05 | 1.22 | 38.8K | 02:40:13 |  91.0%\n",
            "45530 | 3.9412 | 1.1e-05 | 1.24 | 38.8K | 02:40:15 |  91.1%\n",
            "45540 | 4.4666 | 1.1e-05 | 1.22 | 38.8K | 02:40:16 |  91.1%\n",
            "45550 | 4.2990 | 1.1e-05 | 1.22 | 38.8K | 02:40:18 |  91.1%\n",
            "45560 | 4.4814 | 1.0e-05 | 1.19 | 38.8K | 02:40:20 |  91.1%\n",
            "45570 | 4.3763 | 1.0e-05 | 1.26 | 38.8K | 02:40:22 |  91.1%\n",
            "45580 | 4.0745 | 1.0e-05 | 1.20 | 38.8K | 02:40:23 |  91.2%\n",
            "45590 | 4.1927 | 1.0e-05 | 1.20 | 38.8K | 02:40:25 |  91.2%\n",
            "45600 | 3.7567 | 1.0e-05 | 1.23 | 38.8K | 02:40:27 |  91.2%\n",
            "45610 | 4.1508 | 1.0e-05 | 1.27 | 38.8K | 02:40:28 |  91.2%\n",
            "45620 | 4.3240 | 1.0e-05 | 1.19 | 38.8K | 02:40:30 |  91.2%\n",
            "45630 | 4.0608 | 1.0e-05 | 1.16 | 38.8K | 02:40:32 |  91.3%\n",
            "45640 | 3.8864 | 1.0e-05 | 1.18 | 38.8K | 02:40:34 |  91.3%\n",
            "45650 | 3.8461 | 1.0e-05 | 1.23 | 38.8K | 02:40:35 |  91.3%\n",
            "45660 | 4.2480 | 1.0e-05 | 1.25 | 38.8K | 02:40:37 |  91.3%\n",
            "45670 | 4.0763 | 1.0e-05 | 1.22 | 38.8K | 02:40:39 |  91.3%\n",
            "45680 | 3.8663 | 9.9e-06 | 1.14 | 38.8K | 02:40:40 |  91.4%\n",
            "45690 | 4.1671 | 9.9e-06 | 1.25 | 38.8K | 02:40:42 |  91.4%\n",
            "45700 | 4.3292 | 9.8e-06 | 1.25 | 38.8K | 02:40:44 |  91.4%\n",
            "45710 | 3.9962 | 9.8e-06 | 1.35 | 38.8K | 02:40:46 |  91.4%\n",
            "45720 | 3.9458 | 9.7e-06 | 1.16 | 38.8K | 02:40:47 |  91.4%\n",
            "45730 | 4.2774 | 9.7e-06 | 1.18 | 38.8K | 02:40:49 |  91.5%\n",
            "45740 | 4.1991 | 9.7e-06 | 1.19 | 38.8K | 02:40:51 |  91.5%\n",
            "45750 | 4.0072 | 9.6e-06 | 1.23 | 38.8K | 02:40:52 |  91.5%\n",
            "45760 | 4.3779 | 9.6e-06 | 1.18 | 38.8K | 02:40:54 |  91.5%\n",
            "45770 | 4.0997 | 9.5e-06 | 1.20 | 38.8K | 02:40:56 |  91.5%\n",
            "45780 | 4.1479 | 9.5e-06 | 1.26 | 38.8K | 02:40:58 |  91.6%\n",
            "45790 | 4.0159 | 9.4e-06 | 1.17 | 38.8K | 02:40:59 |  91.6%\n",
            "45800 | 4.3203 | 9.4e-06 | 1.23 | 38.8K | 02:41:01 |  91.6%\n",
            "45810 | 4.1883 | 9.3e-06 | 1.24 | 38.8K | 02:41:03 |  91.6%\n",
            "45820 | 4.1974 | 9.3e-06 | 1.23 | 38.8K | 02:41:04 |  91.6%\n",
            "45830 | 4.2326 | 9.3e-06 | 1.22 | 38.8K | 02:41:06 |  91.7%\n",
            "45840 | 4.3379 | 9.2e-06 | 1.20 | 38.8K | 02:41:08 |  91.7%\n",
            "45850 | 4.2132 | 9.2e-06 | 1.24 | 38.8K | 02:41:10 |  91.7%\n",
            "45860 | 4.1583 | 9.1e-06 | 1.18 | 38.8K | 02:41:11 |  91.7%\n",
            "45870 | 4.3316 | 9.1e-06 | 1.22 | 38.8K | 02:41:13 |  91.7%\n",
            "45880 | 4.0324 | 9.0e-06 | 1.26 | 38.8K | 02:41:15 |  91.8%\n",
            "45890 | 3.9408 | 9.0e-06 | 1.21 | 38.8K | 02:41:16 |  91.8%\n",
            "45900 | 4.2721 | 9.0e-06 | 1.20 | 38.8K | 02:41:18 |  91.8%\n",
            "45910 | 3.8788 | 8.9e-06 | 1.17 | 38.9K | 02:41:20 |  91.8%\n",
            "45920 | 4.0901 | 8.9e-06 | 1.19 | 38.9K | 02:41:22 |  91.8%\n",
            "45930 | 4.1287 | 8.8e-06 | 1.23 | 38.9K | 02:41:23 |  91.9%\n",
            "45940 | 4.1252 | 8.8e-06 | 1.21 | 38.9K | 02:41:25 |  91.9%\n",
            "45950 | 3.6348 | 8.7e-06 | 1.15 | 38.9K | 02:41:27 |  91.9%\n",
            "45960 | 4.1135 | 8.7e-06 | 1.24 | 38.9K | 02:41:28 |  91.9%\n",
            "45970 | 4.1770 | 8.7e-06 | 1.24 | 38.9K | 02:41:30 |  91.9%\n",
            "45980 | 4.2344 | 8.6e-06 | 1.24 | 38.9K | 02:41:32 |  92.0%\n",
            "45990 | 4.0547 | 8.6e-06 | 1.23 | 38.9K | 02:41:34 |  92.0%\n",
            "46000 | 4.2790 | 8.5e-06 | 1.20 | 38.9K | 02:41:35 |  92.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 46000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.0947\n",
            "  Perplexity: 60.02\n",
            "  Train loss (avg): 4.1399\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        , bu güzel, İstanbul'da kar yağışı başlıyor. İstanbul'da kar yağışı başlıyor. Meteoroloji'den de bir açıklama yapıldı. Meteoroloji'den yapılan açıklamada, İstanbul'un bugün yağmura hazır olarak\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Ankara'da yapılan ve önümüzdeki aylarda da devam edecek olan 'İstanbul'daki 10 Atatürk Havalimanı'nda, 'Business Türkiye'nin 'Business Türkiye'si' olarak adlandırılan projede,\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , artık her şeyin ve her şeyin çift yönlü, birbirine yakın, daha uzak, daha iyi, daha verimli, daha derin ve daha derin anlamlara ulaşabileceğini gösteren bir teknolojidir. Bu teknolojiler, hem\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.74\n",
            "     ETA: 00:14:04\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "46010 | 4.3403 | 8.5e-06 | 1.28 | 38.8K | 02:41:54 |  92.0%\n",
            "46020 | 4.4776 | 8.4e-06 | 1.20 | 38.8K | 02:41:56 |  92.0%\n",
            "46030 | 4.4143 | 8.4e-06 | 1.21 | 38.8K | 02:41:58 |  92.1%\n",
            "46040 | 4.0260 | 8.4e-06 | 1.18 | 38.8K | 02:41:59 |  92.1%\n",
            "46050 | 4.3914 | 8.3e-06 | 1.23 | 38.8K | 02:42:01 |  92.1%\n",
            "46060 | 4.3641 | 8.3e-06 | 1.22 | 38.8K | 02:42:03 |  92.1%\n",
            "46070 | 4.1609 | 8.2e-06 | 1.22 | 38.8K | 02:42:04 |  92.1%\n",
            "46080 | 4.1695 | 8.2e-06 | 1.24 | 38.8K | 02:42:06 |  92.2%\n",
            "46090 | 4.2859 | 8.1e-06 | 1.20 | 38.8K | 02:42:08 |  92.2%\n",
            "46100 | 4.3326 | 8.1e-06 | 1.21 | 38.8K | 02:42:10 |  92.2%\n",
            "46110 | 4.0795 | 8.1e-06 | 1.16 | 38.8K | 02:42:11 |  92.2%\n",
            "46120 | 4.1409 | 8.0e-06 | 1.18 | 38.8K | 02:42:13 |  92.2%\n",
            "46130 | 4.2704 | 8.0e-06 | 1.18 | 38.8K | 02:42:15 |  92.3%\n",
            "46140 | 4.1154 | 7.9e-06 | 1.27 | 38.8K | 02:42:16 |  92.3%\n",
            "46150 | 4.0944 | 7.9e-06 | 1.21 | 38.8K | 02:42:18 |  92.3%\n",
            "46160 | 4.2574 | 7.9e-06 | 1.20 | 38.8K | 02:42:20 |  92.3%\n",
            "46170 | 4.3424 | 7.8e-06 | 1.21 | 38.8K | 02:42:22 |  92.3%\n",
            "46180 | 3.7793 | 7.8e-06 | 1.21 | 38.8K | 02:42:23 |  92.4%\n",
            "46190 | 3.9397 | 7.7e-06 | 1.29 | 38.8K | 02:42:25 |  92.4%\n",
            "46200 | 3.9969 | 7.7e-06 | 1.19 | 38.8K | 02:42:27 |  92.4%\n",
            "46210 | 4.4167 | 7.7e-06 | 1.19 | 38.8K | 02:42:28 |  92.4%\n",
            "46220 | 4.0981 | 7.6e-06 | 1.21 | 38.8K | 02:42:30 |  92.4%\n",
            "46230 | 4.2491 | 7.6e-06 | 1.22 | 38.8K | 02:42:32 |  92.5%\n",
            "46240 | 4.4551 | 7.5e-06 | 1.22 | 38.8K | 02:42:34 |  92.5%\n",
            "46250 | 4.2943 | 7.5e-06 | 1.18 | 38.8K | 02:42:35 |  92.5%\n",
            "46260 | 4.2255 | 7.5e-06 | 1.18 | 38.8K | 02:42:37 |  92.5%\n",
            "46270 | 4.4722 | 7.4e-06 | 1.22 | 38.8K | 02:42:39 |  92.5%\n",
            "46280 | 4.2369 | 7.4e-06 | 1.19 | 38.8K | 02:42:40 |  92.6%\n",
            "46290 | 4.1748 | 7.3e-06 | 1.19 | 38.8K | 02:42:42 |  92.6%\n",
            "46300 | 4.2500 | 7.3e-06 | 1.22 | 38.8K | 02:42:44 |  92.6%\n",
            "46310 | 4.2086 | 7.3e-06 | 1.20 | 38.8K | 02:42:46 |  92.6%\n",
            "46320 | 4.1326 | 7.2e-06 | 1.18 | 38.8K | 02:42:47 |  92.6%\n",
            "46330 | 4.2255 | 7.2e-06 | 1.21 | 38.8K | 02:42:49 |  92.7%\n",
            "46340 | 3.8852 | 7.1e-06 | 1.28 | 38.9K | 02:42:51 |  92.7%\n",
            "46350 | 4.1285 | 7.1e-06 | 1.22 | 38.9K | 02:42:52 |  92.7%\n",
            "46360 | 3.6212 | 7.1e-06 | 1.25 | 38.9K | 02:42:54 |  92.7%\n",
            "46370 | 4.1530 | 7.0e-06 | 1.17 | 38.9K | 02:42:56 |  92.7%\n",
            "46380 | 4.3487 | 7.0e-06 | 1.20 | 38.9K | 02:42:58 |  92.8%\n",
            "46390 | 4.2579 | 6.9e-06 | 1.19 | 38.9K | 02:42:59 |  92.8%\n",
            "46400 | 4.2876 | 6.9e-06 | 1.28 | 38.9K | 02:43:01 |  92.8%\n",
            "46410 | 3.9488 | 6.9e-06 | 1.23 | 38.9K | 02:43:03 |  92.8%\n",
            "46420 | 4.1086 | 6.8e-06 | 1.17 | 38.9K | 02:43:04 |  92.8%\n",
            "46430 | 4.3417 | 6.8e-06 | 1.22 | 38.9K | 02:43:06 |  92.9%\n",
            "46440 | 3.9601 | 6.8e-06 | 1.22 | 38.9K | 02:43:08 |  92.9%\n",
            "46450 | 4.2639 | 6.7e-06 | 1.21 | 38.9K | 02:43:09 |  92.9%\n",
            "46460 | 4.0344 | 6.7e-06 | 1.21 | 38.9K | 02:43:11 |  92.9%\n",
            "46470 | 4.0082 | 6.6e-06 | 1.19 | 38.9K | 02:43:13 |  92.9%\n",
            "46480 | 4.4063 | 6.6e-06 | 1.20 | 38.9K | 02:43:15 |  93.0%\n",
            "46490 | 3.9415 | 6.6e-06 | 1.34 | 38.9K | 02:43:16 |  93.0%\n",
            "46500 | 4.1694 | 6.5e-06 | 1.22 | 38.9K | 02:43:18 |  93.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 46500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1271\n",
            "  Perplexity: 62.00\n",
            "  Train loss (avg): 4.1506\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        ların ısınması, hızlı bir şekilde yayılacak. Havaların ısınması ile birlikte hava, her yerden daha sıcak oluyor. Hava, daha kısa süre içinde etkili oluyor. Hava kirliliği, sel ve su kaynaklı\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Ankara'da Türk Kızılayı İstanbul Şubesi tarafından düzenlenen silahlı saldırı sonucu, birkaç kişi yaralanmıştı. Olay yerine gelen polis, polis ve ambulanslarla Ankara'daki binalara sıçradı. Saldırıya ilişkin\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        sayesinde, sizin, sizin ve sevdiklerinizin ve size zarar vermeme ya da zarar verme ihtimali olabilir. Size uygun olmayan bir şey bulmanızı gerektirebilir. Eğer sizin gibi bir güvensizlik yaşamamışsanız,\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.74\n",
            "     ETA: 00:12:18\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "46510 | 4.1519 | 6.5e-06 | 1.17 | 38.8K | 02:43:37 |  93.0%\n",
            "46520 | 4.1520 | 6.5e-06 | 1.20 | 38.8K | 02:43:39 |  93.0%\n",
            "46530 | 4.1441 | 6.4e-06 | 1.21 | 38.8K | 02:43:41 |  93.1%\n",
            "46540 | 4.0427 | 6.4e-06 | 1.22 | 38.8K | 02:43:42 |  93.1%\n",
            "46550 | 4.1157 | 6.3e-06 | 1.20 | 38.8K | 02:43:44 |  93.1%\n",
            "46560 | 3.6736 | 6.3e-06 | 1.17 | 38.8K | 02:43:46 |  93.1%\n",
            "46570 | 4.3232 | 6.3e-06 | 1.19 | 38.8K | 02:43:47 |  93.1%\n",
            "46580 | 4.5638 | 6.2e-06 | 1.23 | 38.8K | 02:43:49 |  93.2%\n",
            "46590 | 4.3502 | 6.2e-06 | 1.21 | 38.8K | 02:43:51 |  93.2%\n",
            "46600 | 4.1299 | 6.2e-06 | 1.23 | 38.8K | 02:43:53 |  93.2%\n",
            "46610 | 3.8666 | 6.1e-06 | 1.15 | 38.8K | 02:43:54 |  93.2%\n",
            "46620 | 3.6479 | 6.1e-06 | 1.15 | 38.8K | 02:43:56 |  93.2%\n",
            "46630 | 4.1520 | 6.1e-06 | 1.17 | 38.8K | 02:43:58 |  93.3%\n",
            "46640 | 4.1163 | 6.0e-06 | 1.23 | 38.8K | 02:43:59 |  93.3%\n",
            "46650 | 4.0819 | 6.0e-06 | 1.17 | 38.8K | 02:44:01 |  93.3%\n",
            "46660 | 4.2435 | 6.0e-06 | 1.18 | 38.8K | 02:44:03 |  93.3%\n",
            "46670 | 4.2434 | 5.9e-06 | 1.20 | 38.8K | 02:44:05 |  93.3%\n",
            "46680 | 4.2185 | 5.9e-06 | 1.29 | 38.8K | 02:44:06 |  93.4%\n",
            "46690 | 4.2713 | 5.8e-06 | 1.22 | 38.8K | 02:44:08 |  93.4%\n",
            "46700 | 4.1233 | 5.8e-06 | 1.22 | 38.8K | 02:44:10 |  93.4%\n",
            "46710 | 4.2137 | 5.8e-06 | 1.26 | 38.8K | 02:44:11 |  93.4%\n",
            "46720 | 3.7246 | 5.7e-06 | 1.20 | 38.8K | 02:44:13 |  93.4%\n",
            "46730 | 3.9932 | 5.7e-06 | 1.25 | 38.8K | 02:44:15 |  93.5%\n",
            "46740 | 3.8375 | 5.7e-06 | 1.20 | 38.8K | 02:44:17 |  93.5%\n",
            "46750 | 4.2139 | 5.6e-06 | 1.18 | 38.8K | 02:44:18 |  93.5%\n",
            "46760 | 4.3063 | 5.6e-06 | 1.20 | 38.8K | 02:44:20 |  93.5%\n",
            "46770 | 4.2209 | 5.6e-06 | 1.20 | 38.8K | 02:44:22 |  93.5%\n",
            "46780 | 4.4591 | 5.5e-06 | 1.22 | 38.9K | 02:44:23 |  93.6%\n",
            "46790 | 4.3761 | 5.5e-06 | 1.19 | 38.9K | 02:44:25 |  93.6%\n",
            "46800 | 4.2761 | 5.5e-06 | 1.20 | 38.9K | 02:44:27 |  93.6%\n",
            "46810 | 4.0875 | 5.4e-06 | 1.20 | 38.9K | 02:44:28 |  93.6%\n",
            "46820 | 4.1365 | 5.4e-06 | 1.21 | 38.9K | 02:44:30 |  93.6%\n",
            "46830 | 4.6056 | 5.4e-06 | 1.28 | 38.9K | 02:44:32 |  93.7%\n",
            "46840 | 3.8467 | 5.3e-06 | 1.19 | 38.9K | 02:44:34 |  93.7%\n",
            "46850 | 4.1583 | 5.3e-06 | 1.19 | 38.9K | 02:44:35 |  93.7%\n",
            "46860 | 4.1804 | 5.3e-06 | 1.18 | 38.9K | 02:44:37 |  93.7%\n",
            "46870 | 4.1807 | 5.2e-06 | 1.17 | 38.9K | 02:44:39 |  93.7%\n",
            "46880 | 4.0441 | 5.2e-06 | 1.19 | 38.9K | 02:44:40 |  93.8%\n",
            "46890 | 4.1034 | 5.2e-06 | 1.20 | 38.9K | 02:44:42 |  93.8%\n",
            "46900 | 4.0755 | 5.1e-06 | 1.25 | 38.9K | 02:44:44 |  93.8%\n",
            "46910 | 4.1637 | 5.1e-06 | 1.23 | 38.9K | 02:44:46 |  93.8%\n",
            "46920 | 4.1417 | 5.1e-06 | 1.19 | 38.9K | 02:44:47 |  93.8%\n",
            "46930 | 4.2121 | 5.0e-06 | 1.18 | 38.9K | 02:44:49 |  93.9%\n",
            "46940 | 4.2549 | 5.0e-06 | 1.20 | 38.9K | 02:44:51 |  93.9%\n",
            "46950 | 4.3328 | 5.0e-06 | 1.25 | 38.9K | 02:44:52 |  93.9%\n",
            "46960 | 4.1231 | 4.9e-06 | 1.34 | 38.9K | 02:44:54 |  93.9%\n",
            "46970 | 4.1686 | 4.9e-06 | 1.28 | 38.9K | 02:44:56 |  93.9%\n",
            "46980 | 4.2711 | 4.9e-06 | 1.18 | 38.9K | 02:44:58 |  94.0%\n",
            "46990 | 4.2573 | 4.8e-06 | 1.21 | 38.9K | 02:44:59 |  94.0%\n",
            "47000 | 4.3973 | 4.8e-06 | 1.23 | 38.9K | 02:45:01 |  94.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 47000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1013\n",
            "  Perplexity: 60.42\n",
            "  Train loss (avg): 4.1633\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        durumu tahminleri, hava durumu tahminleri, web site haritaları, forumlar ve bloglar da dahil olmak üzere pek çok farklı özellikte başka pek çok bilgi ve ayrıntıyı bulabileceğiniz bir çok site.\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        İstanbul'un fethinin 2. yılında Büyük Önder Mustafa Kemal Atatürk'ün ve büyükannesinin vefatının ardından bugünlerin bir benzeri yaşanıyor. İstanbul'un fethinin 3. yılında Büyük Önder Mustafa Kemal Atatürk'\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , yüksek seviyede bilme ve gelişmiş performans, yüksek hız ve yüksek hız için temel olarak ortaya çıktı. En önemli nokta, makine öğrenmesi ve daha büyük bir zeka performansı. Amacının, makine öğrenmesi\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.74\n",
            "     ETA: 00:10:33\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "47010 | 4.2270 | 4.8e-06 | 1.23 | 38.8K | 02:45:20 |  94.0%\n",
            "47020 | 4.4684 | 4.7e-06 | 1.23 | 38.8K | 02:45:22 |  94.0%\n",
            "47030 | 4.0997 | 4.7e-06 | 1.17 | 38.8K | 02:45:23 |  94.1%\n",
            "47040 | 4.1953 | 4.7e-06 | 1.17 | 38.8K | 02:45:25 |  94.1%\n",
            "47050 | 4.0799 | 4.6e-06 | 1.16 | 38.8K | 02:45:27 |  94.1%\n",
            "47060 | 4.3364 | 4.6e-06 | 1.24 | 38.8K | 02:45:29 |  94.1%\n",
            "47070 | 4.0594 | 4.6e-06 | 1.23 | 38.8K | 02:45:30 |  94.1%\n",
            "47080 | 4.1042 | 4.6e-06 | 1.21 | 38.8K | 02:45:32 |  94.2%\n",
            "47090 | 4.1982 | 4.5e-06 | 1.23 | 38.8K | 02:45:34 |  94.2%\n",
            "47100 | 4.2691 | 4.5e-06 | 1.20 | 38.8K | 02:45:35 |  94.2%\n",
            "47110 | 4.4474 | 4.5e-06 | 1.19 | 38.8K | 02:45:37 |  94.2%\n",
            "47120 | 4.2439 | 4.4e-06 | 1.19 | 38.8K | 02:45:39 |  94.2%\n",
            "47130 | 4.1236 | 4.4e-06 | 1.24 | 38.8K | 02:45:41 |  94.3%\n",
            "47140 | 4.1522 | 4.4e-06 | 1.21 | 38.8K | 02:45:42 |  94.3%\n",
            "47150 | 4.4436 | 4.3e-06 | 1.19 | 38.8K | 02:45:44 |  94.3%\n",
            "47160 | 4.3527 | 4.3e-06 | 1.29 | 38.8K | 02:45:46 |  94.3%\n",
            "47170 | 4.2817 | 4.3e-06 | 1.23 | 38.8K | 02:45:47 |  94.3%\n",
            "47180 | 4.2288 | 4.2e-06 | 1.19 | 38.8K | 02:45:49 |  94.4%\n",
            "47190 | 4.1918 | 4.2e-06 | 1.18 | 38.8K | 02:45:51 |  94.4%\n",
            "47200 | 4.0847 | 4.2e-06 | 1.21 | 38.8K | 02:45:53 |  94.4%\n",
            "47210 | 4.2226 | 4.2e-06 | 1.20 | 38.9K | 02:45:54 |  94.4%\n",
            "47220 | 4.3014 | 4.1e-06 | 1.23 | 38.9K | 02:45:56 |  94.4%\n",
            "47230 | 4.1387 | 4.1e-06 | 1.20 | 38.9K | 02:45:58 |  94.5%\n",
            "47240 | 3.9952 | 4.1e-06 | 1.24 | 38.9K | 02:45:59 |  94.5%\n",
            "47250 | 4.3487 | 4.0e-06 | 1.22 | 38.9K | 02:46:01 |  94.5%\n",
            "47260 | 4.3002 | 4.0e-06 | 1.20 | 38.9K | 02:46:03 |  94.5%\n",
            "47270 | 4.0154 | 4.0e-06 | 1.24 | 38.9K | 02:46:04 |  94.5%\n",
            "47280 | 4.2044 | 4.0e-06 | 1.19 | 38.9K | 02:46:06 |  94.6%\n",
            "47290 | 4.1479 | 3.9e-06 | 1.24 | 38.9K | 02:46:08 |  94.6%\n",
            "47300 | 4.0657 | 3.9e-06 | 1.19 | 38.9K | 02:46:10 |  94.6%\n",
            "47310 | 3.9598 | 3.9e-06 | 1.17 | 38.9K | 02:46:11 |  94.6%\n",
            "47320 | 4.1810 | 3.8e-06 | 1.19 | 38.9K | 02:46:13 |  94.6%\n",
            "47330 | 4.1452 | 3.8e-06 | 1.20 | 38.9K | 02:46:15 |  94.7%\n",
            "47340 | 4.3796 | 3.8e-06 | 1.22 | 38.9K | 02:46:16 |  94.7%\n",
            "47350 | 4.2443 | 3.8e-06 | 1.21 | 38.9K | 02:46:18 |  94.7%\n",
            "47360 | 4.2885 | 3.7e-06 | 1.26 | 38.9K | 02:46:20 |  94.7%\n",
            "47370 | 4.2965 | 3.7e-06 | 1.20 | 38.9K | 02:46:22 |  94.7%\n",
            "47380 | 4.1107 | 3.7e-06 | 1.22 | 38.9K | 02:46:23 |  94.8%\n",
            "47390 | 4.4312 | 3.6e-06 | 1.23 | 38.9K | 02:46:25 |  94.8%\n",
            "47400 | 4.2187 | 3.6e-06 | 1.19 | 38.9K | 02:46:27 |  94.8%\n",
            "47410 | 3.8910 | 3.6e-06 | 1.27 | 38.9K | 02:46:28 |  94.8%\n",
            "47420 | 4.0638 | 3.6e-06 | 1.17 | 38.9K | 02:46:30 |  94.8%\n",
            "47430 | 4.0842 | 3.5e-06 | 1.21 | 38.9K | 02:46:32 |  94.9%\n",
            "47440 | 3.9295 | 3.5e-06 | 1.21 | 38.9K | 02:46:34 |  94.9%\n",
            "47450 | 4.1846 | 3.5e-06 | 1.19 | 38.9K | 02:46:35 |  94.9%\n",
            "47460 | 4.3166 | 3.4e-06 | 1.21 | 38.9K | 02:46:37 |  94.9%\n",
            "47470 | 4.2741 | 3.4e-06 | 1.19 | 38.9K | 02:46:39 |  94.9%\n",
            "47480 | 4.1701 | 3.4e-06 | 1.19 | 38.9K | 02:46:40 |  95.0%\n",
            "47490 | 4.2346 | 3.4e-06 | 1.18 | 38.9K | 02:46:42 |  95.0%\n",
            "47500 | 4.4657 | 3.3e-06 | 1.19 | 38.9K | 02:46:44 |  95.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 47500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1453\n",
            "  Perplexity: 63.14\n",
            "  Train loss (avg): 4.1262\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        durumu nedir? Türkiye’nin güney sınırındaki bu sıcak hava hiç bir zaman Türkiye’nin güney sınırlarında da çok sıcak ve yağışlı bir hava değildir. Ancak bu hava daha fazla sıcak ve yağışlı günlerde daha\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        olan İstanbul'un İstanbul ve Anadolu yakasının en kalabalık şehri olan İstanbul, İstanbul'un en kalabalık şehri konumundadır. İstanbul'un tam bir projesi olan İstanbul, İstanbul'un en kalabalık şehridir\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        sayesinde, her biri aynı anda, 2 dakika boyunca, 5 saniye içerisinde ve 5 dakika içinde, en hızlı şekilde parmaklarınızı, parmaklarınızı ve parmaklarınızı algılayarak, bir veri işleme merkezine doğru yaklaşmaya\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.74\n",
            "     ETA: 00:08:47\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "47510 | 4.1404 | 3.3e-06 | 1.28 | 38.8K | 02:47:03 |  95.0%\n",
            "47520 | 4.2147 | 3.3e-06 | 1.22 | 38.8K | 02:47:05 |  95.0%\n",
            "47530 | 4.1019 | 3.3e-06 | 1.21 | 38.8K | 02:47:06 |  95.1%\n",
            "47540 | 4.1491 | 3.2e-06 | 1.20 | 38.8K | 02:47:08 |  95.1%\n",
            "47550 | 4.1846 | 3.2e-06 | 1.19 | 38.8K | 02:47:10 |  95.1%\n",
            "47560 | 4.0086 | 3.2e-06 | 1.44 | 38.8K | 02:47:11 |  95.1%\n",
            "47570 | 4.1443 | 3.2e-06 | 1.19 | 38.8K | 02:47:13 |  95.1%\n",
            "47580 | 3.9503 | 3.1e-06 | 1.24 | 38.8K | 02:47:15 |  95.2%\n",
            "47590 | 4.4116 | 3.1e-06 | 1.19 | 38.8K | 02:47:17 |  95.2%\n",
            "47600 | 4.3276 | 3.1e-06 | 1.19 | 38.8K | 02:47:18 |  95.2%\n",
            "47610 | 4.2769 | 3.1e-06 | 1.18 | 38.8K | 02:47:20 |  95.2%\n",
            "47620 | 4.1669 | 3.0e-06 | 1.21 | 38.8K | 02:47:22 |  95.2%\n",
            "47630 | 4.0637 | 3.0e-06 | 1.18 | 38.8K | 02:47:23 |  95.3%\n",
            "47640 | 4.2290 | 3.0e-06 | 1.21 | 38.8K | 02:47:25 |  95.3%\n",
            "47650 | 3.8892 | 3.0e-06 | 1.23 | 38.9K | 02:47:27 |  95.3%\n",
            "47660 | 4.1001 | 2.9e-06 | 1.25 | 38.9K | 02:47:28 |  95.3%\n",
            "47670 | 4.1547 | 2.9e-06 | 1.24 | 38.9K | 02:47:30 |  95.3%\n",
            "47680 | 3.8598 | 2.9e-06 | 1.17 | 38.9K | 02:47:32 |  95.4%\n",
            "47690 | 4.5900 | 2.9e-06 | 1.21 | 38.9K | 02:47:34 |  95.4%\n",
            "47700 | 4.1044 | 2.8e-06 | 1.24 | 38.9K | 02:47:35 |  95.4%\n",
            "47710 | 4.1305 | 2.8e-06 | 1.21 | 38.9K | 02:47:37 |  95.4%\n",
            "47720 | 4.1555 | 2.8e-06 | 1.22 | 38.9K | 02:47:39 |  95.4%\n",
            "47730 | 3.7163 | 2.8e-06 | 1.23 | 38.9K | 02:47:40 |  95.5%\n",
            "47740 | 4.2133 | 2.7e-06 | 1.22 | 38.9K | 02:47:42 |  95.5%\n",
            "47750 | 4.2154 | 2.7e-06 | 1.24 | 38.9K | 02:47:44 |  95.5%\n",
            "47760 | 4.0535 | 2.7e-06 | 1.19 | 38.9K | 02:47:46 |  95.5%\n",
            "47770 | 3.8206 | 2.7e-06 | 1.18 | 38.9K | 02:47:47 |  95.5%\n",
            "47780 | 4.2216 | 2.6e-06 | 1.28 | 38.9K | 02:47:49 |  95.6%\n",
            "47790 | 4.2060 | 2.6e-06 | 1.21 | 38.9K | 02:47:51 |  95.6%\n",
            "47800 | 3.9436 | 2.6e-06 | 1.16 | 38.9K | 02:47:52 |  95.6%\n",
            "47810 | 4.4450 | 2.6e-06 | 1.22 | 38.9K | 02:47:54 |  95.6%\n",
            "47820 | 3.9358 | 2.5e-06 | 1.18 | 38.9K | 02:47:56 |  95.6%\n",
            "47830 | 3.9022 | 2.5e-06 | 1.17 | 38.9K | 02:47:58 |  95.7%\n",
            "47840 | 3.9544 | 2.5e-06 | 1.18 | 38.9K | 02:47:59 |  95.7%\n",
            "47850 | 4.3389 | 2.5e-06 | 1.20 | 38.9K | 02:48:01 |  95.7%\n",
            "47860 | 4.2288 | 2.5e-06 | 1.23 | 38.9K | 02:48:03 |  95.7%\n",
            "47870 | 4.3338 | 2.4e-06 | 1.21 | 38.9K | 02:48:04 |  95.7%\n",
            "47880 | 4.4353 | 2.4e-06 | 1.19 | 38.9K | 02:48:06 |  95.8%\n",
            "47890 | 4.1892 | 2.4e-06 | 1.25 | 38.9K | 02:48:08 |  95.8%\n",
            "47900 | 4.2117 | 2.4e-06 | 1.23 | 38.9K | 02:48:10 |  95.8%\n",
            "47910 | 4.2088 | 2.3e-06 | 1.21 | 38.9K | 02:48:11 |  95.8%\n",
            "47920 | 4.1659 | 2.3e-06 | 1.24 | 38.9K | 02:48:13 |  95.8%\n",
            "47930 | 4.2234 | 2.3e-06 | 1.24 | 38.9K | 02:48:15 |  95.9%\n",
            "47940 | 4.1712 | 2.3e-06 | 1.22 | 38.9K | 02:48:16 |  95.9%\n",
            "47950 | 4.0020 | 2.2e-06 | 1.19 | 38.9K | 02:48:18 |  95.9%\n",
            "47960 | 4.5096 | 2.2e-06 | 1.25 | 38.9K | 02:48:20 |  95.9%\n",
            "47970 | 3.9399 | 2.2e-06 | 1.51 | 38.9K | 02:48:22 |  95.9%\n",
            "47980 | 4.0575 | 2.2e-06 | 1.21 | 38.9K | 02:48:23 |  96.0%\n",
            "47990 | 4.2322 | 2.2e-06 | 1.20 | 38.9K | 02:48:25 |  96.0%\n",
            "48000 | 3.7433 | 2.1e-06 | 1.14 | 38.9K | 02:48:27 |  96.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 48000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1047\n",
            "  Perplexity: 60.63\n",
            "  Train loss (avg): 4.1395\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        durumu tahminleri, en düşük saatteki tatil dönemlerinde özellikle yer altı ve gök gürültülü sağanak yağışların bu akşam saatlerinde etkili olmasını sağladı. Bu bölge, yüksek sıcaklıklara sahip ve aşırı sıcaklar nedeniyle sualtı\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Moskova'da düzenlenen 29 Ekim Cumhuriyet Bayramı'nda Cumhuriyet Bayramı'nın ikinci gününde, Rusya'dan bu yıl onbinlerce vatandaş, büyük bir coşkuyla kutladıklarını belirtti. Rusya'nın başkenti Moskova'\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , çok fonksiyonlu davranışlara sahip, küçük bir yapay zeka, geleneksel yapay zeka teknolojisi, büyük bir hızla hızla devreye giriyor ve robotlar tarafından, robotlara kendi ilgi alanınız ve hizmetiniz ile ulaş\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.74\n",
            "     ETA: 00:07:01\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "48010 | 4.2592 | 2.1e-06 | 1.23 | 38.8K | 02:48:46 |  96.0%\n",
            "48020 | 4.2390 | 2.1e-06 | 1.20 | 38.8K | 02:48:47 |  96.0%\n",
            "48030 | 4.0219 | 2.1e-06 | 1.19 | 38.8K | 02:48:49 |  96.1%\n",
            "48040 | 4.3892 | 2.1e-06 | 1.21 | 38.8K | 02:48:51 |  96.1%\n",
            "48050 | 4.2657 | 2.0e-06 | 1.20 | 38.8K | 02:48:52 |  96.1%\n",
            "48060 | 4.1007 | 2.0e-06 | 1.21 | 38.8K | 02:48:54 |  96.1%\n",
            "48070 | 4.2417 | 2.0e-06 | 1.22 | 38.8K | 02:48:56 |  96.1%\n",
            "48080 | 4.3928 | 2.0e-06 | 1.23 | 38.9K | 02:48:58 |  96.2%\n",
            "48090 | 4.4074 | 2.0e-06 | 1.21 | 38.9K | 02:48:59 |  96.2%\n",
            "48100 | 4.0712 | 1.9e-06 | 1.18 | 38.9K | 02:49:01 |  96.2%\n",
            "48110 | 4.2437 | 1.9e-06 | 1.20 | 38.9K | 02:49:03 |  96.2%\n",
            "48120 | 4.0889 | 1.9e-06 | 1.20 | 38.9K | 02:49:04 |  96.2%\n",
            "48130 | 4.0831 | 1.9e-06 | 1.20 | 38.9K | 02:49:06 |  96.3%\n",
            "48140 | 4.2314 | 1.9e-06 | 1.20 | 38.9K | 02:49:08 |  96.3%\n",
            "48150 | 4.1092 | 1.8e-06 | 1.18 | 38.9K | 02:49:10 |  96.3%\n",
            "48160 | 4.0501 | 1.8e-06 | 1.24 | 38.9K | 02:49:11 |  96.3%\n",
            "48170 | 4.3907 | 1.8e-06 | 1.21 | 38.9K | 02:49:13 |  96.3%\n",
            "48180 | 4.4739 | 1.8e-06 | 1.19 | 38.9K | 02:49:15 |  96.4%\n",
            "48190 | 4.1964 | 1.8e-06 | 1.19 | 38.9K | 02:49:16 |  96.4%\n",
            "48200 | 4.1987 | 1.7e-06 | 1.20 | 38.9K | 02:49:18 |  96.4%\n",
            "48210 | 4.1408 | 1.7e-06 | 1.27 | 38.9K | 02:49:20 |  96.4%\n",
            "48220 | 4.3767 | 1.7e-06 | 1.19 | 38.9K | 02:49:22 |  96.4%\n",
            "48230 | 3.8655 | 1.7e-06 | 1.17 | 38.9K | 02:49:23 |  96.5%\n",
            "48240 | 4.1551 | 1.7e-06 | 1.22 | 38.9K | 02:49:25 |  96.5%\n",
            "48250 | 4.2399 | 1.6e-06 | 1.20 | 38.9K | 02:49:27 |  96.5%\n",
            "48260 | 4.3503 | 1.6e-06 | 1.20 | 38.9K | 02:49:28 |  96.5%\n",
            "48270 | 4.2330 | 1.6e-06 | 1.25 | 38.9K | 02:49:30 |  96.5%\n",
            "48280 | 4.3739 | 1.6e-06 | 1.22 | 38.9K | 02:49:32 |  96.6%\n",
            "48290 | 3.9720 | 1.6e-06 | 1.18 | 38.9K | 02:49:34 |  96.6%\n",
            "48300 | 4.1521 | 1.5e-06 | 1.19 | 38.9K | 02:49:35 |  96.6%\n",
            "48310 | 4.0310 | 1.5e-06 | 1.19 | 38.9K | 02:49:37 |  96.6%\n",
            "48320 | 4.2942 | 1.5e-06 | 1.19 | 38.9K | 02:49:39 |  96.6%\n",
            "48330 | 4.0290 | 1.5e-06 | 1.24 | 38.9K | 02:49:40 |  96.7%\n",
            "48340 | 4.0610 | 1.5e-06 | 1.23 | 38.9K | 02:49:42 |  96.7%\n",
            "48350 | 4.1998 | 1.5e-06 | 1.24 | 38.9K | 02:49:44 |  96.7%\n",
            "48360 | 4.2223 | 1.4e-06 | 1.20 | 38.9K | 02:49:46 |  96.7%\n",
            "48370 | 4.0073 | 1.4e-06 | 1.24 | 38.9K | 02:49:47 |  96.7%\n",
            "48380 | 4.2452 | 1.4e-06 | 1.22 | 38.9K | 02:49:49 |  96.8%\n",
            "48390 | 4.3465 | 1.4e-06 | 1.18 | 38.9K | 02:49:51 |  96.8%\n",
            "48400 | 4.0712 | 1.4e-06 | 1.22 | 38.9K | 02:49:52 |  96.8%\n",
            "48410 | 4.2984 | 1.4e-06 | 1.21 | 38.9K | 02:49:54 |  96.8%\n",
            "48420 | 4.2252 | 1.3e-06 | 1.17 | 38.9K | 02:49:56 |  96.8%\n",
            "48430 | 3.8786 | 1.3e-06 | 1.25 | 38.9K | 02:49:57 |  96.9%\n",
            "48440 | 4.4703 | 1.3e-06 | 1.25 | 38.9K | 02:49:59 |  96.9%\n",
            "48450 | 4.2559 | 1.3e-06 | 1.20 | 38.9K | 02:50:01 |  96.9%\n",
            "48460 | 3.8877 | 1.3e-06 | 1.17 | 38.9K | 02:50:03 |  96.9%\n",
            "48470 | 3.9908 | 1.3e-06 | 1.16 | 38.9K | 02:50:04 |  96.9%\n",
            "48480 | 4.1451 | 1.2e-06 | 1.22 | 38.9K | 02:50:06 |  97.0%\n",
            "48490 | 4.2363 | 1.2e-06 | 1.23 | 38.9K | 02:50:08 |  97.0%\n",
            "48500 | 4.4674 | 1.2e-06 | 1.23 | 38.9K | 02:50:09 |  97.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 48500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1152\n",
            "  Perplexity: 61.27\n",
            "  Train loss (avg): 4.1397\n",
            "\n",
            "  🎯 Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        ların ısınmasıyla birlikte pencereler açık kalıyor. Özellikle müziklerin artması ve her saat ışığı engelleyen bu ateş de bir yandan sağlıklı şekilde korunmaya çalışan bir aşk belirtisi taşıyor. Gözden kaçan bir fırtına gibi görünen\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        olan İstanbul'da insanların kendine has bir yapıya sahip olduğu biliniyor. İstanbul'un nüfusu ise 4 milyon civarında. İstanbul'un nüfusu ise 500 bin civarında. İstanbul'un nüfusu ise 2 milyon. İstanbul\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , hayal gücünü artırmayı ve yeni gözlerin yaratmasını kolaylaştırmayı amaçlıyor. Bu teknolojideki en önemli yeniliklerden biri, teknoloji oldu. Tobey, dört farklı alanlarda çok sayıda rakiple karşı karşıya\n",
            "\n",
            "  📈 Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.74\n",
            "     ETA: 00:05:16\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "48510 | 4.0325 | 1.2e-06 | 1.18 | 38.8K | 02:50:28 |  97.0%\n",
            "48520 | 4.1170 | 1.2e-06 | 1.20 | 38.9K | 02:50:30 |  97.0%\n",
            "48530 | 4.0275 | 1.2e-06 | 1.26 | 38.9K | 02:50:32 |  97.1%\n",
            "48540 | 4.1289 | 1.1e-06 | 1.23 | 38.9K | 02:50:34 |  97.1%\n",
            "48550 | 4.0235 | 1.1e-06 | 1.19 | 38.9K | 02:50:35 |  97.1%\n",
            "48560 | 4.0810 | 1.1e-06 | 1.22 | 38.9K | 02:50:37 |  97.1%\n",
            "48570 | 4.3605 | 1.1e-06 | 1.18 | 38.9K | 02:50:39 |  97.1%\n",
            "48580 | 3.8551 | 1.1e-06 | 1.16 | 38.9K | 02:50:40 |  97.2%\n",
            "48590 | 4.1504 | 1.1e-06 | 1.22 | 38.9K | 02:50:42 |  97.2%\n",
            "48600 | 4.0640 | 1.1e-06 | 1.22 | 38.9K | 02:50:44 |  97.2%\n",
            "48610 | 4.4378 | 1.0e-06 | 1.23 | 38.9K | 02:50:46 |  97.2%\n",
            "48620 | 4.1881 | 1.0e-06 | 1.22 | 38.9K | 02:50:47 |  97.2%\n",
            "48630 | 4.1893 | 1.0e-06 | 1.20 | 38.9K | 02:50:49 |  97.3%\n",
            "48640 | 3.8592 | 9.9e-07 | 1.29 | 38.9K | 02:50:51 |  97.3%\n",
            "48650 | 4.0892 | 9.8e-07 | 1.21 | 38.9K | 02:50:52 |  97.3%\n",
            "48660 | 4.3865 | 9.6e-07 | 1.23 | 38.9K | 02:50:54 |  97.3%\n",
            "48670 | 4.3362 | 9.5e-07 | 1.19 | 38.9K | 02:50:56 |  97.3%\n",
            "48680 | 4.2088 | 9.3e-07 | 1.19 | 38.9K | 02:50:58 |  97.4%\n",
            "48690 | 3.9976 | 9.2e-07 | 1.19 | 38.9K | 02:50:59 |  97.4%\n",
            "48700 | 4.3178 | 9.1e-07 | 1.23 | 38.9K | 02:51:01 |  97.4%\n",
            "48710 | 4.0554 | 8.9e-07 | 1.18 | 38.9K | 02:51:03 |  97.4%\n",
            "48720 | 4.0876 | 8.8e-07 | 1.16 | 38.9K | 02:51:04 |  97.4%\n",
            "48730 | 3.8441 | 8.6e-07 | 1.24 | 38.9K | 02:51:06 |  97.5%\n",
            "48740 | 3.9698 | 8.5e-07 | 1.23 | 38.9K | 02:51:08 |  97.5%\n",
            "48750 | 4.2419 | 8.4e-07 | 1.22 | 38.9K | 02:51:10 |  97.5%\n",
            "48760 | 4.0044 | 8.2e-07 | 1.22 | 38.9K | 02:51:11 |  97.5%\n",
            "48770 | 4.3727 | 8.1e-07 | 1.17 | 38.9K | 02:51:13 |  97.5%\n",
            "48780 | 4.4635 | 8.0e-07 | 1.21 | 38.9K | 02:51:15 |  97.6%\n",
            "48790 | 4.0690 | 7.8e-07 | 1.17 | 38.9K | 02:51:16 |  97.6%\n",
            "48800 | 4.0873 | 7.7e-07 | 1.24 | 38.9K | 02:51:18 |  97.6%\n",
            "48810 | 4.0854 | 7.6e-07 | 1.29 | 38.9K | 02:51:20 |  97.6%\n",
            "48820 | 4.4044 | 7.5e-07 | 1.19 | 38.9K | 02:51:21 |  97.6%\n",
            "48830 | 4.3679 | 7.3e-07 | 1.19 | 38.9K | 02:51:23 |  97.7%\n",
            "48840 | 4.2169 | 7.2e-07 | 1.22 | 38.9K | 02:51:25 |  97.7%\n",
            "48850 | 4.1436 | 7.1e-07 | 1.24 | 38.9K | 02:51:27 |  97.7%\n",
            "48860 | 4.0831 | 7.0e-07 | 1.19 | 38.9K | 02:51:28 |  97.7%\n",
            "48870 | 4.2999 | 6.8e-07 | 1.21 | 38.9K | 02:51:30 |  97.7%\n",
            "48880 | 4.2392 | 6.7e-07 | 1.20 | 38.9K | 02:51:32 |  97.8%\n",
            "48890 | 4.1035 | 6.6e-07 | 1.20 | 38.9K | 02:51:33 |  97.8%\n",
            "48900 | 4.1326 | 6.5e-07 | 1.32 | 38.9K | 02:51:35 |  97.8%\n",
            "48910 | 3.9236 | 6.4e-07 | 1.22 | 38.9K | 02:51:37 |  97.8%\n",
            "48920 | 4.4211 | 6.3e-07 | 1.20 | 38.9K | 02:51:39 |  97.8%\n",
            "48930 | 4.1761 | 6.1e-07 | 1.17 | 38.9K | 02:51:40 |  97.9%\n",
            "48940 | 4.0722 | 6.0e-07 | 1.18 | 38.9K | 02:51:42 |  97.9%\n",
            "48950 | 4.2943 | 5.9e-07 | 1.20 | 38.9K | 02:51:44 |  97.9%\n",
            "48960 | 3.9119 | 5.8e-07 | 1.20 | 38.9K | 02:51:45 |  97.9%\n",
            "48970 | 4.2867 | 5.7e-07 | 1.24 | 38.9K | 02:51:47 |  97.9%\n",
            "48980 | 3.9992 | 5.6e-07 | 1.20 | 38.9K | 02:51:49 |  98.0%\n",
            "48990 | 3.8847 | 5.5e-07 | 1.19 | 38.9K | 02:51:51 |  98.0%\n",
            "49000 | 4.1647 | 5.4e-07 | 1.18 | 38.9K | 02:51:52 |  98.0%\n",
            "\n",
            "======================================================================\n",
            "📊 EVALUATION @ Step 49000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.0810\n",
            "  Perplexity: 59.20\n",
            "  Train loss (avg): 4.1615\n",
            "\n",
            "   Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        şartları gereği ne kadar geniş bir alanda çalıştığımızı bugün inceleyebilirsiniz. Cumartesi günü saat 16.00’da başlayacak olan kar yağışı ve yağmur nedeniyle hava şartlarının çok ağır olduğu Londra’da, hava durumu beklen\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Moskova'nın yanı sıra Moskova, İstanbul, İzmir, Eskişehir ve Kocaeli'nin de aralarında bulunduğu Batı Anadolu Bölgesi'nin önemli illerinden biri olarak bilinen Moskova'da, dünyanın birçok ülkesinde de binlerce turist\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        , dünyanın en önemli cihazlarından biri haline geliyor. Bazı bilim adamları, teknoloji ve teknoloji, geleceğin teknolojilerini nasıl geliştireceğini öneriyor. Bilim insanları, teknolojideki en büyük yeniliklerin şirketlerin zorlayarak yüz\n",
            "\n",
            "   Performans:\n",
            "     Tokens/sec: 38.9K\n",
            "     Steps/sec: 4.74\n",
            "     ETA: 00:03:30\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "49010 | 4.1335 | 5.3e-07 | 1.17 | 38.9K | 02:52:11 |  98.0%\n",
            "49020 | 4.3356 | 5.2e-07 | 1.17 | 38.9K | 02:52:13 |  98.0%\n",
            "49030 | 4.2382 | 5.0e-07 | 1.19 | 38.9K | 02:52:15 |  98.1%\n",
            "49040 | 4.3592 | 4.9e-07 | 1.21 | 38.9K | 02:52:16 |  98.1%\n",
            "49050 | 3.6105 | 4.8e-07 | 1.22 | 38.9K | 02:52:18 |  98.1%\n",
            "49060 | 4.1878 | 4.7e-07 | 1.22 | 38.9K | 02:52:20 |  98.1%\n",
            "49070 | 4.3380 | 4.6e-07 | 1.23 | 38.9K | 02:52:22 |  98.1%\n",
            "49080 | 4.3047 | 4.5e-07 | 1.19 | 38.9K | 02:52:23 |  98.2%\n",
            "49090 | 4.1513 | 4.4e-07 | 1.21 | 38.9K | 02:52:25 |  98.2%\n",
            "49100 | 4.2380 | 4.3e-07 | 1.21 | 38.9K | 02:52:27 |  98.2%\n",
            "49110 | 4.0803 | 4.2e-07 | 1.19 | 38.9K | 02:52:28 |  98.2%\n",
            "49120 | 4.1905 | 4.2e-07 | 1.21 | 38.9K | 02:52:30 |  98.2%\n",
            "49130 | 4.2691 | 4.1e-07 | 1.21 | 38.9K | 02:52:32 |  98.3%\n",
            "49140 | 4.1907 | 4.0e-07 | 1.18 | 38.9K | 02:52:34 |  98.3%\n",
            "49150 | 4.2283 | 3.9e-07 | 1.21 | 38.9K | 02:52:35 |  98.3%\n",
            "49160 | 3.6974 | 3.8e-07 | 1.14 | 38.9K | 02:52:37 |  98.3%\n",
            "49170 | 4.0797 | 3.7e-07 | 1.22 | 38.9K | 02:52:39 |  98.3%\n",
            "49180 | 4.2946 | 3.6e-07 | 1.21 | 38.9K | 02:52:40 |  98.4%\n",
            "49190 | 4.0790 | 3.5e-07 | 1.18 | 38.9K | 02:52:42 |  98.4%\n",
            "49200 | 4.1461 | 3.4e-07 | 1.20 | 38.9K | 02:52:44 |  98.4%\n",
            "49210 | 4.2943 | 3.3e-07 | 1.24 | 38.9K | 02:52:45 |  98.4%\n",
            "49220 | 4.2316 | 3.3e-07 | 1.19 | 38.9K | 02:52:47 |  98.4%\n",
            "49230 | 4.0824 | 3.2e-07 | 1.23 | 38.9K | 02:52:49 |  98.5%\n",
            "49240 | 4.5526 | 3.1e-07 | 1.20 | 38.9K | 02:52:51 |  98.5%\n",
            "49250 | 4.1380 | 3.0e-07 | 1.20 | 38.9K | 02:52:52 |  98.5%\n",
            "49260 | 4.3546 | 2.9e-07 | 1.19 | 38.9K | 02:52:54 |  98.5%\n",
            "49270 | 4.4431 | 2.9e-07 | 1.19 | 38.9K | 02:52:56 |  98.5%\n",
            "49280 | 4.1967 | 2.8e-07 | 1.22 | 38.9K | 02:52:57 |  98.6%\n",
            "49290 | 4.3129 | 2.7e-07 | 1.23 | 38.9K | 02:52:59 |  98.6%\n",
            "49300 | 4.2947 | 2.6e-07 | 1.22 | 38.9K | 02:53:01 |  98.6%\n",
            "49310 | 4.4036 | 2.6e-07 | 1.25 | 38.9K | 02:53:03 |  98.6%\n",
            "49320 | 4.1467 | 2.5e-07 | 1.19 | 38.9K | 02:53:04 |  98.6%\n",
            "49330 | 4.0853 | 2.4e-07 | 1.17 | 38.9K | 02:53:06 |  98.7%\n",
            "49340 | 4.2206 | 2.3e-07 | 1.19 | 38.9K | 02:53:08 |  98.7%\n",
            "49350 | 4.4797 | 2.3e-07 | 1.19 | 38.9K | 02:53:09 |  98.7%\n",
            "49360 | 4.4355 | 2.2e-07 | 1.21 | 38.9K | 02:53:11 |  98.7%\n",
            "49370 | 3.9057 | 2.1e-07 | 1.17 | 38.9K | 02:53:13 |  98.7%\n",
            "49380 | 4.2048 | 2.1e-07 | 1.28 | 38.9K | 02:53:15 |  98.8%\n",
            "49390 | 4.3187 | 2.0e-07 | 1.28 | 38.9K | 02:53:16 |  98.8%\n",
            "49400 | 4.3715 | 1.9e-07 | 1.21 | 38.9K | 02:53:18 |  98.8%\n",
            "49410 | 3.8557 | 1.9e-07 | 1.16 | 38.9K | 02:53:20 |  98.8%\n",
            "49420 | 4.1787 | 1.8e-07 | 1.22 | 38.9K | 02:53:21 |  98.8%\n",
            "49430 | 4.2311 | 1.7e-07 | 1.26 | 38.9K | 02:53:23 |  98.9%\n",
            "49440 | 4.3402 | 1.7e-07 | 1.24 | 38.9K | 02:53:25 |  98.9%\n",
            "49450 | 4.2735 | 1.6e-07 | 1.18 | 38.9K | 02:53:27 |  98.9%\n",
            "49460 | 4.2103 | 1.6e-07 | 1.21 | 38.9K | 02:53:28 |  98.9%\n",
            "49470 | 4.0840 | 1.5e-07 | 1.29 | 38.9K | 02:53:30 |  98.9%\n",
            "49480 | 4.2144 | 1.5e-07 | 1.23 | 38.9K | 02:53:32 |  99.0%\n",
            "49490 | 3.9803 | 1.4e-07 | 1.20 | 38.9K | 02:53:33 |  99.0%\n",
            "49500 | 3.8979 | 1.3e-07 | 1.29 | 38.9K | 02:53:35 |  99.0%\n",
            "\n",
            "======================================================================\n",
            " EVALUATION @ Step 49500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1092\n",
            "  Perplexity: 60.90\n",
            "  Train loss (avg): 4.1625\n",
            "\n",
            "   Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        çok sıcak, insanların kendine ait bir kokusundan ibaret değil. Hatta dünya genelinde neredeyse her gün yeni bir koku ve tat alma hissi yaşıyoruz. Her iki kokunun da aynı kokulara sahip olduğu biliniyordu.\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Ankara'da yaşayan Türk vatandaşlarına yönelik gerçekleştirilen ilk şiddet olayının yaşandığı 19 Ekim'de yapılan basın açıklamasıyla vatandaşlarımızın bir kısmı bu katliama maruz kaldıklarını, bir kısmı ise zorla Kayseri'\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        sayesinde, bilgisayar ve bilgi teknolojileri olmadan insanlar rahatça hareket edebiliyorlar. Bu teknolojinin hiçbir etkisi yok. En çok kullanılan teknolojiler ve şeyler de bilim adamları tarafından geliştirildi. Teknolojinin nasıl olduğu da merak ediliyor.\n",
            "\n",
            "   Performans:\n",
            "     Tokens/sec: 38.9K\n",
            "     Steps/sec: 4.74\n",
            "     ETA: 00:01:45\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "49510 | 4.0671 | 1.3e-07 | 1.18 | 38.9K | 02:53:54 |  99.0%\n",
            "49520 | 3.8706 | 1.2e-07 | 1.21 | 38.9K | 02:53:56 |  99.0%\n",
            "49530 | 4.1307 | 1.2e-07 | 1.19 | 38.9K | 02:53:58 |  99.1%\n",
            "49540 | 4.0757 | 1.1e-07 | 1.21 | 38.9K | 02:53:59 |  99.1%\n",
            "49550 | 4.2312 | 1.1e-07 | 1.22 | 38.9K | 02:54:01 |  99.1%\n",
            "49560 | 4.0259 | 1.0e-07 | 1.21 | 38.9K | 02:54:03 |  99.1%\n",
            "49570 | 4.1237 | 9.9e-08 | 1.25 | 38.9K | 02:54:04 |  99.1%\n",
            "49580 | 4.2912 | 9.5e-08 | 1.19 | 38.9K | 02:54:06 |  99.2%\n",
            "49590 | 3.7354 | 9.0e-08 | 1.20 | 38.9K | 02:54:08 |  99.2%\n",
            "49600 | 4.0607 | 8.6e-08 | 1.19 | 38.9K | 02:54:09 |  99.2%\n",
            "49610 | 4.0763 | 8.2e-08 | 1.19 | 38.9K | 02:54:11 |  99.2%\n",
            "49620 | 4.1110 | 7.8e-08 | 1.21 | 38.9K | 02:54:13 |  99.2%\n",
            "49630 | 4.2676 | 7.4e-08 | 1.18 | 38.9K | 02:54:15 |  99.3%\n",
            "49640 | 4.0301 | 7.0e-08 | 1.18 | 38.9K | 02:54:16 |  99.3%\n",
            "49650 | 4.1633 | 6.6e-08 | 1.18 | 38.9K | 02:54:18 |  99.3%\n",
            "49660 | 4.3111 | 6.2e-08 | 1.20 | 38.9K | 02:54:20 |  99.3%\n",
            "49670 | 4.1393 | 5.9e-08 | 1.26 | 38.9K | 02:54:21 |  99.3%\n",
            "49680 | 4.2249 | 5.5e-08 | 1.21 | 38.9K | 02:54:23 |  99.4%\n",
            "49690 | 3.9465 | 5.2e-08 | 1.24 | 38.9K | 02:54:25 |  99.4%\n",
            "49700 | 4.1393 | 4.9e-08 | 1.22 | 38.9K | 02:54:27 |  99.4%\n",
            "49710 | 4.2585 | 4.5e-08 | 1.19 | 38.9K | 02:54:28 |  99.4%\n",
            "49720 | 4.0947 | 4.2e-08 | 1.21 | 38.9K | 02:54:30 |  99.4%\n",
            "49730 | 4.2874 | 3.9e-08 | 1.24 | 38.9K | 02:54:32 |  99.5%\n",
            "49740 | 4.1833 | 3.6e-08 | 1.21 | 38.9K | 02:54:33 |  99.5%\n",
            "49750 | 4.2631 | 3.4e-08 | 1.22 | 38.9K | 02:54:35 |  99.5%\n",
            "49760 | 3.9861 | 3.1e-08 | 1.25 | 38.9K | 02:54:37 |  99.5%\n",
            "49770 | 4.1149 | 2.9e-08 | 1.22 | 38.9K | 02:54:39 |  99.5%\n",
            "49780 | 4.5076 | 2.6e-08 | 1.20 | 38.9K | 02:54:40 |  99.6%\n",
            "49790 | 4.2833 | 2.4e-08 | 1.20 | 38.9K | 02:54:42 |  99.6%\n",
            "49800 | 4.1279 | 2.2e-08 | 1.22 | 38.9K | 02:54:44 |  99.6%\n",
            "49810 | 4.0149 | 2.0e-08 | 1.24 | 38.9K | 02:54:45 |  99.6%\n",
            "49820 | 4.0402 | 1.8e-08 | 1.21 | 38.9K | 02:54:47 |  99.6%\n",
            "49830 | 4.0589 | 1.6e-08 | 1.21 | 38.9K | 02:54:49 |  99.7%\n",
            "49840 | 4.3767 | 1.4e-08 | 1.20 | 38.9K | 02:54:51 |  99.7%\n",
            "49850 | 4.1657 | 1.2e-08 | 1.20 | 38.9K | 02:54:52 |  99.7%\n",
            "49860 | 4.1632 | 1.1e-08 | 1.20 | 38.9K | 02:54:54 |  99.7%\n",
            "49870 | 4.3541 | 9.2e-09 | 1.19 | 38.9K | 02:54:56 |  99.7%\n",
            "49880 | 4.1606 | 7.8e-09 | 1.21 | 38.9K | 02:54:57 |  99.8%\n",
            "49890 | 4.0334 | 6.6e-09 | 1.18 | 38.9K | 02:54:59 |  99.8%\n",
            "49900 | 4.2016 | 5.5e-09 | 1.24 | 38.9K | 02:55:01 |  99.8%\n",
            "49910 | 4.0114 | 4.4e-09 | 1.20 | 38.9K | 02:55:02 |  99.8%\n",
            "49920 | 4.1072 | 3.5e-09 | 1.19 | 38.9K | 02:55:04 |  99.8%\n",
            "49930 | 4.2467 | 2.7e-09 | 1.24 | 38.9K | 02:55:06 |  99.9%\n",
            "49940 | 4.2663 | 2.0e-09 | 1.21 | 38.9K | 02:55:08 |  99.9%\n",
            "49950 | 4.1963 | 1.4e-09 | 1.20 | 38.9K | 02:55:09 |  99.9%\n",
            "49960 | 4.0162 | 9.0e-10 | 1.19 | 38.9K | 02:55:11 |  99.9%\n",
            "49970 | 4.2545 | 5.1e-10 | 1.23 | 38.9K | 02:55:13 |  99.9%\n",
            "49980 | 4.3397 | 2.4e-10 | 1.20 | 38.9K | 02:55:14 | 100.0%\n",
            "49990 | 3.9306 | 6.5e-11 | 1.20 | 38.9K | 02:55:16 | 100.0%\n",
            "50000 | 4.0653 | 5.4e-13 | 1.19 | 38.9K | 02:55:18 | 100.0%\n",
            "\n",
            "======================================================================\n",
            " EVALUATION @ Step 50000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.0945\n",
            "  Perplexity: 60.01\n",
            "  Train loss (avg): 4.1512\n",
            "\n",
            "   Üretim örnekleri:\n",
            "    [1] 'Bugün hava' →\n",
            "        biraz soğuk, öyle güzel, öyle güzel ki deniz çok sıcak, bu da karlar altında, ne çok seveceksin, ne de çok seveceksin... Özellikle de bahar aylarıydı. Hava güzel ve temiz\n",
            "    [2] 'Türkiye'nin başkenti' →\n",
            "        Londra'da hizmet veren İiberal ve Landing, uluslararası turizm ve yerel yönetimlerin oluşturduğu bir organizasyon. İstanbul'un kültür sanat ve sanat şehri olan Londra'da, 4 farklı ülkeye de\n",
            "    [3] 'Yapay zeka teknolojisi' →\n",
            "        sayesinde “yeni şeyler için” ve “içeriği” ile de otomatik olarak “yeni şeyler”ler üretilebileceğini gözlemliyorsunuz. Her halükarda yeni şeyler de olabilir. Hatta özellikle de\n",
            "\n",
            "   Performans:\n",
            "     Tokens/sec: 38.9K\n",
            "     Steps/sec: 4.75\n",
            "     ETA: 00:00:00\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "💾 Checkpoint kaydediliyor: /content/drive/MyDrive/turkish_llm/checkpoints//checkpoint_step_50000.pt\n",
            "   Checkpoint kaydedildi!\n",
            "\n",
            "\n",
            "======================================================================\n",
            "                         ✨ EĞİTİM TAMAMLANDI!\n",
            "======================================================================\n",
            "\n",
            " Final İstatistikler:\n",
            "  Toplam süre: 02:55:38\n",
            "  Toplam step: 50,000\n",
            "  Toplam token: 0.41B\n",
            "  Final loss: 4.0653\n",
            "  Best eval loss: 4.0716\n",
            "  Ortalama hız: 38.9K token/s\n",
            "\n",
            " Final model kaydedildi: /content/drive/MyDrive/turkish_llm/checkpoints//final_model.pt\n",
            "\n",
            " Final üretim örnekleri:\n",
            "\n",
            "'Bugün hava':\n",
            "  → durumu tahminleri için tıklayın: Türkiye’de hava durumu tahminleri için tıklayın: Türkiye’de hava durumu tahminleri için tıklayın: Türkiye’de hava durumu tahminleri için tıklayın: Türkiye’de hava durumu tahminleri için tıklayın: Türkiye’de hava\n",
            "\n",
            "'Türkiye'nin başkenti':\n",
            "  → Ankara'da, ABD'nin Suriye'ye müdahalesinin ardından, Türkiye'nin Suriye'de yaptığı müdahalelerin ardından Ankara'da da bir araya gelen Suriyeli bir grup, Türkiye'nin Suriye'ye müdahale ettiği ve Türk yetkililere de herhangi bir\n",
            "\n",
            "'Yapay zeka teknolojisi':\n",
            "  → , yapay zeka teknolojilerinin daha çok yaygınlaşmasını ve birçok kişinin daha hızlı çalışılmasını sağlar. Bu teknoloji, kişinin en çok ilgi gösterdiği, en çok ilgi gören ve en çok ilgi gören teknolojik ürünleridir. Ne yazık ki, bu teknoloji sayesinde, daha çok\n",
            "\n",
            "'İnsanlar neden':\n",
            "  → azarlar? Onlar ne kadar çok biliyor? Onların seni çok sevdiğine inanırlar. Onların bu nedenle, onlarla birlikte yarattıkları bütün davranışlarında, başkalarının senin için daha çok bir şey yapmalarını ister. Onlar, onlardan daha çok sevilirler. Onlar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def generate_improved(model, prompt, max_tokens=50, temperature=0.7, top_p=0.9, repetition_penalty=1.2):\n",
        "    \"\"\"Geliştirilmiş generation\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    tokens = sp.encode(prompt)\n",
        "    tokens = torch.tensor([tokens], dtype=torch.long).cuda()\n",
        "    generated = []\n",
        "\n",
        "    for _ in range(max_tokens):\n",
        "        logits = model(tokens)[:, -1, :]\n",
        "\n",
        "        # Repetition penalty uygula\n",
        "        for token_id in set(generated[-20:]):  # Son 20 token\n",
        "            logits[0, token_id] /= repetition_penalty\n",
        "\n",
        "        # Temperature ve top-p\n",
        "        logits = logits / temperature\n",
        "        # ... (top-p sampling)\n",
        "\n",
        "        next_token = torch.multinomial(F.softmax(logits, dim=-1), 1)\n",
        "        if next_token.item() == sp.eos_id():\n",
        "            break\n",
        "        generated.append(next_token.item())\n",
        "        tokens = torch.cat([tokens, next_token], dim=1)\n",
        "\n",
        "    return sp.decode(generated)\n",
        "\n",
        "# Test\n",
        "prompts = [\"Ben bir\", \"İstanbul\", \"Yapay zeka\"]\n",
        "for p in prompts:\n",
        "    result = generate_improved(model, p, temperature=0.7, repetition_penalty=1.3)\n",
        "    print(f\"'{p}': {result}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFApN7iA3l0j",
        "outputId": "151cf286-85f7-456d-dcb8-8fc761653a61"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Ben bir': önceki yazımda İstanbul Üniversitesi İşletme Fakültesi’nden mezun oldum. Üniversite, Türkiye’de “Matematik” alanında eğitim almış veya “Türkiye’nin En İyi Öğrenci Derneği” olarak mezun oldum. Buımdaki en büyük başarılardan biri de kuşkusuz “Mate\n",
            "\n",
            "'İstanbul': ’un en gözde semtlerinden biri olan İzmir, senelerdir de bölgede hayat kurtarıyor. İzmir Büyükşehir Belediyesi’nin sunduğu bayramlaşma programına katılan Başkan Aziz Kocaoğlu, “Şehir merkezimiz her türlü hizmeti vermeye devam ediyor” şeklinde konuştu. İzmir Büyükşehir Belediyesi\n",
            "\n",
            "'Yapay zeka': ve Cosmic IBM, en çok kullanılan yazılım platformlardan biri olan Y-Bi7 ile birlikte en küçük bir bilgiye sahip olmak için, yalnızca öğrenciler için tasarlanmıştır. Veriler ve bilgiler doğrulayacak şekilde tasarlanmalıdır. Tether\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === MODEL TESTİ ===================================\n",
        "\n",
        "# Test prompts\n",
        "test_prompts = [\n",
        "    \"Bugün hava\",\n",
        "    \"İstanbul'un\",\n",
        "    \"Türkiye ekonomisi\",\n",
        "    \"Yapay zeka nedir\",\n",
        "    \"En sevdiğim\",\n",
        "    \"Bir varmış bir yokmuş\",\n",
        "    \"Python programlama dili\",\n",
        "]\n",
        "\n",
        "print(\"GENERATION TESTLERİ\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for prompt in test_prompts:\n",
        "    print(f\"\\n Prompt: '{prompt}'\")\n",
        "\n",
        "    # Farklı temperature'larla test\n",
        "    for temp in [0.5, 0.8]:\n",
        "        output = generate_improved(\n",
        "            model,\n",
        "            prompt,\n",
        "            max_tokens=40,\n",
        "            temperature=temp,\n",
        "            top_p=0.9,\n",
        "            repetition_penalty=1.3\n",
        "        )\n",
        "        print(f\"  (temp={temp}): {output}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# İnteraktif test\n",
        "print(\"\\n💬 İNTERAKTİF TEST (çıkmak için 'quit' yazın)\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"\\n Siz: \")\n",
        "    if user_input.lower() in ['quit', 'çık', 'exit']:\n",
        "        break\n",
        "\n",
        "    response = generate_improved(\n",
        "        model,\n",
        "        user_input,\n",
        "        max_tokens=80,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        repetition_penalty=1.25\n",
        "    )\n",
        "\n",
        "    print(f\" Model: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98qzrhnP4Tej",
        "outputId": "c609543d-cb3b-4160-9ec4-866a35a07548"
      },
      "execution_count": 22,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " GENERATION TESTLERİ\n",
            "============================================================\n",
            "\n",
            " Prompt: 'Bugün hava'\n",
            "  (temp=0.5): , işçi ve emekçi kesimlere göre daha çok sorun çıkarıyor. İşçiler, emekçilerin, emekçilerin, emekçinin ve emekçi kesimlerin sorunları ile mücadele ederken, iş gücü piyasasını da olumsuz\n",
            "  (temp=0.8): şartları çok kötü değil. Oh değil mi? Sokağımıza girecek oyuncular sanırım yüzde 80 civarında! W Yunusemre’nin en ünlü oyuncusunun sol bek olması, kaleci Meclis Başkanı ve eski futbolcu Metin\n",
            "\n",
            " Prompt: 'İstanbul'un'\n",
            "  (temp=0.5): en büyük ve modern alışveriş merkezi olan İstanbul'un merkezinde yer alan, şehrin binlerce kilometre uzağında bulunan bir restorandır. Şehrin en büyük ve modern alışveriş merkezi olan İstanbul'un merkezinde yer alan, şehrin\n",
            "  (temp=0.8): en büyük ve popüler alışveriş caddesi Hermessi'nin D&R mağazalarında stoksuz olarak yer alan Parfüm, fiyatları ile alışveriş yapan ve alışveriş yapmak isteyen kişilerin ilk adresi. Parmessa\n",
            "\n",
            " Prompt: 'Türkiye ekonomisi'\n",
            "  (temp=0.5): yüzde 12 ile yüzde 4 arasında değişen bir büyüme kaydetti. Türkiye'nin en büyük sanayi kuruluşu olan Avrupa Birliği, özellikle de Türkiye ekonomisinin lokomotif sektörlerinden biri haline geldi. Bu yıl ikinci kez istihdam edilen Türkiye\n",
            "  (temp=0.8): bir bütün olarak Türkiye'nin ekonomisini de karşılayabilecek düzeyde finansal büyüklüğe sahip. Bu özelliğin enerji ve doğal gaz verimi seferberliğine girdiği, en fazla nahoş TL'nin değer kazan\n",
            "\n",
            " Prompt: 'Yapay zeka nedir'\n",
            "  (temp=0.5): ? Yapay zeka ne demektir, yapay zekayı nasıl etkiler ? Yapay zeka nedir? Yapay zeka nedir ve yapay zeka hakkında bilgi sahibi olmak için en iyi yol yapay zekanın nasıl çalıştığını öğrenmektir. Yapay zeka\n",
            "  (temp=0.8): , benim aklıma geçtiğimiz 15-30 yılda yapılan bir araştırma denek yaparak bu sistemi test eden insanların, bunun nasıl olduğunu ve bunun evrimsel olmadığını gözlemledim. Bu durumda beyindeki en büyük dildeki insanların kaf\n",
            "\n",
            " Prompt: 'En sevdiğim'\n",
            "  (temp=0.5): şeyse, bu hafta içinde en çok sevdiğim şey sanırım, bu ay da çok fazla bloga bakmam. Bu ay bir blog açmayı düşünüyorum ve en sevdiğim şey ise, blogumu açtığım ilk\n",
            "  (temp=0.8): arkadaşlardan biri olan Etiketler: eteği (kuru) kol, fırına ,şişman ve sarık ile seyahat eden şehrimizde nerelere gidilebilir? Elbette. Görüp de görmediğini\n",
            "\n",
            " Prompt: 'Bir varmış bir yokmuş'\n",
            "  (temp=0.5): . O da bir gün, bu gece de yine iki ayrı güneş ışığı altında toplanıp eve varınca bir yerde yatıyormuş. \"Seyahatin sonu nereye gidiyor?\" diye sormuşlar, bir de\n",
            "  (temp=0.8): . Vay be! Kendimi var artık: \"Gelin şu elinizden, belki bir kölesiniz\" dedim... Ne olduğunu unutmuştum. Boynum kaydı; ben de bir tek, b\n",
            "\n",
            " Prompt: 'Python programlama dili'\n",
            "  (temp=0.5): ile ilgili en iyi şey, bir komut veya komuta sahip olmak. Bu durumda, komutlar bir komutla ilgili olarak ayarlanabilir. Bu komut, komutların herhangi biri tarafından oluşturulan bir komuta sahip\n",
            "  (temp=0.8): ile ilgili her türlü bilgiyi bulabileceğiniz ve en kolay biçimde kullanabileceğiniz bir dildir. Bu nedenle, daha detaylı bilgi için bizimle iletişime geçebilirsiniz: Bu tüyo hakkında daha fazla bilgi edinmek ve bu alandaki uzmanlaşmayı\n",
            "\n",
            "============================================================\n",
            "\n",
            "💬 İNTERAKTİF TEST (çıkmak için 'quit' yazın)\n",
            "------------------------------------------------------------\n",
            "\n",
            " Siz: merhaba\n",
            " Model: . Feyza bey, öncelikle bana da mail yoluyla ulaşmanız gerekmekte ve kesinlikle bu konuda bilgi sahibi olduğunuzu söylemek istiyorum. Ayrıca “Para nasıl başlar?” diye sorsanız 1 hafta sonra ikinci sorum olacak: 1- Öncelikle, “nefes alma” nedir? 2- Bir süre önce “Para nasıl başlar?” diye sorsanız 1 hafta sonra ikinci sorumun cevabı yazarız. 3- Tahsilat edilen ifad\n",
            "\n",
            " Siz: süleyman demirel\n",
            " Model: , bir alıntı ekledi. Ne kadar geriğin var o ki... Psk.Murat ÖZGÜR, \"Canlılar, bütün bunlar için bir şey yapmazlar\" diyor. Bedeviler, \"Madem ki, bu, millet için bir şey yapsan, sen de artık her yerde sulh ve selamet vardır. Bu millet, kendi başına dünyanın hiçbir yerinde sulh olamaz\"\n",
            "\n",
            " Siz: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Checkpoint'leri kontrol et\n",
        "checkpoint_dir = '/content/drive/MyDrive/turkish_llm/checkpoints/'\n",
        "print(\" Kaydedilen checkpoint'ler:\")\n",
        "for file in os.listdir(checkpoint_dir):\n",
        "    if file.endswith('.pt'):\n",
        "        size = os.path.getsize(os.path.join(checkpoint_dir, file)) / (1024**3)\n",
        "        print(f\"  ✓ {file} ({size:.2f} GB)\")\n",
        "\n",
        "# Tokenizer'ı kontrol et\n",
        "tokenizer_path = '/content/drive/MyDrive/turkish_llm/tokenizer_tr_32k_v2.model'\n",
        "if os.path.exists(tokenizer_path):\n",
        "    print(f\"✓ Tokenizer mevcut: {tokenizer_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weJ2HXVO9MpV",
        "outputId": "3aaa5efc-48d5-4525-d282-be215ea9834c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Kaydedilen checkpoint'ler:\n",
            "  ✓ best_model.pt (1.34 GB)\n",
            "  ✓ checkpoint_step_5000.pt (1.34 GB)\n",
            "  ✓ checkpoint_step_10000.pt (1.34 GB)\n",
            "  ✓ checkpoint_step_15000.pt (1.34 GB)\n",
            "  ✓ checkpoint_step_20000.pt (1.34 GB)\n",
            "  ✓ checkpoint_step_25000.pt (1.34 GB)\n",
            "  ✓ checkpoint_step_30000.pt (1.34 GB)\n",
            "  ✓ checkpoint_step_35000.pt (1.34 GB)\n",
            "  ✓ checkpoint_step_40000.pt (1.34 GB)\n",
            "  ✓ checkpoint_step_45000.pt (1.34 GB)\n",
            "  ✓ checkpoint_step_50000.pt (1.34 GB)\n",
            "  ✓ final_model.pt (1.34 GB)\n",
            "✓ Tokenizer mevcut: /content/drive/MyDrive/turkish_llm/tokenizer_tr_32k_v2.model\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
