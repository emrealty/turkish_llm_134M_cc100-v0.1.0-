{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i3Y8n1DVWnN"
      },
      "source": [
        "Verisetinin indirilmesi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDsX_GURRahl",
        "outputId": "6ff88c32-8227-40fd-a189-7f748bb2eaa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-08-07 16:17:41--  http://data.statmt.org/cc-100/tr.txt.xz\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.32.28\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://data.statmt.org/cc-100/tr.txt.xz [following]\n",
            "--2025-08-07 16:17:41--  https://data.statmt.org/cc-100/tr.txt.xz\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5710467188 (5.3G) [application/x-xz]\n",
            "Saving to: ‚Äò/content/drive/MyDrive/turkish_llm/cc100-tr.txt.xz‚Äô\n",
            "\n",
            "/content/drive/MyDr 100%[===================>]   5.32G  9.61MB/s    in 9m 35s  \n",
            "\n",
            "2025-08-07 16:27:16 (9.48 MB/s) - ‚Äò/content/drive/MyDrive/turkish_llm/cc100-tr.txt.xz‚Äô saved [5710467188/5710467188]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# ‚Ü≥ yakla≈üƒ±k 3 GB .xz dosyasƒ± (~11 GB a√ßƒ±lmƒ±≈ü metin)\n",
        "!wget -c http://data.statmt.org/cc-100/tr.txt.xz \\\n",
        "      -O /content/drive/MyDrive/turkish_llm/cc100-tr.txt.xz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jrO4qfGWyoD"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet fasttext tqdm xxhash\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewQCSZswW8_1",
        "outputId": "ff3b6174-40ca-4e72-a649-caefb0809266"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ƒ∞ndiriliyor‚Ä¶ (~126 MB)\n",
            "‚úì Dil modeli indirildi ‚Üí /content/lid.176.bin\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ],
      "source": [
        "import pathlib, requests, shutil, os, gzip, lzma, xxhash, json, math, itertools\n",
        "from tqdm import tqdm\n",
        "\n",
        "lid_path = pathlib.Path('/content/lid.176.bin')\n",
        "if not lid_path.exists():\n",
        "    url = 'https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin'\n",
        "    print('ƒ∞ndiriliyor‚Ä¶ (~126 MB)')\n",
        "    with requests.get(url, stream=True) as r, open(lid_path, 'wb') as f:\n",
        "        shutil.copyfileobj(r.raw, f)\n",
        "    print('‚úì Dil modeli indirildi ‚Üí', lid_path)\n",
        "\n",
        "import fasttext\n",
        "lid_model = fasttext.load_model(str(lid_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zu2zpvMPYK8b",
        "outputId": "f97126f7-d70c-4bf8-e99c-6143ac13c854"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --quiet --upgrade \"numpy<2.0\" \"fasttext==0.9.2\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0M5Rj4JXAsD",
        "outputId": "c61a7649-7f04-4467-8333-c7ab7c9de2d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "ƒ∞≈üleniyor: 99822767 satƒ±r [2:55:03, 9503.42 satƒ±r/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚èπ  2,000,000,047 token hedefine ula≈üƒ±ldƒ±. Durduruluyor‚Ä¶\n",
            "\n",
            "‚úì Temizleme tamamlandƒ± ‚Üí /content/drive/MyDrive/turkish_llm/cc100-tr.clean.txt.gz\n",
            "Toplam token: 2,000,000,047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# === CC100-tr TEMƒ∞ZLEME H√úCRESƒ∞ =========================================\n",
        "# Girdi  : /content/drive/MyDrive/turkish_llm/cc100-tr.txt.xz\n",
        "# √áƒ±ktƒ±  : /content/drive/MyDrive/turkish_llm/cc100-tr.clean.txt.gz\n",
        "# Ama√ß   : Dil filtresi (TR), uzun/kƒ±sa satƒ±r filtresi, deduplikasyon,\n",
        "#          ~2B token hedefi (isteƒüe baƒülƒ±) ‚Äì √ßƒ±kƒ±≈ü ‚âà 12 GB ham metin\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)   # zaten baƒülƒ±ysa deƒüi≈ümez\n",
        "\n",
        "import lzma, gzip, xxhash, fasttext, pathlib, requests, shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "# -------- Ayarlar --------\n",
        "RAW_PATH   = '/content/drive/MyDrive/turkish_llm/cc100-tr.txt.xz'\n",
        "CLEAN_PATH = '/content/drive/MyDrive/turkish_llm/cc100-tr.clean.txt.gz'\n",
        "\n",
        "MIN_TOKENS    = 5          # satƒ±rdaki min token\n",
        "MAX_TOKENS    = 200        # satƒ±rdaki max token\n",
        "MAX_CHARS     = 1000       # satƒ±rdaki max karakter\n",
        "TARGET_TOKENS = 2_000_000_000  # None => sƒ±nƒ±r yok (~2B token hedefi)\n",
        "\n",
        "# -------- Dil modeli (FastText LID-176) --------\n",
        "lid_path = pathlib.Path('/content/lid.176.bin')\n",
        "if not lid_path.exists():\n",
        "    print('‚ñ∫ FastText model indiriliyor‚Ä¶')\n",
        "    url = 'https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin'\n",
        "    with requests.get(url, stream=True) as r, open(lid_path, 'wb') as f:\n",
        "        shutil.copyfileobj(r.raw, f)\n",
        "ft = fasttext.load_model(str(lid_path))\n",
        "\n",
        "def is_turkish(text: str) -> bool:\n",
        "    \"\"\"0-1 T√ºrk√ße satƒ±r filtresi (‚â•0.80 olasƒ±lƒ±k).\"\"\"\n",
        "    text = text.strip()\n",
        "    if not text:\n",
        "        return False\n",
        "    label, prob = ft.predict(text, k=1)\n",
        "    return label[0] == '__label__tr' and prob[0] > 0.80\n",
        "\n",
        "def simple_tokenize(t: str):\n",
        "    return t.split()\n",
        "\n",
        "# -------- Akƒ±≈ülƒ± okuma / yazma --------\n",
        "seen_hashes = set()\n",
        "total_tokens = 0\n",
        "\n",
        "with lzma.open(RAW_PATH, mode='rt', encoding='utf-8', errors='ignore') as fin, \\\n",
        "     gzip.open(CLEAN_PATH, mode='wt', encoding='utf-8') as fout, \\\n",
        "     tqdm(total=None, unit=' satƒ±r', desc='ƒ∞≈üleniyor') as pbar:\n",
        "\n",
        "    for raw_line in fin:\n",
        "        pbar.update()\n",
        "        line = raw_line.rstrip('\\n')\n",
        "\n",
        "        # Uzunluk filtreleri\n",
        "        if len(line) < 2 or len(line) > MAX_CHARS:\n",
        "            continue\n",
        "        tokens = simple_tokenize(line)\n",
        "        if not (MIN_TOKENS <= len(tokens) <= MAX_TOKENS):\n",
        "            continue\n",
        "\n",
        "        # Dil filtresi\n",
        "        if not is_turkish(line):\n",
        "            continue\n",
        "\n",
        "        # Basit deduplikasyon\n",
        "        h = xxhash.xxh64(line).intdigest()\n",
        "        if h in seen_hashes:\n",
        "            continue\n",
        "        seen_hashes.add(h)\n",
        "        if len(seen_hashes) > 10_000_000:   # bellek korumasƒ±\n",
        "            seen_hashes.clear()\n",
        "\n",
        "        # Yaz & saya√ß\n",
        "        fout.write(line + '\\n')\n",
        "        total_tokens += len(tokens)\n",
        "\n",
        "        if TARGET_TOKENS and total_tokens >= TARGET_TOKENS:\n",
        "            print(f'\\n‚èπ  {total_tokens:,} token hedefine ula≈üƒ±ldƒ±. Durduruluyor‚Ä¶')\n",
        "            break\n",
        "\n",
        "print(f'\\n‚úì Temizleme tamamlandƒ± ‚Üí {CLEAN_PATH}')\n",
        "print(f'Toplam token: {total_tokens:,}')\n",
        "# ========================================================================\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLJXb4GTKgTA",
        "outputId": "0e93d137-264c-4280-ba2a-9bd17391162e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw------- 1 root root 5.9G Aug  7 19:32 /content/drive/MyDrive/turkish_llm/cc100-tr.clean.txt.gz\n",
            "         compressed        uncompressed  ratio uncompressed_name\n",
            "         6273266558          3584799583 -75.0% /content/drive/MyDrive/turkish_llm/cc100-tr.clean.txt\n"
          ]
        }
      ],
      "source": [
        "!ls -lh /content/drive/MyDrive/turkish_llm/cc100-tr.clean.txt.gz\n",
        "!gzip -l  /content/drive/MyDrive/turkish_llm/cc100-tr.clean.txt.gz\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqbl7HSBiW97",
        "outputId": "6020cce6-ba9c-4c04-f7d4-534863951edf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU: NVIDIA A100-SXM4-40GB\n",
            "VRAM: 42.5 GB\n",
            "ƒ∞mportlar tamamlandƒ±\n"
          ]
        }
      ],
      "source": [
        "# === H√úCRE 1: ƒ∞MPORTLAR VE GPU KONTROL√ú ===================================\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import numpy as np\n",
        "import sentencepiece as spm\n",
        "import gzip\n",
        "import time\n",
        "import os\n",
        "import gc\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional, Tuple\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# GPU kontrol√º\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üíæ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"GPU bulunamadƒ±!\")\n",
        "\n",
        "# Pathler\n",
        "DATA_PATH = '/content/drive/MyDrive/turkish_llm/cc100-tr.clean.txt.gz'\n",
        "TOKENIZER_PATH = '/content/drive/MyDrive/turkish_llm/tokenizer_tr_32k_v2.model'\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/turkish_llm/checkpoints/'\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"ƒ∞mportlar tamamlandƒ±\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC2lKinUiaCq",
        "outputId": "e84529bd-b827-429f-9ebe-085e2ab8cd4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer y√ºklendi (vocab size: 32000)\n",
            "\n",
            "Test: 'Merhaba d√ºnya, nasƒ±lsƒ±nƒ±z?'\n",
            "Tokens (6): [2514, 1212, 31895, 782, 1243, 31934]\n",
            "Decoded: 'Merhaba d√ºnya, nasƒ±lsƒ±nƒ±z?'\n"
          ]
        }
      ],
      "source": [
        "# === H√úCRE 2: TOKENIZER Y√úKLEME ===================================\n",
        "\n",
        "# Tokenizer y√ºkle\n",
        "sp = spm.SentencePieceProcessor(model_file=TOKENIZER_PATH)\n",
        "print(f\"Tokenizer y√ºklendi (vocab size: {sp.vocab_size()})\")\n",
        "\n",
        "# Test\n",
        "test_text = \"Merhaba d√ºnya, nasƒ±lsƒ±nƒ±z?\"\n",
        "tokens = sp.encode(test_text)\n",
        "decoded = sp.decode(tokens)\n",
        "print(f\"\\nTest: '{test_text}'\")\n",
        "print(f\"Tokens ({len(tokens)}): {tokens}\")\n",
        "print(f\"Decoded: '{decoded}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDw6yE2VicJQ",
        "outputId": "365b0e3d-0994-4343-cfff-e01e7f5f3aef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Config: 12 layers, 768 dim, 12 heads\n",
            "Training Config: batch_size=8, max_steps=10000\n"
          ]
        }
      ],
      "source": [
        "# === H√úCRE 3: MODEL KONFƒ∞G√úRASYONU ===================================\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    dim: int = 768\n",
        "    n_layers: int = 12\n",
        "    n_heads: int = 12\n",
        "    n_kv_heads: int = 12\n",
        "    vocab_size: int = 32000\n",
        "    max_seq_len: int = 1024  # Optimize edilmi≈ü\n",
        "    dropout: float = 0.0\n",
        "\n",
        "    multiple_of: int = 256\n",
        "    ffn_dim_multiplier: float = 2.7\n",
        "    norm_eps: float = 1e-5\n",
        "    rope_theta: float = 10000.0\n",
        "\n",
        "    def __post_init__(self):\n",
        "        hidden_dim = int(2 * self.dim * self.ffn_dim_multiplier / 3)\n",
        "        self.ffn_hidden_dim = self.multiple_of * ((hidden_dim + self.multiple_of - 1) // self.multiple_of)\n",
        "        self.head_dim = self.dim // self.n_heads\n",
        "\n",
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    batch_size: int = 8           # A100 i√ßin optimize\n",
        "    max_length: int = 1024\n",
        "    num_workers: int = 2\n",
        "\n",
        "    learning_rate: float = 5e-4\n",
        "    weight_decay: float = 0.1\n",
        "    adam_beta1: float = 0.9\n",
        "    adam_beta2: float = 0.95\n",
        "    grad_clip: float = 1.0\n",
        "\n",
        "    warmup_steps: int = 1000\n",
        "    max_steps: int = 10000\n",
        "    eval_interval: int = 250\n",
        "    save_interval: int = 1000\n",
        "    log_interval: int = 10\n",
        "\n",
        "    use_amp: bool = True\n",
        "\n",
        "config = ModelConfig()\n",
        "train_config = TrainingConfig()\n",
        "\n",
        "print(f\"Model Config: {config.n_layers} layers, {config.dim} dim, {config.n_heads} heads\")\n",
        "print(f\"Training Config: batch_size={train_config.batch_size}, max_steps={train_config.max_steps}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRZ_9mr5id-z",
        "outputId": "dc4dcd98-71ac-4e43-9571-7812a7ee4954"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model componentleri tanƒ±mlandƒ±\n"
          ]
        }
      ],
      "source": [
        "# === H√úCRE 4: MODEL COMPONENTLERƒ∞ ===================================\n",
        "\n",
        "# RMSNorm\n",
        "class RMSNorm(nn.Module):\n",
        "    def __init__(self, dim: int, eps: float = 1e-6):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.weight = nn.Parameter(torch.ones(dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        norm = x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
        "        return self.weight * norm\n",
        "\n",
        "# SwiGLU activation\n",
        "class SwiGLU(nn.Module):\n",
        "    def forward(self, x, gate):\n",
        "        return F.silu(gate) * x\n",
        "\n",
        "# FeedForward\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, config: ModelConfig):\n",
        "        super().__init__()\n",
        "        self.w1 = nn.Linear(config.dim, config.ffn_hidden_dim, bias=False)\n",
        "        self.w2 = nn.Linear(config.ffn_hidden_dim, config.dim, bias=False)\n",
        "        self.w3 = nn.Linear(config.dim, config.ffn_hidden_dim, bias=False)\n",
        "        self.swiglu = SwiGLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w2(self.swiglu(self.w1(x), self.w3(x)))\n",
        "\n",
        "print(\"Model componentleri tanƒ±mlandƒ±\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gR4Powzwif0r",
        "outputId": "e97512bc-c3e9-4ade-fa91-63d9b0f26fe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RoPE ve Attention tanƒ±mlandƒ±\n"
          ]
        }
      ],
      "source": [
        "# === H√úCRE 5: ROPE VE ATTENTION ===================================\n",
        "\n",
        "# RoPE fonksiyonlarƒ±\n",
        "def precompute_freqs_cis(dim: int, max_seq_len: int, theta: float = 10000.0):\n",
        "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
        "    t = torch.arange(max_seq_len, device=freqs.device)\n",
        "    freqs = torch.outer(t, freqs).float()\n",
        "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)\n",
        "    return freqs_cis\n",
        "\n",
        "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
        "    ndim = x.ndim\n",
        "    assert 0 <= 1 < ndim\n",
        "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
        "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
        "    return freqs_cis.view(*shape)\n",
        "\n",
        "def apply_rotary_emb(xq, xk, freqs_cis):\n",
        "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
        "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
        "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
        "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
        "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
        "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
        "\n",
        "# Attention\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.n_heads = config.n_heads\n",
        "        self.n_kv_heads = config.n_kv_heads\n",
        "        self.head_dim = config.head_dim\n",
        "        self.n_rep = self.n_heads // self.n_kv_heads\n",
        "\n",
        "        self.wq = nn.Linear(config.dim, config.n_heads * config.head_dim, bias=False)\n",
        "        self.wk = nn.Linear(config.dim, config.n_kv_heads * config.head_dim, bias=False)\n",
        "        self.wv = nn.Linear(config.dim, config.n_kv_heads * config.head_dim, bias=False)\n",
        "        self.wo = nn.Linear(config.n_heads * config.head_dim, config.dim, bias=False)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "\n",
        "    def forward(self, x, freqs_cis, mask=None):\n",
        "        bsz, seqlen, _ = x.shape\n",
        "\n",
        "        xq, xk, xv = self.wq(x), self.wk(x), self.wv(x)\n",
        "        xq = xq.view(bsz, seqlen, self.n_heads, self.head_dim)\n",
        "        xk = xk.view(bsz, seqlen, self.n_kv_heads, self.head_dim)\n",
        "        xv = xv.view(bsz, seqlen, self.n_kv_heads, self.head_dim)\n",
        "\n",
        "        xq, xk = apply_rotary_emb(xq, xk, freqs_cis)\n",
        "\n",
        "        if self.n_rep > 1:\n",
        "            xk = xk.unsqueeze(3).expand(-1, -1, -1, self.n_rep, -1).flatten(2, 3)\n",
        "            xv = xv.unsqueeze(3).expand(-1, -1, -1, self.n_rep, -1).flatten(2, 3)\n",
        "\n",
        "        xq = xq.transpose(1, 2)\n",
        "        xk = xk.transpose(1, 2)\n",
        "        xv = xv.transpose(1, 2)\n",
        "\n",
        "        scores = torch.matmul(xq, xk.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
        "        if mask is not None:\n",
        "            scores = scores + mask\n",
        "        scores = F.softmax(scores.float(), dim=-1).type_as(xq)\n",
        "        scores = self.dropout(scores)\n",
        "        output = torch.matmul(scores, xv)\n",
        "\n",
        "        output = output.transpose(1, 2).contiguous().view(bsz, seqlen, -1)\n",
        "        return self.wo(output)\n",
        "\n",
        "print(\"RoPE ve Attention tanƒ±mlandƒ±\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKtllILSiiID",
        "outputId": "fd792d1a-c6a3-4693-b3a1-025aeb30c000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model olu≈üturuldu: 120.0M parametre\n",
            "VRAM kullanƒ±mƒ±: 0.48 GB\n"
          ]
        }
      ],
      "source": [
        "# === H√úCRE 6: TRANSFORMER BLOCK VE ANA MODEL ===================================\n",
        "\n",
        "# Transformer Block\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.attention = Attention(config)\n",
        "        self.feed_forward = FeedForward(config)\n",
        "        self.attention_norm = RMSNorm(config.dim, eps=config.norm_eps)\n",
        "        self.ffn_norm = RMSNorm(config.dim, eps=config.norm_eps)\n",
        "\n",
        "    def forward(self, x, freqs_cis, mask=None):\n",
        "        h = x + self.attention(self.attention_norm(x), freqs_cis, mask)\n",
        "        out = h + self.feed_forward(self.ffn_norm(h))\n",
        "        return out\n",
        "\n",
        "# Ana Model\n",
        "class TurkishLLaMA(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.tok_embeddings = nn.Embedding(config.vocab_size, config.dim)\n",
        "        self.dropout = nn.Dropout(config.dropout)\n",
        "        self.layers = nn.ModuleList([TransformerBlock(config) for _ in range(config.n_layers)])\n",
        "        self.norm = RMSNorm(config.dim, eps=config.norm_eps)\n",
        "        self.output = nn.Linear(config.dim, config.vocab_size, bias=False)\n",
        "\n",
        "        self.register_buffer(\"freqs_cis\", precompute_freqs_cis(\n",
        "            config.head_dim, config.max_seq_len * 2, config.rope_theta\n",
        "        ))\n",
        "\n",
        "    def forward(self, tokens: torch.Tensor):\n",
        "        bsz, seqlen = tokens.shape\n",
        "        h = self.tok_embeddings(tokens)\n",
        "        h = self.dropout(h)\n",
        "\n",
        "        mask = torch.full((1, 1, seqlen, seqlen), float(\"-inf\"), device=tokens.device)\n",
        "        mask = torch.triu(mask, diagonal=1).type_as(h)\n",
        "\n",
        "        freqs_cis = self.freqs_cis[:seqlen]\n",
        "        for layer in self.layers:\n",
        "            h = layer(h, freqs_cis, mask)\n",
        "\n",
        "        h = self.norm(h)\n",
        "        output = self.output(h)\n",
        "        return output\n",
        "\n",
        "# Model olu≈ütur\n",
        "model = TurkishLLaMA(config).cuda()\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\" Model olu≈üturuldu: {total_params/1e6:.1f}M parametre\")\n",
        "print(f\" VRAM kullanƒ±mƒ±: {torch.cuda.memory_allocated()/1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lT_qs_fDikKz",
        "outputId": "413e9301-68e8-4cfb-e169-17916bd629f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Dataset sƒ±nƒ±fƒ± tanƒ±mlandƒ±\n"
          ]
        }
      ],
      "source": [
        "# === H√úCRE 7: DATASET SINIFI ===================================\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, file_path, tokenizer, max_length=1024, max_samples=None):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.samples = []\n",
        "\n",
        "        print(\" Veri y√ºkleniyor...\")\n",
        "        with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
        "            current_chunk = []\n",
        "            current_len = 0\n",
        "\n",
        "            for i, line in enumerate(tqdm(f, desc=\"Satƒ±rlar i≈üleniyor\", total=max_samples or 100000)):\n",
        "                if max_samples and len(self.samples) >= max_samples:\n",
        "                    break\n",
        "\n",
        "                tokens = tokenizer.encode(line.strip())\n",
        "                if not tokens:\n",
        "                    continue\n",
        "\n",
        "                if current_len + len(tokens) > max_length:\n",
        "                    if current_chunk:\n",
        "                        self.samples.append(current_chunk[:max_length])\n",
        "                    current_chunk = tokens\n",
        "                    current_len = len(tokens)\n",
        "                else:\n",
        "                    current_chunk.extend(tokens)\n",
        "                    current_len += len(tokens)\n",
        "\n",
        "            if current_chunk and len(current_chunk) > 100:\n",
        "                self.samples.append(current_chunk[:max_length])\n",
        "\n",
        "        print(f\" {len(self.samples):,} √∂rnek hazƒ±r\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.samples[idx]\n",
        "\n",
        "        if len(tokens) < self.max_length:\n",
        "            tokens = tokens + [self.tokenizer.pad_id()] * (self.max_length - len(tokens))\n",
        "\n",
        "        input_ids = torch.tensor(tokens[:-1], dtype=torch.long)\n",
        "        labels = torch.tensor(tokens[1:], dtype=torch.long)\n",
        "\n",
        "        return input_ids, labels\n",
        "\n",
        "print(\" Dataset sƒ±nƒ±fƒ± tanƒ±mlandƒ±\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1B-gEVQimJu",
        "outputId": "c1e8bf13-0172-4c6e-de26-3585f5427168"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 10M SATIRLIK B√úY√úK VERƒ∞ SETƒ∞ HAZIRLANIYOR\n",
            "\n",
            "üìö 10,000,000 satƒ±r okunacak...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Satƒ±rlar i≈üleniyor: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000000/10000000 [23:20<00:00, 7140.33it/s, √ñrnekler=400,000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "404,561 √∂rnek olu≈üturuldu\n",
            "Ortalama: 24.7 satƒ±r/√∂rnek\n",
            "\n",
            "============================================================\n",
            "üìä VERƒ∞ SETƒ∞ √ñZETƒ∞:\n",
            "  √ñrnek sayƒ±sƒ±: 404,561\n",
            "  Toplam token: ~414M\n",
            "  Token/parametre: 3.5\n",
            "  Batch size: 32\n",
            "  Batch count: 12,642\n",
            "  Tokens per batch: 32,768\n",
            "\n",
            "üìä Eƒûƒ∞Tƒ∞M PLANI:\n",
            "  Max steps: 50,000\n",
            "  Warmup steps: 2,000\n",
            "  Epoch sayƒ±sƒ±: ~4.0\n",
            "  Toplam token (training): ~1.6B\n",
            "\n",
            "üíæ BELLEK DURUMU:\n",
            "  Model VRAM: 0.48 GB\n",
            "  Toplam VRAM: 40 GB\n",
            "  Kullanƒ±labilir: 39.52 GB\n",
            "\n",
            "‚ö° TAHMƒ∞Nƒ∞ PERFORMANS:\n",
            "  Beklenen hƒ±z: ~200-250K token/saniye\n",
            "  Tahmini s√ºre: 2.3-1.8 saat\n",
            "\n",
            "Sƒ∞STEM HAZIR! Eƒüitim ba≈ülatƒ±labilir.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# === 10M SATIRLA VERƒ∞ Y√úKLEME (A100 40GB i√ßin optimal) ===================================\n",
        "\n",
        "import gc\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import gzip\n",
        "\n",
        "# Bellek temizliƒüi\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "print(\"10M SATIRLIK B√úY√úK VERƒ∞ SETƒ∞ HAZIRLANIYOR\")\n",
        "\n",
        "class OptimizedTextDataset(Dataset):\n",
        "    def __init__(self, file_path, tokenizer, max_length=1024, max_lines=10_000_000):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.samples = []\n",
        "\n",
        "        print(f\"üìö {max_lines:,} satƒ±r okunacak...\")\n",
        "\n",
        "        with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
        "            current_chunk = []\n",
        "            current_len = 0\n",
        "            lines_processed = 0\n",
        "\n",
        "            pbar = tqdm(total=max_lines, desc=\"Satƒ±rlar i≈üleniyor\")\n",
        "\n",
        "            for line in f:\n",
        "                if lines_processed >= max_lines:\n",
        "                    break\n",
        "\n",
        "                lines_processed += 1\n",
        "                pbar.update(1)\n",
        "\n",
        "                # Bo≈ü veya √ßok kƒ±sa satƒ±rlarƒ± atla\n",
        "                line = line.strip()\n",
        "                if len(line) < 30:  # Min 30 karakter\n",
        "                    continue\n",
        "\n",
        "                tokens = tokenizer.encode(line)\n",
        "                if not tokens or len(tokens) < 5:\n",
        "                    continue\n",
        "\n",
        "                # Chunk'lara b√∂l\n",
        "                if current_len + len(tokens) > max_length:\n",
        "                    if len(current_chunk) > 100:\n",
        "                        self.samples.append(current_chunk[:max_length])\n",
        "\n",
        "                        # Her 10K √∂rnekte durum bildir\n",
        "                        if len(self.samples) % 10000 == 0:\n",
        "                            pbar.set_postfix({\"√ñrnekler\": f\"{len(self.samples):,}\"})\n",
        "\n",
        "                    current_chunk = tokens\n",
        "                    current_len = len(tokens)\n",
        "                else:\n",
        "                    current_chunk.extend(tokens)\n",
        "                    current_len += len(tokens)\n",
        "\n",
        "            pbar.close()\n",
        "\n",
        "            # Son chunk\n",
        "            if len(current_chunk) > 100:\n",
        "                self.samples.append(current_chunk[:max_length])\n",
        "\n",
        "        print(f\"\\n {len(self.samples):,} √∂rnek olu≈üturuldu\")\n",
        "        print(f\" Ortalama: {lines_processed/len(self.samples):.1f} satƒ±r/√∂rnek\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.samples[idx]\n",
        "\n",
        "        if len(tokens) < self.max_length:\n",
        "            tokens = tokens + [self.tokenizer.pad_id()] * (self.max_length - len(tokens))\n",
        "\n",
        "        input_ids = torch.tensor(tokens[:-1], dtype=torch.long)\n",
        "        labels = torch.tensor(tokens[1:], dtype=torch.long)\n",
        "\n",
        "        return input_ids, labels\n",
        "\n",
        "# Dataset olu≈ütur\n",
        "dataset = OptimizedTextDataset(\n",
        "    DATA_PATH,\n",
        "    sp,\n",
        "    max_length=1024,\n",
        "    max_lines=10_000_000  # 10M satƒ±r\n",
        ")\n",
        "\n",
        "# A100 i√ßin optimal batch size\n",
        "BATCH_SIZE = 32  # VRAM'e g√∂re artƒ±rƒ±labilir\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "    drop_last=True,\n",
        "    persistent_workers=True\n",
        ")\n",
        "\n",
        "# Training config g√ºncelle\n",
        "train_config.batch_size = BATCH_SIZE\n",
        "train_config.max_steps = 50_000  # Yeterli step\n",
        "train_config.eval_interval = 500\n",
        "train_config.save_interval = 5000\n",
        "train_config.warmup_steps = 2000\n",
        "\n",
        "# Optimizer'ƒ± yeniden olu≈ütur\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=train_config.learning_rate,\n",
        "    weight_decay=train_config.weight_decay,\n",
        "    betas=(train_config.adam_beta1, train_config.adam_beta2),\n",
        "    fused=True  # A100 optimizasyonu\n",
        ")\n",
        "\n",
        "scaler = torch.amp.GradScaler('cuda')\n",
        "\n",
        "print(f\"\\n\" + \"=\"*60)\n",
        "print(f\" VERƒ∞ SETƒ∞ √ñZETƒ∞:\")\n",
        "print(f\"  √ñrnek sayƒ±sƒ±: {len(dataset):,}\")\n",
        "print(f\"  Toplam token: ~{len(dataset) * 1024 / 1e6:.0f}M\")\n",
        "print(f\"  Token/parametre: {(len(dataset) * 1024) / (120 * 1e6):.1f}\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  Batch count: {len(train_loader):,}\")\n",
        "print(f\"  Tokens per batch: {BATCH_SIZE * 1024:,}\")\n",
        "\n",
        "print(f\"\\n Eƒûƒ∞Tƒ∞M PLANI:\")\n",
        "print(f\"  Max steps: {train_config.max_steps:,}\")\n",
        "print(f\"  Warmup steps: {train_config.warmup_steps:,}\")\n",
        "print(f\"  Epoch sayƒ±sƒ±: ~{train_config.max_steps / len(train_loader):.1f}\")\n",
        "print(f\"  Toplam token (training): ~{train_config.max_steps * BATCH_SIZE * 1024 / 1e9:.1f}B\")\n",
        "\n",
        "print(f\"\\n BELLEK DURUMU:\")\n",
        "print(f\"  Model VRAM: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
        "print(f\"  Toplam VRAM: 40 GB\")\n",
        "print(f\"  Kullanƒ±labilir: {(40 - torch.cuda.memory_allocated()/1e9):.2f} GB\")\n",
        "\n",
        "print(f\"\\n TAHMƒ∞Nƒ∞ PERFORMANS:\")\n",
        "print(f\"  Beklenen hƒ±z: ~200-250K token/saniye\")\n",
        "print(f\"  Tahmini s√ºre: {train_config.max_steps * BATCH_SIZE * 1024 / (200_000 * 3600):.1f}-{train_config.max_steps * BATCH_SIZE * 1024 / (250_000 * 3600):.1f} saat\")\n",
        "\n",
        "print(f\"\\n Sƒ∞STEM HAZIR! Eƒüitim ba≈ülatƒ±labilir.\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FD0GfHreitwq",
        "outputId": "293c893a-41b3-42d8-d182-090f803e372f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚è≥ Veri y√ºklenmesini bekleyin, sonra bu h√ºcreyi √ßalƒ±≈ütƒ±rƒ±n:\n",
            "train_losses, eval_losses = train()\n"
          ]
        }
      ],
      "source": [
        "# === Eƒûƒ∞Tƒ∞M D√ñNG√úS√ú (A100 Optimized) ===================================\n",
        "\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Helper fonksiyonlar\n",
        "def get_lr(step, config):\n",
        "    \"\"\"Cosine learning rate schedule with warmup\"\"\"\n",
        "    if step < config.warmup_steps:\n",
        "        return config.learning_rate * step / config.warmup_steps\n",
        "    progress = (step - config.warmup_steps) / (config.max_steps - config.warmup_steps)\n",
        "    return config.learning_rate * 0.5 * (1.0 + np.cos(np.pi * progress))\n",
        "\n",
        "def format_time(seconds):\n",
        "    \"\"\"Saniyeyi saat:dakika:saniye formatƒ±na √ßevir\"\"\"\n",
        "    hours = int(seconds // 3600)\n",
        "    minutes = int((seconds % 3600) // 60)\n",
        "    seconds = int(seconds % 60)\n",
        "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
        "\n",
        "# Training step\n",
        "def train_step(model, batch, optimizer, scaler, config):\n",
        "    \"\"\"Tek training step\"\"\"\n",
        "    model.train()\n",
        "\n",
        "    inputs, targets = batch\n",
        "    inputs = inputs.cuda()\n",
        "    targets = targets.cuda()\n",
        "\n",
        "    # Mixed precision training\n",
        "    with torch.amp.autocast('cuda', enabled=config.use_amp):\n",
        "        logits = model(inputs)\n",
        "        loss = F.cross_entropy(\n",
        "            logits.view(-1, logits.size(-1)),\n",
        "            targets.view(-1),\n",
        "            ignore_index=sp.pad_id()\n",
        "        )\n",
        "\n",
        "    # Backward pass\n",
        "    scaler.scale(loss).backward()\n",
        "\n",
        "    # Gradient clipping\n",
        "    scaler.unscale_(optimizer)\n",
        "    grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip)\n",
        "\n",
        "    # Optimizer step\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "    return loss.item(), grad_norm.item()\n",
        "\n",
        "# Evaluation\n",
        "@torch.no_grad()\n",
        "def evaluate(model, data_loader, num_batches=50):\n",
        "    \"\"\"Model evaluation\"\"\"\n",
        "    model.eval()\n",
        "    losses = []\n",
        "\n",
        "    for i, (inputs, targets) in enumerate(data_loader):\n",
        "        if i >= num_batches:\n",
        "            break\n",
        "\n",
        "        inputs = inputs.cuda()\n",
        "        targets = targets.cuda()\n",
        "\n",
        "        logits = model(inputs)\n",
        "        loss = F.cross_entropy(\n",
        "            logits.view(-1, logits.size(-1)),\n",
        "            targets.view(-1),\n",
        "            ignore_index=sp.pad_id()\n",
        "        )\n",
        "        losses.append(loss.item())\n",
        "\n",
        "    model.train()\n",
        "    return np.mean(losses)\n",
        "\n",
        "# Text generation\n",
        "@torch.no_grad()\n",
        "def generate(model, prompt, max_tokens=50, temperature=0.8, top_p=0.9):\n",
        "    \"\"\"Generate text from prompt\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenize prompt\n",
        "    tokens = sp.encode(prompt)\n",
        "    tokens = torch.tensor([tokens], dtype=torch.long).cuda()\n",
        "\n",
        "    generated = []\n",
        "    for _ in range(max_tokens):\n",
        "        # Forward pass\n",
        "        with torch.amp.autocast('cuda', enabled=False):  # Generation'da amp kapalƒ±\n",
        "            logits = model(tokens)\n",
        "\n",
        "        logits = logits[:, -1, :] / temperature\n",
        "\n",
        "        # Top-p (nucleus) sampling\n",
        "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "        sorted_indices_to_remove = cumulative_probs > top_p\n",
        "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "        sorted_indices_to_remove[..., 0] = 0\n",
        "        indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)\n",
        "        logits[indices_to_remove] = float('-inf')\n",
        "\n",
        "        # Sample\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "        generated.append(next_token.item())\n",
        "\n",
        "        # Stop at EOS\n",
        "        if next_token.item() == sp.eos_id():\n",
        "            break\n",
        "\n",
        "        # Append token\n",
        "        tokens = torch.cat([tokens, next_token], dim=1)\n",
        "\n",
        "        # Truncate if too long\n",
        "        if tokens.shape[1] > config.max_seq_len:\n",
        "            tokens = tokens[:, -config.max_seq_len:]\n",
        "\n",
        "    model.train()\n",
        "    return sp.decode(generated)\n",
        "\n",
        "# Ana eƒüitim fonksiyonu\n",
        "def train():\n",
        "    \"\"\"Ana eƒüitim d√∂ng√ºs√º\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\" \"*25 + \"üöÄ Eƒûƒ∞Tƒ∞M BA≈ûLIYOR!\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Test prompts\n",
        "    test_prompts = [\n",
        "        \"Bug√ºn hava\",\n",
        "        \"T√ºrkiye'nin ba≈ükenti\",\n",
        "        \"Yapay zeka teknolojisi\",\n",
        "        \"ƒ∞nsanlar neden\",\n",
        "    ]\n",
        "\n",
        "    # Training state\n",
        "    step = 0\n",
        "    best_loss = float('inf')\n",
        "    train_losses = []\n",
        "    eval_losses = []\n",
        "\n",
        "    # Timing\n",
        "    start_time = time.time()\n",
        "    tokens_processed = 0\n",
        "\n",
        "    # Data iterator\n",
        "    train_iter = iter(train_loader)\n",
        "\n",
        "    # Initial evaluation\n",
        "    print(\"\\n Ba≈ülangƒ±√ß deƒüerlendirmesi...\")\n",
        "    initial_loss = evaluate(model, train_loader, num_batches=50)\n",
        "    print(f\"  Initial loss: {initial_loss:.4f}\")\n",
        "    print(f\"  Perplexity: {np.exp(initial_loss):.2f}\")\n",
        "\n",
        "    # Initial generation samples\n",
        "    print(\"\\n ƒ∞lk √ºretim √∂rnekleri:\")\n",
        "    for prompt in test_prompts[:2]:\n",
        "        output = generate(model, prompt, max_tokens=30, temperature=1.0)\n",
        "        print(f\"  '{prompt}' ‚Üí {output}\")\n",
        "\n",
        "    print(\"\\n\" + \"-\"*70)\n",
        "    print(\"Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    # Training loop\n",
        "    while step < train_config.max_steps:\n",
        "        try:\n",
        "            batch = next(train_iter)\n",
        "        except StopIteration:\n",
        "            train_iter = iter(train_loader)\n",
        "            batch = next(train_iter)\n",
        "\n",
        "        # Update learning rate\n",
        "        lr = get_lr(step, train_config)\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "        # Training step\n",
        "        loss, grad_norm = train_step(model, batch, optimizer, scaler, train_config)\n",
        "\n",
        "        train_losses.append(loss)\n",
        "        tokens_processed += train_config.batch_size * train_config.max_length\n",
        "        step += 1\n",
        "\n",
        "        # Logging\n",
        "        if step % train_config.log_interval == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            tokens_per_sec = tokens_processed / elapsed\n",
        "            progress = step / train_config.max_steps * 100\n",
        "\n",
        "            print(f\"{step:5d} | {loss:.4f} | {lr:.1e} | {grad_norm:.2f} | \"\n",
        "                  f\"{tokens_per_sec/1000:.1f}K | {format_time(elapsed)} | {progress:5.1f}%\")\n",
        "\n",
        "        # Evaluation\n",
        "        if step % train_config.eval_interval == 0:\n",
        "            print(\"\\n\" + \"=\"*70)\n",
        "            print(f\" EVALUATION @ Step {step}\")\n",
        "            print(\"-\"*70)\n",
        "\n",
        "            # Evaluate\n",
        "            eval_loss = evaluate(model, train_loader, num_batches=100)\n",
        "            eval_losses.append(eval_loss)\n",
        "\n",
        "            print(f\"  Eval loss: {eval_loss:.4f}\")\n",
        "            print(f\"  Perplexity: {np.exp(eval_loss):.2f}\")\n",
        "            print(f\"  Train loss (avg): {np.mean(train_losses[-100:]):.4f}\")\n",
        "\n",
        "            # Generation samples\n",
        "            print(\"\\n   √úretim √∂rnekleri:\")\n",
        "            for i, prompt in enumerate(test_prompts[:3]):\n",
        "                output = generate(model, prompt, max_tokens=40, temperature=0.8)\n",
        "                print(f\"    [{i+1}] '{prompt}' ‚Üí\")\n",
        "                print(f\"        {output}\")\n",
        "\n",
        "            # Best model\n",
        "            if eval_loss < best_loss:\n",
        "                best_loss = eval_loss\n",
        "                print(f\"\\n   Yeni en iyi model! (loss: {best_loss:.4f})\")\n",
        "\n",
        "                # Save best model\n",
        "                best_path = f\"{CHECKPOINT_DIR}/best_model.pt\"\n",
        "                torch.save({\n",
        "                    'step': step,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'loss': best_loss,\n",
        "                    'config': config,\n",
        "                }, best_path)\n",
        "\n",
        "            # Performance stats\n",
        "            elapsed = time.time() - start_time\n",
        "            tokens_per_sec = tokens_processed / elapsed\n",
        "            eta = (train_config.max_steps - step) / (step / elapsed)\n",
        "\n",
        "            print(f\"\\n   Performans:\")\n",
        "            print(f\"     Tokens/sec: {tokens_per_sec/1000:.1f}K\")\n",
        "            print(f\"     Steps/sec: {step/elapsed:.2f}\")\n",
        "            print(f\"     ETA: {format_time(eta)}\")\n",
        "\n",
        "            print(\"=\"*70 + \"\\n\")\n",
        "            print(\"Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\")\n",
        "            print(\"-\"*70)\n",
        "\n",
        "        # Checkpoint save\n",
        "        if step % train_config.save_interval == 0:\n",
        "            checkpoint_path = f\"{CHECKPOINT_DIR}/checkpoint_step_{step}.pt\"\n",
        "            print(f\"\\n Checkpoint kaydediliyor: {checkpoint_path}\")\n",
        "\n",
        "            torch.save({\n",
        "                'step': step,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': loss,\n",
        "                'config': config,\n",
        "                'train_losses': train_losses,\n",
        "                'eval_losses': eval_losses,\n",
        "            }, checkpoint_path)\n",
        "\n",
        "            print(f\"   Checkpoint kaydedildi!\\n\")\n",
        "\n",
        "        # Early stopping check\n",
        "        if step > 1000 and loss > 15.0:\n",
        "            print(\"\\n Model diverge ediyor! Eƒüitim durduruluyor.\")\n",
        "            break\n",
        "\n",
        "    # Training complete\n",
        "    total_time = time.time() - start_time\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\" \"*25 + \" Eƒûƒ∞Tƒ∞M TAMAMLANDI!\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"\\n Final ƒ∞statistikler:\")\n",
        "    print(f\"  Toplam s√ºre: {format_time(total_time)}\")\n",
        "    print(f\"  Toplam step: {step:,}\")\n",
        "    print(f\"  Toplam token: {tokens_processed/1e9:.2f}B\")\n",
        "    print(f\"  Final loss: {loss:.4f}\")\n",
        "    print(f\"  Best eval loss: {best_loss:.4f}\")\n",
        "    print(f\"  Ortalama hƒ±z: {tokens_processed/(total_time*1000):.1f}K token/s\")\n",
        "\n",
        "    # Save final model\n",
        "    final_path = f\"{CHECKPOINT_DIR}/final_model.pt\"\n",
        "    torch.save({\n",
        "        'step': step,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss,\n",
        "        'config': config,\n",
        "        'train_losses': train_losses,\n",
        "        'eval_losses': eval_losses,\n",
        "        'total_time': total_time,\n",
        "    }, final_path)\n",
        "\n",
        "    print(f\"\\n Final model kaydedildi: {final_path}\")\n",
        "\n",
        "    # Final generation samples\n",
        "    print(\"\\n Final √ºretim √∂rnekleri:\")\n",
        "    for prompt in test_prompts:\n",
        "        output = generate(model, prompt, max_tokens=50, temperature=0.7)\n",
        "        print(f\"\\n'{prompt}':\")\n",
        "        print(f\"  ‚Üí {output}\")\n",
        "\n",
        "    return train_losses, eval_losses\n",
        "\n",
        "# Eƒüitimi ba≈ülat (veri y√ºklendikten sonra √ßalƒ±≈ütƒ±rƒ±n)\n",
        "print(\"\\n Veri y√ºklenmesini bekleyin, sonra bu h√ºcreyi √ßalƒ±≈ütƒ±rƒ±n:\")\n",
        "print(\"train_losses, eval_losses = train()\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === BELLEK TEMƒ∞ZLEME VE OPTƒ∞Mƒ∞ZASYON ===================================\n",
        "\n",
        "import gc\n",
        "import torch\n",
        "\n",
        "# Belleƒüi tamamen temizle\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "print(\"üßπ GPU belleƒüi temizlendi\")\n",
        "print(f\" Mevcut VRAM: {torch.cuda.memory_allocated()/1e9:.2f} GB\\n\")\n",
        "\n",
        "# Batch size'ƒ± d√º≈ü√ºr\n",
        "OPTIMAL_BATCH_SIZE = 8  # 32'den 8'e d√º≈ü√ºr\n",
        "GRADIENT_ACCUMULATION = 4  # Efektif batch size: 32\n",
        "\n",
        "# DataLoader'ƒ± yeniden olu≈ütur\n",
        "train_loader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=OPTIMAL_BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True,\n",
        "    drop_last=True\n",
        ")\n",
        "\n",
        "# Config g√ºncelle\n",
        "train_config.batch_size = OPTIMAL_BATCH_SIZE\n",
        "train_config.gradient_accumulation = GRADIENT_ACCUMULATION\n",
        "\n",
        "print(f\" Yeni ayarlar:\")\n",
        "print(f\"  Batch size: {OPTIMAL_BATCH_SIZE}\")\n",
        "print(f\"  Gradient accumulation: {GRADIENT_ACCUMULATION}\")\n",
        "print(f\"  Efektif batch size: {OPTIMAL_BATCH_SIZE * GRADIENT_ACCUMULATION}\")\n",
        "print(f\"  Batch count: {len(train_loader):,}\")\n",
        "\n",
        "# Optimizer'ƒ± yeniden olu≈ütur\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=train_config.learning_rate,\n",
        "    weight_decay=train_config.weight_decay,\n",
        "    betas=(train_config.adam_beta1, train_config.adam_beta2)\n",
        ")\n",
        "\n",
        "scaler = torch.amp.GradScaler('cuda')\n",
        "\n",
        "# PYTORCH_CUDA_ALLOC_CONF ayarla\n",
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "print(f\"\\n VRAM Durumu:\")\n",
        "print(f\"  Kullanƒ±lan: {torch.cuda.memory_allocated()/1e9:.2f} GB\")\n",
        "print(f\"  Toplam: 40 GB\")\n",
        "print(f\"  Bo≈ü: {(40 - torch.cuda.memory_allocated()/1e9):.2f} GB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XENxpKa7H5U9",
        "outputId": "8f92e020-8f10-4bc8-8007-7cd9a5da5909"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " GPU belleƒüi temizlendi\n",
            " Mevcut VRAM: 1.54 GB\n",
            "\n",
            " Yeni ayarlar:\n",
            "  Batch size: 8\n",
            "  Gradient accumulation: 4\n",
            "  Efektif batch size: 32\n",
            "  Batch count: 50,570\n",
            "\n",
            " VRAM Durumu:\n",
            "  Kullanƒ±lan: 1.54 GB\n",
            "  Toplam: 40 GB\n",
            "  Bo≈ü: 38.46 GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === GRADIENT ACCUMULATION'LI TRAINING STEP ===================================\n",
        "\n",
        "def train_step_with_accumulation(model, data_loader, optimizer, scaler, config, step):\n",
        "    \"\"\"Gradient accumulation ile training step\"\"\"\n",
        "    model.train()\n",
        "\n",
        "    total_loss = 0\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "    # Gradient accumulation loop\n",
        "    for micro_step in range(config.gradient_accumulation):\n",
        "        try:\n",
        "            batch = next(data_loader)\n",
        "        except StopIteration:\n",
        "            data_loader = iter(train_loader)\n",
        "            batch = next(data_loader)\n",
        "\n",
        "        inputs, targets = batch\n",
        "        inputs = inputs.cuda()\n",
        "        targets = targets.cuda()\n",
        "\n",
        "        # Forward pass\n",
        "        with torch.amp.autocast('cuda', enabled=config.use_amp):\n",
        "            logits = model(inputs)\n",
        "            loss = F.cross_entropy(\n",
        "                logits.view(-1, logits.size(-1)),\n",
        "                targets.view(-1),\n",
        "                ignore_index=sp.pad_id()\n",
        "            )\n",
        "            loss = loss / config.gradient_accumulation  # Scale loss\n",
        "\n",
        "        # Backward pass\n",
        "        scaler.scale(loss).backward()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Optimizer step (her N micro-step'te bir)\n",
        "    scaler.unscale_(optimizer)\n",
        "    grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip)\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()\n",
        "\n",
        "    return total_loss * config.gradient_accumulation, grad_norm.item()\n",
        "\n",
        "# train() fonksiyonunda train_step yerine train_step_with_accumulation kullan\n",
        "print(\"\\n Sistem optimize edildi!\")\n",
        "print(\" Eƒüitimi tekrar ba≈ülatabilirsiniz:\")\n",
        "print(\"train_losses, eval_losses = train()\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QH9E9d0BOnV6",
        "outputId": "0c666b3b-5478-4446-c2b1-65c3bd04ed57"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Sistem optimize edildi!\n",
            "train_losses, eval_losses = train()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Eƒûƒ∞Tƒ∞Mƒ∞ BA≈ûLAT ===================================\n",
        "\n",
        "# Veri y√ºklendiƒüini kontrol et\n",
        "try:\n",
        "    print(f\" Dataset hazƒ±r: {len(dataset):,} √∂rnek\")\n",
        "    print(f\" DataLoader hazƒ±r: {len(train_loader):,} batch\")\n",
        "    print(f\" Model hazƒ±r: {sum(p.numel() for p in model.parameters())/1e6:.1f}M parametre\")\n",
        "    print(f\" VRAM: {torch.cuda.memory_allocated()/1e9:.2f}/{40:.0f} GB\\n\")\n",
        "\n",
        "    # Eƒüitimi ba≈ülat\n",
        "    train_losses, eval_losses = train()\n",
        "\n",
        "except NameError as e:\n",
        "    print(f\" Hata: {e}\")\n",
        "    print(\"√ñnce veri y√ºkleme h√ºcresinin bitmesini bekleyin!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jt-GpJ8mO1ef",
        "outputId": "e5965356-4cce-4e3f-d41c-1ec750547bfb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mG√∂r√ºnt√ºlenen √ßƒ±kƒ±≈ü son 5000 satƒ±ra kƒ±saltƒ±ldƒ±.\u001b[0m\n",
            "17050 | 4.6403 | 3.9e-04 | 0.89 | 38.6K | 01:00:20 |  34.1%\n",
            "17060 | 4.6486 | 3.9e-04 | 0.92 | 38.6K | 01:00:22 |  34.1%\n",
            "17070 | 4.5201 | 3.9e-04 | 0.99 | 38.6K | 01:00:24 |  34.1%\n",
            "17080 | 4.5719 | 3.9e-04 | 0.93 | 38.6K | 01:00:25 |  34.2%\n",
            "17090 | 4.7263 | 3.9e-04 | 0.97 | 38.6K | 01:00:27 |  34.2%\n",
            "17100 | 4.4889 | 3.9e-04 | 0.91 | 38.6K | 01:00:29 |  34.2%\n",
            "17110 | 4.6243 | 3.9e-04 | 0.92 | 38.6K | 01:00:30 |  34.2%\n",
            "17120 | 4.6772 | 3.9e-04 | 0.96 | 38.6K | 01:00:32 |  34.2%\n",
            "17130 | 4.6167 | 3.9e-04 | 0.95 | 38.6K | 01:00:34 |  34.3%\n",
            "17140 | 4.5441 | 3.9e-04 | 0.91 | 38.6K | 01:00:36 |  34.3%\n",
            "17150 | 4.6358 | 3.9e-04 | 0.92 | 38.6K | 01:00:37 |  34.3%\n",
            "17160 | 4.6652 | 3.9e-04 | 0.93 | 38.6K | 01:00:39 |  34.3%\n",
            "17170 | 4.6051 | 3.9e-04 | 0.91 | 38.6K | 01:00:41 |  34.3%\n",
            "17180 | 4.6446 | 3.9e-04 | 0.90 | 38.6K | 01:00:42 |  34.4%\n",
            "17190 | 4.5981 | 3.9e-04 | 0.93 | 38.6K | 01:00:44 |  34.4%\n",
            "17200 | 4.5814 | 3.9e-04 | 0.91 | 38.6K | 01:00:46 |  34.4%\n",
            "17210 | 4.8100 | 3.9e-04 | 0.90 | 38.6K | 01:00:48 |  34.4%\n",
            "17220 | 4.5021 | 3.9e-04 | 1.01 | 38.7K | 01:00:49 |  34.4%\n",
            "17230 | 4.3308 | 3.9e-04 | 0.99 | 38.7K | 01:00:51 |  34.5%\n",
            "17240 | 4.4855 | 3.9e-04 | 1.02 | 38.7K | 01:00:53 |  34.5%\n",
            "17250 | 4.7194 | 3.9e-04 | 0.96 | 38.7K | 01:00:54 |  34.5%\n",
            "17260 | 4.3949 | 3.9e-04 | 0.98 | 38.7K | 01:00:56 |  34.5%\n",
            "17270 | 4.6419 | 3.9e-04 | 1.01 | 38.7K | 01:00:58 |  34.5%\n",
            "17280 | 4.8110 | 3.9e-04 | 0.91 | 38.7K | 01:01:00 |  34.6%\n",
            "17290 | 4.4734 | 3.8e-04 | 0.97 | 38.7K | 01:01:01 |  34.6%\n",
            "17300 | 4.6455 | 3.8e-04 | 0.96 | 38.7K | 01:01:03 |  34.6%\n",
            "17310 | 4.7039 | 3.8e-04 | 0.91 | 38.7K | 01:01:05 |  34.6%\n",
            "17320 | 4.4760 | 3.8e-04 | 0.94 | 38.7K | 01:01:06 |  34.6%\n",
            "17330 | 4.6009 | 3.8e-04 | 0.93 | 38.7K | 01:01:08 |  34.7%\n",
            "17340 | 4.4310 | 3.8e-04 | 1.11 | 38.7K | 01:01:10 |  34.7%\n",
            "17350 | 4.4785 | 3.8e-04 | 0.91 | 38.7K | 01:01:12 |  34.7%\n",
            "17360 | 4.7936 | 3.8e-04 | 0.97 | 38.7K | 01:01:13 |  34.7%\n",
            "17370 | 4.7287 | 3.8e-04 | 0.93 | 38.7K | 01:01:15 |  34.7%\n",
            "17380 | 4.7556 | 3.8e-04 | 0.88 | 38.7K | 01:01:17 |  34.8%\n",
            "17390 | 4.8929 | 3.8e-04 | 0.92 | 38.7K | 01:01:18 |  34.8%\n",
            "17400 | 4.4046 | 3.8e-04 | 0.94 | 38.7K | 01:01:20 |  34.8%\n",
            "17410 | 4.6182 | 3.8e-04 | 0.93 | 38.7K | 01:01:22 |  34.8%\n",
            "17420 | 4.5264 | 3.8e-04 | 0.98 | 38.7K | 01:01:24 |  34.8%\n",
            "17430 | 4.4829 | 3.8e-04 | 0.92 | 38.7K | 01:01:25 |  34.9%\n",
            "17440 | 4.7710 | 3.8e-04 | 0.91 | 38.7K | 01:01:27 |  34.9%\n",
            "17450 | 4.1770 | 3.8e-04 | 1.53 | 38.7K | 01:01:29 |  34.9%\n",
            "17460 | 4.6141 | 3.8e-04 | 0.93 | 38.8K | 01:01:30 |  34.9%\n",
            "17470 | 4.8251 | 3.8e-04 | 0.94 | 38.8K | 01:01:32 |  34.9%\n",
            "17480 | 4.5095 | 3.8e-04 | 0.94 | 38.8K | 01:01:34 |  35.0%\n",
            "17490 | 4.5382 | 3.8e-04 | 0.93 | 38.8K | 01:01:35 |  35.0%\n",
            "17500 | 4.5617 | 3.8e-04 | 0.90 | 38.8K | 01:01:37 |  35.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 17500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.5842\n",
            "  Perplexity: 97.92\n",
            "  Train loss (avg): 4.5957\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        sƒ±caklƒ±klarƒ± d√º≈ü√ºkse kƒ±≈ü aylarƒ±nda sƒ±caklƒ±ƒüƒ±n en y√ºksek olduƒüu ve en sƒ±cak olan bir sƒ±caklƒ±ƒüa sahip olan terlik, grip, grip, grip, bron≈üit, grip, grip gibi hastalƒ±klara kar≈üƒ± sava≈ütƒ±ƒüƒ±\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        ve d√ºnyanƒ±n en b√ºy√ºk ve en b√ºy√ºk halklarƒ±nƒ±n katƒ±ldƒ±ƒüƒ± \"Silahlƒ±\". UNESCO'nun ba≈ükenti ve d√ºnya genelindeki t√ºm √ºlke vatanda≈ülarƒ±nƒ±n katƒ±ldƒ±ƒüƒ± \"Silahlƒ± Kent\" ve \"Astantlƒ±\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , g√ºn√ºm√ºzde, teknolojik giri≈üimlerin ve sosyal ekosistemin geli≈ümesine, bilimsel ve dijitalle≈üme alƒ±≈ükanlƒ±ƒüƒ±nƒ±n geli≈ütirilmesine kadar pek √ßok alanda √∂nemli akt√∂rler haline gelmi≈ütir. Bu baƒülamda, yapay zeka, k√ºt√ºphane, ev-\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.5842)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.71\n",
            "     ETA: 01:55:05\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "17510 | 4.5931 | 3.8e-04 | 0.94 | 38.6K | 01:02:00 |  35.0%\n",
            "17520 | 4.1729 | 3.8e-04 | 1.00 | 38.6K | 01:02:01 |  35.0%\n",
            "17530 | 4.6902 | 3.8e-04 | 0.91 | 38.6K | 01:02:03 |  35.1%\n",
            "17540 | 4.6710 | 3.8e-04 | 0.90 | 38.6K | 01:02:05 |  35.1%\n",
            "17550 | 4.5302 | 3.8e-04 | 0.93 | 38.6K | 01:02:07 |  35.1%\n",
            "17560 | 4.8319 | 3.8e-04 | 0.95 | 38.6K | 01:02:08 |  35.1%\n",
            "17570 | 4.6848 | 3.8e-04 | 0.91 | 38.6K | 01:02:10 |  35.1%\n",
            "17580 | 4.7484 | 3.8e-04 | 0.98 | 38.6K | 01:02:12 |  35.2%\n",
            "17590 | 4.5371 | 3.8e-04 | 1.00 | 38.6K | 01:02:13 |  35.2%\n",
            "17600 | 4.7008 | 3.8e-04 | 0.96 | 38.6K | 01:02:15 |  35.2%\n",
            "17610 | 4.5617 | 3.8e-04 | 0.91 | 38.6K | 01:02:17 |  35.2%\n",
            "17620 | 4.6905 | 3.8e-04 | 0.91 | 38.6K | 01:02:19 |  35.2%\n",
            "17630 | 4.7018 | 3.8e-04 | 0.95 | 38.6K | 01:02:20 |  35.3%\n",
            "17640 | 4.8154 | 3.8e-04 | 0.94 | 38.6K | 01:02:22 |  35.3%\n",
            "17650 | 4.7043 | 3.8e-04 | 0.91 | 38.6K | 01:02:24 |  35.3%\n",
            "17660 | 4.5573 | 3.8e-04 | 1.05 | 38.6K | 01:02:25 |  35.3%\n",
            "17670 | 4.5851 | 3.8e-04 | 0.95 | 38.6K | 01:02:27 |  35.3%\n",
            "17680 | 4.7006 | 3.8e-04 | 1.00 | 38.6K | 01:02:29 |  35.4%\n",
            "17690 | 4.4586 | 3.8e-04 | 0.95 | 38.6K | 01:02:31 |  35.4%\n",
            "17700 | 4.7871 | 3.8e-04 | 0.92 | 38.6K | 01:02:32 |  35.4%\n",
            "17710 | 4.6827 | 3.8e-04 | 0.91 | 38.6K | 01:02:34 |  35.4%\n",
            "17720 | 4.4409 | 3.8e-04 | 0.95 | 38.6K | 01:02:36 |  35.4%\n",
            "17730 | 4.5099 | 3.8e-04 | 0.97 | 38.7K | 01:02:37 |  35.5%\n",
            "17740 | 4.6519 | 3.8e-04 | 0.95 | 38.7K | 01:02:39 |  35.5%\n",
            "17750 | 4.5653 | 3.8e-04 | 1.01 | 38.7K | 01:02:41 |  35.5%\n",
            "17760 | 4.7751 | 3.8e-04 | 0.92 | 38.7K | 01:02:43 |  35.5%\n",
            "17770 | 4.6912 | 3.8e-04 | 0.91 | 38.7K | 01:02:44 |  35.5%\n",
            "17780 | 4.7174 | 3.8e-04 | 0.95 | 38.7K | 01:02:46 |  35.6%\n",
            "17790 | 4.8509 | 3.8e-04 | 0.93 | 38.7K | 01:02:48 |  35.6%\n",
            "17800 | 4.7406 | 3.8e-04 | 1.00 | 38.7K | 01:02:49 |  35.6%\n",
            "17810 | 4.5699 | 3.8e-04 | 0.92 | 38.7K | 01:02:51 |  35.6%\n",
            "17820 | 4.1645 | 3.8e-04 | 1.08 | 38.7K | 01:02:53 |  35.6%\n",
            "17830 | 4.5813 | 3.8e-04 | 1.04 | 38.7K | 01:02:55 |  35.7%\n",
            "17840 | 4.2549 | 3.8e-04 | 0.91 | 38.7K | 01:02:56 |  35.7%\n",
            "17850 | 4.7585 | 3.8e-04 | 0.93 | 38.7K | 01:02:58 |  35.7%\n",
            "17860 | 4.6176 | 3.8e-04 | 0.98 | 38.7K | 01:03:00 |  35.7%\n",
            "17870 | 4.8348 | 3.8e-04 | 0.92 | 38.7K | 01:03:01 |  35.7%\n",
            "17880 | 4.5652 | 3.8e-04 | 0.94 | 38.7K | 01:03:03 |  35.8%\n",
            "17890 | 4.7113 | 3.8e-04 | 0.91 | 38.7K | 01:03:05 |  35.8%\n",
            "17900 | 4.5212 | 3.8e-04 | 0.99 | 38.7K | 01:03:07 |  35.8%\n",
            "17910 | 4.5618 | 3.8e-04 | 0.90 | 38.7K | 01:03:08 |  35.8%\n",
            "17920 | 4.7030 | 3.8e-04 | 0.97 | 38.7K | 01:03:10 |  35.8%\n",
            "17930 | 4.8365 | 3.8e-04 | 0.92 | 38.7K | 01:03:12 |  35.9%\n",
            "17940 | 4.5032 | 3.8e-04 | 0.98 | 38.7K | 01:03:13 |  35.9%\n",
            "17950 | 4.4759 | 3.8e-04 | 0.95 | 38.7K | 01:03:15 |  35.9%\n",
            "17960 | 4.8598 | 3.8e-04 | 0.94 | 38.7K | 01:03:17 |  35.9%\n",
            "17970 | 4.7818 | 3.8e-04 | 1.01 | 38.7K | 01:03:19 |  35.9%\n",
            "17980 | 4.7562 | 3.8e-04 | 0.94 | 38.8K | 01:03:20 |  36.0%\n",
            "17990 | 4.6198 | 3.8e-04 | 0.94 | 38.8K | 01:03:22 |  36.0%\n",
            "18000 | 4.6864 | 3.8e-04 | 0.97 | 38.8K | 01:03:24 |  36.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 18000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.5586\n",
            "  Perplexity: 95.45\n",
            "  Train loss (avg): 4.6176\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        sƒ±caklƒ±ƒüƒ±nƒ±n 300 ile 400 bandƒ±nda olduƒüu tahmin ediliyor. Hava sƒ±caklƒ±ƒüƒ±nƒ±n 400 ile 350 bandƒ±nda olduƒüu tahmin ediliyor. Hava sƒ±caklƒ±ƒüƒ±nƒ±n 400 ile 300 bandƒ±nda olduƒüu tahmin ediliyor. Hava sƒ±caklƒ±ƒüƒ±nƒ±n 70 ile\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Antalya'da bulunan tarihi ve turistik yerleri gezme imkanƒ±. Antalya'da ≈üehrin en g√ºzel yerlerinden biri olan ve i√ßerisinde bir√ßok tarihi yapƒ±larƒ±, tarihi ve turistik mekanlarƒ±, tarihini, tarihini, tarihini, tarihini,\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        ve yapay zeka teknolojisi sayesinde insan sanal ger√ßeklik olarak algƒ±lanabilir. Ancak teknoloji, g√ºnl√ºk ya≈üantƒ±mƒ±zda onlarƒ±n ger√ßek ve sezgisel g√∂zlemler, robotlar ve robotlar i√ßin yeni teknoloji t√ºrlerini i√ßeren teknolojik verileri\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.5586)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.71\n",
            "     ETA: 01:53:19\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "18010 | 4.3230 | 3.7e-04 | 1.04 | 38.6K | 01:03:46 |  36.0%\n",
            "18020 | 4.6833 | 3.7e-04 | 0.94 | 38.6K | 01:03:48 |  36.0%\n",
            "18030 | 4.5749 | 3.7e-04 | 1.05 | 38.6K | 01:03:50 |  36.1%\n",
            "18040 | 4.4938 | 3.7e-04 | 0.92 | 38.6K | 01:03:51 |  36.1%\n",
            "18050 | 4.4774 | 3.7e-04 | 1.01 | 38.6K | 01:03:53 |  36.1%\n",
            "18060 | 4.6612 | 3.7e-04 | 1.13 | 38.6K | 01:03:55 |  36.1%\n",
            "18070 | 4.6988 | 3.7e-04 | 0.93 | 38.6K | 01:03:56 |  36.1%\n",
            "18080 | 4.7359 | 3.7e-04 | 0.94 | 38.6K | 01:03:58 |  36.2%\n",
            "18090 | 4.6143 | 3.7e-04 | 0.96 | 38.6K | 01:04:00 |  36.2%\n",
            "18100 | 4.5059 | 3.7e-04 | 1.00 | 38.6K | 01:04:02 |  36.2%\n",
            "18110 | 4.6119 | 3.7e-04 | 0.97 | 38.6K | 01:04:03 |  36.2%\n",
            "18120 | 4.5778 | 3.7e-04 | 0.91 | 38.6K | 01:04:05 |  36.2%\n",
            "18130 | 4.6366 | 3.7e-04 | 0.98 | 38.6K | 01:04:07 |  36.3%\n",
            "18140 | 4.6158 | 3.7e-04 | 0.93 | 38.6K | 01:04:08 |  36.3%\n",
            "18150 | 4.4299 | 3.7e-04 | 0.98 | 38.6K | 01:04:10 |  36.3%\n",
            "18160 | 4.7519 | 3.7e-04 | 0.99 | 38.6K | 01:04:12 |  36.3%\n",
            "18170 | 4.6396 | 3.7e-04 | 0.94 | 38.6K | 01:04:14 |  36.3%\n",
            "18180 | 4.7124 | 3.7e-04 | 0.90 | 38.6K | 01:04:15 |  36.4%\n",
            "18190 | 4.5583 | 3.7e-04 | 1.05 | 38.6K | 01:04:17 |  36.4%\n",
            "18200 | 4.8592 | 3.7e-04 | 0.91 | 38.6K | 01:04:19 |  36.4%\n",
            "18210 | 4.6476 | 3.7e-04 | 1.00 | 38.6K | 01:04:20 |  36.4%\n",
            "18220 | 4.6224 | 3.7e-04 | 0.95 | 38.6K | 01:04:22 |  36.4%\n",
            "18230 | 4.7086 | 3.7e-04 | 0.95 | 38.6K | 01:04:24 |  36.5%\n",
            "18240 | 4.4395 | 3.7e-04 | 0.96 | 38.7K | 01:04:26 |  36.5%\n",
            "18250 | 4.5014 | 3.7e-04 | 0.91 | 38.7K | 01:04:27 |  36.5%\n",
            "18260 | 4.6304 | 3.7e-04 | 0.91 | 38.7K | 01:04:29 |  36.5%\n",
            "18270 | 4.3691 | 3.7e-04 | 1.04 | 38.7K | 01:04:31 |  36.5%\n",
            "18280 | 4.7342 | 3.7e-04 | 0.97 | 38.7K | 01:04:32 |  36.6%\n",
            "18290 | 4.3917 | 3.7e-04 | 1.00 | 38.7K | 01:04:34 |  36.6%\n",
            "18300 | 4.7063 | 3.7e-04 | 0.95 | 38.7K | 01:04:36 |  36.6%\n",
            "18310 | 4.5486 | 3.7e-04 | 0.93 | 38.7K | 01:04:38 |  36.6%\n",
            "18320 | 4.6147 | 3.7e-04 | 0.96 | 38.7K | 01:04:39 |  36.6%\n",
            "18330 | 4.7051 | 3.7e-04 | 0.94 | 38.7K | 01:04:41 |  36.7%\n",
            "18340 | 4.6957 | 3.7e-04 | 0.95 | 38.7K | 01:04:43 |  36.7%\n",
            "18350 | 4.6875 | 3.7e-04 | 0.93 | 38.7K | 01:04:44 |  36.7%\n",
            "18360 | 4.6466 | 3.7e-04 | 0.95 | 38.7K | 01:04:46 |  36.7%\n",
            "18370 | 4.6831 | 3.7e-04 | 0.94 | 38.7K | 01:04:48 |  36.7%\n",
            "18380 | 4.7451 | 3.7e-04 | 0.93 | 38.7K | 01:04:50 |  36.8%\n",
            "18390 | 4.7153 | 3.7e-04 | 0.92 | 38.7K | 01:04:51 |  36.8%\n",
            "18400 | 4.6722 | 3.7e-04 | 0.95 | 38.7K | 01:04:53 |  36.8%\n",
            "18410 | 4.5816 | 3.7e-04 | 0.92 | 38.7K | 01:04:55 |  36.8%\n",
            "18420 | 4.3175 | 3.7e-04 | 0.98 | 38.7K | 01:04:56 |  36.8%\n",
            "18430 | 4.6589 | 3.7e-04 | 0.99 | 38.7K | 01:04:58 |  36.9%\n",
            "18440 | 4.8814 | 3.7e-04 | 0.93 | 38.7K | 01:05:00 |  36.9%\n",
            "18450 | 4.7954 | 3.7e-04 | 0.98 | 38.7K | 01:05:02 |  36.9%\n",
            "18460 | 4.4478 | 3.7e-04 | 0.93 | 38.7K | 01:05:03 |  36.9%\n",
            "18470 | 4.8682 | 3.7e-04 | 0.95 | 38.7K | 01:05:05 |  36.9%\n",
            "18480 | 4.2712 | 3.7e-04 | 1.01 | 38.7K | 01:05:07 |  37.0%\n",
            "18490 | 4.7802 | 3.7e-04 | 0.97 | 38.8K | 01:05:08 |  37.0%\n",
            "18500 | 4.6087 | 3.7e-04 | 0.96 | 38.8K | 01:05:10 |  37.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 18500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.5451\n",
            "  Perplexity: 94.17\n",
            "  Train loss (avg): 4.6112\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        durumu, hava ≈üartlarƒ±, hava ko≈üullarƒ±, hava ko≈üullarƒ± ve dikkat s√ºresi gibi unsurlar ile ilgili olarak, 2003-2009 yƒ±llarƒ± arasƒ±nda, T√ºrkiye'de, Refahiye Mahsulleri Ofisi'nde g√∂revli olarak\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Washington'da bulunan Katowers'ƒ±n hizmet binasƒ±, her yƒ±l ev yapƒ±mƒ± sokaklardan olu≈üuyor. Var≈üova'nƒ±n batƒ± kƒ±yƒ±sƒ±nda yer aldƒ±ƒüƒ± Katowers'ƒ±n burada da bulunduƒüu ileri karakol,\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        sayesinde sadece 20 dakikada bir arada √ßalƒ±≈üabilme imkanƒ±nƒ±z var mƒ±? Microsoft artƒ±k bu hizmete a√ßƒ±k deƒüil. Ki≈üiselle≈ütirilmi≈ü i√ßerikte de kendi √ºrettikleri telefon √ºzerinden Office veya IOS i√ßin √ßalƒ±≈üan bir √ºlke haline geliyorlar\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.5451)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.71\n",
            "     ETA: 01:51:33\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "18510 | 4.7507 | 3.7e-04 | 0.95 | 38.6K | 01:05:32 |  37.0%\n",
            "18520 | 4.5066 | 3.7e-04 | 0.92 | 38.6K | 01:05:34 |  37.0%\n",
            "18530 | 4.5711 | 3.7e-04 | 0.93 | 38.6K | 01:05:36 |  37.1%\n",
            "18540 | 4.3525 | 3.7e-04 | 1.08 | 38.6K | 01:05:38 |  37.1%\n",
            "18550 | 4.3188 | 3.7e-04 | 0.96 | 38.6K | 01:05:39 |  37.1%\n",
            "18560 | 4.7873 | 3.7e-04 | 1.01 | 38.6K | 01:05:41 |  37.1%\n",
            "18570 | 4.2072 | 3.7e-04 | 1.87 | 38.6K | 01:05:43 |  37.1%\n",
            "18580 | 4.8041 | 3.7e-04 | 0.95 | 38.6K | 01:05:44 |  37.2%\n",
            "18590 | 4.3685 | 3.7e-04 | 0.99 | 38.6K | 01:05:46 |  37.2%\n",
            "18600 | 4.4054 | 3.7e-04 | 1.02 | 38.6K | 01:05:48 |  37.2%\n",
            "18610 | 4.5332 | 3.7e-04 | 0.97 | 38.6K | 01:05:50 |  37.2%\n",
            "18620 | 4.6509 | 3.7e-04 | 0.96 | 38.6K | 01:05:51 |  37.2%\n",
            "18630 | 4.3273 | 3.7e-04 | 0.99 | 38.6K | 01:05:53 |  37.3%\n",
            "18640 | 4.4670 | 3.7e-04 | 0.96 | 38.6K | 01:05:55 |  37.3%\n",
            "18650 | 4.6254 | 3.7e-04 | 0.98 | 38.6K | 01:05:56 |  37.3%\n",
            "18660 | 4.7216 | 3.7e-04 | 0.94 | 38.6K | 01:05:58 |  37.3%\n",
            "18670 | 4.5446 | 3.7e-04 | 0.96 | 38.6K | 01:06:00 |  37.3%\n",
            "18680 | 4.6593 | 3.7e-04 | 0.99 | 38.6K | 01:06:02 |  37.4%\n",
            "18690 | 4.4628 | 3.7e-04 | 0.95 | 38.6K | 01:06:03 |  37.4%\n",
            "18700 | 4.6709 | 3.6e-04 | 0.94 | 38.6K | 01:06:05 |  37.4%\n",
            "18710 | 4.2814 | 3.6e-04 | 1.07 | 38.6K | 01:06:07 |  37.4%\n",
            "18720 | 4.7475 | 3.6e-04 | 0.95 | 38.6K | 01:06:08 |  37.4%\n",
            "18730 | 4.6956 | 3.6e-04 | 0.93 | 38.6K | 01:06:10 |  37.5%\n",
            "18740 | 4.7527 | 3.6e-04 | 0.94 | 38.6K | 01:06:12 |  37.5%\n",
            "18750 | 4.6073 | 3.6e-04 | 0.99 | 38.7K | 01:06:14 |  37.5%\n",
            "18760 | 4.6110 | 3.6e-04 | 1.20 | 38.7K | 01:06:15 |  37.5%\n",
            "18770 | 4.7245 | 3.6e-04 | 0.92 | 38.7K | 01:06:17 |  37.5%\n",
            "18780 | 4.5729 | 3.6e-04 | 0.94 | 38.7K | 01:06:19 |  37.6%\n",
            "18790 | 4.5236 | 3.6e-04 | 0.95 | 38.7K | 01:06:20 |  37.6%\n",
            "18800 | 4.6086 | 3.6e-04 | 0.95 | 38.7K | 01:06:22 |  37.6%\n",
            "18810 | 4.2646 | 3.6e-04 | 0.96 | 38.7K | 01:06:24 |  37.6%\n",
            "18820 | 4.4468 | 3.6e-04 | 0.96 | 38.7K | 01:06:26 |  37.6%\n",
            "18830 | 4.3181 | 3.6e-04 | 1.05 | 38.7K | 01:06:27 |  37.7%\n",
            "18840 | 4.5739 | 3.6e-04 | 0.95 | 38.7K | 01:06:29 |  37.7%\n",
            "18850 | 4.4475 | 3.6e-04 | 0.92 | 38.7K | 01:06:31 |  37.7%\n",
            "18860 | 4.3371 | 3.6e-04 | 0.97 | 38.7K | 01:06:32 |  37.7%\n",
            "18870 | 4.8200 | 3.6e-04 | 1.01 | 38.7K | 01:06:34 |  37.7%\n",
            "18880 | 4.4746 | 3.6e-04 | 0.92 | 38.7K | 01:06:36 |  37.8%\n",
            "18890 | 4.6973 | 3.6e-04 | 0.96 | 38.7K | 01:06:38 |  37.8%\n",
            "18900 | 4.7961 | 3.6e-04 | 0.93 | 38.7K | 01:06:39 |  37.8%\n",
            "18910 | 4.5848 | 3.6e-04 | 0.96 | 38.7K | 01:06:41 |  37.8%\n",
            "18920 | 4.5422 | 3.6e-04 | 0.95 | 38.7K | 01:06:43 |  37.8%\n",
            "18930 | 4.2776 | 3.6e-04 | 0.95 | 38.7K | 01:06:44 |  37.9%\n",
            "18940 | 4.5355 | 3.6e-04 | 0.98 | 38.7K | 01:06:46 |  37.9%\n",
            "18950 | 4.6593 | 3.6e-04 | 0.95 | 38.7K | 01:06:48 |  37.9%\n",
            "18960 | 4.4653 | 3.6e-04 | 1.01 | 38.7K | 01:06:50 |  37.9%\n",
            "18970 | 4.4472 | 3.6e-04 | 0.98 | 38.7K | 01:06:51 |  37.9%\n",
            "18980 | 4.3745 | 3.6e-04 | 1.01 | 38.7K | 01:06:53 |  38.0%\n",
            "18990 | 4.6196 | 3.6e-04 | 0.97 | 38.7K | 01:06:55 |  38.0%\n",
            "19000 | 4.3269 | 3.6e-04 | 0.95 | 38.7K | 01:06:56 |  38.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 19000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.5323\n",
            "  Perplexity: 92.97\n",
            "  Train loss (avg): 4.5692\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        sƒ±caklƒ±klarƒ±nƒ±n d√º≈ü√ºk olduƒüu g√ºnlerde, hava sƒ±caklƒ±klarƒ±nƒ±n d√º≈ümesiyle beraber artan yaƒüƒ±≈ü miktarƒ± artacak, hafta sonlarƒ± g√ºne≈üle ve gece saatlerindeki g√ºne≈ü ƒ±≈üƒ±nlarƒ± ile daha da kuvvetlenecektir. Bunun da etkisiyle enerji,\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Ankara'nƒ±n en g√∂zde ≈üehirlerindendir. New York, Kuzey Amerika, Afrika, Asya, Asya, Avrupa ve Avrupa, Amerika, Japonya, Fransa, Fransa, Fransa, ƒ∞ngiltere, ƒ∞talya, ƒ∞talya,\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        ; ba≈üarƒ±, sosyal ili≈ükiler ve g√ºvenlilik gibi bir√ßok alanda, sanal ger√ßeklik ile d√ºnyanƒ±n en √∂nde gelen ileti≈üim aƒüƒ±dƒ±r. Bu sayede hem basit bir ≈üekilde sanal ger√ßeklik farklarƒ±nƒ±n azalmasƒ±nƒ± saƒülar, hem de sanal\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.5323)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.5K\n",
            "     Steps/sec: 4.71\n",
            "     ETA: 01:49:47\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "19010 | 4.3506 | 3.6e-04 | 1.04 | 38.6K | 01:07:19 |  38.0%\n",
            "19020 | 4.4911 | 3.6e-04 | 0.92 | 38.6K | 01:07:21 |  38.0%\n",
            "19030 | 4.6830 | 3.6e-04 | 0.95 | 38.6K | 01:07:22 |  38.1%\n",
            "19040 | 4.6294 | 3.6e-04 | 0.93 | 38.6K | 01:07:24 |  38.1%\n",
            "19050 | 4.6713 | 3.6e-04 | 0.92 | 38.6K | 01:07:26 |  38.1%\n",
            "19060 | 4.5832 | 3.6e-04 | 0.95 | 38.6K | 01:07:27 |  38.1%\n",
            "19070 | 4.5507 | 3.6e-04 | 0.99 | 38.6K | 01:07:29 |  38.1%\n",
            "19080 | 4.6042 | 3.6e-04 | 0.99 | 38.6K | 01:07:31 |  38.2%\n",
            "19090 | 4.8783 | 3.6e-04 | 1.00 | 38.6K | 01:07:33 |  38.2%\n",
            "19100 | 4.5620 | 3.6e-04 | 0.97 | 38.6K | 01:07:34 |  38.2%\n",
            "19110 | 4.5652 | 3.6e-04 | 1.06 | 38.6K | 01:07:36 |  38.2%\n",
            "19120 | 4.5602 | 3.6e-04 | 0.97 | 38.6K | 01:07:38 |  38.2%\n",
            "19130 | 4.7128 | 3.6e-04 | 0.94 | 38.6K | 01:07:39 |  38.3%\n",
            "19140 | 4.3664 | 3.6e-04 | 0.97 | 38.6K | 01:07:41 |  38.3%\n",
            "19150 | 4.7611 | 3.6e-04 | 0.93 | 38.6K | 01:07:43 |  38.3%\n",
            "19160 | 4.6006 | 3.6e-04 | 0.95 | 38.6K | 01:07:45 |  38.3%\n",
            "19170 | 4.7866 | 3.6e-04 | 0.97 | 38.6K | 01:07:46 |  38.3%\n",
            "19180 | 4.5016 | 3.6e-04 | 0.94 | 38.6K | 01:07:48 |  38.4%\n",
            "19190 | 4.2373 | 3.6e-04 | 1.01 | 38.6K | 01:07:50 |  38.4%\n",
            "19200 | 4.4584 | 3.6e-04 | 0.98 | 38.6K | 01:07:51 |  38.4%\n",
            "19210 | 4.7748 | 3.6e-04 | 0.92 | 38.6K | 01:07:53 |  38.4%\n",
            "19220 | 4.5135 | 3.6e-04 | 1.04 | 38.6K | 01:07:55 |  38.4%\n",
            "19230 | 4.5446 | 3.6e-04 | 0.98 | 38.6K | 01:07:57 |  38.5%\n",
            "19240 | 4.3352 | 3.6e-04 | 1.03 | 38.6K | 01:07:58 |  38.5%\n",
            "19250 | 4.7688 | 3.6e-04 | 0.95 | 38.6K | 01:08:00 |  38.5%\n",
            "19260 | 4.6653 | 3.6e-04 | 1.00 | 38.7K | 01:08:02 |  38.5%\n",
            "19270 | 4.6365 | 3.6e-04 | 0.99 | 38.7K | 01:08:03 |  38.5%\n",
            "19280 | 4.6420 | 3.6e-04 | 0.93 | 38.7K | 01:08:05 |  38.6%\n",
            "19290 | 4.4981 | 3.6e-04 | 0.96 | 38.7K | 01:08:07 |  38.6%\n",
            "19300 | 4.6408 | 3.6e-04 | 0.95 | 38.7K | 01:08:09 |  38.6%\n",
            "19310 | 4.8212 | 3.6e-04 | 0.95 | 38.7K | 01:08:10 |  38.6%\n",
            "19320 | 4.6089 | 3.6e-04 | 0.95 | 38.7K | 01:08:12 |  38.6%\n",
            "19330 | 4.0897 | 3.6e-04 | 1.10 | 38.7K | 01:08:14 |  38.7%\n",
            "19340 | 4.7680 | 3.6e-04 | 0.96 | 38.7K | 01:08:15 |  38.7%\n",
            "19350 | 4.3721 | 3.6e-04 | 1.11 | 38.7K | 01:08:17 |  38.7%\n",
            "19360 | 4.5714 | 3.6e-04 | 0.94 | 38.7K | 01:08:19 |  38.7%\n",
            "19370 | 4.9029 | 3.6e-04 | 0.98 | 38.7K | 01:08:21 |  38.7%\n",
            "19380 | 4.6822 | 3.5e-04 | 0.93 | 38.7K | 01:08:22 |  38.8%\n",
            "19390 | 4.7166 | 3.5e-04 | 0.98 | 38.7K | 01:08:24 |  38.8%\n",
            "19400 | 4.6131 | 3.5e-04 | 0.98 | 38.7K | 01:08:26 |  38.8%\n",
            "19410 | 4.8610 | 3.5e-04 | 0.97 | 38.7K | 01:08:27 |  38.8%\n",
            "19420 | 4.1461 | 3.5e-04 | 0.94 | 38.7K | 01:08:29 |  38.8%\n",
            "19430 | 4.3655 | 3.5e-04 | 1.00 | 38.7K | 01:08:31 |  38.9%\n",
            "19440 | 4.7877 | 3.5e-04 | 0.94 | 38.7K | 01:08:32 |  38.9%\n",
            "19450 | 4.5304 | 3.5e-04 | 1.00 | 38.7K | 01:08:34 |  38.9%\n",
            "19460 | 4.4776 | 3.5e-04 | 0.95 | 38.7K | 01:08:36 |  38.9%\n",
            "19470 | 4.4581 | 3.5e-04 | 0.95 | 38.7K | 01:08:38 |  38.9%\n",
            "19480 | 4.6013 | 3.5e-04 | 0.99 | 38.7K | 01:08:39 |  39.0%\n",
            "19490 | 4.6208 | 3.5e-04 | 0.97 | 38.7K | 01:08:41 |  39.0%\n",
            "19500 | 4.2525 | 3.5e-04 | 0.97 | 38.7K | 01:08:43 |  39.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 19500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.5579\n",
            "  Perplexity: 95.38\n",
            "  Train loss (avg): 4.5906\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        sƒ±caklƒ±klarƒ±yla birlikte y√ºzlere √ßƒ±kan yaz mevsiminin aydƒ±nlƒ±ƒüƒ± bir yandan da sƒ±caklƒ±ƒüƒ±n etkisiyle, doƒüayla i√ß i√ße olduƒüumuz ko≈üullar bir yandan da i√ß i√ße olan mevsiminin yenilenmesine yol a√ßarken, ge√ßi≈üimizin\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        ƒ∞stanbul'da her t√ºrl√º ≈üekilde insanlarƒ±n ya≈üadƒ±ƒüƒ± bir ≈üehir olarak bu b√∂lgede konumlanan ≈üehirlerle d√ºnyanƒ±n en pop√ºler ≈üehirlerinin ba≈üƒ±nda geliyor. G√ºn√ºm√ºzde de ƒ∞stanbul'un her yeri gezilip g√∂r√ºlmesi gereken bir ≈üehir. Farklƒ±\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        firmalarƒ±nƒ± bir araya getiren bir √ßok firma bulunuyor. Firmalarƒ±n √∂zel ev kullanƒ±cƒ±larƒ± i√ßin √∂zel bir program hazƒ±rlamak da bu firmalardan biri. Ba≈üvuru s√ºresi dolmadan, 35 saatten az bir s√ºre de olsa t√ºm m√º≈üterilerin\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.71\n",
            "     ETA: 01:47:56\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "19510 | 4.7144 | 3.5e-04 | 0.98 | 38.6K | 01:09:02 |  39.0%\n",
            "19520 | 4.5843 | 3.5e-04 | 1.00 | 38.6K | 01:09:04 |  39.0%\n",
            "19530 | 4.9122 | 3.5e-04 | 0.93 | 38.6K | 01:09:05 |  39.1%\n",
            "19540 | 4.2563 | 3.5e-04 | 0.94 | 38.6K | 01:09:07 |  39.1%\n",
            "19550 | 4.6005 | 3.5e-04 | 0.96 | 38.6K | 01:09:09 |  39.1%\n",
            "19560 | 4.4661 | 3.5e-04 | 1.02 | 38.6K | 01:09:10 |  39.1%\n",
            "19570 | 4.2887 | 3.5e-04 | 1.01 | 38.6K | 01:09:12 |  39.1%\n",
            "19580 | 4.6567 | 3.5e-04 | 0.95 | 38.6K | 01:09:14 |  39.2%\n",
            "19590 | 4.6891 | 3.5e-04 | 0.95 | 38.6K | 01:09:16 |  39.2%\n",
            "19600 | 4.5786 | 3.5e-04 | 0.95 | 38.6K | 01:09:17 |  39.2%\n",
            "19610 | 4.5586 | 3.5e-04 | 0.96 | 38.6K | 01:09:19 |  39.2%\n",
            "19620 | 4.5616 | 3.5e-04 | 0.93 | 38.6K | 01:09:21 |  39.2%\n",
            "19630 | 4.5202 | 3.5e-04 | 0.96 | 38.6K | 01:09:22 |  39.3%\n",
            "19640 | 4.5747 | 3.5e-04 | 1.09 | 38.6K | 01:09:24 |  39.3%\n",
            "19650 | 4.5645 | 3.5e-04 | 0.94 | 38.6K | 01:09:26 |  39.3%\n",
            "19660 | 4.3529 | 3.5e-04 | 0.97 | 38.6K | 01:09:27 |  39.3%\n",
            "19670 | 4.4267 | 3.5e-04 | 0.96 | 38.6K | 01:09:29 |  39.3%\n",
            "19680 | 4.4971 | 3.5e-04 | 0.96 | 38.6K | 01:09:31 |  39.4%\n",
            "19690 | 4.4751 | 3.5e-04 | 0.95 | 38.7K | 01:09:33 |  39.4%\n",
            "19700 | 4.3692 | 3.5e-04 | 1.01 | 38.7K | 01:09:34 |  39.4%\n",
            "19710 | 4.5824 | 3.5e-04 | 0.93 | 38.7K | 01:09:36 |  39.4%\n",
            "19720 | 4.5207 | 3.5e-04 | 1.03 | 38.7K | 01:09:38 |  39.4%\n",
            "19730 | 4.6231 | 3.5e-04 | 0.97 | 38.7K | 01:09:39 |  39.5%\n",
            "19740 | 4.5802 | 3.5e-04 | 0.95 | 38.7K | 01:09:41 |  39.5%\n",
            "19750 | 4.6598 | 3.5e-04 | 0.97 | 38.7K | 01:09:43 |  39.5%\n",
            "19760 | 4.6686 | 3.5e-04 | 0.93 | 38.7K | 01:09:45 |  39.5%\n",
            "19770 | 4.6914 | 3.5e-04 | 1.04 | 38.7K | 01:09:46 |  39.5%\n",
            "19780 | 4.3564 | 3.5e-04 | 0.99 | 38.7K | 01:09:48 |  39.6%\n",
            "19790 | 4.5676 | 3.5e-04 | 0.98 | 38.7K | 01:09:50 |  39.6%\n",
            "19800 | 4.8913 | 3.5e-04 | 0.94 | 38.7K | 01:09:51 |  39.6%\n",
            "19810 | 4.5123 | 3.5e-04 | 0.95 | 38.7K | 01:09:53 |  39.6%\n",
            "19820 | 4.8238 | 3.5e-04 | 0.94 | 38.7K | 01:09:55 |  39.6%\n",
            "19830 | 4.3311 | 3.5e-04 | 0.97 | 38.7K | 01:09:57 |  39.7%\n",
            "19840 | 4.5474 | 3.5e-04 | 0.93 | 38.7K | 01:09:58 |  39.7%\n",
            "19850 | 4.2846 | 3.5e-04 | 1.07 | 38.7K | 01:10:00 |  39.7%\n",
            "19860 | 4.2742 | 3.5e-04 | 0.96 | 38.7K | 01:10:02 |  39.7%\n",
            "19870 | 4.8332 | 3.5e-04 | 0.97 | 38.7K | 01:10:03 |  39.7%\n",
            "19880 | 4.2203 | 3.5e-04 | 0.96 | 38.7K | 01:10:05 |  39.8%\n",
            "19890 | 4.5275 | 3.5e-04 | 0.99 | 38.7K | 01:10:07 |  39.8%\n",
            "19900 | 4.4681 | 3.5e-04 | 0.97 | 38.7K | 01:10:09 |  39.8%\n",
            "19910 | 4.5928 | 3.5e-04 | 0.98 | 38.7K | 01:10:10 |  39.8%\n",
            "19920 | 4.4612 | 3.5e-04 | 0.96 | 38.7K | 01:10:12 |  39.8%\n",
            "19930 | 4.5914 | 3.5e-04 | 1.02 | 38.7K | 01:10:14 |  39.9%\n",
            "19940 | 4.6670 | 3.5e-04 | 1.00 | 38.7K | 01:10:15 |  39.9%\n",
            "19950 | 4.2972 | 3.5e-04 | 1.02 | 38.7K | 01:10:17 |  39.9%\n",
            "19960 | 4.5296 | 3.5e-04 | 0.97 | 38.8K | 01:10:19 |  39.9%\n",
            "19970 | 4.8010 | 3.5e-04 | 0.98 | 38.8K | 01:10:21 |  39.9%\n",
            "19980 | 4.6874 | 3.5e-04 | 0.95 | 38.8K | 01:10:22 |  40.0%\n",
            "19990 | 4.7444 | 3.5e-04 | 0.97 | 38.8K | 01:10:24 |  40.0%\n",
            "20000 | 4.5636 | 3.5e-04 | 0.97 | 38.8K | 01:10:26 |  40.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 20000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.5430\n",
            "  Perplexity: 93.98\n",
            "  Train loss (avg): 4.5460\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        durumu iyi durumda ve dƒ±≈ü politikadaki yava≈ülamalarla birlikte T√ºrkiye‚Äôde ekonomi, end√ºstri, otomotiv sekt√∂r√ºnden kalma ve sosyal g√ºvenlik, end√ºstri, end√ºstri, tasarƒ±m ve teknoloji sekt√∂r√ºnden kalma turizm sekt√∂r√º ve bu\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        olan San Francisco‚Äônun en b√ºy√ºk ≈üehri konumunda bulunan San Francisco, 2200 yƒ±l sonra d√ºnyanƒ±n en b√ºy√ºk ≈üehri konumunda. San Francisco‚Äônun ba≈ükenti San Francisco‚Äônun en b√ºy√ºk ≈üehri diyebiliriz. San Francisco‚Äô\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        yapay zeka teknolojileri, bir √ßok farklƒ± alanda en √ßok tercih edilen tercih edilen bilgisayarlerden biridir. Teknoloji devi yapay zeka teknolojisi i√ßin yapay zeka sistemleri geli≈ütirilmi≈ü bir akƒ±llƒ± telefondƒ±r. Yapay zeka teknolojisinin geli≈ümesi ile akƒ±llƒ± telefon\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.71\n",
            "     ETA: 01:46:05\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "üíæ Checkpoint kaydediliyor: /content/drive/MyDrive/turkish_llm/checkpoints//checkpoint_step_20000.pt\n",
            "  ‚úÖ Checkpoint kaydedildi!\n",
            "\n",
            "20010 | 4.5963 | 3.5e-04 | 0.99 | 38.6K | 01:10:48 |  40.0%\n",
            "20020 | 4.4982 | 3.5e-04 | 0.98 | 38.6K | 01:10:50 |  40.0%\n",
            "20030 | 4.6342 | 3.5e-04 | 0.97 | 38.6K | 01:10:51 |  40.1%\n",
            "20040 | 4.6591 | 3.5e-04 | 0.94 | 38.6K | 01:10:53 |  40.1%\n",
            "20050 | 4.5571 | 3.4e-04 | 0.96 | 38.6K | 01:10:55 |  40.1%\n",
            "20060 | 4.2798 | 3.4e-04 | 1.04 | 38.6K | 01:10:57 |  40.1%\n",
            "20070 | 4.7420 | 3.4e-04 | 0.95 | 38.6K | 01:10:58 |  40.1%\n",
            "20080 | 4.5448 | 3.4e-04 | 0.94 | 38.6K | 01:11:00 |  40.2%\n",
            "20090 | 4.6083 | 3.4e-04 | 0.93 | 38.6K | 01:11:02 |  40.2%\n",
            "20100 | 4.3115 | 3.4e-04 | 1.15 | 38.6K | 01:11:04 |  40.2%\n",
            "20110 | 4.6177 | 3.4e-04 | 1.01 | 38.6K | 01:11:05 |  40.2%\n",
            "20120 | 4.6460 | 3.4e-04 | 0.98 | 38.6K | 01:11:07 |  40.2%\n",
            "20130 | 4.4085 | 3.4e-04 | 1.05 | 38.6K | 01:11:09 |  40.3%\n",
            "20140 | 4.7725 | 3.4e-04 | 0.99 | 38.6K | 01:11:10 |  40.3%\n",
            "20150 | 4.5956 | 3.4e-04 | 0.99 | 38.6K | 01:11:12 |  40.3%\n",
            "20160 | 4.3586 | 3.4e-04 | 0.95 | 38.6K | 01:11:14 |  40.3%\n",
            "20170 | 4.5741 | 3.4e-04 | 0.98 | 38.6K | 01:11:16 |  40.3%\n",
            "20180 | 4.8436 | 3.4e-04 | 0.96 | 38.6K | 01:11:17 |  40.4%\n",
            "20190 | 4.5322 | 3.4e-04 | 1.01 | 38.6K | 01:11:19 |  40.4%\n",
            "20200 | 4.5482 | 3.4e-04 | 0.97 | 38.7K | 01:11:21 |  40.4%\n",
            "20210 | 4.6339 | 3.4e-04 | 1.01 | 38.7K | 01:11:22 |  40.4%\n",
            "20220 | 4.3230 | 3.4e-04 | 1.20 | 38.7K | 01:11:24 |  40.4%\n",
            "20230 | 4.5662 | 3.4e-04 | 1.03 | 38.7K | 01:11:26 |  40.5%\n",
            "20240 | 4.1178 | 3.4e-04 | 1.01 | 38.7K | 01:11:28 |  40.5%\n",
            "20250 | 4.6816 | 3.4e-04 | 1.00 | 38.7K | 01:11:29 |  40.5%\n",
            "20260 | 4.3913 | 3.4e-04 | 1.01 | 38.7K | 01:11:31 |  40.5%\n",
            "20270 | 4.6810 | 3.4e-04 | 0.97 | 38.7K | 01:11:33 |  40.5%\n",
            "20280 | 4.6413 | 3.4e-04 | 0.98 | 38.7K | 01:11:34 |  40.6%\n",
            "20290 | 4.5785 | 3.4e-04 | 0.98 | 38.7K | 01:11:36 |  40.6%\n",
            "20300 | 4.7393 | 3.4e-04 | 0.97 | 38.7K | 01:11:38 |  40.6%\n",
            "20310 | 4.7395 | 3.4e-04 | 0.97 | 38.7K | 01:11:40 |  40.6%\n",
            "20320 | 4.4079 | 3.4e-04 | 0.98 | 38.7K | 01:11:41 |  40.6%\n",
            "20330 | 4.4807 | 3.4e-04 | 0.99 | 38.7K | 01:11:43 |  40.7%\n",
            "20340 | 4.6444 | 3.4e-04 | 0.95 | 38.7K | 01:11:45 |  40.7%\n",
            "20350 | 4.6618 | 3.4e-04 | 0.95 | 38.7K | 01:11:46 |  40.7%\n",
            "20360 | 4.6180 | 3.4e-04 | 0.98 | 38.7K | 01:11:48 |  40.7%\n",
            "20370 | 4.4944 | 3.4e-04 | 1.01 | 38.7K | 01:11:50 |  40.7%\n",
            "20380 | 4.2053 | 3.4e-04 | 0.97 | 38.7K | 01:11:52 |  40.8%\n",
            "20390 | 4.9442 | 3.4e-04 | 1.00 | 38.7K | 01:11:53 |  40.8%\n",
            "20400 | 4.7358 | 3.4e-04 | 1.04 | 38.7K | 01:11:55 |  40.8%\n",
            "20410 | 4.6043 | 3.4e-04 | 0.95 | 38.7K | 01:11:57 |  40.8%\n",
            "20420 | 4.4548 | 3.4e-04 | 1.02 | 38.7K | 01:11:58 |  40.8%\n",
            "20430 | 4.8124 | 3.4e-04 | 1.06 | 38.7K | 01:12:00 |  40.9%\n",
            "20440 | 4.5598 | 3.4e-04 | 0.98 | 38.7K | 01:12:02 |  40.9%\n",
            "20450 | 4.2559 | 3.4e-04 | 1.05 | 38.7K | 01:12:03 |  40.9%\n",
            "20460 | 4.6076 | 3.4e-04 | 0.95 | 38.7K | 01:12:05 |  40.9%\n",
            "20470 | 4.6086 | 3.4e-04 | 1.05 | 38.8K | 01:12:07 |  40.9%\n",
            "20480 | 4.6799 | 3.4e-04 | 0.97 | 38.8K | 01:12:09 |  41.0%\n",
            "20490 | 4.6034 | 3.4e-04 | 1.03 | 38.8K | 01:12:10 |  41.0%\n",
            "20500 | 4.6781 | 3.4e-04 | 0.97 | 38.8K | 01:12:12 |  41.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 20500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.5113\n",
            "  Perplexity: 91.04\n",
            "  Train loss (avg): 4.5553\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        durumu d√ºn hava durumu ile d√ºn hava durumu pek √ßok ki≈üinin g√∂zlerini√últeledi. Bug√ºn hava durumu bug√ºn hava durumu yarƒ±n hava durumu ise hava durumu d√ºn hava durumu bug√ºn hava durumu bug√ºn hava durumu yarƒ±n hava\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        ve d√ºnyanƒ±n en b√ºy√ºk ikinci ≈üehri, \"√áiftlik, Bin yƒ±lƒ±n yorgunluƒüu, yorgunluƒüu, yorgunluƒüu\" filmi  ‚Åá Ma√ßta huzur  ‚Åá T√ºrkiye'nin en b√ºy√ºk ikinci ≈üehri,\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        g√ºn√ºm√ºzde insanlar tarafƒ±ndan bile yapƒ±lmƒ±yor. Fakat g√ºn√ºm√ºzde bir √ßok teknolojik ve teknolojik geli≈ümelerin olduƒüu, sanal ger√ßekliklerin, teknolojik √ß√∂z√ºmlerin ve hatta yapay zeka teknolojisi ile yapay zekanƒ±n yaratƒ±ldƒ±ƒüƒ± bir sekt√∂r. Bu alanda\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.5113)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.71\n",
            "     ETA: 01:44:24\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "20510 | 4.3896 | 3.4e-04 | 1.20 | 38.6K | 01:12:35 |  41.0%\n",
            "20520 | 4.6140 | 3.4e-04 | 0.97 | 38.6K | 01:12:36 |  41.0%\n",
            "20530 | 4.7421 | 3.4e-04 | 0.96 | 38.6K | 01:12:38 |  41.1%\n",
            "20540 | 4.5875 | 3.4e-04 | 0.96 | 38.6K | 01:12:40 |  41.1%\n",
            "20550 | 4.3817 | 3.4e-04 | 2.50 | 38.6K | 01:12:41 |  41.1%\n",
            "20560 | 4.6000 | 3.4e-04 | 1.03 | 38.6K | 01:12:43 |  41.1%\n",
            "20570 | 4.6106 | 3.4e-04 | 1.00 | 38.6K | 01:12:45 |  41.1%\n",
            "20580 | 4.7316 | 3.4e-04 | 0.95 | 38.6K | 01:12:47 |  41.2%\n",
            "20590 | 4.0638 | 3.4e-04 | 0.97 | 38.6K | 01:12:48 |  41.2%\n",
            "20600 | 4.3662 | 3.4e-04 | 0.95 | 38.6K | 01:12:50 |  41.2%\n",
            "20610 | 4.3396 | 3.4e-04 | 1.10 | 38.6K | 01:12:52 |  41.2%\n",
            "20620 | 4.6885 | 3.4e-04 | 0.99 | 38.6K | 01:12:53 |  41.2%\n",
            "20630 | 4.2022 | 3.4e-04 | 1.05 | 38.6K | 01:12:55 |  41.3%\n",
            "20640 | 4.6061 | 3.4e-04 | 1.06 | 38.6K | 01:12:57 |  41.3%\n",
            "20650 | 4.2725 | 3.4e-04 | 0.95 | 38.6K | 01:12:59 |  41.3%\n",
            "20660 | 4.7255 | 3.4e-04 | 0.91 | 38.6K | 01:13:00 |  41.3%\n",
            "20670 | 4.7929 | 3.4e-04 | 0.97 | 38.6K | 01:13:02 |  41.3%\n",
            "20680 | 4.6056 | 3.4e-04 | 0.99 | 38.6K | 01:13:04 |  41.4%\n",
            "20690 | 4.6960 | 3.4e-04 | 0.99 | 38.6K | 01:13:05 |  41.4%\n",
            "20700 | 4.7162 | 3.4e-04 | 0.98 | 38.6K | 01:13:07 |  41.4%\n",
            "20710 | 4.6260 | 3.3e-04 | 0.99 | 38.7K | 01:13:09 |  41.4%\n",
            "20720 | 4.5498 | 3.3e-04 | 0.98 | 38.7K | 01:13:11 |  41.4%\n",
            "20730 | 4.6541 | 3.3e-04 | 0.94 | 38.7K | 01:13:12 |  41.5%\n",
            "20740 | 4.4854 | 3.3e-04 | 1.00 | 38.7K | 01:13:14 |  41.5%\n",
            "20750 | 4.4126 | 3.3e-04 | 0.98 | 38.7K | 01:13:16 |  41.5%\n",
            "20760 | 4.1545 | 3.3e-04 | 1.07 | 38.7K | 01:13:17 |  41.5%\n",
            "20770 | 4.6250 | 3.3e-04 | 1.19 | 38.7K | 01:13:19 |  41.5%\n",
            "20780 | 4.8035 | 3.3e-04 | 1.00 | 38.7K | 01:13:21 |  41.6%\n",
            "20790 | 4.5342 | 3.3e-04 | 1.02 | 38.7K | 01:13:22 |  41.6%\n",
            "20800 | 4.3573 | 3.3e-04 | 1.07 | 38.7K | 01:13:24 |  41.6%\n",
            "20810 | 4.5923 | 3.3e-04 | 0.95 | 38.7K | 01:13:26 |  41.6%\n",
            "20820 | 4.4790 | 3.3e-04 | 1.07 | 38.7K | 01:13:28 |  41.6%\n",
            "20830 | 4.8632 | 3.3e-04 | 0.97 | 38.7K | 01:13:29 |  41.7%\n",
            "20840 | 4.7784 | 3.3e-04 | 1.01 | 38.7K | 01:13:31 |  41.7%\n",
            "20850 | 4.6555 | 3.3e-04 | 0.94 | 38.7K | 01:13:33 |  41.7%\n",
            "20860 | 4.3265 | 3.3e-04 | 0.99 | 38.7K | 01:13:34 |  41.7%\n",
            "20870 | 4.5567 | 3.3e-04 | 0.99 | 38.7K | 01:13:36 |  41.7%\n",
            "20880 | 4.7013 | 3.3e-04 | 0.97 | 38.7K | 01:13:38 |  41.8%\n",
            "20890 | 4.6222 | 3.3e-04 | 0.98 | 38.7K | 01:13:40 |  41.8%\n",
            "20900 | 4.5546 | 3.3e-04 | 0.95 | 38.7K | 01:13:41 |  41.8%\n",
            "20910 | 4.5317 | 3.3e-04 | 0.96 | 38.7K | 01:13:43 |  41.8%\n",
            "20920 | 4.7360 | 3.3e-04 | 1.07 | 38.7K | 01:13:45 |  41.8%\n",
            "20930 | 4.4781 | 3.3e-04 | 1.02 | 38.7K | 01:13:46 |  41.9%\n",
            "20940 | 4.6105 | 3.3e-04 | 0.97 | 38.7K | 01:13:48 |  41.9%\n",
            "20950 | 4.6042 | 3.3e-04 | 0.95 | 38.7K | 01:13:50 |  41.9%\n",
            "20960 | 4.4934 | 3.3e-04 | 1.07 | 38.7K | 01:13:52 |  41.9%\n",
            "20970 | 4.2548 | 3.3e-04 | 1.02 | 38.7K | 01:13:53 |  41.9%\n",
            "20980 | 4.7149 | 3.3e-04 | 0.94 | 38.7K | 01:13:55 |  42.0%\n",
            "20990 | 4.3999 | 3.3e-04 | 0.97 | 38.8K | 01:13:57 |  42.0%\n",
            "21000 | 4.6515 | 3.3e-04 | 0.98 | 38.8K | 01:13:58 |  42.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 21000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.4997\n",
            "  Perplexity: 89.99\n",
            "  Train loss (avg): 4.5574\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        sƒ±caklƒ±ƒüƒ±ndaki y√ºkseli≈üte gerileyen yeni geli≈ümeler yeni nesil yeni nesilleri daha √∂nceki nesillerin aksine daha √ßok beƒüeneceƒüini ve bunun daha verimli olacaƒüƒ±nƒ± d√º≈ü√ºn√ºyor ve yeni nesilleri daha √ßok terk edeceƒüimizi vurgulamaya √ßalƒ±≈üƒ±yor\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        New York'taki I. Travel Otel'de ger√ßekle≈ütirilen yangƒ±n sonucu hayatƒ±nƒ± kaybetti. ƒ∞zmir'in Aliaƒüa il√ßesinde bazƒ± semtlerde yangƒ±n √ßƒ±ktƒ±. Edinilen bilgilere g√∂re, vatanda≈ülarƒ±mƒ±zƒ±n daha sonra alevler i√ßinde\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        ile √ºretilen yapay zeka, √ßok ama√ßlƒ±, √∂zel olarak √ºretilen yapay zeka ile geli≈ütirilen yapay zeka √ºr√ºn√º ile √ºretilen yapay zeka, bu √∂zellikleri ile de zengin bir kitleye hitap eden yapay zeka ve yapay zeka, bu √∂zelliƒüi\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.4997)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.71\n",
            "     ETA: 01:42:38\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "21010 | 4.5661 | 3.3e-04 | 1.02 | 38.6K | 01:14:21 |  42.0%\n",
            "21020 | 4.4187 | 3.3e-04 | 0.99 | 38.6K | 01:14:23 |  42.0%\n",
            "21030 | 4.6430 | 3.3e-04 | 0.96 | 38.6K | 01:14:24 |  42.1%\n",
            "21040 | 4.6827 | 3.3e-04 | 0.98 | 38.6K | 01:14:26 |  42.1%\n",
            "21050 | 4.5672 | 3.3e-04 | 0.99 | 38.6K | 01:14:28 |  42.1%\n",
            "21060 | 4.2675 | 3.3e-04 | 0.98 | 38.6K | 01:14:29 |  42.1%\n",
            "21070 | 4.4301 | 3.3e-04 | 1.03 | 38.6K | 01:14:31 |  42.1%\n",
            "21080 | 4.4418 | 3.3e-04 | 1.03 | 38.6K | 01:14:33 |  42.2%\n",
            "21090 | 4.5036 | 3.3e-04 | 0.99 | 38.6K | 01:14:35 |  42.2%\n",
            "21100 | 4.6554 | 3.3e-04 | 1.00 | 38.6K | 01:14:36 |  42.2%\n",
            "21110 | 4.4735 | 3.3e-04 | 0.98 | 38.6K | 01:14:38 |  42.2%\n",
            "21120 | 4.4373 | 3.3e-04 | 0.97 | 38.6K | 01:14:40 |  42.2%\n",
            "21130 | 4.4701 | 3.3e-04 | 0.96 | 38.6K | 01:14:41 |  42.3%\n",
            "21140 | 4.0759 | 3.3e-04 | 1.07 | 38.6K | 01:14:43 |  42.3%\n",
            "21150 | 4.4342 | 3.3e-04 | 1.03 | 38.6K | 01:14:45 |  42.3%\n",
            "21160 | 4.4433 | 3.3e-04 | 0.99 | 38.6K | 01:14:47 |  42.3%\n",
            "21170 | 4.7297 | 3.3e-04 | 0.96 | 38.6K | 01:14:48 |  42.3%\n",
            "21180 | 4.4641 | 3.3e-04 | 1.01 | 38.6K | 01:14:50 |  42.4%\n",
            "21190 | 4.6284 | 3.3e-04 | 1.03 | 38.6K | 01:14:52 |  42.4%\n",
            "21200 | 4.5812 | 3.3e-04 | 0.98 | 38.6K | 01:14:53 |  42.4%\n",
            "21210 | 4.6084 | 3.3e-04 | 1.05 | 38.6K | 01:14:55 |  42.4%\n",
            "21220 | 4.5248 | 3.3e-04 | 0.96 | 38.7K | 01:14:57 |  42.4%\n",
            "21230 | 4.6283 | 3.3e-04 | 1.01 | 38.7K | 01:14:59 |  42.5%\n",
            "21240 | 4.5278 | 3.3e-04 | 0.98 | 38.7K | 01:15:00 |  42.5%\n",
            "21250 | 4.4860 | 3.3e-04 | 1.02 | 38.7K | 01:15:02 |  42.5%\n",
            "21260 | 4.5968 | 3.3e-04 | 1.02 | 38.7K | 01:15:04 |  42.5%\n",
            "21270 | 4.3093 | 3.3e-04 | 1.05 | 38.7K | 01:15:05 |  42.5%\n",
            "21280 | 4.6974 | 3.3e-04 | 0.96 | 38.7K | 01:15:07 |  42.6%\n",
            "21290 | 4.5978 | 3.3e-04 | 0.95 | 38.7K | 01:15:09 |  42.6%\n",
            "21300 | 4.4728 | 3.3e-04 | 1.00 | 38.7K | 01:15:11 |  42.6%\n",
            "21310 | 4.6121 | 3.3e-04 | 1.01 | 38.7K | 01:15:12 |  42.6%\n",
            "21320 | 4.5909 | 3.3e-04 | 0.96 | 38.7K | 01:15:14 |  42.6%\n",
            "21330 | 4.7977 | 3.3e-04 | 0.99 | 38.7K | 01:15:16 |  42.7%\n",
            "21340 | 4.6734 | 3.3e-04 | 0.97 | 38.7K | 01:15:17 |  42.7%\n",
            "21350 | 4.4204 | 3.2e-04 | 0.98 | 38.7K | 01:15:19 |  42.7%\n",
            "21360 | 4.7178 | 3.2e-04 | 0.97 | 38.7K | 01:15:21 |  42.7%\n",
            "21370 | 4.3604 | 3.2e-04 | 1.00 | 38.7K | 01:15:23 |  42.7%\n",
            "21380 | 4.6598 | 3.2e-04 | 1.01 | 38.7K | 01:15:24 |  42.8%\n",
            "21390 | 4.4545 | 3.2e-04 | 1.02 | 38.7K | 01:15:26 |  42.8%\n",
            "21400 | 4.6657 | 3.2e-04 | 1.03 | 38.7K | 01:15:28 |  42.8%\n",
            "21410 | 4.7002 | 3.2e-04 | 0.97 | 38.7K | 01:15:29 |  42.8%\n",
            "21420 | 4.5741 | 3.2e-04 | 1.00 | 38.7K | 01:15:31 |  42.8%\n",
            "21430 | 4.4913 | 3.2e-04 | 0.96 | 38.7K | 01:15:33 |  42.9%\n",
            "21440 | 4.4138 | 3.2e-04 | 1.00 | 38.7K | 01:15:35 |  42.9%\n",
            "21450 | 4.7303 | 3.2e-04 | 0.96 | 38.7K | 01:15:36 |  42.9%\n",
            "21460 | 4.4514 | 3.2e-04 | 0.99 | 38.7K | 01:15:38 |  42.9%\n",
            "21470 | 4.3757 | 3.2e-04 | 1.04 | 38.7K | 01:15:40 |  42.9%\n",
            "21480 | 4.6076 | 3.2e-04 | 0.99 | 38.7K | 01:15:41 |  43.0%\n",
            "21490 | 4.5434 | 3.2e-04 | 0.98 | 38.7K | 01:15:43 |  43.0%\n",
            "21500 | 4.4512 | 3.2e-04 | 1.02 | 38.7K | 01:15:45 |  43.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 21500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.5129\n",
            "  Perplexity: 91.18\n",
            "  Train loss (avg): 4.5467\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        ≈üartlarƒ± ve hava durumu nedir? ƒ∞nsan kaynaklarƒ± yeterli d√ºzeyde, her konuda yeterli bilgiye sahip deƒüil, her zaman gerekli bilgileri veren bir kurumdur. Bu kurum; hem belli bir s√ºre i√ßinde, hem de bu s√ºre\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        ƒ∞stanbul'un sahilinden ge√ßen ve d√ºnyanƒ±n en b√ºy√ºk liman kenti olan Hadrianen, d√ºnyanƒ±n en b√ºy√ºk liman kentidir. ƒ∞stanbul'da T√ºrkiye'nin en b√ºy√ºk liman kenti olan ƒ∞stanbul'da ≈üehrin en\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , davranƒ±≈ülarƒ±mƒ±za √∂zel bir yazƒ±lƒ±m geli≈ütirmi≈ütir. Hemen hemen her ≈üeyi etkileyen ve olaƒüan√ºst√º bir i≈ülem olan, temel olarak, o kadar √ßok ≈üey √ºreten ve olmayan, o kadar √ßok ≈üey √∂ƒüreten bir yazƒ±lƒ±m geli≈ütirmi≈ütir\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.71\n",
            "     ETA: 01:40:48\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "21510 | 4.4039 | 3.2e-04 | 0.98 | 38.6K | 01:16:04 |  43.0%\n",
            "21520 | 4.7239 | 3.2e-04 | 0.97 | 38.6K | 01:16:06 |  43.0%\n",
            "21530 | 4.5021 | 3.2e-04 | 0.98 | 38.6K | 01:16:07 |  43.1%\n",
            "21540 | 4.3593 | 3.2e-04 | 1.01 | 38.6K | 01:16:09 |  43.1%\n",
            "21550 | 4.4262 | 3.2e-04 | 1.02 | 38.6K | 01:16:11 |  43.1%\n",
            "21560 | 4.5017 | 3.2e-04 | 0.99 | 38.6K | 01:16:12 |  43.1%\n",
            "21570 | 4.6788 | 3.2e-04 | 1.04 | 38.6K | 01:16:14 |  43.1%\n",
            "21580 | 4.5604 | 3.2e-04 | 1.00 | 38.6K | 01:16:16 |  43.2%\n",
            "21590 | 4.2296 | 3.2e-04 | 1.09 | 38.6K | 01:16:18 |  43.2%\n",
            "21600 | 4.4986 | 3.2e-04 | 0.99 | 38.6K | 01:16:19 |  43.2%\n",
            "21610 | 4.6355 | 3.2e-04 | 0.98 | 38.6K | 01:16:21 |  43.2%\n",
            "21620 | 4.4716 | 3.2e-04 | 1.04 | 38.6K | 01:16:23 |  43.2%\n",
            "21630 | 4.5037 | 3.2e-04 | 0.97 | 38.6K | 01:16:24 |  43.3%\n",
            "21640 | 4.3690 | 3.2e-04 | 1.02 | 38.7K | 01:16:26 |  43.3%\n",
            "21650 | 3.8976 | 3.2e-04 | 1.18 | 38.7K | 01:16:28 |  43.3%\n",
            "21660 | 4.4802 | 3.2e-04 | 0.96 | 38.7K | 01:16:30 |  43.3%\n",
            "21670 | 4.5901 | 3.2e-04 | 1.01 | 38.7K | 01:16:31 |  43.3%\n",
            "21680 | 4.6720 | 3.2e-04 | 1.00 | 38.7K | 01:16:33 |  43.4%\n",
            "21690 | 4.4542 | 3.2e-04 | 0.99 | 38.7K | 01:16:35 |  43.4%\n",
            "21700 | 4.3267 | 3.2e-04 | 1.03 | 38.7K | 01:16:36 |  43.4%\n",
            "21710 | 4.4819 | 3.2e-04 | 0.98 | 38.7K | 01:16:38 |  43.4%\n",
            "21720 | 4.7197 | 3.2e-04 | 1.00 | 38.7K | 01:16:40 |  43.4%\n",
            "21730 | 4.7587 | 3.2e-04 | 0.98 | 38.7K | 01:16:42 |  43.5%\n",
            "21740 | 4.6447 | 3.2e-04 | 1.04 | 38.7K | 01:16:43 |  43.5%\n",
            "21750 | 4.5184 | 3.2e-04 | 0.98 | 38.7K | 01:16:45 |  43.5%\n",
            "21760 | 4.6379 | 3.2e-04 | 1.07 | 38.7K | 01:16:47 |  43.5%\n",
            "21770 | 4.2771 | 3.2e-04 | 1.00 | 38.7K | 01:16:48 |  43.5%\n",
            "21780 | 4.4412 | 3.2e-04 | 1.05 | 38.7K | 01:16:50 |  43.6%\n",
            "21790 | 4.5610 | 3.2e-04 | 0.96 | 38.7K | 01:16:52 |  43.6%\n",
            "21800 | 4.5621 | 3.2e-04 | 0.99 | 38.7K | 01:16:54 |  43.6%\n",
            "21810 | 4.3961 | 3.2e-04 | 0.98 | 38.7K | 01:16:55 |  43.6%\n",
            "21820 | 4.6786 | 3.2e-04 | 0.98 | 38.7K | 01:16:57 |  43.6%\n",
            "21830 | 4.5236 | 3.2e-04 | 0.98 | 38.7K | 01:16:59 |  43.7%\n",
            "21840 | 4.5061 | 3.2e-04 | 1.00 | 38.7K | 01:17:00 |  43.7%\n",
            "21850 | 4.8195 | 3.2e-04 | 1.12 | 38.7K | 01:17:02 |  43.7%\n",
            "21860 | 4.7018 | 3.2e-04 | 0.99 | 38.7K | 01:17:04 |  43.7%\n",
            "21870 | 4.3978 | 3.2e-04 | 1.05 | 38.7K | 01:17:06 |  43.7%\n",
            "21880 | 4.6047 | 3.2e-04 | 1.01 | 38.7K | 01:17:07 |  43.8%\n",
            "21890 | 4.4518 | 3.2e-04 | 1.00 | 38.7K | 01:17:09 |  43.8%\n",
            "21900 | 4.6375 | 3.2e-04 | 0.95 | 38.7K | 01:17:11 |  43.8%\n",
            "21910 | 4.8322 | 3.2e-04 | 1.01 | 38.7K | 01:17:12 |  43.8%\n",
            "21920 | 4.2896 | 3.2e-04 | 0.96 | 38.7K | 01:17:14 |  43.8%\n",
            "21930 | 4.7722 | 3.2e-04 | 0.98 | 38.7K | 01:17:16 |  43.9%\n",
            "21940 | 4.4713 | 3.2e-04 | 0.99 | 38.8K | 01:17:17 |  43.9%\n",
            "21950 | 4.6905 | 3.2e-04 | 0.99 | 38.8K | 01:17:19 |  43.9%\n",
            "21960 | 4.7141 | 3.2e-04 | 0.98 | 38.8K | 01:17:21 |  43.9%\n",
            "21970 | 4.5670 | 3.2e-04 | 1.00 | 38.8K | 01:17:23 |  43.9%\n",
            "21980 | 4.4648 | 3.2e-04 | 0.99 | 38.8K | 01:17:24 |  44.0%\n",
            "21990 | 4.4843 | 3.1e-04 | 0.97 | 38.8K | 01:17:26 |  44.0%\n",
            "22000 | 4.6575 | 3.1e-04 | 1.02 | 38.8K | 01:17:28 |  44.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 22000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.5107\n",
            "  Perplexity: 90.99\n",
            "  Train loss (avg): 4.5226\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        , bir bu√ßuk saat s√ºr√ºyor. Hava hem de gece sƒ±caklƒ±klarƒ±yla birlikte bu g√ºne≈üin ƒ±sƒ±nmasƒ±nƒ± zorla≈ütƒ±rƒ±yor. Hava, r√ºzgar ve r√ºzgar gibi olumsuz hava ko≈üullarƒ± sebebiyle de bu r√ºzgarƒ±n a≈üƒ±rƒ± sƒ±cak olduƒüunu g√∂steriyor. √ñyle\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        ƒ∞stanbul'da, b√∂lgede ikamet eden yakla≈üƒ±k 8 bin ki≈üi yakalandƒ±. A tipi 'Teknik Yapƒ±'nƒ±n eylem alanƒ± yakla≈üƒ±k 10 bin ki≈üilik grup tarafƒ±ndan saniye saniye saniye saniye saniye saniye kaydedildi. T√ºrkiye'de\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        sayesinde √∂ƒürenme ve √∂ƒürenme ile ilgili bilgi sahibi olabilmenin sadece temel bir bilgiden ibaret olmadƒ±ƒüƒ±nƒ± anlatan beyaz yakalƒ±, bilgi, tutum, zeka, tutum, zihin ve mantƒ±k kavramlarƒ±nƒ± inceleyen bilim dalƒ±dƒ±r\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:38:57\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "22010 | 4.6644 | 3.1e-04 | 0.99 | 38.6K | 01:17:47 |  44.0%\n",
            "22020 | 4.5621 | 3.1e-04 | 0.98 | 38.6K | 01:17:48 |  44.0%\n",
            "22030 | 4.4441 | 3.1e-04 | 1.03 | 38.6K | 01:17:50 |  44.1%\n",
            "22040 | 4.4347 | 3.1e-04 | 1.07 | 38.6K | 01:17:52 |  44.1%\n",
            "22050 | 4.6236 | 3.1e-04 | 0.98 | 38.6K | 01:17:54 |  44.1%\n",
            "22060 | 4.4621 | 3.1e-04 | 0.98 | 38.6K | 01:17:55 |  44.1%\n",
            "22070 | 4.2572 | 3.1e-04 | 1.07 | 38.7K | 01:17:57 |  44.1%\n",
            "22080 | 4.5890 | 3.1e-04 | 0.98 | 38.7K | 01:17:59 |  44.2%\n",
            "22090 | 4.5005 | 3.1e-04 | 0.97 | 38.7K | 01:18:00 |  44.2%\n",
            "22100 | 4.3961 | 3.1e-04 | 0.98 | 38.7K | 01:18:02 |  44.2%\n",
            "22110 | 4.3063 | 3.1e-04 | 0.96 | 38.7K | 01:18:04 |  44.2%\n",
            "22120 | 4.3368 | 3.1e-04 | 0.95 | 38.7K | 01:18:06 |  44.2%\n",
            "22130 | 4.7251 | 3.1e-04 | 1.03 | 38.7K | 01:18:07 |  44.3%\n",
            "22140 | 4.6588 | 3.1e-04 | 1.04 | 38.7K | 01:18:09 |  44.3%\n",
            "22150 | 4.7971 | 3.1e-04 | 1.00 | 38.7K | 01:18:11 |  44.3%\n",
            "22160 | 4.7030 | 3.1e-04 | 1.00 | 38.7K | 01:18:12 |  44.3%\n",
            "22170 | 4.6545 | 3.1e-04 | 0.98 | 38.7K | 01:18:14 |  44.3%\n",
            "22180 | 4.5396 | 3.1e-04 | 1.03 | 38.7K | 01:18:16 |  44.4%\n",
            "22190 | 4.4650 | 3.1e-04 | 1.08 | 38.7K | 01:18:18 |  44.4%\n",
            "22200 | 4.5378 | 3.1e-04 | 1.00 | 38.7K | 01:18:19 |  44.4%\n",
            "22210 | 4.3874 | 3.1e-04 | 1.01 | 38.7K | 01:18:21 |  44.4%\n",
            "22220 | 4.4248 | 3.1e-04 | 0.98 | 38.7K | 01:18:23 |  44.4%\n",
            "22230 | 4.1069 | 3.1e-04 | 1.06 | 38.7K | 01:18:24 |  44.5%\n",
            "22240 | 4.4247 | 3.1e-04 | 1.02 | 38.7K | 01:18:26 |  44.5%\n",
            "22250 | 4.6458 | 3.1e-04 | 0.98 | 38.7K | 01:18:28 |  44.5%\n",
            "22260 | 4.5328 | 3.1e-04 | 0.97 | 38.7K | 01:18:30 |  44.5%\n",
            "22270 | 4.6554 | 3.1e-04 | 1.07 | 38.7K | 01:18:31 |  44.5%\n",
            "22280 | 4.2987 | 3.1e-04 | 1.12 | 38.7K | 01:18:33 |  44.6%\n",
            "22290 | 4.4320 | 3.1e-04 | 1.00 | 38.7K | 01:18:35 |  44.6%\n",
            "22300 | 4.5617 | 3.1e-04 | 0.99 | 38.7K | 01:18:36 |  44.6%\n",
            "22310 | 4.5615 | 3.1e-04 | 0.99 | 38.7K | 01:18:38 |  44.6%\n",
            "22320 | 4.1275 | 3.1e-04 | 1.11 | 38.7K | 01:18:40 |  44.6%\n",
            "22330 | 4.7548 | 3.1e-04 | 1.02 | 38.7K | 01:18:42 |  44.7%\n",
            "22340 | 4.6639 | 3.1e-04 | 1.02 | 38.7K | 01:18:43 |  44.7%\n",
            "22350 | 4.5293 | 3.1e-04 | 1.01 | 38.7K | 01:18:45 |  44.7%\n",
            "22360 | 4.3343 | 3.1e-04 | 1.13 | 38.7K | 01:18:47 |  44.7%\n",
            "22370 | 4.5190 | 3.1e-04 | 0.98 | 38.8K | 01:18:48 |  44.7%\n",
            "22380 | 4.7005 | 3.1e-04 | 1.04 | 38.8K | 01:18:50 |  44.8%\n",
            "22390 | 4.4652 | 3.1e-04 | 1.00 | 38.8K | 01:18:52 |  44.8%\n",
            "22400 | 4.6717 | 3.1e-04 | 1.02 | 38.8K | 01:18:54 |  44.8%\n",
            "22410 | 4.3147 | 3.1e-04 | 0.98 | 38.8K | 01:18:55 |  44.8%\n",
            "22420 | 4.2634 | 3.1e-04 | 1.06 | 38.8K | 01:18:57 |  44.8%\n",
            "22430 | 4.4512 | 3.1e-04 | 1.01 | 38.8K | 01:18:59 |  44.9%\n",
            "22440 | 4.8528 | 3.1e-04 | 0.99 | 38.8K | 01:19:00 |  44.9%\n",
            "22450 | 4.4052 | 3.1e-04 | 1.00 | 38.8K | 01:19:02 |  44.9%\n",
            "22460 | 4.2086 | 3.1e-04 | 1.19 | 38.8K | 01:19:04 |  44.9%\n",
            "22470 | 4.3965 | 3.1e-04 | 0.99 | 38.8K | 01:19:06 |  44.9%\n",
            "22480 | 4.7352 | 3.1e-04 | 1.04 | 38.8K | 01:19:07 |  45.0%\n",
            "22490 | 4.5043 | 3.1e-04 | 1.03 | 38.8K | 01:19:09 |  45.0%\n",
            "22500 | 4.3546 | 3.1e-04 | 0.99 | 38.8K | 01:19:11 |  45.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 22500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.4843\n",
            "  Perplexity: 88.62\n",
            "  Train loss (avg): 4.5274\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        durumu da √ßok normal. Tabii ben de bu durumu daha √ßok anlƒ±yorum. Bu, insanlarƒ±n ya≈üadƒ±ƒüƒ± durumu da yok. ≈ûu anda durum √ßok farklƒ±. Ama hava durumu pek √∂yle. Biz hava durumunu ne zaman g√∂ster\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Moskova'da ya≈üanan FET√ñ/PDY operasyonunda ter√∂ristlere y√∂nelik saldƒ±rƒ±larda 23 ki≈üi tutuklandƒ±. Ter√∂r √∂rg√ºt√º DEA≈û'ƒ±n adƒ±nƒ± ta≈üƒ±yan bir √∂rg√ºtten ter√∂r √∂rg√ºt√º tarafƒ±ndan kabul edilen 6 ki≈üi tutuklandƒ±. Yapƒ±lan a√ßƒ±klamada,\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        tarafƒ±ndan geli≈ütirilen sistemlerde yapay zekanƒ±n nasƒ±l yapƒ±lacaƒüƒ±na dair yeni bir imkanƒ±n ortaya √ßƒ±kmasƒ± i√ßin bu sistemlerde de hem yapay zeka hem de yapay zekanƒ±n nasƒ±l kullanƒ±lacaƒüƒ±na dair bir yenilik yer alƒ±yor\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.4843)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:37:12\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "22510 | 4.5615 | 3.1e-04 | 1.00 | 38.6K | 01:19:33 |  45.0%\n",
            "22520 | 4.4360 | 3.1e-04 | 1.03 | 38.6K | 01:19:35 |  45.0%\n",
            "22530 | 4.7707 | 3.1e-04 | 1.01 | 38.6K | 01:19:37 |  45.1%\n",
            "22540 | 4.7901 | 3.1e-04 | 1.04 | 38.6K | 01:19:38 |  45.1%\n",
            "22550 | 4.6003 | 3.1e-04 | 0.97 | 38.6K | 01:19:40 |  45.1%\n",
            "22560 | 4.7267 | 3.1e-04 | 1.16 | 38.6K | 01:19:42 |  45.1%\n",
            "22570 | 4.1256 | 3.1e-04 | 1.05 | 38.6K | 01:19:43 |  45.1%\n",
            "22580 | 4.4633 | 3.1e-04 | 1.07 | 38.7K | 01:19:45 |  45.2%\n",
            "22590 | 4.2776 | 3.1e-04 | 1.04 | 38.7K | 01:19:47 |  45.2%\n",
            "22600 | 4.3801 | 3.1e-04 | 1.10 | 38.7K | 01:19:48 |  45.2%\n",
            "22610 | 4.6694 | 3.1e-04 | 1.03 | 38.7K | 01:19:50 |  45.2%\n",
            "22620 | 4.5465 | 3.0e-04 | 0.96 | 38.7K | 01:19:52 |  45.2%\n",
            "22630 | 4.1129 | 3.0e-04 | 1.08 | 38.7K | 01:19:54 |  45.3%\n",
            "22640 | 4.3767 | 3.0e-04 | 1.01 | 38.7K | 01:19:55 |  45.3%\n",
            "22650 | 4.5315 | 3.0e-04 | 1.01 | 38.7K | 01:19:57 |  45.3%\n",
            "22660 | 4.3745 | 3.0e-04 | 1.01 | 38.7K | 01:19:59 |  45.3%\n",
            "22670 | 4.2831 | 3.0e-04 | 1.01 | 38.7K | 01:20:00 |  45.3%\n",
            "22680 | 4.2973 | 3.0e-04 | 1.03 | 38.7K | 01:20:02 |  45.4%\n",
            "22690 | 4.5686 | 3.0e-04 | 0.99 | 38.7K | 01:20:04 |  45.4%\n",
            "22700 | 4.6905 | 3.0e-04 | 1.01 | 38.7K | 01:20:06 |  45.4%\n",
            "22710 | 4.1478 | 3.0e-04 | 1.11 | 38.7K | 01:20:07 |  45.4%\n",
            "22720 | 4.4931 | 3.0e-04 | 1.08 | 38.7K | 01:20:09 |  45.4%\n",
            "22730 | 4.5319 | 3.0e-04 | 0.99 | 38.7K | 01:20:11 |  45.5%\n",
            "22740 | 4.4981 | 3.0e-04 | 1.04 | 38.7K | 01:20:12 |  45.5%\n",
            "22750 | 4.5814 | 3.0e-04 | 1.05 | 38.7K | 01:20:14 |  45.5%\n",
            "22760 | 4.4826 | 3.0e-04 | 1.03 | 38.7K | 01:20:16 |  45.5%\n",
            "22770 | 4.7564 | 3.0e-04 | 0.99 | 38.7K | 01:20:18 |  45.5%\n",
            "22780 | 4.1194 | 3.0e-04 | 1.09 | 38.7K | 01:20:19 |  45.6%\n",
            "22790 | 4.5280 | 3.0e-04 | 0.98 | 38.7K | 01:20:21 |  45.6%\n",
            "22800 | 4.7264 | 3.0e-04 | 1.02 | 38.7K | 01:20:23 |  45.6%\n",
            "22810 | 4.4410 | 3.0e-04 | 1.04 | 38.7K | 01:20:24 |  45.6%\n",
            "22820 | 4.6758 | 3.0e-04 | 1.04 | 38.7K | 01:20:26 |  45.6%\n",
            "22830 | 4.6442 | 3.0e-04 | 1.01 | 38.7K | 01:20:28 |  45.7%\n",
            "22840 | 4.4499 | 3.0e-04 | 0.96 | 38.7K | 01:20:30 |  45.7%\n",
            "22850 | 4.2486 | 3.0e-04 | 1.00 | 38.7K | 01:20:31 |  45.7%\n",
            "22860 | 4.4014 | 3.0e-04 | 1.08 | 38.7K | 01:20:33 |  45.7%\n",
            "22870 | 4.5804 | 3.0e-04 | 0.98 | 38.7K | 01:20:35 |  45.7%\n",
            "22880 | 4.2613 | 3.0e-04 | 1.24 | 38.8K | 01:20:36 |  45.8%\n",
            "22890 | 4.4105 | 3.0e-04 | 1.08 | 38.8K | 01:20:38 |  45.8%\n",
            "22900 | 4.6678 | 3.0e-04 | 0.99 | 38.8K | 01:20:40 |  45.8%\n",
            "22910 | 4.0939 | 3.0e-04 | 1.03 | 38.8K | 01:20:42 |  45.8%\n",
            "22920 | 4.5444 | 3.0e-04 | 1.02 | 38.8K | 01:20:43 |  45.8%\n",
            "22930 | 4.3661 | 3.0e-04 | 1.02 | 38.8K | 01:20:45 |  45.9%\n",
            "22940 | 4.6095 | 3.0e-04 | 1.03 | 38.8K | 01:20:47 |  45.9%\n",
            "22950 | 4.6091 | 3.0e-04 | 1.47 | 38.8K | 01:20:48 |  45.9%\n",
            "22960 | 4.3832 | 3.0e-04 | 1.05 | 38.8K | 01:20:50 |  45.9%\n",
            "22970 | 4.2990 | 3.0e-04 | 1.01 | 38.8K | 01:20:52 |  45.9%\n",
            "22980 | 4.4604 | 3.0e-04 | 1.01 | 38.8K | 01:20:54 |  46.0%\n",
            "22990 | 4.2479 | 3.0e-04 | 1.02 | 38.8K | 01:20:55 |  46.0%\n",
            "23000 | 4.5342 | 3.0e-04 | 1.01 | 38.8K | 01:20:57 |  46.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 23000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.4371\n",
            "  Perplexity: 84.53\n",
            "  Train loss (avg): 4.5009\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        ƒ±sƒ±sƒ± a≈üƒ±rƒ± derecede g√∂z g√∂re 1.3.5 derece ila 1.9 derece arasƒ±nda olacak. Bu arada hava, hava, hava ve hava saatlerinden dolayƒ± daha fazla yaƒüƒ±≈ü bekleyebilir. Bunlar ise a≈üƒ±rƒ± soƒüuktan\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Berlin'de yer alan ve Avrupa'nƒ±n en g√ºzel ≈üehirlerinden biri olan Berlin'de gezilecek pek √ßok yer var. Bu b√∂lgeler en yakƒ±n olan ≈üehirlerden olan Berlin'de, d√ºnyanƒ±n en eski ≈üehirlerinden biri\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , bu teknolojinin kullanƒ±mƒ±yla ilgili daha detaylƒ± bilgi edinmenizi saƒülar. Bir ya da birka√ß farklƒ± akƒ±llƒ± teknoloji, √∂zellikle Google tarafƒ±ndan yapƒ±lan bir ara≈ütƒ±rmaya g√∂re, bir bulu≈üun g√∂revi, kurumdaki bir kurum veya bir\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.4371)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.71\n",
            "     ETA: 01:35:27\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "23010 | 4.6099 | 3.0e-04 | 0.97 | 38.6K | 01:21:20 |  46.0%\n",
            "23020 | 4.4063 | 3.0e-04 | 0.98 | 38.6K | 01:21:22 |  46.0%\n",
            "23030 | 4.5337 | 3.0e-04 | 1.07 | 38.6K | 01:21:23 |  46.1%\n",
            "23040 | 4.5382 | 3.0e-04 | 1.03 | 38.6K | 01:21:25 |  46.1%\n",
            "23050 | 4.6946 | 3.0e-04 | 1.02 | 38.6K | 01:21:27 |  46.1%\n",
            "23060 | 4.5823 | 3.0e-04 | 0.99 | 38.6K | 01:21:28 |  46.1%\n",
            "23070 | 4.5804 | 3.0e-04 | 1.04 | 38.6K | 01:21:30 |  46.1%\n",
            "23080 | 4.5364 | 3.0e-04 | 1.00 | 38.6K | 01:21:32 |  46.2%\n",
            "23090 | 4.6414 | 3.0e-04 | 1.02 | 38.6K | 01:21:34 |  46.2%\n",
            "23100 | 4.6109 | 3.0e-04 | 1.02 | 38.7K | 01:21:35 |  46.2%\n",
            "23110 | 4.5849 | 3.0e-04 | 1.03 | 38.7K | 01:21:37 |  46.2%\n",
            "23120 | 4.4431 | 3.0e-04 | 1.03 | 38.7K | 01:21:39 |  46.2%\n",
            "23130 | 4.5775 | 3.0e-04 | 1.08 | 38.7K | 01:21:40 |  46.3%\n",
            "23140 | 4.3705 | 3.0e-04 | 1.01 | 38.7K | 01:21:42 |  46.3%\n",
            "23150 | 4.5854 | 3.0e-04 | 1.02 | 38.7K | 01:21:44 |  46.3%\n",
            "23160 | 4.5075 | 3.0e-04 | 1.06 | 38.7K | 01:21:46 |  46.3%\n",
            "23170 | 4.4076 | 3.0e-04 | 1.04 | 38.7K | 01:21:47 |  46.3%\n",
            "23180 | 4.6966 | 3.0e-04 | 1.02 | 38.7K | 01:21:49 |  46.4%\n",
            "23190 | 4.4033 | 3.0e-04 | 1.01 | 38.7K | 01:21:51 |  46.4%\n",
            "23200 | 4.3786 | 3.0e-04 | 1.04 | 38.7K | 01:21:52 |  46.4%\n",
            "23210 | 4.6046 | 3.0e-04 | 1.00 | 38.7K | 01:21:54 |  46.4%\n",
            "23220 | 4.7823 | 3.0e-04 | 0.99 | 38.7K | 01:21:56 |  46.4%\n",
            "23230 | 4.5375 | 3.0e-04 | 1.01 | 38.7K | 01:21:58 |  46.5%\n",
            "23240 | 4.5984 | 2.9e-04 | 1.04 | 38.7K | 01:21:59 |  46.5%\n",
            "23250 | 4.2991 | 2.9e-04 | 1.06 | 38.7K | 01:22:01 |  46.5%\n",
            "23260 | 4.3426 | 2.9e-04 | 1.01 | 38.7K | 01:22:03 |  46.5%\n",
            "23270 | 4.1829 | 2.9e-04 | 1.13 | 38.7K | 01:22:04 |  46.5%\n",
            "23280 | 4.2124 | 2.9e-04 | 1.36 | 38.7K | 01:22:06 |  46.6%\n",
            "23290 | 4.2711 | 2.9e-04 | 0.98 | 38.7K | 01:22:08 |  46.6%\n",
            "23300 | 4.0095 | 2.9e-04 | 1.07 | 38.7K | 01:22:10 |  46.6%\n",
            "23310 | 4.4617 | 2.9e-04 | 0.99 | 38.7K | 01:22:11 |  46.6%\n",
            "23320 | 4.3148 | 2.9e-04 | 1.00 | 38.7K | 01:22:13 |  46.6%\n",
            "23330 | 4.4736 | 2.9e-04 | 1.00 | 38.7K | 01:22:15 |  46.7%\n",
            "23340 | 4.3537 | 2.9e-04 | 1.07 | 38.7K | 01:22:16 |  46.7%\n",
            "23350 | 4.6219 | 2.9e-04 | 1.00 | 38.7K | 01:22:18 |  46.7%\n",
            "23360 | 4.1893 | 2.9e-04 | 1.04 | 38.7K | 01:22:20 |  46.7%\n",
            "23370 | 4.5297 | 2.9e-04 | 1.07 | 38.7K | 01:22:21 |  46.7%\n",
            "23380 | 4.7370 | 2.9e-04 | 1.06 | 38.7K | 01:22:23 |  46.8%\n",
            "23390 | 4.4672 | 2.9e-04 | 1.06 | 38.7K | 01:22:25 |  46.8%\n",
            "23400 | 4.4162 | 2.9e-04 | 1.75 | 38.7K | 01:22:27 |  46.8%\n",
            "23410 | 4.4508 | 2.9e-04 | 1.08 | 38.8K | 01:22:28 |  46.8%\n",
            "23420 | 4.4790 | 2.9e-04 | 1.02 | 38.8K | 01:22:30 |  46.8%\n",
            "23430 | 4.5595 | 2.9e-04 | 1.02 | 38.8K | 01:22:32 |  46.9%\n",
            "23440 | 4.4615 | 2.9e-04 | 0.99 | 38.8K | 01:22:33 |  46.9%\n",
            "23450 | 4.4921 | 2.9e-04 | 1.00 | 38.8K | 01:22:35 |  46.9%\n",
            "23460 | 4.4637 | 2.9e-04 | 1.02 | 38.8K | 01:22:37 |  46.9%\n",
            "23470 | 4.4828 | 2.9e-04 | 0.99 | 38.8K | 01:22:39 |  46.9%\n",
            "23480 | 4.3647 | 2.9e-04 | 1.01 | 38.8K | 01:22:40 |  47.0%\n",
            "23490 | 4.3361 | 2.9e-04 | 1.10 | 38.8K | 01:22:42 |  47.0%\n",
            "23500 | 4.4267 | 2.9e-04 | 0.97 | 38.8K | 01:22:44 |  47.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 23500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.4759\n",
            "  Perplexity: 87.88\n",
            "  Train loss (avg): 4.5152\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        larƒ±n soƒüuk olmasƒ±na raƒümen kar, yaz aylarƒ±nda kar yaƒüƒ±yor. Ancak kar yaƒüƒ±≈üƒ± ile birlikte kar yaƒüƒ±yor. Kar yaƒüƒ±≈üƒ± ise kar yaƒüƒ±≈üƒ± i√ßin kar yaƒüdƒ±. Kar yaƒüƒ±≈üƒ± bu kadar etkili olmazken kar yaƒüƒ±≈üƒ±\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Ankara'da yapƒ±lan bir konu≈ümada, Ankara'da yapƒ±lan bir konu≈ümada, ‚ÄúBunu ben asla kabul edemem‚Äù dedi. Bu a√ßƒ±klama, Ankara'da yapƒ±lan bir konu≈ümada, ‚ÄúBizim ba≈ükent Ankara'da da\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        (M2, 3M2, 3M2, 3M2, 3M2, 3M2, 3M2, 4M2, 2M2, 3M2, 3M2, 3M2, 3M2, 2\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:33:37\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "23510 | 4.1628 | 2.9e-04 | 1.04 | 38.6K | 01:23:03 |  47.0%\n",
            "23520 | 4.4317 | 2.9e-04 | 1.05 | 38.7K | 01:23:04 |  47.0%\n",
            "23530 | 4.3081 | 2.9e-04 | 1.01 | 38.7K | 01:23:06 |  47.1%\n",
            "23540 | 4.5684 | 2.9e-04 | 1.04 | 38.7K | 01:23:08 |  47.1%\n",
            "23550 | 4.4366 | 2.9e-04 | 1.02 | 38.7K | 01:23:10 |  47.1%\n",
            "23560 | 4.4734 | 2.9e-04 | 1.00 | 38.7K | 01:23:11 |  47.1%\n",
            "23570 | 4.4544 | 2.9e-04 | 1.04 | 38.7K | 01:23:13 |  47.1%\n",
            "23580 | 4.6047 | 2.9e-04 | 1.07 | 38.7K | 01:23:15 |  47.2%\n",
            "23590 | 4.7487 | 2.9e-04 | 1.03 | 38.7K | 01:23:16 |  47.2%\n",
            "23600 | 4.5682 | 2.9e-04 | 0.99 | 38.7K | 01:23:18 |  47.2%\n",
            "23610 | 4.3364 | 2.9e-04 | 1.05 | 38.7K | 01:23:20 |  47.2%\n",
            "23620 | 4.5460 | 2.9e-04 | 0.98 | 38.7K | 01:23:22 |  47.2%\n",
            "23630 | 4.5816 | 2.9e-04 | 1.05 | 38.7K | 01:23:23 |  47.3%\n",
            "23640 | 4.4344 | 2.9e-04 | 1.07 | 38.7K | 01:23:25 |  47.3%\n",
            "23650 | 4.9031 | 2.9e-04 | 1.08 | 38.7K | 01:23:27 |  47.3%\n",
            "23660 | 4.4108 | 2.9e-04 | 0.98 | 38.7K | 01:23:28 |  47.3%\n",
            "23670 | 4.4108 | 2.9e-04 | 0.98 | 38.7K | 01:23:30 |  47.3%\n",
            "23680 | 4.5954 | 2.9e-04 | 1.01 | 38.7K | 01:23:32 |  47.4%\n",
            "23690 | 4.3378 | 2.9e-04 | 1.02 | 38.7K | 01:23:34 |  47.4%\n",
            "23700 | 4.5839 | 2.9e-04 | 1.05 | 38.7K | 01:23:35 |  47.4%\n",
            "23710 | 4.5437 | 2.9e-04 | 1.05 | 38.7K | 01:23:37 |  47.4%\n",
            "23720 | 4.4325 | 2.9e-04 | 1.27 | 38.7K | 01:23:39 |  47.4%\n",
            "23730 | 4.4255 | 2.9e-04 | 1.06 | 38.7K | 01:23:40 |  47.5%\n",
            "23740 | 4.2289 | 2.9e-04 | 1.07 | 38.7K | 01:23:42 |  47.5%\n",
            "23750 | 4.7978 | 2.9e-04 | 1.01 | 38.7K | 01:23:44 |  47.5%\n",
            "23760 | 4.6067 | 2.9e-04 | 0.99 | 38.7K | 01:23:46 |  47.5%\n",
            "23770 | 4.4209 | 2.9e-04 | 1.08 | 38.7K | 01:23:47 |  47.5%\n",
            "23780 | 4.7223 | 2.9e-04 | 1.03 | 38.7K | 01:23:49 |  47.6%\n",
            "23790 | 4.6637 | 2.9e-04 | 1.02 | 38.7K | 01:23:51 |  47.6%\n",
            "23800 | 4.2490 | 2.9e-04 | 1.01 | 38.7K | 01:23:52 |  47.6%\n",
            "23810 | 4.5839 | 2.9e-04 | 1.00 | 38.7K | 01:23:54 |  47.6%\n",
            "23820 | 4.6751 | 2.9e-04 | 1.01 | 38.7K | 01:23:56 |  47.6%\n",
            "23830 | 4.8057 | 2.9e-04 | 1.01 | 38.7K | 01:23:58 |  47.7%\n",
            "23840 | 4.3292 | 2.9e-04 | 0.99 | 38.8K | 01:23:59 |  47.7%\n",
            "23850 | 4.4520 | 2.9e-04 | 1.00 | 38.8K | 01:24:01 |  47.7%\n",
            "23860 | 4.5673 | 2.8e-04 | 1.00 | 38.8K | 01:24:03 |  47.7%\n",
            "23870 | 4.5987 | 2.8e-04 | 1.05 | 38.8K | 01:24:04 |  47.7%\n",
            "23880 | 4.5534 | 2.8e-04 | 1.04 | 38.8K | 01:24:06 |  47.8%\n",
            "23890 | 4.2676 | 2.8e-04 | 1.03 | 38.8K | 01:24:08 |  47.8%\n",
            "23900 | 4.4105 | 2.8e-04 | 1.01 | 38.8K | 01:24:10 |  47.8%\n",
            "23910 | 4.5720 | 2.8e-04 | 1.01 | 38.8K | 01:24:11 |  47.8%\n",
            "23920 | 4.5446 | 2.8e-04 | 1.05 | 38.8K | 01:24:13 |  47.8%\n",
            "23930 | 4.3822 | 2.8e-04 | 1.03 | 38.8K | 01:24:15 |  47.9%\n",
            "23940 | 4.3582 | 2.8e-04 | 1.03 | 38.8K | 01:24:16 |  47.9%\n",
            "23950 | 4.7589 | 2.8e-04 | 1.02 | 38.8K | 01:24:18 |  47.9%\n",
            "23960 | 4.6426 | 2.8e-04 | 1.02 | 38.8K | 01:24:20 |  47.9%\n",
            "23970 | 4.3717 | 2.8e-04 | 0.98 | 38.8K | 01:24:22 |  47.9%\n",
            "23980 | 4.4628 | 2.8e-04 | 1.00 | 38.8K | 01:24:23 |  48.0%\n",
            "23990 | 4.7228 | 2.8e-04 | 1.04 | 38.8K | 01:24:25 |  48.0%\n",
            "24000 | 4.7840 | 2.8e-04 | 1.05 | 38.8K | 01:24:27 |  48.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 24000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.4364\n",
            "  Perplexity: 84.47\n",
            "  Train loss (avg): 4.5144\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        sƒ±caklƒ±ƒüƒ±nƒ±n b√ºy√ºk oranda azalmasƒ±na neden olan √∂nemli bir fakt√∂r olan kol saati, yol boyunca uzanan bir hƒ±zla hareket etmeye ba≈ülar. Bu sebeple sƒ±rt kƒ±smƒ±nda uzun uzun sapmalarƒ± yoksa, ya da uzun uzun sapmalarƒ±\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        ve T√ºrkiye'nin merkez il√ßelerinden birisi olan ve T√ºrkiye'nin en b√ºy√ºk ve en b√ºy√ºk kenti olarak kabul edilen Gazi Mustafa Kemal Atat√ºrk'√ºn \"Muƒürideler\" dediƒüi \"Hocam\"\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        ve yapay zeka teknolojilerini destekleyerek, yapay zekada ya≈üananlarƒ±n √∂n√ºne ge√ßilebilir. Bu teknolojiler, yapay zeka ile ilgilenen insanlarƒ±n t√ºm bilgiye eri≈üimini saƒülar ve hatta biz onlarƒ± nasƒ±l kullandƒ±ƒüƒ±mƒ±z konusunda bilgilendirir.\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.4364)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:31:51\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "24010 | 4.3795 | 2.8e-04 | 1.00 | 38.6K | 01:24:49 |  48.0%\n",
            "24020 | 4.7696 | 2.8e-04 | 1.03 | 38.6K | 01:24:51 |  48.0%\n",
            "24030 | 4.7189 | 2.8e-04 | 1.03 | 38.7K | 01:24:53 |  48.1%\n",
            "24040 | 4.3344 | 2.8e-04 | 1.09 | 38.7K | 01:24:54 |  48.1%\n",
            "24050 | 4.3578 | 2.8e-04 | 1.02 | 38.7K | 01:24:56 |  48.1%\n",
            "24060 | 4.4709 | 2.8e-04 | 1.01 | 38.7K | 01:24:58 |  48.1%\n",
            "24070 | 4.3022 | 2.8e-04 | 1.07 | 38.7K | 01:24:59 |  48.1%\n",
            "24080 | 4.4613 | 2.8e-04 | 0.99 | 38.7K | 01:25:01 |  48.2%\n",
            "24090 | 4.8824 | 2.8e-04 | 1.02 | 38.7K | 01:25:03 |  48.2%\n",
            "24100 | 4.4441 | 2.8e-04 | 1.00 | 38.7K | 01:25:05 |  48.2%\n",
            "24110 | 4.3427 | 2.8e-04 | 1.09 | 38.7K | 01:25:06 |  48.2%\n",
            "24120 | 4.3904 | 2.8e-04 | 1.01 | 38.7K | 01:25:08 |  48.2%\n",
            "24130 | 4.4755 | 2.8e-04 | 1.00 | 38.7K | 01:25:10 |  48.3%\n",
            "24140 | 4.4675 | 2.8e-04 | 1.06 | 38.7K | 01:25:11 |  48.3%\n",
            "24150 | 4.5876 | 2.8e-04 | 1.04 | 38.7K | 01:25:13 |  48.3%\n",
            "24160 | 4.5376 | 2.8e-04 | 1.07 | 38.7K | 01:25:15 |  48.3%\n",
            "24170 | 4.6843 | 2.8e-04 | 1.02 | 38.7K | 01:25:17 |  48.3%\n",
            "24180 | 4.6066 | 2.8e-04 | 0.99 | 38.7K | 01:25:18 |  48.4%\n",
            "24190 | 4.6334 | 2.8e-04 | 1.03 | 38.7K | 01:25:20 |  48.4%\n",
            "24200 | 4.3233 | 2.8e-04 | 1.02 | 38.7K | 01:25:22 |  48.4%\n",
            "24210 | 4.4207 | 2.8e-04 | 1.13 | 38.7K | 01:25:23 |  48.4%\n",
            "24220 | 4.4880 | 2.8e-04 | 1.03 | 38.7K | 01:25:25 |  48.4%\n",
            "24230 | 4.5393 | 2.8e-04 | 1.09 | 38.7K | 01:25:27 |  48.5%\n",
            "24240 | 4.3364 | 2.8e-04 | 1.00 | 38.7K | 01:25:29 |  48.5%\n",
            "24250 | 4.1187 | 2.8e-04 | 1.12 | 38.7K | 01:25:30 |  48.5%\n",
            "24260 | 4.3758 | 2.8e-04 | 1.03 | 38.7K | 01:25:32 |  48.5%\n",
            "24270 | 4.5493 | 2.8e-04 | 1.05 | 38.7K | 01:25:34 |  48.5%\n",
            "24280 | 4.3550 | 2.8e-04 | 1.00 | 38.7K | 01:25:35 |  48.6%\n",
            "24290 | 4.6451 | 2.8e-04 | 1.13 | 38.7K | 01:25:37 |  48.6%\n",
            "24300 | 4.5456 | 2.8e-04 | 1.07 | 38.7K | 01:25:39 |  48.6%\n",
            "24310 | 4.4951 | 2.8e-04 | 1.05 | 38.7K | 01:25:41 |  48.6%\n",
            "24320 | 4.5642 | 2.8e-04 | 1.04 | 38.7K | 01:25:42 |  48.6%\n",
            "24330 | 4.6380 | 2.8e-04 | 1.05 | 38.7K | 01:25:44 |  48.7%\n",
            "24340 | 4.3406 | 2.8e-04 | 1.06 | 38.7K | 01:25:46 |  48.7%\n",
            "24350 | 4.4673 | 2.8e-04 | 1.07 | 38.7K | 01:25:47 |  48.7%\n",
            "24360 | 4.3458 | 2.8e-04 | 1.03 | 38.8K | 01:25:49 |  48.7%\n",
            "24370 | 4.2877 | 2.8e-04 | 1.10 | 38.8K | 01:25:51 |  48.7%\n",
            "24380 | 4.2748 | 2.8e-04 | 1.10 | 38.8K | 01:25:53 |  48.8%\n",
            "24390 | 4.7743 | 2.8e-04 | 0.99 | 38.8K | 01:25:54 |  48.8%\n",
            "24400 | 4.4533 | 2.8e-04 | 1.05 | 38.8K | 01:25:56 |  48.8%\n",
            "24410 | 4.6154 | 2.8e-04 | 1.06 | 38.8K | 01:25:58 |  48.8%\n",
            "24420 | 4.5792 | 2.8e-04 | 1.03 | 38.8K | 01:25:59 |  48.8%\n",
            "24430 | 4.6660 | 2.8e-04 | 1.02 | 38.8K | 01:26:01 |  48.9%\n",
            "24440 | 4.5399 | 2.8e-04 | 1.03 | 38.8K | 01:26:03 |  48.9%\n",
            "24450 | 4.5049 | 2.8e-04 | 1.01 | 38.8K | 01:26:05 |  48.9%\n",
            "24460 | 4.3247 | 2.8e-04 | 1.06 | 38.8K | 01:26:06 |  48.9%\n",
            "24470 | 4.6039 | 2.8e-04 | 1.05 | 38.8K | 01:26:08 |  48.9%\n",
            "24480 | 4.2164 | 2.7e-04 | 1.12 | 38.8K | 01:26:10 |  49.0%\n",
            "24490 | 4.5017 | 2.7e-04 | 1.12 | 38.8K | 01:26:11 |  49.0%\n",
            "24500 | 4.4236 | 2.7e-04 | 1.05 | 38.8K | 01:26:13 |  49.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 24500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.4180\n",
            "  Perplexity: 82.93\n",
            "  Train loss (avg): 4.4658\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        ko≈üullarƒ±na kar≈üƒ± duyarlƒ± olan herkes, her ≈üeyi √ß√∂zecek bir ≈üeyler arar. Derhal bir kadƒ±n olan herkesin niyetinde tek bir ≈üey yoktur. √áaresiz ve karamsar olan herkesin hayatƒ±n planlarƒ±nƒ± bilmeniz, asla kabul etmeniz\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Ankara'da ya≈üayan T√ºrk vatanda≈ülarƒ±, ya≈üadƒ±klarƒ± tehdit, yabancƒ± uyruklularla da kar≈üƒ± kar≈üƒ±yalar. T√ºrkiye'nin vize serbestliƒüi konusundaki taleplerinin ba≈üƒ±nda Suriye. T√ºrkiye ile yapƒ±lan anla≈ümalarda, T√ºrkiye'nin vize\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , yapay zeka ile √ßalƒ±≈ümaya devam ediyor. Yapay zeka, yapay zeka ile √ßalƒ±≈ümaya devam ediyor. Yapay zeka ile √ßalƒ±≈ümanƒ±n dijital d√ºnyada √ßok daha kolay olacaƒüƒ±nƒ± belirten Yapay Zeka, yapay zeka ile √ßalƒ±≈ümanƒ±n daha kolay olacaƒüƒ±nƒ± belirtiyor\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.4180)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:30:06\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "24510 | 4.4122 | 2.7e-04 | 1.10 | 38.6K | 01:26:36 |  49.0%\n",
            "24520 | 4.5520 | 2.7e-04 | 1.03 | 38.6K | 01:26:37 |  49.0%\n",
            "24530 | 4.5924 | 2.7e-04 | 1.04 | 38.6K | 01:26:39 |  49.1%\n",
            "24540 | 4.7534 | 2.7e-04 | 1.04 | 38.7K | 01:26:41 |  49.1%\n",
            "24550 | 4.8397 | 2.7e-04 | 1.02 | 38.7K | 01:26:43 |  49.1%\n",
            "24560 | 4.2924 | 2.7e-04 | 1.04 | 38.7K | 01:26:44 |  49.1%\n",
            "24570 | 4.5454 | 2.7e-04 | 1.03 | 38.7K | 01:26:46 |  49.1%\n",
            "24580 | 4.3247 | 2.7e-04 | 1.02 | 38.7K | 01:26:48 |  49.2%\n",
            "24590 | 4.4107 | 2.7e-04 | 1.01 | 38.7K | 01:26:49 |  49.2%\n",
            "24600 | 4.3235 | 2.7e-04 | 1.03 | 38.7K | 01:26:51 |  49.2%\n",
            "24610 | 4.6227 | 2.7e-04 | 1.04 | 38.7K | 01:26:53 |  49.2%\n",
            "24620 | 4.3354 | 2.7e-04 | 0.99 | 38.7K | 01:26:55 |  49.2%\n",
            "24630 | 4.1744 | 2.7e-04 | 1.03 | 38.7K | 01:26:56 |  49.3%\n",
            "24640 | 4.2232 | 2.7e-04 | 1.05 | 38.7K | 01:26:58 |  49.3%\n",
            "24650 | 4.3845 | 2.7e-04 | 1.04 | 38.7K | 01:27:00 |  49.3%\n",
            "24660 | 4.6275 | 2.7e-04 | 1.05 | 38.7K | 01:27:01 |  49.3%\n",
            "24670 | 4.4615 | 2.7e-04 | 1.21 | 38.7K | 01:27:03 |  49.3%\n",
            "24680 | 4.6800 | 2.7e-04 | 1.01 | 38.7K | 01:27:05 |  49.4%\n",
            "24690 | 4.3467 | 2.7e-04 | 1.02 | 38.7K | 01:27:07 |  49.4%\n",
            "24700 | 4.4895 | 2.7e-04 | 1.05 | 38.7K | 01:27:08 |  49.4%\n",
            "24710 | 4.5545 | 2.7e-04 | 1.04 | 38.7K | 01:27:10 |  49.4%\n",
            "24720 | 4.5838 | 2.7e-04 | 1.01 | 38.7K | 01:27:12 |  49.4%\n",
            "24730 | 4.3064 | 2.7e-04 | 1.05 | 38.7K | 01:27:13 |  49.5%\n",
            "24740 | 4.4321 | 2.7e-04 | 1.02 | 38.7K | 01:27:15 |  49.5%\n",
            "24750 | 4.6012 | 2.7e-04 | 1.00 | 38.7K | 01:27:17 |  49.5%\n",
            "24760 | 4.2952 | 2.7e-04 | 1.04 | 38.7K | 01:27:19 |  49.5%\n",
            "24770 | 4.5882 | 2.7e-04 | 1.06 | 38.7K | 01:27:20 |  49.5%\n",
            "24780 | 4.1810 | 2.7e-04 | 1.02 | 38.7K | 01:27:22 |  49.6%\n",
            "24790 | 4.4807 | 2.7e-04 | 1.06 | 38.7K | 01:27:24 |  49.6%\n",
            "24800 | 4.3776 | 2.7e-04 | 1.03 | 38.7K | 01:27:25 |  49.6%\n",
            "24810 | 4.4651 | 2.7e-04 | 1.11 | 38.7K | 01:27:27 |  49.6%\n",
            "24820 | 4.5489 | 2.7e-04 | 1.66 | 38.7K | 01:27:29 |  49.6%\n",
            "24830 | 4.6013 | 2.7e-04 | 1.03 | 38.7K | 01:27:30 |  49.7%\n",
            "24840 | 4.3641 | 2.7e-04 | 1.19 | 38.7K | 01:27:32 |  49.7%\n",
            "24850 | 4.4005 | 2.7e-04 | 1.06 | 38.7K | 01:27:34 |  49.7%\n",
            "24860 | 4.2218 | 2.7e-04 | 1.05 | 38.7K | 01:27:36 |  49.7%\n",
            "24870 | 4.5249 | 2.7e-04 | 1.06 | 38.7K | 01:27:37 |  49.7%\n",
            "24880 | 4.3978 | 2.7e-04 | 1.05 | 38.8K | 01:27:39 |  49.8%\n",
            "24890 | 4.4080 | 2.7e-04 | 1.10 | 38.8K | 01:27:41 |  49.8%\n",
            "24900 | 4.5893 | 2.7e-04 | 1.00 | 38.8K | 01:27:42 |  49.8%\n",
            "24910 | 4.0391 | 2.7e-04 | 1.10 | 38.8K | 01:27:44 |  49.8%\n",
            "24920 | 4.6697 | 2.7e-04 | 1.03 | 38.8K | 01:27:46 |  49.8%\n",
            "24930 | 4.5538 | 2.7e-04 | 1.04 | 38.8K | 01:27:48 |  49.9%\n",
            "24940 | 4.4941 | 2.7e-04 | 1.05 | 38.8K | 01:27:49 |  49.9%\n",
            "24950 | 4.4626 | 2.7e-04 | 1.03 | 38.8K | 01:27:51 |  49.9%\n",
            "24960 | 4.6441 | 2.7e-04 | 1.05 | 38.8K | 01:27:53 |  49.9%\n",
            "24970 | 4.4653 | 2.7e-04 | 1.02 | 38.8K | 01:27:54 |  49.9%\n",
            "24980 | 4.6102 | 2.7e-04 | 1.05 | 38.8K | 01:27:56 |  50.0%\n",
            "24990 | 4.5981 | 2.7e-04 | 1.02 | 38.8K | 01:27:58 |  50.0%\n",
            "25000 | 4.3208 | 2.7e-04 | 1.02 | 38.8K | 01:28:00 |  50.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 25000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.4063\n",
            "  Perplexity: 81.97\n",
            "  Train loss (avg): 4.4603\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        larƒ±n √ßok yava≈ü ilerlediƒüi ve fƒ±rtƒ±nalarƒ±n b√ºy√ºk etkisi olduƒüu bir ortamda, a≈üƒ±rƒ± derecede sƒ±caklƒ±klarƒ±n bir miktar y√ºkselmesine sebep olacaƒüƒ±, bu da √ßok ge√ß bir derecede yaƒüa d√∂n√º≈üebilir. Yaƒümura bile karƒ±≈ü\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        olan ƒ∞stanbul, √∂zellikle ƒ∞stanbul, Ankara, ƒ∞stanbul, Ankara ve Ankara gibi bir√ßok farklƒ± lokasyonda hizmet veriyor. Ankara'nƒ±n bir diƒüer √∂zelliƒüi de ƒ∞stanbul, Ankara, ƒ∞stanbul ve ƒ∞zmir gibi bir√ßok farklƒ± lokasyonda\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , bilim ve teknoloji d√ºnyasƒ±nda kullanƒ±lan sanal robotlar gibi, insanlarƒ±n zeka ile olan ili≈ükilerini olduk√ßa karma≈üƒ±k bir hale getirmi≈ütir. Bu sayede insanlarƒ±n beyinlerine olan merakƒ± azalmƒ±≈ü ve √ßok da ilgin√ß bir y√∂ntem haline gelmi≈ütir\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.4063)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:28:20\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "üíæ Checkpoint kaydediliyor: /content/drive/MyDrive/turkish_llm/checkpoints//checkpoint_step_25000.pt\n",
            "  ‚úÖ Checkpoint kaydedildi!\n",
            "\n",
            "25010 | 4.0557 | 2.7e-04 | 1.13 | 38.6K | 01:28:25 |  50.0%\n",
            "25020 | 4.5594 | 2.7e-04 | 1.05 | 38.6K | 01:28:27 |  50.0%\n",
            "25030 | 4.5558 | 2.7e-04 | 1.02 | 38.6K | 01:28:29 |  50.1%\n",
            "25040 | 4.5460 | 2.7e-04 | 1.06 | 38.6K | 01:28:30 |  50.1%\n",
            "25050 | 4.2729 | 2.7e-04 | 1.06 | 38.6K | 01:28:32 |  50.1%\n",
            "25060 | 4.6313 | 2.7e-04 | 1.08 | 38.6K | 01:28:34 |  50.1%\n",
            "25070 | 4.3422 | 2.7e-04 | 1.11 | 38.6K | 01:28:36 |  50.1%\n",
            "25080 | 4.3165 | 2.7e-04 | 1.02 | 38.6K | 01:28:37 |  50.2%\n",
            "25090 | 4.5483 | 2.6e-04 | 1.02 | 38.6K | 01:28:39 |  50.2%\n",
            "25100 | 4.2404 | 2.6e-04 | 1.07 | 38.6K | 01:28:41 |  50.2%\n",
            "25110 | 4.3481 | 2.6e-04 | 1.05 | 38.6K | 01:28:42 |  50.2%\n",
            "25120 | 4.4636 | 2.6e-04 | 1.05 | 38.6K | 01:28:44 |  50.2%\n",
            "25130 | 4.8048 | 2.6e-04 | 1.02 | 38.6K | 01:28:46 |  50.3%\n",
            "25140 | 4.3667 | 2.6e-04 | 1.02 | 38.7K | 01:28:48 |  50.3%\n",
            "25150 | 4.2737 | 2.6e-04 | 1.20 | 38.7K | 01:28:49 |  50.3%\n",
            "25160 | 4.6139 | 2.6e-04 | 1.01 | 38.7K | 01:28:51 |  50.3%\n",
            "25170 | 4.3292 | 2.6e-04 | 1.00 | 38.7K | 01:28:53 |  50.3%\n",
            "25180 | 4.4264 | 2.6e-04 | 1.08 | 38.7K | 01:28:54 |  50.4%\n",
            "25190 | 4.3159 | 2.6e-04 | 1.08 | 38.7K | 01:28:56 |  50.4%\n",
            "25200 | 4.5756 | 2.6e-04 | 1.06 | 38.7K | 01:28:58 |  50.4%\n",
            "25210 | 4.3621 | 2.6e-04 | 1.03 | 38.7K | 01:29:00 |  50.4%\n",
            "25220 | 4.5878 | 2.6e-04 | 1.04 | 38.7K | 01:29:01 |  50.4%\n",
            "25230 | 4.5065 | 2.6e-04 | 1.05 | 38.7K | 01:29:03 |  50.5%\n",
            "25240 | 4.4741 | 2.6e-04 | 1.05 | 38.7K | 01:29:05 |  50.5%\n",
            "25250 | 4.5063 | 2.6e-04 | 1.03 | 38.7K | 01:29:06 |  50.5%\n",
            "25260 | 4.3001 | 2.6e-04 | 1.02 | 38.7K | 01:29:08 |  50.5%\n",
            "25270 | 4.3672 | 2.6e-04 | 1.07 | 38.7K | 01:29:10 |  50.5%\n",
            "25280 | 4.3464 | 2.6e-04 | 1.07 | 38.7K | 01:29:12 |  50.6%\n",
            "25290 | 4.4102 | 2.6e-04 | 1.04 | 38.7K | 01:29:13 |  50.6%\n",
            "25300 | 4.6300 | 2.6e-04 | 1.03 | 38.7K | 01:29:15 |  50.6%\n",
            "25310 | 4.5816 | 2.6e-04 | 1.02 | 38.7K | 01:29:17 |  50.6%\n",
            "25320 | 4.4138 | 2.6e-04 | 1.01 | 38.7K | 01:29:18 |  50.6%\n",
            "25330 | 4.4503 | 2.6e-04 | 1.06 | 38.7K | 01:29:20 |  50.7%\n",
            "25340 | 4.2702 | 2.6e-04 | 1.04 | 38.7K | 01:29:22 |  50.7%\n",
            "25350 | 4.5454 | 2.6e-04 | 1.04 | 38.7K | 01:29:24 |  50.7%\n",
            "25360 | 4.5223 | 2.6e-04 | 1.01 | 38.7K | 01:29:25 |  50.7%\n",
            "25370 | 4.2396 | 2.6e-04 | 1.04 | 38.7K | 01:29:27 |  50.7%\n",
            "25380 | 4.4186 | 2.6e-04 | 1.04 | 38.7K | 01:29:29 |  50.8%\n",
            "25390 | 4.5627 | 2.6e-04 | 1.03 | 38.7K | 01:29:30 |  50.8%\n",
            "25400 | 4.5978 | 2.6e-04 | 1.08 | 38.7K | 01:29:32 |  50.8%\n",
            "25410 | 4.7149 | 2.6e-04 | 1.02 | 38.7K | 01:29:34 |  50.8%\n",
            "25420 | 4.4791 | 2.6e-04 | 1.03 | 38.7K | 01:29:36 |  50.8%\n",
            "25430 | 4.4416 | 2.6e-04 | 1.09 | 38.7K | 01:29:37 |  50.9%\n",
            "25440 | 4.4962 | 2.6e-04 | 1.04 | 38.7K | 01:29:39 |  50.9%\n",
            "25450 | 4.5475 | 2.6e-04 | 1.00 | 38.7K | 01:29:41 |  50.9%\n",
            "25460 | 4.5813 | 2.6e-04 | 1.06 | 38.7K | 01:29:42 |  50.9%\n",
            "25470 | 4.0552 | 2.6e-04 | 1.24 | 38.7K | 01:29:44 |  50.9%\n",
            "25480 | 4.3325 | 2.6e-04 | 1.09 | 38.8K | 01:29:46 |  51.0%\n",
            "25490 | 4.3559 | 2.6e-04 | 1.12 | 38.8K | 01:29:48 |  51.0%\n",
            "25500 | 4.5432 | 2.6e-04 | 1.05 | 38.8K | 01:29:49 |  51.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 25500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.4170\n",
            "  Perplexity: 82.85\n",
            "  Train loss (avg): 4.4895\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        ≈üartlarƒ±ndan daha tehlikeler var. Biz de bu tehlikeleri fƒ±rsata d√∂n√º≈üt√ºrmeyi hedefliyoruz. Vatanda≈üƒ±n isteƒüi doƒürultusunda hava ko≈üullarƒ± uygun olacak. Bakanlar Kurulu da bu sebeple kararƒ±nƒ± a√ßƒ±klayacaƒüƒ± zaman buyursun ki bu\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Ankara'da ortaya √ßƒ±kan n√ºkleer santralin en b√ºy√ºk kƒ±smƒ± T√ºrkiye'ye geliyor. Ankara'ya ba≈üka bir √ºlkeye gitmek isteyen T√ºrkiye'nin, n√ºkleer santralin daha da g√ºzelle≈ümesini saƒülayan bir diƒüer fakt√∂r\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        kullanƒ±lƒ±yor. G√ºn√ºm√ºzde insanlar artƒ±k bu yazƒ±lƒ±mlarla (g√∂zleme ve √∂ƒürenme ama√ßlƒ±) g√∂zlemleniyor. Her ne kadar da dijital ortamda yapƒ±lan bir ara≈ütƒ±rmaya g√∂re, sanal ger√ßeklik, bir sanal ger√ßeklik, sanal ger√ßeklik, yapay\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:26:35\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "25510 | 4.5360 | 2.6e-04 | 1.03 | 38.6K | 01:30:08 |  51.0%\n",
            "25520 | 4.4037 | 2.6e-04 | 1.04 | 38.6K | 01:30:10 |  51.0%\n",
            "25530 | 4.6170 | 2.6e-04 | 1.03 | 38.6K | 01:30:12 |  51.1%\n",
            "25540 | 4.4021 | 2.6e-04 | 1.10 | 38.6K | 01:30:13 |  51.1%\n",
            "25550 | 4.3833 | 2.6e-04 | 1.10 | 38.6K | 01:30:15 |  51.1%\n",
            "25560 | 4.1835 | 2.6e-04 | 1.05 | 38.7K | 01:30:17 |  51.1%\n",
            "25570 | 4.5816 | 2.6e-04 | 1.02 | 38.7K | 01:30:19 |  51.1%\n",
            "25580 | 4.5319 | 2.6e-04 | 1.04 | 38.7K | 01:30:20 |  51.2%\n",
            "25590 | 4.4519 | 2.6e-04 | 1.04 | 38.7K | 01:30:22 |  51.2%\n",
            "25600 | 4.2558 | 2.6e-04 | 1.07 | 38.7K | 01:30:24 |  51.2%\n",
            "25610 | 4.5048 | 2.6e-04 | 1.03 | 38.7K | 01:30:25 |  51.2%\n",
            "25620 | 4.6581 | 2.6e-04 | 1.03 | 38.7K | 01:30:27 |  51.2%\n",
            "25630 | 4.5813 | 2.6e-04 | 1.08 | 38.7K | 01:30:29 |  51.3%\n",
            "25640 | 4.4677 | 2.6e-04 | 1.03 | 38.7K | 01:30:31 |  51.3%\n",
            "25650 | 4.5887 | 2.6e-04 | 1.03 | 38.7K | 01:30:32 |  51.3%\n",
            "25660 | 4.3682 | 2.6e-04 | 1.04 | 38.7K | 01:30:34 |  51.3%\n",
            "25670 | 4.7123 | 2.6e-04 | 1.04 | 38.7K | 01:30:36 |  51.3%\n",
            "25680 | 4.4956 | 2.6e-04 | 1.02 | 38.7K | 01:30:37 |  51.4%\n",
            "25690 | 4.4649 | 2.6e-04 | 1.03 | 38.7K | 01:30:39 |  51.4%\n",
            "25700 | 4.4180 | 2.5e-04 | 1.10 | 38.7K | 01:30:41 |  51.4%\n",
            "25710 | 4.6021 | 2.5e-04 | 1.00 | 38.7K | 01:30:43 |  51.4%\n",
            "25720 | 4.4406 | 2.5e-04 | 1.14 | 38.7K | 01:30:44 |  51.4%\n",
            "25730 | 4.5144 | 2.5e-04 | 1.14 | 38.7K | 01:30:46 |  51.5%\n",
            "25740 | 4.5114 | 2.5e-04 | 1.03 | 38.7K | 01:30:48 |  51.5%\n",
            "25750 | 4.5773 | 2.5e-04 | 1.05 | 38.7K | 01:30:49 |  51.5%\n",
            "25760 | 4.4538 | 2.5e-04 | 1.06 | 38.7K | 01:30:51 |  51.5%\n",
            "25770 | 4.4770 | 2.5e-04 | 1.01 | 38.7K | 01:30:53 |  51.5%\n",
            "25780 | 4.3854 | 2.5e-04 | 1.04 | 38.7K | 01:30:55 |  51.6%\n",
            "25790 | 4.5822 | 2.5e-04 | 1.07 | 38.7K | 01:30:56 |  51.6%\n",
            "25800 | 4.5247 | 2.5e-04 | 1.08 | 38.7K | 01:30:58 |  51.6%\n",
            "25810 | 4.3434 | 2.5e-04 | 1.10 | 38.7K | 01:31:00 |  51.6%\n",
            "25820 | 4.5227 | 2.5e-04 | 1.12 | 38.7K | 01:31:01 |  51.6%\n",
            "25830 | 4.0954 | 2.5e-04 | 1.12 | 38.7K | 01:31:03 |  51.7%\n",
            "25840 | 4.7705 | 2.5e-04 | 1.00 | 38.7K | 01:31:05 |  51.7%\n",
            "25850 | 4.2648 | 2.5e-04 | 1.05 | 38.7K | 01:31:07 |  51.7%\n",
            "25860 | 4.2607 | 2.5e-04 | 1.06 | 38.7K | 01:31:08 |  51.7%\n",
            "25870 | 4.6235 | 2.5e-04 | 1.08 | 38.7K | 01:31:10 |  51.7%\n",
            "25880 | 4.4825 | 2.5e-04 | 1.02 | 38.7K | 01:31:12 |  51.8%\n",
            "25890 | 4.7892 | 2.5e-04 | 1.07 | 38.7K | 01:31:14 |  51.8%\n",
            "25900 | 4.4459 | 2.5e-04 | 1.02 | 38.7K | 01:31:15 |  51.8%\n",
            "25910 | 4.3940 | 2.5e-04 | 1.03 | 38.8K | 01:31:17 |  51.8%\n",
            "25920 | 4.4225 | 2.5e-04 | 1.04 | 38.8K | 01:31:19 |  51.8%\n",
            "25930 | 4.4057 | 2.5e-04 | 1.11 | 38.8K | 01:31:20 |  51.9%\n",
            "25940 | 4.4503 | 2.5e-04 | 1.01 | 38.8K | 01:31:22 |  51.9%\n",
            "25950 | 4.3804 | 2.5e-04 | 1.02 | 38.8K | 01:31:24 |  51.9%\n",
            "25960 | 4.3160 | 2.5e-04 | 1.23 | 38.8K | 01:31:26 |  51.9%\n",
            "25970 | 4.4209 | 2.5e-04 | 1.01 | 38.8K | 01:31:27 |  51.9%\n",
            "25980 | 4.1912 | 2.5e-04 | 1.18 | 38.8K | 01:31:29 |  52.0%\n",
            "25990 | 4.2733 | 2.5e-04 | 1.09 | 38.8K | 01:31:31 |  52.0%\n",
            "26000 | 4.4628 | 2.5e-04 | 1.04 | 38.8K | 01:31:32 |  52.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 26000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.4134\n",
            "  Perplexity: 82.55\n",
            "  Train loss (avg): 4.4012\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        durumunu kontrol altƒ±nda tutan ve dolayƒ±sƒ±yla yoƒüunla≈üan havalarƒ±n etkisiyle, hava √ßok ≈üiddetli olup, hava sƒ±caklƒ±ƒüƒ± hemen √∂l√ß√ºlemeyecek kadar y√ºksek ve; hava sƒ±caklƒ±ƒüƒ± yakla≈üƒ±k 0‚Äôa kadar inmektedir. Yoƒüun olan hava\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        D√ºsek'in doƒüusunda bulunan B√ºy√ºk Sel√ßuklu, Osmanlƒ± ve Cumhuriyet'in ilk M√ºsl√ºman halifesi olan ≈ûeyh Said'in, halifelikten sonra tahttan indirilmesine karar vermi≈ütir. Bu durum, yeni\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , bu teknolojinin, √∂zellikle teknolojiyi kullanan ki≈üilerin, kazandƒ±klarƒ±, kazandƒ±klarƒ± veya kazandƒ±klarƒ± √ºr√ºnlerin, √ºr√ºn ve donanƒ±mlarƒ±ndan, maliyetlerinden, maliyetlerinden, maliyetlerinden ve maliyetlerinden etkilenerek etkilenip etkilen\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:24:46\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "26010 | 4.6071 | 2.5e-04 | 1.05 | 38.7K | 01:31:51 |  52.0%\n",
            "26020 | 4.7394 | 2.5e-04 | 1.06 | 38.7K | 01:31:53 |  52.0%\n",
            "26030 | 4.5876 | 2.5e-04 | 1.05 | 38.7K | 01:31:55 |  52.1%\n",
            "26040 | 4.7789 | 2.5e-04 | 1.02 | 38.7K | 01:31:56 |  52.1%\n",
            "26050 | 4.2973 | 2.5e-04 | 1.04 | 38.7K | 01:31:58 |  52.1%\n",
            "26060 | 4.3097 | 2.5e-04 | 1.06 | 38.7K | 01:32:00 |  52.1%\n",
            "26070 | 4.3521 | 2.5e-04 | 1.08 | 38.7K | 01:32:02 |  52.1%\n",
            "26080 | 4.0336 | 2.5e-04 | 1.28 | 38.7K | 01:32:03 |  52.2%\n",
            "26090 | 4.5311 | 2.5e-04 | 1.04 | 38.7K | 01:32:05 |  52.2%\n",
            "26100 | 4.3178 | 2.5e-04 | 1.08 | 38.7K | 01:32:07 |  52.2%\n",
            "26110 | 4.3711 | 2.5e-04 | 1.05 | 38.7K | 01:32:08 |  52.2%\n",
            "26120 | 4.8370 | 2.5e-04 | 1.03 | 38.7K | 01:32:10 |  52.2%\n",
            "26130 | 4.1596 | 2.5e-04 | 1.11 | 38.7K | 01:32:12 |  52.3%\n",
            "26140 | 3.9635 | 2.5e-04 | 1.08 | 38.7K | 01:32:14 |  52.3%\n",
            "26150 | 3.9417 | 2.5e-04 | 1.17 | 38.7K | 01:32:15 |  52.3%\n",
            "26160 | 4.6737 | 2.5e-04 | 1.06 | 38.7K | 01:32:17 |  52.3%\n",
            "26170 | 4.4043 | 2.5e-04 | 1.05 | 38.7K | 01:32:19 |  52.3%\n",
            "26180 | 4.4938 | 2.5e-04 | 1.06 | 38.7K | 01:32:20 |  52.4%\n",
            "26190 | 4.4504 | 2.5e-04 | 1.06 | 38.7K | 01:32:22 |  52.4%\n",
            "26200 | 4.4309 | 2.5e-04 | 1.03 | 38.7K | 01:32:24 |  52.4%\n",
            "26210 | 4.5863 | 2.5e-04 | 1.06 | 38.7K | 01:32:26 |  52.4%\n",
            "26220 | 4.2892 | 2.5e-04 | 1.77 | 38.7K | 01:32:27 |  52.4%\n",
            "26230 | 4.4046 | 2.5e-04 | 1.10 | 38.7K | 01:32:29 |  52.5%\n",
            "26240 | 4.3906 | 2.5e-04 | 1.03 | 38.7K | 01:32:31 |  52.5%\n",
            "26250 | 4.3372 | 2.5e-04 | 1.04 | 38.7K | 01:32:32 |  52.5%\n",
            "26260 | 4.6262 | 2.5e-04 | 1.08 | 38.7K | 01:32:34 |  52.5%\n",
            "26270 | 4.6262 | 2.5e-04 | 1.05 | 38.7K | 01:32:36 |  52.5%\n",
            "26280 | 4.0202 | 2.5e-04 | 1.07 | 38.7K | 01:32:38 |  52.6%\n",
            "26290 | 4.6872 | 2.5e-04 | 1.05 | 38.7K | 01:32:39 |  52.6%\n",
            "26300 | 4.7608 | 2.5e-04 | 1.05 | 38.7K | 01:32:41 |  52.6%\n",
            "26310 | 4.6281 | 2.4e-04 | 1.02 | 38.7K | 01:32:43 |  52.6%\n",
            "26320 | 4.4458 | 2.4e-04 | 1.04 | 38.7K | 01:32:44 |  52.6%\n",
            "26330 | 4.2716 | 2.4e-04 | 1.06 | 38.7K | 01:32:46 |  52.7%\n",
            "26340 | 4.5004 | 2.4e-04 | 1.08 | 38.8K | 01:32:48 |  52.7%\n",
            "26350 | 4.3078 | 2.4e-04 | inf | 38.8K | 01:32:50 |  52.7%\n",
            "26360 | 4.7239 | 2.4e-04 | 1.05 | 38.8K | 01:32:51 |  52.7%\n",
            "26370 | 4.4127 | 2.4e-04 | 1.04 | 38.8K | 01:32:53 |  52.7%\n",
            "26380 | 4.2429 | 2.4e-04 | 1.09 | 38.8K | 01:32:55 |  52.8%\n",
            "26390 | 4.6812 | 2.4e-04 | 1.07 | 38.8K | 01:32:56 |  52.8%\n",
            "26400 | 4.5632 | 2.4e-04 | 1.05 | 38.8K | 01:32:58 |  52.8%\n",
            "26410 | 4.2747 | 2.4e-04 | 1.09 | 38.8K | 01:33:00 |  52.8%\n",
            "26420 | 4.3136 | 2.4e-04 | 1.01 | 38.8K | 01:33:02 |  52.8%\n",
            "26430 | 4.4112 | 2.4e-04 | 1.17 | 38.8K | 01:33:03 |  52.9%\n",
            "26440 | 4.7032 | 2.4e-04 | 1.05 | 38.8K | 01:33:05 |  52.9%\n",
            "26450 | 4.5790 | 2.4e-04 | 1.05 | 38.8K | 01:33:07 |  52.9%\n",
            "26460 | 4.6230 | 2.4e-04 | 1.06 | 38.8K | 01:33:08 |  52.9%\n",
            "26470 | 4.0945 | 2.4e-04 | 1.03 | 38.8K | 01:33:10 |  52.9%\n",
            "26480 | 4.4008 | 2.4e-04 | 1.08 | 38.8K | 01:33:12 |  53.0%\n",
            "26490 | 4.5046 | 2.4e-04 | 1.07 | 38.8K | 01:33:14 |  53.0%\n",
            "26500 | 4.9096 | 2.4e-04 | 1.03 | 38.8K | 01:33:15 |  53.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 26500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.3809\n",
            "  Perplexity: 79.91\n",
            "  Train loss (avg): 4.4266\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        larƒ±n soƒüumaya ba≈üladƒ±ƒüƒ± bug√ºnlerde, hava sƒ±caklƒ±ƒüƒ±nƒ±n en d√º≈ü√ºk seviyede olduƒüu; hava sƒ±caklƒ±ƒüƒ±nƒ±n en y√ºksek olduƒüu alanlar; hava sƒ±caklƒ±klarƒ±nƒ±n en y√ºksek olduƒüu alanlar; hava sƒ±caklƒ±ƒüƒ±nƒ±n en y√ºksek olduƒüu alanlar; hava sƒ±cak\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        ƒ∞stanbul'da, T√ºrkiye'nin en √ßok ziyaret edilen il√ßesi ƒ∞zmir oldu. ƒ∞zmir'de Atat√ºrk Havalimanƒ±'nƒ±n a√ßƒ±lƒ±≈ü t√∂reni yapƒ±ldƒ±. T√ºrkiye'nin en b√ºy√ºk kentlerinden ƒ∞zmir'in en b√ºy√ºk kenti ƒ∞zmir\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        √ºzerine yapay zekanƒ±n kullanƒ±mƒ± hakkƒ±nda daha fazla bilgi vereceƒüiz. Yapay zekanƒ±n nasƒ±l kullanƒ±ldƒ±ƒüƒ± konusu; Yapay zeka sistemlerinin insan zekasƒ±nƒ±n nasƒ±l ve nasƒ±l kullanƒ±lacaƒüƒ±; Yapay zeka sistemlerinin insan zekasƒ±nƒ± nasƒ±l kullanacaƒüƒ±;\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.3809)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.6K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:23:01\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "26510 | 4.4685 | 2.4e-04 | 1.03 | 38.6K | 01:33:38 |  53.0%\n",
            "26520 | 4.2007 | 2.4e-04 | 1.07 | 38.7K | 01:33:40 |  53.0%\n",
            "26530 | 4.4616 | 2.4e-04 | 1.04 | 38.7K | 01:33:42 |  53.1%\n",
            "26540 | 4.3625 | 2.4e-04 | 1.04 | 38.7K | 01:33:44 |  53.1%\n",
            "26550 | 4.4910 | 2.4e-04 | 1.04 | 38.7K | 01:33:45 |  53.1%\n",
            "26560 | 4.3125 | 2.4e-04 | 1.10 | 38.7K | 01:33:47 |  53.1%\n",
            "26570 | 4.6984 | 2.4e-04 | 1.09 | 38.7K | 01:33:49 |  53.1%\n",
            "26580 | 4.5687 | 2.4e-04 | 1.04 | 38.7K | 01:33:50 |  53.2%\n",
            "26590 | 4.4274 | 2.4e-04 | 1.08 | 38.7K | 01:33:52 |  53.2%\n",
            "26600 | 4.4058 | 2.4e-04 | 1.12 | 38.7K | 01:33:54 |  53.2%\n",
            "26610 | 4.3997 | 2.4e-04 | 1.05 | 38.7K | 01:33:56 |  53.2%\n",
            "26620 | 4.3545 | 2.4e-04 | 1.06 | 38.7K | 01:33:57 |  53.2%\n",
            "26630 | 4.4922 | 2.4e-04 | 1.17 | 38.7K | 01:33:59 |  53.3%\n",
            "26640 | 4.6459 | 2.4e-04 | 1.01 | 38.7K | 01:34:01 |  53.3%\n",
            "26650 | 4.6611 | 2.4e-04 | 1.03 | 38.7K | 01:34:02 |  53.3%\n",
            "26660 | 4.2754 | 2.4e-04 | 1.04 | 38.7K | 01:34:04 |  53.3%\n",
            "26670 | 4.6516 | 2.4e-04 | 1.05 | 38.7K | 01:34:06 |  53.3%\n",
            "26680 | 4.2850 | 2.4e-04 | 1.05 | 38.7K | 01:34:08 |  53.4%\n",
            "26690 | 4.3983 | 2.4e-04 | 1.06 | 38.7K | 01:34:09 |  53.4%\n",
            "26700 | 4.4790 | 2.4e-04 | 1.05 | 38.7K | 01:34:11 |  53.4%\n",
            "26710 | 4.2005 | 2.4e-04 | 1.30 | 38.7K | 01:34:13 |  53.4%\n",
            "26720 | 4.4759 | 2.4e-04 | 1.09 | 38.7K | 01:34:14 |  53.4%\n",
            "26730 | 4.1553 | 2.4e-04 | 1.09 | 38.7K | 01:34:16 |  53.5%\n",
            "26740 | 4.3243 | 2.4e-04 | 1.06 | 38.7K | 01:34:18 |  53.5%\n",
            "26750 | 4.6505 | 2.4e-04 | 1.11 | 38.7K | 01:34:20 |  53.5%\n",
            "26760 | 4.4899 | 2.4e-04 | 1.05 | 38.7K | 01:34:21 |  53.5%\n",
            "26770 | 4.6099 | 2.4e-04 | 1.05 | 38.7K | 01:34:23 |  53.5%\n",
            "26780 | 4.7675 | 2.4e-04 | 1.05 | 38.7K | 01:34:25 |  53.6%\n",
            "26790 | 4.5377 | 2.4e-04 | 1.04 | 38.7K | 01:34:26 |  53.6%\n",
            "26800 | 4.4142 | 2.4e-04 | 1.02 | 38.7K | 01:34:28 |  53.6%\n",
            "26810 | 4.0552 | 2.4e-04 | 1.18 | 38.7K | 01:34:30 |  53.6%\n",
            "26820 | 4.4081 | 2.4e-04 | 1.06 | 38.7K | 01:34:32 |  53.6%\n",
            "26830 | 4.5344 | 2.4e-04 | 1.13 | 38.7K | 01:34:33 |  53.7%\n",
            "26840 | 4.4313 | 2.4e-04 | 1.06 | 38.7K | 01:34:35 |  53.7%\n",
            "26850 | 4.5340 | 2.4e-04 | 1.05 | 38.7K | 01:34:37 |  53.7%\n",
            "26860 | 4.4468 | 2.4e-04 | 1.12 | 38.7K | 01:34:38 |  53.7%\n",
            "26870 | 4.1389 | 2.4e-04 | 1.01 | 38.7K | 01:34:40 |  53.7%\n",
            "26880 | 4.1820 | 2.4e-04 | 1.04 | 38.8K | 01:34:42 |  53.8%\n",
            "26890 | 4.3684 | 2.4e-04 | 1.06 | 38.8K | 01:34:44 |  53.8%\n",
            "26900 | 4.5434 | 2.4e-04 | 1.05 | 38.8K | 01:34:45 |  53.8%\n",
            "26910 | 4.2145 | 2.4e-04 | 1.08 | 38.8K | 01:34:47 |  53.8%\n",
            "26920 | 4.5478 | 2.3e-04 | 1.05 | 38.8K | 01:34:49 |  53.8%\n",
            "26930 | 4.5672 | 2.3e-04 | 1.06 | 38.8K | 01:34:50 |  53.9%\n",
            "26940 | 4.1442 | 2.3e-04 | 1.31 | 38.8K | 01:34:52 |  53.9%\n",
            "26950 | 4.3847 | 2.3e-04 | 1.07 | 38.8K | 01:34:54 |  53.9%\n",
            "26960 | 4.2845 | 2.3e-04 | 1.16 | 38.8K | 01:34:56 |  53.9%\n",
            "26970 | 4.4144 | 2.3e-04 | 1.07 | 38.8K | 01:34:57 |  53.9%\n",
            "26980 | 4.5813 | 2.3e-04 | 1.10 | 38.8K | 01:34:59 |  54.0%\n",
            "26990 | 4.6563 | 2.3e-04 | 1.08 | 38.8K | 01:35:01 |  54.0%\n",
            "27000 | 4.3758 | 2.3e-04 | 1.05 | 38.8K | 01:35:02 |  54.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 27000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.4084\n",
            "  Perplexity: 82.14\n",
            "  Train loss (avg): 4.4218\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        durumu ve ilk yardƒ±mlar ne zaman? Hava durumu ve hava durumu tahmin ediliyor. Hava durumu tahminleri belli oluyor. Hava durumu tahminleri belli oluyor. Hava durumu tahminleri belli oluyor. Hava durumu tahmin\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        olan ƒ∞stanbul'da 11 Eyl√ºl Per≈üembe g√ºn√º ba≈ülayan saƒüanak yaƒüƒ±≈üla birlikte, ƒ∞stanbul'da da ƒ∞stanbul'da da hissedilecek saƒüanak yaƒüƒ±≈üla birlikte, ƒ∞stanbul'un ... T√ºrkiye'nin ilk ve tek kurulu≈ü\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        en b√ºy√ºk g√º√ßler ve d√ºnya liderlerinin d√ºnya pazarlarƒ± ve k√ºresel pazara verdiƒüi √∂nemin bir sonucu olarak, √ºlkelerin ba≈üarƒ±yla uluslararasƒ± pazarda yer almasƒ±nƒ± saƒülayacak bir sistem kurmak ve geli≈ütirmek ve ticaret i√ßin gereken teknolojik imkan ve kapasit\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:21:12\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "27010 | 4.3542 | 2.3e-04 | 1.14 | 38.7K | 01:35:21 |  54.0%\n",
            "27020 | 4.4864 | 2.3e-04 | 1.05 | 38.7K | 01:35:23 |  54.0%\n",
            "27030 | 4.3664 | 2.3e-04 | 1.05 | 38.7K | 01:35:25 |  54.1%\n",
            "27040 | 4.5579 | 2.3e-04 | 1.07 | 38.7K | 01:35:27 |  54.1%\n",
            "27050 | 4.6841 | 2.3e-04 | 1.07 | 38.7K | 01:35:28 |  54.1%\n",
            "27060 | 4.0402 | 2.3e-04 | 1.02 | 38.7K | 01:35:30 |  54.1%\n",
            "27070 | 4.5767 | 2.3e-04 | 1.07 | 38.7K | 01:35:32 |  54.1%\n",
            "27080 | 4.3971 | 2.3e-04 | 1.05 | 38.7K | 01:35:33 |  54.2%\n",
            "27090 | 4.2397 | 2.3e-04 | 1.07 | 38.7K | 01:35:35 |  54.2%\n",
            "27100 | 4.0494 | 2.3e-04 | 1.12 | 38.7K | 01:35:37 |  54.2%\n",
            "27110 | 4.4306 | 2.3e-04 | 1.07 | 38.7K | 01:35:39 |  54.2%\n",
            "27120 | 4.6121 | 2.3e-04 | 1.04 | 38.7K | 01:35:40 |  54.2%\n",
            "27130 | 4.5370 | 2.3e-04 | 1.10 | 38.7K | 01:35:42 |  54.3%\n",
            "27140 | 4.3212 | 2.3e-04 | 1.06 | 38.7K | 01:35:44 |  54.3%\n",
            "27150 | 4.5467 | 2.3e-04 | 1.06 | 38.7K | 01:35:45 |  54.3%\n",
            "27160 | 4.1922 | 2.3e-04 | 1.09 | 38.7K | 01:35:47 |  54.3%\n",
            "27170 | 4.2918 | 2.3e-04 | 1.03 | 38.7K | 01:35:49 |  54.3%\n",
            "27180 | 4.5409 | 2.3e-04 | 1.06 | 38.7K | 01:35:51 |  54.4%\n",
            "27190 | 4.3314 | 2.3e-04 | 1.09 | 38.7K | 01:35:52 |  54.4%\n",
            "27200 | 4.5300 | 2.3e-04 | 1.03 | 38.7K | 01:35:54 |  54.4%\n",
            "27210 | 4.7729 | 2.3e-04 | 1.09 | 38.7K | 01:35:56 |  54.4%\n",
            "27220 | 4.4151 | 2.3e-04 | 1.06 | 38.7K | 01:35:57 |  54.4%\n",
            "27230 | 4.5606 | 2.3e-04 | 1.08 | 38.7K | 01:35:59 |  54.5%\n",
            "27240 | 4.2502 | 2.3e-04 | 1.05 | 38.7K | 01:36:01 |  54.5%\n",
            "27250 | 4.0978 | 2.3e-04 | 1.08 | 38.7K | 01:36:02 |  54.5%\n",
            "27260 | 4.5887 | 2.3e-04 | 1.08 | 38.7K | 01:36:04 |  54.5%\n",
            "27270 | 4.4770 | 2.3e-04 | 1.11 | 38.7K | 01:36:06 |  54.5%\n",
            "27280 | 4.0643 | 2.3e-04 | 1.10 | 38.7K | 01:36:08 |  54.6%\n",
            "27290 | 4.1851 | 2.3e-04 | 1.09 | 38.7K | 01:36:09 |  54.6%\n",
            "27300 | 4.6204 | 2.3e-04 | 1.07 | 38.7K | 01:36:11 |  54.6%\n",
            "27310 | 4.3611 | 2.3e-04 | 1.22 | 38.8K | 01:36:13 |  54.6%\n",
            "27320 | 4.3750 | 2.3e-04 | 1.06 | 38.8K | 01:36:14 |  54.6%\n",
            "27330 | 4.7436 | 2.3e-04 | 1.04 | 38.8K | 01:36:16 |  54.7%\n",
            "27340 | 4.3679 | 2.3e-04 | 1.07 | 38.8K | 01:36:18 |  54.7%\n",
            "27350 | 4.5385 | 2.3e-04 | 1.07 | 38.8K | 01:36:20 |  54.7%\n",
            "27360 | 4.6232 | 2.3e-04 | 1.08 | 38.8K | 01:36:21 |  54.7%\n",
            "27370 | 4.4698 | 2.3e-04 | 1.04 | 38.8K | 01:36:23 |  54.7%\n",
            "27380 | 4.4231 | 2.3e-04 | 1.06 | 38.8K | 01:36:25 |  54.8%\n",
            "27390 | 4.3634 | 2.3e-04 | 1.10 | 38.8K | 01:36:26 |  54.8%\n",
            "27400 | 4.5302 | 2.3e-04 | 1.06 | 38.8K | 01:36:28 |  54.8%\n",
            "27410 | 4.1306 | 2.3e-04 | 1.04 | 38.8K | 01:36:30 |  54.8%\n",
            "27420 | 4.1475 | 2.3e-04 | 1.17 | 38.8K | 01:36:32 |  54.8%\n",
            "27430 | 4.5225 | 2.3e-04 | 1.11 | 38.8K | 01:36:33 |  54.9%\n",
            "27440 | 4.3497 | 2.3e-04 | 1.05 | 38.8K | 01:36:35 |  54.9%\n",
            "27450 | 4.8504 | 2.3e-04 | 1.07 | 38.8K | 01:36:37 |  54.9%\n",
            "27460 | 4.4637 | 2.3e-04 | 1.07 | 38.8K | 01:36:38 |  54.9%\n",
            "27470 | 4.5468 | 2.3e-04 | 1.07 | 38.8K | 01:36:40 |  54.9%\n",
            "27480 | 4.1757 | 2.3e-04 | 1.05 | 38.8K | 01:36:42 |  55.0%\n",
            "27490 | 4.2084 | 2.3e-04 | 1.07 | 38.8K | 01:36:44 |  55.0%\n",
            "27500 | 4.3143 | 2.3e-04 | 1.09 | 38.8K | 01:36:45 |  55.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 27500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.3565\n",
            "  Perplexity: 77.99\n",
            "  Train loss (avg): 4.3854\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        larƒ±n ƒ±sƒ±nmasƒ±yla beraber, havalarƒ±n soƒüuk olmasƒ± ve su emiliminin artmasƒ± nedeniyle kƒ±≈ü aylarƒ±nda soƒüuk hava almaya ve kƒ±≈ü aylarƒ±nda soƒüuk hava ile i√ßildikleri i√ßin soƒüuk hava dalgasƒ±nƒ± engellemeye devam ederken,\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        dir. Bu √ºlkede ya≈üayan, √ºreten, √ºreten, √ºreten, √ºreten, √ºreten, b√ºy√ºyen bir millet yoktur. Bizim derdimiz de burasƒ±. Bunun i√ßin her t√ºrl√º yolu tercih ettik. Yƒ±llardƒ±r ter√∂r √∂rg√ºt√º ile m√ºcadele\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        artƒ±k robotlar, robotlar, robotlar ve robotlar √ºzerinde √ßalƒ±≈üabilecek. Yapay zeka teknolojisi artƒ±k robotlar ve robotlar √ºzerinde √ßalƒ±≈üabilecek. Yapay zekalƒ± robotlar, robotlar ve robotlar\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.3565)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:19:27\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "27510 | 4.2125 | 2.3e-04 | 1.05 | 38.7K | 01:37:08 |  55.0%\n",
            "27520 | 4.4141 | 2.3e-04 | 1.13 | 38.7K | 01:37:09 |  55.0%\n",
            "27530 | 4.2854 | 2.3e-04 | 1.14 | 38.7K | 01:37:11 |  55.1%\n",
            "27540 | 4.3136 | 2.2e-04 | 1.09 | 38.7K | 01:37:13 |  55.1%\n",
            "27550 | 4.3519 | 2.2e-04 | 1.12 | 38.7K | 01:37:14 |  55.1%\n",
            "27560 | 4.4450 | 2.2e-04 | 1.08 | 38.7K | 01:37:16 |  55.1%\n",
            "27570 | 4.0077 | 2.2e-04 | 1.08 | 38.7K | 01:37:18 |  55.1%\n",
            "27580 | 4.3320 | 2.2e-04 | 1.15 | 38.7K | 01:37:20 |  55.2%\n",
            "27590 | 4.4343 | 2.2e-04 | 1.05 | 38.7K | 01:37:21 |  55.2%\n",
            "27600 | 4.5971 | 2.2e-04 | 1.09 | 38.7K | 01:37:23 |  55.2%\n",
            "27610 | 4.1517 | 2.2e-04 | 1.10 | 38.7K | 01:37:25 |  55.2%\n",
            "27620 | 4.7222 | 2.2e-04 | 1.09 | 38.7K | 01:37:26 |  55.2%\n",
            "27630 | 4.3565 | 2.2e-04 | 1.10 | 38.7K | 01:37:28 |  55.3%\n",
            "27640 | 4.3519 | 2.2e-04 | 1.08 | 38.7K | 01:37:30 |  55.3%\n",
            "27650 | 4.4694 | 2.2e-04 | 1.07 | 38.7K | 01:37:32 |  55.3%\n",
            "27660 | 4.5186 | 2.2e-04 | 1.09 | 38.7K | 01:37:33 |  55.3%\n",
            "27670 | 3.9868 | 2.2e-04 | 1.14 | 38.7K | 01:37:35 |  55.3%\n",
            "27680 | 4.5449 | 2.2e-04 | 1.07 | 38.7K | 01:37:37 |  55.4%\n",
            "27690 | 4.4005 | 2.2e-04 | 1.12 | 38.7K | 01:37:38 |  55.4%\n",
            "27700 | 4.1424 | 2.2e-04 | 1.12 | 38.7K | 01:37:40 |  55.4%\n",
            "27710 | 4.5009 | 2.2e-04 | 1.08 | 38.7K | 01:37:42 |  55.4%\n",
            "27720 | 4.3996 | 2.2e-04 | 1.10 | 38.7K | 01:37:44 |  55.4%\n",
            "27730 | 4.2814 | 2.2e-04 | 1.16 | 38.7K | 01:37:45 |  55.5%\n",
            "27740 | 4.1813 | 2.2e-04 | 1.09 | 38.7K | 01:37:47 |  55.5%\n",
            "27750 | 4.3236 | 2.2e-04 | 1.08 | 38.7K | 01:37:49 |  55.5%\n",
            "27760 | 4.6989 | 2.2e-04 | 1.06 | 38.7K | 01:37:50 |  55.5%\n",
            "27770 | 4.3123 | 2.2e-04 | 1.08 | 38.7K | 01:37:52 |  55.5%\n",
            "27780 | 4.2333 | 2.2e-04 | 1.09 | 38.7K | 01:37:54 |  55.6%\n",
            "27790 | 4.4881 | 2.2e-04 | 1.09 | 38.7K | 01:37:56 |  55.6%\n",
            "27800 | 4.3456 | 2.2e-04 | 1.09 | 38.7K | 01:37:57 |  55.6%\n",
            "27810 | 4.5264 | 2.2e-04 | 1.08 | 38.7K | 01:37:59 |  55.6%\n",
            "27820 | 4.1783 | 2.2e-04 | 1.08 | 38.8K | 01:38:01 |  55.6%\n",
            "27830 | 4.5626 | 2.2e-04 | 1.08 | 38.8K | 01:38:02 |  55.7%\n",
            "27840 | 4.4974 | 2.2e-04 | 1.10 | 38.8K | 01:38:04 |  55.7%\n",
            "27850 | 4.6005 | 2.2e-04 | 1.07 | 38.8K | 01:38:06 |  55.7%\n",
            "27860 | 4.3858 | 2.2e-04 | 1.06 | 38.8K | 01:38:08 |  55.7%\n",
            "27870 | 4.2982 | 2.2e-04 | 1.14 | 38.8K | 01:38:09 |  55.7%\n",
            "27880 | 4.2890 | 2.2e-04 | 1.08 | 38.8K | 01:38:11 |  55.8%\n",
            "27890 | 4.6054 | 2.2e-04 | 1.08 | 38.8K | 01:38:13 |  55.8%\n",
            "27900 | 4.6497 | 2.2e-04 | 1.10 | 38.8K | 01:38:14 |  55.8%\n",
            "27910 | 4.5458 | 2.2e-04 | 1.07 | 38.8K | 01:38:16 |  55.8%\n",
            "27920 | 4.5774 | 2.2e-04 | 1.06 | 38.8K | 01:38:18 |  55.8%\n",
            "27930 | 4.6642 | 2.2e-04 | 1.14 | 38.8K | 01:38:20 |  55.9%\n",
            "27940 | 4.4224 | 2.2e-04 | 1.10 | 38.8K | 01:38:21 |  55.9%\n",
            "27950 | 4.6081 | 2.2e-04 | 1.11 | 38.8K | 01:38:23 |  55.9%\n",
            "27960 | 4.4019 | 2.2e-04 | 1.07 | 38.8K | 01:38:25 |  55.9%\n",
            "27970 | 4.2718 | 2.2e-04 | 1.09 | 38.8K | 01:38:26 |  55.9%\n",
            "27980 | 4.5962 | 2.2e-04 | 1.10 | 38.8K | 01:38:28 |  56.0%\n",
            "27990 | 4.4450 | 2.2e-04 | 1.10 | 38.8K | 01:38:30 |  56.0%\n",
            "28000 | 4.4702 | 2.2e-04 | 1.07 | 38.8K | 01:38:31 |  56.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 28000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.3496\n",
            "  Perplexity: 77.45\n",
            "  Train loss (avg): 4.4150\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        larƒ±n da par√ßalƒ± bulutlu olmasƒ± nedeniyle sabah saat 18.00 sƒ±ralarƒ±nda devam eden orman yangƒ±nƒ±nda ya≈üamƒ±nƒ± yitirdi. Atiker Konyaspor'da arama ve bankalara saldƒ±rƒ±! D√ºnyada 400 milyon ki≈üi hayatƒ±nƒ± kaybetti Atik\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        olan ƒ∞stanbul'un coƒürafi konumu itibariyle d√ºnyanƒ±n en b√ºy√ºk kenti olan ƒ∞stanbul'un tarihi konumunu g√∂stermektedir. ƒ∞stanbul, Osmanlƒ±‚Äônƒ±n ilk ba≈ükenti olma √∂zelliƒüini kaybetmesine raƒümen, ƒ∞stanbul‚Äôun tarihi a√ßƒ±dan en zengin kenti\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , bilimsel veri ve yapay zeka i≈ülemleriyle doƒürudan i≈ülem yapƒ±labilen bir teknolojidir. Temel ihtiya√ß olan akƒ±llƒ± bilgisayarlar, akƒ±llƒ± telefonlar ve tabletlerin ekranlarƒ±, net veya net olarak net olarak g√∂rebilmektedir. S\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.3496)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:17:41\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "28010 | 4.3299 | 2.2e-04 | 1.06 | 38.7K | 01:38:54 |  56.0%\n",
            "28020 | 4.4673 | 2.2e-04 | 1.11 | 38.7K | 01:38:56 |  56.0%\n",
            "28030 | 4.4206 | 2.2e-04 | 1.14 | 38.7K | 01:38:57 |  56.1%\n",
            "28040 | 4.4577 | 2.2e-04 | 1.07 | 38.7K | 01:38:59 |  56.1%\n",
            "28050 | 4.4322 | 2.2e-04 | 1.07 | 38.7K | 01:39:01 |  56.1%\n",
            "28060 | 4.4835 | 2.2e-04 | 1.10 | 38.7K | 01:39:02 |  56.1%\n",
            "28070 | 4.2852 | 2.2e-04 | 1.08 | 38.7K | 01:39:04 |  56.1%\n",
            "28080 | 4.2009 | 2.2e-04 | 1.11 | 38.7K | 01:39:06 |  56.2%\n",
            "28090 | 4.4297 | 2.2e-04 | 1.08 | 38.7K | 01:39:08 |  56.2%\n",
            "28100 | 4.4969 | 2.2e-04 | 1.09 | 38.7K | 01:39:09 |  56.2%\n",
            "28110 | 4.5265 | 2.2e-04 | 1.09 | 38.7K | 01:39:11 |  56.2%\n",
            "28120 | 4.3723 | 2.2e-04 | 1.12 | 38.7K | 01:39:13 |  56.2%\n",
            "28130 | 4.2510 | 2.2e-04 | 1.11 | 38.7K | 01:39:14 |  56.3%\n",
            "28140 | 4.2755 | 2.2e-04 | 1.09 | 38.7K | 01:39:16 |  56.3%\n",
            "28150 | 4.1501 | 2.1e-04 | 1.05 | 38.7K | 01:39:18 |  56.3%\n",
            "28160 | 4.5018 | 2.1e-04 | 1.08 | 38.7K | 01:39:20 |  56.3%\n",
            "28170 | 4.5858 | 2.1e-04 | 1.08 | 38.7K | 01:39:21 |  56.3%\n",
            "28180 | 3.9864 | 2.1e-04 | 1.16 | 38.7K | 01:39:23 |  56.4%\n",
            "28190 | 4.6536 | 2.1e-04 | 1.13 | 38.7K | 01:39:25 |  56.4%\n",
            "28200 | 4.4664 | 2.1e-04 | 1.11 | 38.7K | 01:39:26 |  56.4%\n",
            "28210 | 4.4279 | 2.1e-04 | 1.06 | 38.7K | 01:39:28 |  56.4%\n",
            "28220 | 4.6039 | 2.1e-04 | 1.10 | 38.7K | 01:39:30 |  56.4%\n",
            "28230 | 4.0997 | 2.1e-04 | 1.15 | 38.7K | 01:39:32 |  56.5%\n",
            "28240 | 4.3326 | 2.1e-04 | 1.07 | 38.7K | 01:39:33 |  56.5%\n",
            "28250 | 4.0617 | 2.1e-04 | 1.17 | 38.7K | 01:39:35 |  56.5%\n",
            "28260 | 4.5421 | 2.1e-04 | 1.10 | 38.7K | 01:39:37 |  56.5%\n",
            "28270 | 4.5992 | 2.1e-04 | 1.16 | 38.7K | 01:39:38 |  56.5%\n",
            "28280 | 4.2637 | 2.1e-04 | 1.07 | 38.7K | 01:39:40 |  56.6%\n",
            "28290 | 4.1698 | 2.1e-04 | 1.09 | 38.7K | 01:39:42 |  56.6%\n",
            "28300 | 4.5883 | 2.1e-04 | 1.11 | 38.7K | 01:39:43 |  56.6%\n",
            "28310 | 4.6175 | 2.1e-04 | 1.13 | 38.7K | 01:39:45 |  56.6%\n",
            "28320 | 4.4297 | 2.1e-04 | 1.08 | 38.7K | 01:39:47 |  56.6%\n",
            "28330 | 4.7020 | 2.1e-04 | 1.11 | 38.8K | 01:39:49 |  56.7%\n",
            "28340 | 4.0984 | 2.1e-04 | 1.07 | 38.8K | 01:39:50 |  56.7%\n",
            "28350 | 4.4577 | 2.1e-04 | 1.10 | 38.8K | 01:39:52 |  56.7%\n",
            "28360 | 4.4787 | 2.1e-04 | 1.06 | 38.8K | 01:39:54 |  56.7%\n",
            "28370 | 4.6230 | 2.1e-04 | 1.14 | 38.8K | 01:39:55 |  56.7%\n",
            "28380 | 4.0736 | 2.1e-04 | 1.10 | 38.8K | 01:39:57 |  56.8%\n",
            "28390 | 4.5204 | 2.1e-04 | 1.09 | 38.8K | 01:39:59 |  56.8%\n",
            "28400 | 4.4640 | 2.1e-04 | 1.11 | 38.8K | 01:40:01 |  56.8%\n",
            "28410 | 4.4275 | 2.1e-04 | 1.11 | 38.8K | 01:40:02 |  56.8%\n",
            "28420 | 4.2439 | 2.1e-04 | 1.11 | 38.8K | 01:40:04 |  56.8%\n",
            "28430 | 4.4443 | 2.1e-04 | 1.04 | 38.8K | 01:40:06 |  56.9%\n",
            "28440 | 4.4549 | 2.1e-04 | 1.06 | 38.8K | 01:40:07 |  56.9%\n",
            "28450 | 4.4655 | 2.1e-04 | 1.08 | 38.8K | 01:40:09 |  56.9%\n",
            "28460 | 4.3259 | 2.1e-04 | 1.10 | 38.8K | 01:40:11 |  56.9%\n",
            "28470 | 4.3634 | 2.1e-04 | 1.09 | 38.8K | 01:40:13 |  56.9%\n",
            "28480 | 4.4128 | 2.1e-04 | 1.07 | 38.8K | 01:40:14 |  57.0%\n",
            "28490 | 4.3736 | 2.1e-04 | 1.08 | 38.8K | 01:40:16 |  57.0%\n",
            "28500 | 4.3781 | 2.1e-04 | 1.12 | 38.8K | 01:40:18 |  57.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 28500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.3624\n",
            "  Perplexity: 78.44\n",
            "  Train loss (avg): 4.4049\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        larƒ±n ƒ±sƒ±nmasƒ±yla birlikte havalarƒ±n ƒ±sƒ±nmasƒ±yla birlikte hava sƒ±caklƒ±ƒüƒ±nƒ±n y√ºkselmesi bu yolla da ger√ßekle≈üti. Peki hava sƒ±caklƒ±klarƒ±nƒ±n bir √ßok nedeni olabilir? Bilemiyorum. Bazƒ± √ºlkeler hava sƒ±caklƒ±klarƒ± sebebiyle hava sƒ±caklƒ±klarƒ±nda artƒ±≈ü\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        olan Sabiha G√∂k√ßen Havalimanƒ±'na T√ºrk hava ara√ßlarƒ±yla ula≈üƒ±m saƒülanabiliyor. Havalimanƒ±nda saat 19:30'da Atat√ºrk Havalimanƒ±'nda saat 19.00'da Atat√ºrk Havalimanƒ±'na gelen yolculardan bir tanesi saat 19\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , teknolojinin kolay ve ucuz olduƒüu d√∂nemde insanlarƒ±n bir araya geli≈üinden √ßok daha ileri ya≈ülarda kullanabilecekleri bir teknoloji haline gelmi≈üti. T√ºrkiye‚Äôde bu teknolojinin aslƒ±nda bilgisayarlara g√∂re √ßok daha hƒ±zlƒ± olduƒüu ve cihazlara g√∂re\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:15:53\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "28510 | 4.4004 | 2.1e-04 | 1.07 | 38.7K | 01:40:37 |  57.0%\n",
            "28520 | 4.4015 | 2.1e-04 | 1.09 | 38.7K | 01:40:38 |  57.0%\n",
            "28530 | 4.4915 | 2.1e-04 | 1.07 | 38.7K | 01:40:40 |  57.1%\n",
            "28540 | 4.4874 | 2.1e-04 | 1.14 | 38.7K | 01:40:42 |  57.1%\n",
            "28550 | 4.5499 | 2.1e-04 | 1.06 | 38.7K | 01:40:44 |  57.1%\n",
            "28560 | 4.5785 | 2.1e-04 | 1.07 | 38.7K | 01:40:45 |  57.1%\n",
            "28570 | 4.5574 | 2.1e-04 | 1.07 | 38.7K | 01:40:47 |  57.1%\n",
            "28580 | 4.3316 | 2.1e-04 | 1.15 | 38.7K | 01:40:49 |  57.2%\n",
            "28590 | 4.3888 | 2.1e-04 | 1.32 | 38.7K | 01:40:50 |  57.2%\n",
            "28600 | 4.4752 | 2.1e-04 | 1.05 | 38.7K | 01:40:52 |  57.2%\n",
            "28610 | 4.4082 | 2.1e-04 | 1.07 | 38.7K | 01:40:54 |  57.2%\n",
            "28620 | 4.6260 | 2.1e-04 | 1.08 | 38.7K | 01:40:56 |  57.2%\n",
            "28630 | 4.2715 | 2.1e-04 | 1.08 | 38.7K | 01:40:57 |  57.3%\n",
            "28640 | 4.4811 | 2.1e-04 | 1.10 | 38.7K | 01:40:59 |  57.3%\n",
            "28650 | 4.3569 | 2.1e-04 | 1.08 | 38.7K | 01:41:01 |  57.3%\n",
            "28660 | 4.5119 | 2.1e-04 | 1.17 | 38.7K | 01:41:02 |  57.3%\n",
            "28670 | 4.4954 | 2.1e-04 | 1.11 | 38.7K | 01:41:04 |  57.3%\n",
            "28680 | 3.9993 | 2.1e-04 | 1.15 | 38.7K | 01:41:06 |  57.4%\n",
            "28690 | 4.4974 | 2.1e-04 | 1.08 | 38.7K | 01:41:08 |  57.4%\n",
            "28700 | 4.3855 | 2.1e-04 | 1.18 | 38.7K | 01:41:09 |  57.4%\n",
            "28710 | 4.4323 | 2.1e-04 | 1.12 | 38.7K | 01:41:11 |  57.4%\n",
            "28720 | 4.5345 | 2.1e-04 | 1.08 | 38.7K | 01:41:13 |  57.4%\n",
            "28730 | 4.2679 | 2.1e-04 | 1.10 | 38.7K | 01:41:14 |  57.5%\n",
            "28740 | 4.5319 | 2.1e-04 | 1.06 | 38.7K | 01:41:16 |  57.5%\n",
            "28750 | 4.2380 | 2.1e-04 | 1.06 | 38.7K | 01:41:18 |  57.5%\n",
            "28760 | 4.2934 | 2.1e-04 | 1.11 | 38.8K | 01:41:19 |  57.5%\n",
            "28770 | 4.2176 | 2.0e-04 | 1.09 | 38.8K | 01:41:21 |  57.5%\n",
            "28780 | 4.6593 | 2.0e-04 | 1.10 | 38.8K | 01:41:23 |  57.6%\n",
            "28790 | 4.5403 | 2.0e-04 | 1.06 | 38.8K | 01:41:25 |  57.6%\n",
            "28800 | 4.3027 | 2.0e-04 | 1.12 | 38.8K | 01:41:26 |  57.6%\n",
            "28810 | 4.4477 | 2.0e-04 | 1.08 | 38.8K | 01:41:28 |  57.6%\n",
            "28820 | 4.2132 | 2.0e-04 | 1.11 | 38.8K | 01:41:30 |  57.6%\n",
            "28830 | 4.2576 | 2.0e-04 | 1.14 | 38.8K | 01:41:31 |  57.7%\n",
            "28840 | 4.3327 | 2.0e-04 | 1.46 | 38.8K | 01:41:33 |  57.7%\n",
            "28850 | 4.2319 | 2.0e-04 | 1.06 | 38.8K | 01:41:35 |  57.7%\n",
            "28860 | 4.2109 | 2.0e-04 | 1.11 | 38.8K | 01:41:37 |  57.7%\n",
            "28870 | 4.6300 | 2.0e-04 | 1.09 | 38.8K | 01:41:38 |  57.7%\n",
            "28880 | 4.0845 | 2.0e-04 | 1.18 | 38.8K | 01:41:40 |  57.8%\n",
            "28890 | 4.4777 | 2.0e-04 | 1.15 | 38.8K | 01:41:42 |  57.8%\n",
            "28900 | 4.1114 | 2.0e-04 | 1.17 | 38.8K | 01:41:43 |  57.8%\n",
            "28910 | 4.5255 | 2.0e-04 | 1.11 | 38.8K | 01:41:45 |  57.8%\n",
            "28920 | 4.4597 | 2.0e-04 | 1.06 | 38.8K | 01:41:47 |  57.8%\n",
            "28930 | 4.3859 | 2.0e-04 | 1.11 | 38.8K | 01:41:49 |  57.9%\n",
            "28940 | 4.3524 | 2.0e-04 | 1.10 | 38.8K | 01:41:50 |  57.9%\n",
            "28950 | 4.3344 | 2.0e-04 | 1.14 | 38.8K | 01:41:52 |  57.9%\n",
            "28960 | 4.2173 | 2.0e-04 | 1.39 | 38.8K | 01:41:54 |  57.9%\n",
            "28970 | 4.6315 | 2.0e-04 | 1.10 | 38.8K | 01:41:55 |  57.9%\n",
            "28980 | 4.2686 | 2.0e-04 | 1.11 | 38.8K | 01:41:57 |  58.0%\n",
            "28990 | 4.3475 | 2.0e-04 | 1.15 | 38.8K | 01:41:59 |  58.0%\n",
            "29000 | 4.5084 | 2.0e-04 | 1.06 | 38.8K | 01:42:01 |  58.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 29000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.3386\n",
            "  Perplexity: 76.60\n",
            "  Train loss (avg): 4.3875\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        ile ilgili bazƒ± ≈üeylerden uzak duruyorum. Alcantara mƒ±, nerelerden nereye giderseniz gidin, kaybolmadƒ±nƒ±z. Bu y√ºzden y√ºr√ºy√º≈ü yollarƒ± tercih ediyorum. Fakat groteskler ile ilgili\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        olan Ankara'da, bir d√∂nem ev sahibi olan Kemal Kƒ±lƒ±√ßdaroƒülu'nun siyaset √ºzerinden kurduƒüu \"Sanal Haklar\" isimli dava nedeniyle dava a√ßƒ±ldƒ±. ƒ∞zmir'de, \"Sanal Haklar\" adlƒ±\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        ile bu teknolojiyi bir arada kullanan yapay zeka bu i≈ületim sistemi ile yapay zeka i√ßin √ßok iyi bir teknoloji. Yapay zeka ve yapay zeka ve yapay zekayƒ± da i√ßeren yapay zeka, yapay zeka ile yapay zekanƒ±n\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.3386)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:14:07\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "29010 | 4.4722 | 2.0e-04 | 1.06 | 38.7K | 01:42:23 |  58.0%\n",
            "29020 | 4.3587 | 2.0e-04 | 1.12 | 38.7K | 01:42:25 |  58.0%\n",
            "29030 | 4.4067 | 2.0e-04 | 1.05 | 38.7K | 01:42:26 |  58.1%\n",
            "29040 | 4.4085 | 2.0e-04 | 1.14 | 38.7K | 01:42:28 |  58.1%\n",
            "29050 | 4.3226 | 2.0e-04 | 1.10 | 38.7K | 01:42:30 |  58.1%\n",
            "29060 | 4.4863 | 2.0e-04 | 1.11 | 38.7K | 01:42:31 |  58.1%\n",
            "29070 | 4.4072 | 2.0e-04 | 1.07 | 38.7K | 01:42:33 |  58.1%\n",
            "29080 | 4.5283 | 2.0e-04 | 1.09 | 38.7K | 01:42:35 |  58.2%\n",
            "29090 | 4.3500 | 2.0e-04 | 1.07 | 38.7K | 01:42:37 |  58.2%\n",
            "29100 | 4.3602 | 2.0e-04 | 1.12 | 38.7K | 01:42:38 |  58.2%\n",
            "29110 | 4.4449 | 2.0e-04 | 1.11 | 38.7K | 01:42:40 |  58.2%\n",
            "29120 | 4.3002 | 2.0e-04 | 1.18 | 38.7K | 01:42:42 |  58.2%\n",
            "29130 | 4.4559 | 2.0e-04 | 1.09 | 38.7K | 01:42:43 |  58.3%\n",
            "29140 | 4.5722 | 2.0e-04 | 1.14 | 38.7K | 01:42:45 |  58.3%\n",
            "29150 | 4.1397 | 2.0e-04 | 1.11 | 38.7K | 01:42:47 |  58.3%\n",
            "29160 | 4.3906 | 2.0e-04 | 1.13 | 38.7K | 01:42:49 |  58.3%\n",
            "29170 | 4.2117 | 2.0e-04 | 1.12 | 38.7K | 01:42:50 |  58.3%\n",
            "29180 | 4.6144 | 2.0e-04 | 1.10 | 38.7K | 01:42:52 |  58.4%\n",
            "29190 | 4.4748 | 2.0e-04 | 1.09 | 38.7K | 01:42:54 |  58.4%\n",
            "29200 | 4.3803 | 2.0e-04 | 1.12 | 38.7K | 01:42:55 |  58.4%\n",
            "29210 | 4.3174 | 2.0e-04 | 1.10 | 38.7K | 01:42:57 |  58.4%\n",
            "29220 | 4.2355 | 2.0e-04 | 1.16 | 38.7K | 01:42:59 |  58.4%\n",
            "29230 | 3.9920 | 2.0e-04 | 1.17 | 38.7K | 01:43:01 |  58.5%\n",
            "29240 | 4.2648 | 2.0e-04 | 1.13 | 38.7K | 01:43:02 |  58.5%\n",
            "29250 | 4.4587 | 2.0e-04 | 1.09 | 38.7K | 01:43:04 |  58.5%\n",
            "29260 | 4.4960 | 2.0e-04 | 1.09 | 38.7K | 01:43:06 |  58.5%\n",
            "29270 | 4.4074 | 2.0e-04 | 1.10 | 38.7K | 01:43:07 |  58.5%\n",
            "29280 | 4.6807 | 2.0e-04 | 1.11 | 38.8K | 01:43:09 |  58.6%\n",
            "29290 | 4.4409 | 2.0e-04 | 1.10 | 38.8K | 01:43:11 |  58.6%\n",
            "29300 | 4.4344 | 2.0e-04 | 1.12 | 38.8K | 01:43:13 |  58.6%\n",
            "29310 | 4.4763 | 2.0e-04 | 1.11 | 38.8K | 01:43:14 |  58.6%\n",
            "29320 | 4.2114 | 2.0e-04 | 1.09 | 38.8K | 01:43:16 |  58.6%\n",
            "29330 | 4.3583 | 2.0e-04 | 1.09 | 38.8K | 01:43:18 |  58.7%\n",
            "29340 | 4.1734 | 2.0e-04 | 1.10 | 38.8K | 01:43:19 |  58.7%\n",
            "29350 | 4.5802 | 2.0e-04 | 1.06 | 38.8K | 01:43:21 |  58.7%\n",
            "29360 | 4.0966 | 2.0e-04 | 1.08 | 38.8K | 01:43:23 |  58.7%\n",
            "29370 | 4.3963 | 2.0e-04 | 1.08 | 38.8K | 01:43:25 |  58.7%\n",
            "29380 | 4.7470 | 2.0e-04 | 1.10 | 38.8K | 01:43:26 |  58.8%\n",
            "29390 | 4.3479 | 2.0e-04 | 1.13 | 38.8K | 01:43:28 |  58.8%\n",
            "29400 | 4.2589 | 1.9e-04 | 1.10 | 38.8K | 01:43:30 |  58.8%\n",
            "29410 | 4.4168 | 1.9e-04 | 1.12 | 38.8K | 01:43:31 |  58.8%\n",
            "29420 | 4.3150 | 1.9e-04 | 1.12 | 38.8K | 01:43:33 |  58.8%\n",
            "29430 | 4.5878 | 1.9e-04 | 1.12 | 38.8K | 01:43:35 |  58.9%\n",
            "29440 | 4.4813 | 1.9e-04 | 1.12 | 38.8K | 01:43:37 |  58.9%\n",
            "29450 | 4.3646 | 1.9e-04 | 1.07 | 38.8K | 01:43:38 |  58.9%\n",
            "29460 | 4.4496 | 1.9e-04 | 1.07 | 38.8K | 01:43:40 |  58.9%\n",
            "29470 | 4.2092 | 1.9e-04 | 1.08 | 38.8K | 01:43:42 |  58.9%\n",
            "29480 | 4.1964 | 1.9e-04 | 1.12 | 38.8K | 01:43:43 |  59.0%\n",
            "29490 | 4.3344 | 1.9e-04 | 1.11 | 38.8K | 01:43:45 |  59.0%\n",
            "29500 | 4.4086 | 1.9e-04 | 1.08 | 38.8K | 01:43:47 |  59.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 29500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.3211\n",
            "  Perplexity: 75.27\n",
            "  Train loss (avg): 4.3933\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        ko≈üullarƒ± nedeniyle 2020 yƒ±lƒ±na kadar √ºlkeler, hava ko≈üullarƒ± nedeniyle yabancƒ± √ºlke konumunda bulunuyor. T√ºrkiye‚Äônin Rusya ile ilgili en √∂nemli sorunu, Rusya‚Äônƒ±n Karadeniz B√∂lgesi‚Äônde ya≈üadƒ±ƒüƒ±. Ancak Rusya‚Äônƒ±n Karadeniz B√∂lgesi\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        ƒ∞stanbul'da bir √ßok tarihi b√∂lgeye ev sahipliƒüi yapan g√ºzel ve tarihi atmosferin yanƒ± sƒ±ra ≈üehrin her noktasƒ±nda tarihi yapƒ±lar, tarihi yerleri gezip g√∂rmeniz m√ºmk√ºn. En g√ºzel rotalardan birisi de tarihi bir g√ºn ge√ßirmek.\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        sayesinde, insanlarƒ±n %99‚Äôu ev ve i≈ü yerinde rahat rahat konu≈üabiliyor, kar≈üƒ±dan gelen bir sese, ev ve i≈ü yerinde sakin kalabiliyor ve yalnƒ±zla≈üabiliyor. Aynƒ± zamanda, s√ºrekli √ßalƒ±≈üma\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.3211)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:12:21\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "29510 | 4.2877 | 1.9e-04 | 1.07 | 38.7K | 01:44:09 |  59.0%\n",
            "29520 | 4.4000 | 1.9e-04 | 1.10 | 38.7K | 01:44:11 |  59.0%\n",
            "29530 | 4.1803 | 1.9e-04 | 1.26 | 38.7K | 01:44:13 |  59.1%\n",
            "29540 | 4.3776 | 1.9e-04 | 1.07 | 38.7K | 01:44:14 |  59.1%\n",
            "29550 | 4.3802 | 1.9e-04 | 1.11 | 38.7K | 01:44:16 |  59.1%\n",
            "29560 | 4.4481 | 1.9e-04 | 1.09 | 38.7K | 01:44:18 |  59.1%\n",
            "29570 | 4.4616 | 1.9e-04 | 1.11 | 38.7K | 01:44:20 |  59.1%\n",
            "29580 | 4.4250 | 1.9e-04 | 1.09 | 38.7K | 01:44:21 |  59.2%\n",
            "29590 | 4.1818 | 1.9e-04 | 1.08 | 38.7K | 01:44:23 |  59.2%\n",
            "29600 | 4.3229 | 1.9e-04 | 1.11 | 38.7K | 01:44:25 |  59.2%\n",
            "29610 | 4.0889 | 1.9e-04 | 1.09 | 38.7K | 01:44:26 |  59.2%\n",
            "29620 | 4.7807 | 1.9e-04 | 1.14 | 38.7K | 01:44:28 |  59.2%\n",
            "29630 | 4.3663 | 1.9e-04 | 1.05 | 38.7K | 01:44:30 |  59.3%\n",
            "29640 | 4.5296 | 1.9e-04 | 1.12 | 38.7K | 01:44:31 |  59.3%\n",
            "29650 | 4.4948 | 1.9e-04 | 1.09 | 38.7K | 01:44:33 |  59.3%\n",
            "29660 | 4.4244 | 1.9e-04 | 1.09 | 38.7K | 01:44:35 |  59.3%\n",
            "29670 | 4.4300 | 1.9e-04 | 1.09 | 38.7K | 01:44:37 |  59.3%\n",
            "29680 | 4.5784 | 1.9e-04 | 1.17 | 38.7K | 01:44:38 |  59.4%\n",
            "29690 | 4.2627 | 1.9e-04 | 1.40 | 38.7K | 01:44:40 |  59.4%\n",
            "29700 | 4.4752 | 1.9e-04 | 1.12 | 38.7K | 01:44:42 |  59.4%\n",
            "29710 | 4.3992 | 1.9e-04 | 1.10 | 38.7K | 01:44:43 |  59.4%\n",
            "29720 | 4.4149 | 1.9e-04 | 1.13 | 38.7K | 01:44:45 |  59.4%\n",
            "29730 | 4.3205 | 1.9e-04 | 1.09 | 38.7K | 01:44:47 |  59.5%\n",
            "29740 | 4.4675 | 1.9e-04 | 1.16 | 38.7K | 01:44:49 |  59.5%\n",
            "29750 | 4.6212 | 1.9e-04 | 1.11 | 38.7K | 01:44:50 |  59.5%\n",
            "29760 | 4.1202 | 1.9e-04 | 1.09 | 38.7K | 01:44:52 |  59.5%\n",
            "29770 | 4.4166 | 1.9e-04 | 1.17 | 38.7K | 01:44:54 |  59.5%\n",
            "29780 | 4.3414 | 1.9e-04 | 1.12 | 38.7K | 01:44:55 |  59.6%\n",
            "29790 | 4.4278 | 1.9e-04 | 1.11 | 38.8K | 01:44:57 |  59.6%\n",
            "29800 | 4.2335 | 1.9e-04 | 1.10 | 38.8K | 01:44:59 |  59.6%\n",
            "29810 | 4.4270 | 1.9e-04 | 1.15 | 38.8K | 01:45:01 |  59.6%\n",
            "29820 | 4.3103 | 1.9e-04 | 1.09 | 38.8K | 01:45:02 |  59.6%\n",
            "29830 | 4.6672 | 1.9e-04 | 1.09 | 38.8K | 01:45:04 |  59.7%\n",
            "29840 | 4.2594 | 1.9e-04 | 1.13 | 38.8K | 01:45:06 |  59.7%\n",
            "29850 | 4.4466 | 1.9e-04 | 1.09 | 38.8K | 01:45:07 |  59.7%\n",
            "29860 | 4.3849 | 1.9e-04 | 1.08 | 38.8K | 01:45:09 |  59.7%\n",
            "29870 | 4.1396 | 1.9e-04 | 1.16 | 38.8K | 01:45:11 |  59.7%\n",
            "29880 | 4.2981 | 1.9e-04 | 1.41 | 38.8K | 01:45:13 |  59.8%\n",
            "29890 | 4.1751 | 1.9e-04 | 1.16 | 38.8K | 01:45:14 |  59.8%\n",
            "29900 | 4.7683 | 1.9e-04 | 1.08 | 38.8K | 01:45:16 |  59.8%\n",
            "29910 | 4.5355 | 1.9e-04 | 1.09 | 38.8K | 01:45:18 |  59.8%\n",
            "29920 | 4.5262 | 1.9e-04 | 1.10 | 38.8K | 01:45:19 |  59.8%\n",
            "29930 | 4.5118 | 1.9e-04 | 1.07 | 38.8K | 01:45:21 |  59.9%\n",
            "29940 | 4.3082 | 1.9e-04 | 1.11 | 38.8K | 01:45:23 |  59.9%\n",
            "29950 | 4.2146 | 1.9e-04 | 1.13 | 38.8K | 01:45:25 |  59.9%\n",
            "29960 | 4.3558 | 1.9e-04 | 1.11 | 38.8K | 01:45:26 |  59.9%\n",
            "29970 | 4.5977 | 1.9e-04 | 1.12 | 38.8K | 01:45:28 |  59.9%\n",
            "29980 | 4.3565 | 1.9e-04 | 1.20 | 38.8K | 01:45:30 |  60.0%\n",
            "29990 | 4.1924 | 1.9e-04 | 1.12 | 38.8K | 01:45:31 |  60.0%\n",
            "30000 | 4.5681 | 1.9e-04 | 1.10 | 38.8K | 01:45:33 |  60.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 30000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.3041\n",
            "  Perplexity: 74.00\n",
            "  Train loss (avg): 4.3720\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        sƒ±caklƒ±ƒüƒ±nƒ±n azaldƒ±ƒüƒ±nƒ±, b√ºy√ºk bir ihtimalle batƒ±k havalarƒ±n ƒ±sƒ±nmasƒ± ile birlikte yaƒüan yaƒümur nedeniyle buzlanma ≈üeklinde devam ettiƒüini anlatan G√ºl≈üah, ‚Äú√ñzellikle √ßok sƒ±cak olan sƒ±caklarda buzlanma ≈üeklinde devam\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        olan ƒ∞stanbul'da altƒ± g√ºn boyunca, dost ve akrabalarla birlikte serin, huzurlu, mesut bir g√ºn ge√ßireceƒüiz. ƒ∞stanbul'da, bir √ßok ≈üehirde, bu ≈üehirde, yeni arkada≈ülar, yeni arkada≈ü\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        sayesinde, gelecek yƒ±l √∂ƒürenme ve uygulama alanƒ±nda kendinizi geli≈ütirmek √ºzere √ßok daha fazla zaman ayƒ±rmayƒ± ama√ßlayan bir giri≈üimi daha; bu sayede hem zeka √ºzerinde hem de yenilik√ßilik konusunda daha fazla bilgi sahibi olacaƒüƒ±nƒ±zƒ± kaydeden Prof\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.3041)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:10:36\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "üíæ Checkpoint kaydediliyor: /content/drive/MyDrive/turkish_llm/checkpoints//checkpoint_step_30000.pt\n",
            "  ‚úÖ Checkpoint kaydedildi!\n",
            "\n",
            "30010 | 4.0440 | 1.9e-04 | 1.12 | 38.7K | 01:45:59 |  60.0%\n",
            "30020 | 4.2383 | 1.8e-04 | 1.12 | 38.7K | 01:46:00 |  60.0%\n",
            "30030 | 4.6060 | 1.8e-04 | 1.09 | 38.7K | 01:46:02 |  60.1%\n",
            "30040 | 4.5426 | 1.8e-04 | 1.11 | 38.7K | 01:46:04 |  60.1%\n",
            "30050 | 4.3690 | 1.8e-04 | 1.08 | 38.7K | 01:46:06 |  60.1%\n",
            "30060 | 4.0060 | 1.8e-04 | 1.12 | 38.7K | 01:46:07 |  60.1%\n",
            "30070 | 4.5575 | 1.8e-04 | 1.09 | 38.7K | 01:46:09 |  60.1%\n",
            "30080 | 4.3827 | 1.8e-04 | 1.10 | 38.7K | 01:46:11 |  60.2%\n",
            "30090 | 4.4537 | 1.8e-04 | 1.13 | 38.7K | 01:46:12 |  60.2%\n",
            "30100 | 4.1387 | 1.8e-04 | 1.22 | 38.7K | 01:46:14 |  60.2%\n",
            "30110 | 4.5401 | 1.8e-04 | 1.10 | 38.7K | 01:46:16 |  60.2%\n",
            "30120 | 4.4438 | 1.8e-04 | 1.13 | 38.7K | 01:46:18 |  60.2%\n",
            "30130 | 4.2095 | 1.8e-04 | 1.10 | 38.7K | 01:46:19 |  60.3%\n",
            "30140 | 4.5301 | 1.8e-04 | 1.13 | 38.7K | 01:46:21 |  60.3%\n",
            "30150 | 4.5653 | 1.8e-04 | 1.10 | 38.7K | 01:46:23 |  60.3%\n",
            "30160 | 4.5430 | 1.8e-04 | 1.13 | 38.7K | 01:46:24 |  60.3%\n",
            "30170 | 4.2418 | 1.8e-04 | 1.13 | 38.7K | 01:46:26 |  60.3%\n",
            "30180 | 4.3277 | 1.8e-04 | 1.18 | 38.7K | 01:46:28 |  60.4%\n",
            "30190 | 4.4629 | 1.8e-04 | 1.10 | 38.7K | 01:46:30 |  60.4%\n",
            "30200 | 4.2872 | 1.8e-04 | 1.12 | 38.7K | 01:46:31 |  60.4%\n",
            "30210 | 4.3645 | 1.8e-04 | 1.08 | 38.7K | 01:46:33 |  60.4%\n",
            "30220 | 4.4393 | 1.8e-04 | 1.23 | 38.7K | 01:46:35 |  60.4%\n",
            "30230 | 4.5245 | 1.8e-04 | 1.12 | 38.7K | 01:46:36 |  60.5%\n",
            "30240 | 4.4790 | 1.8e-04 | 1.12 | 38.7K | 01:46:38 |  60.5%\n",
            "30250 | 4.5447 | 1.8e-04 | 1.12 | 38.7K | 01:46:40 |  60.5%\n",
            "30260 | 4.4191 | 1.8e-04 | 1.11 | 38.7K | 01:46:42 |  60.5%\n",
            "30270 | 4.5118 | 1.8e-04 | 1.12 | 38.7K | 01:46:43 |  60.5%\n",
            "30280 | 4.1452 | 1.8e-04 | 1.08 | 38.7K | 01:46:45 |  60.6%\n",
            "30290 | 4.5705 | 1.8e-04 | 1.13 | 38.7K | 01:46:47 |  60.6%\n",
            "30300 | 4.4690 | 1.8e-04 | 1.14 | 38.7K | 01:46:48 |  60.6%\n",
            "30310 | 4.4353 | 1.8e-04 | 1.09 | 38.7K | 01:46:50 |  60.6%\n",
            "30320 | 4.4077 | 1.8e-04 | 1.12 | 38.7K | 01:46:52 |  60.6%\n",
            "30330 | 4.1506 | 1.8e-04 | 1.28 | 38.7K | 01:46:54 |  60.7%\n",
            "30340 | 4.4051 | 1.8e-04 | 1.11 | 38.7K | 01:46:55 |  60.7%\n",
            "30350 | 4.2033 | 1.8e-04 | 1.13 | 38.7K | 01:46:57 |  60.7%\n",
            "30360 | 4.4480 | 1.8e-04 | 1.09 | 38.7K | 01:46:59 |  60.7%\n",
            "30370 | 4.3051 | 1.8e-04 | 1.11 | 38.7K | 01:47:00 |  60.7%\n",
            "30380 | 4.5726 | 1.8e-04 | 1.15 | 38.7K | 01:47:02 |  60.8%\n",
            "30390 | 3.8685 | 1.8e-04 | 1.10 | 38.8K | 01:47:04 |  60.8%\n",
            "30400 | 4.3149 | 1.8e-04 | 1.24 | 38.8K | 01:47:06 |  60.8%\n",
            "30410 | 4.4192 | 1.8e-04 | 1.12 | 38.8K | 01:47:07 |  60.8%\n",
            "30420 | 4.5003 | 1.8e-04 | 1.13 | 38.8K | 01:47:09 |  60.8%\n",
            "30430 | 4.5187 | 1.8e-04 | 1.12 | 38.8K | 01:47:11 |  60.9%\n",
            "30440 | 4.4319 | 1.8e-04 | 1.11 | 38.8K | 01:47:12 |  60.9%\n",
            "30450 | 4.2214 | 1.8e-04 | 1.16 | 38.8K | 01:47:14 |  60.9%\n",
            "30460 | 4.3662 | 1.8e-04 | 1.14 | 38.8K | 01:47:16 |  60.9%\n",
            "30470 | 4.0117 | 1.8e-04 | 1.12 | 38.8K | 01:47:18 |  60.9%\n",
            "30480 | 4.5187 | 1.8e-04 | 1.19 | 38.8K | 01:47:19 |  61.0%\n",
            "30490 | 4.4263 | 1.8e-04 | 1.13 | 38.8K | 01:47:21 |  61.0%\n",
            "30500 | 4.2350 | 1.8e-04 | 1.13 | 38.8K | 01:47:23 |  61.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 30500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.3021\n",
            "  Perplexity: 73.85\n",
            "  Train loss (avg): 4.3278\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        ≈üartlarƒ± a√ßƒ±sƒ±ndan etkili olan kar yaƒüƒ±≈üƒ±nƒ±n ardƒ±ndan b√∂lgede ciddi bir iyile≈üme s√ºrecine girilirken, kar yaƒüƒ±≈üƒ±nƒ±n ardƒ±ndan b√∂lgede hava ≈üartlarƒ± a√ßƒ±sƒ±ndan etkili olan kar yaƒüƒ±≈üƒ±nƒ±n ardƒ±ndan b√∂lgede soƒüuk hava nedeniyle, bu durumun da ya≈üanmasƒ± muhtemel\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Bak√º'ye giden yakla≈üƒ±k 60 bin ki≈üi, T√ºrkiye'nin √ße≈üitli illerinde √ßay ve kahve i√ßerek, √ßay ve kahve i√ßiyor. √áay, kahvenin tadƒ± damaƒüƒ±nƒ±zda kalacak. Cumhurba≈ükanƒ± Recep Tayyip\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        ile bir√ßok insan, biyolog, doktorlar ve psikologlarƒ±n de yer aldƒ±ƒüƒ± etkinlikte, bilim insanlarƒ±, psikolo-Medical Parker, psikolo-Medical Parker, eƒüitmenlerin yanƒ±\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.3021)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:08:52\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "30510 | 4.3889 | 1.8e-04 | 1.12 | 38.7K | 01:47:45 |  61.0%\n",
            "30520 | 4.1207 | 1.8e-04 | 1.15 | 38.7K | 01:47:47 |  61.0%\n",
            "30530 | 4.4644 | 1.8e-04 | 1.11 | 38.7K | 01:47:49 |  61.1%\n",
            "30540 | 4.5076 | 1.8e-04 | 1.11 | 38.7K | 01:47:50 |  61.1%\n",
            "30550 | 4.3339 | 1.8e-04 | 1.12 | 38.7K | 01:47:52 |  61.1%\n",
            "30560 | 4.3590 | 1.8e-04 | 1.09 | 38.7K | 01:47:54 |  61.1%\n",
            "30570 | 4.2845 | 1.8e-04 | 1.10 | 38.7K | 01:47:55 |  61.1%\n",
            "30580 | 4.5757 | 1.8e-04 | 1.23 | 38.7K | 01:47:57 |  61.2%\n",
            "30590 | 4.2581 | 1.8e-04 | 1.09 | 38.7K | 01:47:59 |  61.2%\n",
            "30600 | 4.4200 | 1.8e-04 | 1.10 | 38.7K | 01:48:00 |  61.2%\n",
            "30610 | 4.4220 | 1.8e-04 | 1.15 | 38.7K | 01:48:02 |  61.2%\n",
            "30620 | 4.2836 | 1.8e-04 | 1.22 | 38.7K | 01:48:04 |  61.2%\n",
            "30630 | 4.2437 | 1.8e-04 | 1.12 | 38.7K | 01:48:06 |  61.3%\n",
            "30640 | 4.6234 | 1.8e-04 | 1.10 | 38.7K | 01:48:07 |  61.3%\n",
            "30650 | 4.2642 | 1.8e-04 | 1.16 | 38.7K | 01:48:09 |  61.3%\n",
            "30660 | 4.2086 | 1.7e-04 | 1.14 | 38.7K | 01:48:11 |  61.3%\n",
            "30670 | 4.1694 | 1.7e-04 | 1.10 | 38.7K | 01:48:12 |  61.3%\n",
            "30680 | 4.4308 | 1.7e-04 | 1.11 | 38.7K | 01:48:14 |  61.4%\n",
            "30690 | 4.5437 | 1.7e-04 | 1.12 | 38.7K | 01:48:16 |  61.4%\n",
            "30700 | 4.4647 | 1.7e-04 | 1.18 | 38.7K | 01:48:18 |  61.4%\n",
            "30710 | 4.2520 | 1.7e-04 | 1.12 | 38.7K | 01:48:19 |  61.4%\n",
            "30720 | 4.4173 | 1.7e-04 | 1.12 | 38.7K | 01:48:21 |  61.4%\n",
            "30730 | 4.4274 | 1.7e-04 | 1.14 | 38.7K | 01:48:23 |  61.5%\n",
            "30740 | 4.2773 | 1.7e-04 | 1.14 | 38.7K | 01:48:24 |  61.5%\n",
            "30750 | 4.0057 | 1.7e-04 | 1.66 | 38.7K | 01:48:26 |  61.5%\n",
            "30760 | 4.4537 | 1.7e-04 | 1.14 | 38.7K | 01:48:28 |  61.5%\n",
            "30770 | 4.3182 | 1.7e-04 | 1.11 | 38.7K | 01:48:30 |  61.5%\n",
            "30780 | 4.2272 | 1.7e-04 | 1.14 | 38.7K | 01:48:31 |  61.6%\n",
            "30790 | 4.3809 | 1.7e-04 | 1.13 | 38.7K | 01:48:33 |  61.6%\n",
            "30800 | 4.2069 | 1.7e-04 | 1.21 | 38.7K | 01:48:35 |  61.6%\n",
            "30810 | 4.2050 | 1.7e-04 | 1.16 | 38.7K | 01:48:36 |  61.6%\n",
            "30820 | 4.2322 | 1.7e-04 | 1.10 | 38.7K | 01:48:38 |  61.6%\n",
            "30830 | 4.3781 | 1.7e-04 | 1.11 | 38.7K | 01:48:40 |  61.7%\n",
            "30840 | 4.2855 | 1.7e-04 | 1.09 | 38.7K | 01:48:42 |  61.7%\n",
            "30850 | 4.6592 | 1.7e-04 | 1.12 | 38.7K | 01:48:43 |  61.7%\n",
            "30860 | 4.2932 | 1.7e-04 | 1.14 | 38.7K | 01:48:45 |  61.7%\n",
            "30870 | 4.0085 | 1.7e-04 | 1.19 | 38.7K | 01:48:47 |  61.7%\n",
            "30880 | 4.2232 | 1.7e-04 | 1.11 | 38.7K | 01:48:48 |  61.8%\n",
            "30890 | 4.5221 | 1.7e-04 | 1.13 | 38.7K | 01:48:50 |  61.8%\n",
            "30900 | 4.3649 | 1.7e-04 | 1.10 | 38.8K | 01:48:52 |  61.8%\n",
            "30910 | 4.1241 | 1.7e-04 | 1.10 | 38.8K | 01:48:54 |  61.8%\n",
            "30920 | 4.4772 | 1.7e-04 | 1.12 | 38.8K | 01:48:55 |  61.8%\n",
            "30930 | 4.5898 | 1.7e-04 | 1.12 | 38.8K | 01:48:57 |  61.9%\n",
            "30940 | 4.4917 | 1.7e-04 | 1.15 | 38.8K | 01:48:59 |  61.9%\n",
            "30950 | 4.3114 | 1.7e-04 | 1.15 | 38.8K | 01:49:00 |  61.9%\n",
            "30960 | 4.2595 | 1.7e-04 | 1.13 | 38.8K | 01:49:02 |  61.9%\n",
            "30970 | 4.2901 | 1.7e-04 | 1.07 | 38.8K | 01:49:04 |  61.9%\n",
            "30980 | 4.2854 | 1.7e-04 | 1.09 | 38.8K | 01:49:06 |  62.0%\n",
            "30990 | 4.5433 | 1.7e-04 | 1.16 | 38.8K | 01:49:07 |  62.0%\n",
            "31000 | 4.4548 | 1.7e-04 | 1.08 | 38.8K | 01:49:09 |  62.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 31000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.3315\n",
            "  Perplexity: 76.06\n",
            "  Train loss (avg): 4.3275\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        durumu iyi ancak, tatilin zorluƒüunu a≈ümƒ±≈ü durumdayƒ±z. Lakin, son derece uygun fiyatlƒ± ve uygun fiyatlƒ± oteller bulunamadƒ±. Ev sahibinin durumu da bu. Yemek i√ßin az zaman ayƒ±rabilir, ancak\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Ankara'da hizmet veren T√ºrkiye'nin √∂nde gelen ofislerinden birisi olan T√ºrkiye'nin ilk profesyonel ofis ta≈üƒ±ma ≈üirketi olan Ankara'da hizmet veren bir firmadƒ±r. Ankara'da bulunan Ankara ƒ∞stanbul ofis ta≈üƒ±ma\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , insan ve √ßevreyle baƒülantƒ±lƒ± olarak, her iki sinir aƒüƒ± √ºzerinde de √∂nc√º bir uygulama olarak kullanƒ±lmaktadƒ±r. Bu uygulama, insan ve √ßevre arasƒ±ndaki ileti≈üimi g√º√ßlendirmek i√ßin b√ºy√ºk √∂nem ta≈üƒ±maktadƒ±r. A≈üaƒüƒ±da belirtilen bilgiler, ki≈üilerin\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:07:04\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "31010 | 4.4866 | 1.7e-04 | 1.14 | 38.7K | 01:49:28 |  62.0%\n",
            "31020 | 4.3972 | 1.7e-04 | 1.19 | 38.7K | 01:49:30 |  62.0%\n",
            "31030 | 4.3357 | 1.7e-04 | 1.10 | 38.7K | 01:49:31 |  62.1%\n",
            "31040 | 4.3016 | 1.7e-04 | 1.12 | 38.7K | 01:49:33 |  62.1%\n",
            "31050 | 4.3162 | 1.7e-04 | 1.10 | 38.7K | 01:49:35 |  62.1%\n",
            "31060 | 4.3172 | 1.7e-04 | 1.12 | 38.7K | 01:49:36 |  62.1%\n",
            "31070 | 4.0366 | 1.7e-04 | 1.27 | 38.7K | 01:49:38 |  62.1%\n",
            "31080 | 4.3235 | 1.7e-04 | 1.17 | 38.7K | 01:49:40 |  62.2%\n",
            "31090 | 4.3665 | 1.7e-04 | 1.11 | 38.7K | 01:49:42 |  62.2%\n",
            "31100 | 4.5795 | 1.7e-04 | 1.20 | 38.7K | 01:49:43 |  62.2%\n",
            "31110 | 4.1667 | 1.7e-04 | 1.18 | 38.7K | 01:49:45 |  62.2%\n",
            "31120 | 4.5387 | 1.7e-04 | 1.11 | 38.7K | 01:49:47 |  62.2%\n",
            "31130 | 4.1626 | 1.7e-04 | 1.15 | 38.7K | 01:49:48 |  62.3%\n",
            "31140 | 4.2968 | 1.7e-04 | 1.09 | 38.7K | 01:49:50 |  62.3%\n",
            "31150 | 4.3659 | 1.7e-04 | 1.13 | 38.7K | 01:49:52 |  62.3%\n",
            "31160 | 4.4406 | 1.7e-04 | 1.13 | 38.7K | 01:49:54 |  62.3%\n",
            "31170 | 4.3204 | 1.7e-04 | 1.06 | 38.7K | 01:49:55 |  62.3%\n",
            "31180 | 4.1121 | 1.7e-04 | 1.19 | 38.7K | 01:49:57 |  62.4%\n",
            "31190 | 3.9156 | 1.7e-04 | 1.12 | 38.7K | 01:49:59 |  62.4%\n",
            "31200 | 4.1871 | 1.7e-04 | 1.15 | 38.7K | 01:50:00 |  62.4%\n",
            "31210 | 4.3692 | 1.7e-04 | 1.16 | 38.7K | 01:50:02 |  62.4%\n",
            "31220 | 4.4112 | 1.7e-04 | 1.12 | 38.7K | 01:50:04 |  62.4%\n",
            "31230 | 4.3578 | 1.7e-04 | 1.15 | 38.7K | 01:50:06 |  62.5%\n",
            "31240 | 4.5361 | 1.7e-04 | 1.13 | 38.7K | 01:50:07 |  62.5%\n",
            "31250 | 4.4659 | 1.7e-04 | 1.12 | 38.7K | 01:50:09 |  62.5%\n",
            "31260 | 4.3645 | 1.7e-04 | 1.11 | 38.7K | 01:50:11 |  62.5%\n",
            "31270 | 4.4252 | 1.7e-04 | 1.13 | 38.7K | 01:50:12 |  62.5%\n",
            "31280 | 4.1610 | 1.7e-04 | 1.16 | 38.7K | 01:50:14 |  62.6%\n",
            "31290 | 3.9659 | 1.7e-04 | 1.15 | 38.7K | 01:50:16 |  62.6%\n",
            "31300 | 4.1798 | 1.7e-04 | 1.12 | 38.7K | 01:50:18 |  62.6%\n",
            "31310 | 4.2239 | 1.6e-04 | 1.12 | 38.7K | 01:50:19 |  62.6%\n",
            "31320 | 4.2272 | 1.6e-04 | 1.17 | 38.7K | 01:50:21 |  62.6%\n",
            "31330 | 3.8525 | 1.6e-04 | 1.09 | 38.8K | 01:50:23 |  62.7%\n",
            "31340 | 4.6016 | 1.6e-04 | 1.15 | 38.8K | 01:50:24 |  62.7%\n",
            "31350 | 4.3817 | 1.6e-04 | 1.11 | 38.8K | 01:50:26 |  62.7%\n",
            "31360 | 4.2998 | 1.6e-04 | 1.11 | 38.8K | 01:50:28 |  62.7%\n",
            "31370 | 4.6027 | 1.6e-04 | 1.21 | 38.8K | 01:50:30 |  62.7%\n",
            "31380 | 4.4595 | 1.6e-04 | 1.10 | 38.8K | 01:50:31 |  62.8%\n",
            "31390 | 4.5597 | 1.6e-04 | 1.10 | 38.8K | 01:50:33 |  62.8%\n",
            "31400 | 4.3396 | 1.6e-04 | 1.14 | 38.8K | 01:50:35 |  62.8%\n",
            "31410 | 4.2203 | 1.6e-04 | 1.12 | 38.8K | 01:50:36 |  62.8%\n",
            "31420 | 4.8337 | 1.6e-04 | 1.15 | 38.8K | 01:50:38 |  62.8%\n",
            "31430 | 4.3355 | 1.6e-04 | 1.12 | 38.8K | 01:50:40 |  62.9%\n",
            "31440 | 3.8720 | 1.6e-04 | 1.14 | 38.8K | 01:50:41 |  62.9%\n",
            "31450 | 4.5693 | 1.6e-04 | 1.17 | 38.8K | 01:50:43 |  62.9%\n",
            "31460 | 4.3102 | 1.6e-04 | 1.15 | 38.8K | 01:50:45 |  62.9%\n",
            "31470 | 4.4861 | 1.6e-04 | 1.12 | 38.8K | 01:50:47 |  62.9%\n",
            "31480 | 4.2232 | 1.6e-04 | 1.11 | 38.8K | 01:50:48 |  63.0%\n",
            "31490 | 4.4220 | 1.6e-04 | 1.21 | 38.8K | 01:50:50 |  63.0%\n",
            "31500 | 4.5279 | 1.6e-04 | 1.09 | 38.8K | 01:50:52 |  63.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 31500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.2617\n",
            "  Perplexity: 70.93\n",
            "  Train loss (avg): 4.3145\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        durumu nedeniyle elektronik ortamdaki hava durumu verileri ve hava durumu verileri de etkilenmektedir. Her iki durumda da hava durumu bilgileri ve hava durumu durumu rapor edilmesi gerekir. Elektriklerin duyulmasƒ± i√ßin yapƒ±lmasƒ± gereken hava durumu\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        olan Ankara, T√ºrkiye'nin en b√ºy√ºk turizm kurulu≈ülarƒ±ndan biridir. Ankara'nƒ±n ba≈ülƒ±ca turizm merkezlerinden birisi olan Ankara'nƒ±n en b√ºy√ºk turizm kurulu≈ülarƒ±ndandƒ±r. Ankara'nƒ±n en b√ºy√ºk turizm kurulu≈ülarƒ±ndan birisi olan\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        her zaman en y√ºksek teknolojiye sahip ve teknoloji alanƒ±ndaki yeniliklere, yeniliklere ve teknolojilere sahip. CADI i√ßin son derece ba≈üarƒ±lƒ± bir teknoloji. Dijital teknoloji, markalar ve teknoloji konularƒ±nƒ± inceleyerek, farklƒ± farklƒ±\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.2617)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:05:19\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "31510 | 4.5417 | 1.6e-04 | 1.13 | 38.7K | 01:51:14 |  63.0%\n",
            "31520 | 4.5881 | 1.6e-04 | 1.13 | 38.7K | 01:51:16 |  63.0%\n",
            "31530 | 4.5225 | 1.6e-04 | 1.12 | 38.7K | 01:51:18 |  63.1%\n",
            "31540 | 4.0425 | 1.6e-04 | 1.11 | 38.7K | 01:51:19 |  63.1%\n",
            "31550 | 4.3199 | 1.6e-04 | 1.10 | 38.7K | 01:51:21 |  63.1%\n",
            "31560 | 3.9865 | 1.6e-04 | 1.16 | 38.7K | 01:51:23 |  63.1%\n",
            "31570 | 4.3282 | 1.6e-04 | 1.13 | 38.7K | 01:51:24 |  63.1%\n",
            "31580 | 4.3419 | 1.6e-04 | 1.21 | 38.7K | 01:51:26 |  63.2%\n",
            "31590 | 4.2635 | 1.6e-04 | 1.11 | 38.7K | 01:51:28 |  63.2%\n",
            "31600 | 4.4724 | 1.6e-04 | 1.12 | 38.7K | 01:51:30 |  63.2%\n",
            "31610 | 3.9877 | 1.6e-04 | 1.16 | 38.7K | 01:51:31 |  63.2%\n",
            "31620 | 4.2466 | 1.6e-04 | 1.14 | 38.7K | 01:51:33 |  63.2%\n",
            "31630 | 4.4418 | 1.6e-04 | 1.11 | 38.7K | 01:51:35 |  63.3%\n",
            "31640 | 4.2092 | 1.6e-04 | 1.14 | 38.7K | 01:51:36 |  63.3%\n",
            "31650 | 4.2535 | 1.6e-04 | 1.08 | 38.7K | 01:51:38 |  63.3%\n",
            "31660 | 4.4202 | 1.6e-04 | 1.11 | 38.7K | 01:51:40 |  63.3%\n",
            "31670 | 4.3633 | 1.6e-04 | 1.15 | 38.7K | 01:51:42 |  63.3%\n",
            "31680 | 4.5544 | 1.6e-04 | 1.16 | 38.7K | 01:51:43 |  63.4%\n",
            "31690 | 4.4953 | 1.6e-04 | 1.13 | 38.7K | 01:51:45 |  63.4%\n",
            "31700 | 4.5075 | 1.6e-04 | 1.17 | 38.7K | 01:51:47 |  63.4%\n",
            "31710 | 4.2924 | 1.6e-04 | 1.10 | 38.7K | 01:51:48 |  63.4%\n",
            "31720 | 4.4926 | 1.6e-04 | 1.18 | 38.7K | 01:51:50 |  63.4%\n",
            "31730 | 4.2695 | 1.6e-04 | 1.11 | 38.7K | 01:51:52 |  63.5%\n",
            "31740 | 4.3493 | 1.6e-04 | 1.11 | 38.7K | 01:51:54 |  63.5%\n",
            "31750 | 4.2136 | 1.6e-04 | 1.14 | 38.7K | 01:51:55 |  63.5%\n",
            "31760 | 4.4387 | 1.6e-04 | 1.18 | 38.7K | 01:51:57 |  63.5%\n",
            "31770 | 3.6059 | 1.6e-04 | 1.16 | 38.7K | 01:51:59 |  63.5%\n",
            "31780 | 4.4064 | 1.6e-04 | 1.10 | 38.7K | 01:52:00 |  63.6%\n",
            "31790 | 4.1649 | 1.6e-04 | 1.08 | 38.7K | 01:52:02 |  63.6%\n",
            "31800 | 4.2494 | 1.6e-04 | 1.20 | 38.7K | 01:52:04 |  63.6%\n",
            "31810 | 4.5245 | 1.6e-04 | 1.15 | 38.7K | 01:52:06 |  63.6%\n",
            "31820 | 4.5547 | 1.6e-04 | 1.14 | 38.7K | 01:52:07 |  63.6%\n",
            "31830 | 4.5188 | 1.6e-04 | 1.11 | 38.7K | 01:52:09 |  63.7%\n",
            "31840 | 4.1130 | 1.6e-04 | 1.21 | 38.8K | 01:52:11 |  63.7%\n",
            "31850 | 4.5788 | 1.6e-04 | 1.14 | 38.8K | 01:52:12 |  63.7%\n",
            "31860 | 4.1486 | 1.6e-04 | 1.14 | 38.8K | 01:52:14 |  63.7%\n",
            "31870 | 4.4766 | 1.6e-04 | 1.11 | 38.8K | 01:52:16 |  63.7%\n",
            "31880 | 4.4088 | 1.6e-04 | 1.11 | 38.8K | 01:52:18 |  63.8%\n",
            "31890 | 4.4585 | 1.6e-04 | 1.11 | 38.8K | 01:52:19 |  63.8%\n",
            "31900 | 4.3990 | 1.6e-04 | 1.19 | 38.8K | 01:52:21 |  63.8%\n",
            "31910 | 4.2972 | 1.6e-04 | 1.13 | 38.8K | 01:52:23 |  63.8%\n",
            "31920 | 4.4136 | 1.6e-04 | 1.15 | 38.8K | 01:52:24 |  63.8%\n",
            "31930 | 4.5993 | 1.6e-04 | 1.11 | 38.8K | 01:52:26 |  63.9%\n",
            "31940 | 4.5226 | 1.6e-04 | 1.17 | 38.8K | 01:52:28 |  63.9%\n",
            "31950 | 4.3363 | 1.6e-04 | 1.09 | 38.8K | 01:52:29 |  63.9%\n",
            "31960 | 4.1246 | 1.5e-04 | 1.17 | 38.8K | 01:52:31 |  63.9%\n",
            "31970 | 4.1876 | 1.5e-04 | 1.17 | 38.8K | 01:52:33 |  63.9%\n",
            "31980 | 4.5569 | 1.5e-04 | 1.16 | 38.8K | 01:52:35 |  64.0%\n",
            "31990 | 4.2202 | 1.5e-04 | 1.14 | 38.8K | 01:52:36 |  64.0%\n",
            "32000 | 4.3670 | 1.5e-04 | 1.13 | 38.8K | 01:52:38 |  64.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 32000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.3061\n",
            "  Perplexity: 74.15\n",
            "  Train loss (avg): 4.3216\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        larƒ±n √ßok iyi ve yoƒüun olduƒüu bir g√ºnd√º. Neden bu kadar soƒüuk bir g√ºn√ºn getirdiklerini merak ettiƒüim bir durumdu. Nitekim her iki taraf √ßok sƒ±cak ve serin bir g√ºn√ºn getirildiƒüini biliyorduk. Bir\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Washington'da bulunan G√ºney Amerika Uluslararasƒ± Boris... D√ºnyanƒ±n en pahalƒ± ve en pahalƒ± yolcu ta≈üƒ±yan √ºlkesi olan G√ºney Amerika, Doƒüu Avrupa'da en pahalƒ± ve en pahalƒ± kir... D√ºnya n√ºfusla bir diƒüer √∂nemli\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , dijital bilim insanlarƒ±nƒ± daha g√º√ßl√º bir ≈üekilde yansƒ±tacak, yeni i≈ü imkanlarƒ± yaratarak i≈ü d√ºnyasƒ±nda ve vizyonlarda yer alacaƒüƒ±z. Etkin bir ≈üekilde i≈ü d√ºnyasƒ±nda ve vizyonlarda yer alabilecek, i≈ü d√ºnyasƒ±nda da iy\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:03:31\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "32010 | 4.4435 | 1.5e-04 | 1.12 | 38.7K | 01:52:57 |  64.0%\n",
            "32020 | 4.3000 | 1.5e-04 | 1.10 | 38.7K | 01:52:59 |  64.0%\n",
            "32030 | 4.4608 | 1.5e-04 | 1.13 | 38.7K | 01:53:00 |  64.1%\n",
            "32040 | 4.1795 | 1.5e-04 | 1.15 | 38.7K | 01:53:02 |  64.1%\n",
            "32050 | 3.9890 | 1.5e-04 | 1.11 | 38.7K | 01:53:04 |  64.1%\n",
            "32060 | 4.3454 | 1.5e-04 | 1.13 | 38.7K | 01:53:06 |  64.1%\n",
            "32070 | 4.2967 | 1.5e-04 | 1.21 | 38.7K | 01:53:07 |  64.1%\n",
            "32080 | 4.4365 | 1.5e-04 | 1.10 | 38.7K | 01:53:09 |  64.2%\n",
            "32090 | 4.4194 | 1.5e-04 | 1.12 | 38.7K | 01:53:11 |  64.2%\n",
            "32100 | 4.0430 | 1.5e-04 | 1.16 | 38.7K | 01:53:12 |  64.2%\n",
            "32110 | 4.3609 | 1.5e-04 | 1.15 | 38.7K | 01:53:14 |  64.2%\n",
            "32120 | 4.5276 | 1.5e-04 | 1.14 | 38.7K | 01:53:16 |  64.2%\n",
            "32130 | 4.1820 | 1.5e-04 | 1.15 | 38.7K | 01:53:18 |  64.3%\n",
            "32140 | 4.3816 | 1.5e-04 | 1.13 | 38.7K | 01:53:19 |  64.3%\n",
            "32150 | 4.3572 | 1.5e-04 | 1.15 | 38.7K | 01:53:21 |  64.3%\n",
            "32160 | 4.0565 | 1.5e-04 | 1.12 | 38.7K | 01:53:23 |  64.3%\n",
            "32170 | 4.0301 | 1.5e-04 | 1.13 | 38.7K | 01:53:24 |  64.3%\n",
            "32180 | 4.2327 | 1.5e-04 | 1.15 | 38.7K | 01:53:26 |  64.4%\n",
            "32190 | 4.0994 | 1.5e-04 | 1.11 | 38.7K | 01:53:28 |  64.4%\n",
            "32200 | 4.2427 | 1.5e-04 | 1.14 | 38.7K | 01:53:30 |  64.4%\n",
            "32210 | 4.4657 | 1.5e-04 | 1.15 | 38.7K | 01:53:31 |  64.4%\n",
            "32220 | 4.4634 | 1.5e-04 | 1.10 | 38.7K | 01:53:33 |  64.4%\n",
            "32230 | 3.9936 | 1.5e-04 | 1.17 | 38.7K | 01:53:35 |  64.5%\n",
            "32240 | 4.0169 | 1.5e-04 | 1.16 | 38.7K | 01:53:36 |  64.5%\n",
            "32250 | 4.0719 | 1.5e-04 | 1.11 | 38.7K | 01:53:38 |  64.5%\n",
            "32260 | 4.3609 | 1.5e-04 | 1.14 | 38.7K | 01:53:40 |  64.5%\n",
            "32270 | 4.4871 | 1.5e-04 | 1.17 | 38.8K | 01:53:42 |  64.5%\n",
            "32280 | 4.1862 | 1.5e-04 | 1.18 | 38.8K | 01:53:43 |  64.6%\n",
            "32290 | 4.4520 | 1.5e-04 | 1.12 | 38.8K | 01:53:45 |  64.6%\n",
            "32300 | 4.2065 | 1.5e-04 | 1.12 | 38.8K | 01:53:47 |  64.6%\n",
            "32310 | 4.1621 | 1.5e-04 | 1.12 | 38.8K | 01:53:48 |  64.6%\n",
            "32320 | 4.5319 | 1.5e-04 | 1.12 | 38.8K | 01:53:50 |  64.6%\n",
            "32330 | 4.4557 | 1.5e-04 | 1.11 | 38.8K | 01:53:52 |  64.7%\n",
            "32340 | 4.5910 | 1.5e-04 | 1.23 | 38.8K | 01:53:54 |  64.7%\n",
            "32350 | 4.3160 | 1.5e-04 | 1.13 | 38.8K | 01:53:55 |  64.7%\n",
            "32360 | 4.0423 | 1.5e-04 | 1.17 | 38.8K | 01:53:57 |  64.7%\n",
            "32370 | 4.5499 | 1.5e-04 | 1.12 | 38.8K | 01:53:59 |  64.7%\n",
            "32380 | 4.2674 | 1.5e-04 | 1.12 | 38.8K | 01:54:00 |  64.8%\n",
            "32390 | 4.3782 | 1.5e-04 | 1.14 | 38.8K | 01:54:02 |  64.8%\n",
            "32400 | 4.1852 | 1.5e-04 | 1.15 | 38.8K | 01:54:04 |  64.8%\n",
            "32410 | 4.5108 | 1.5e-04 | 1.13 | 38.8K | 01:54:05 |  64.8%\n",
            "32420 | 4.4879 | 1.5e-04 | 1.10 | 38.8K | 01:54:07 |  64.8%\n",
            "32430 | 4.3413 | 1.5e-04 | 1.16 | 38.8K | 01:54:09 |  64.9%\n",
            "32440 | 4.2567 | 1.5e-04 | 1.11 | 38.8K | 01:54:11 |  64.9%\n",
            "32450 | 4.4236 | 1.5e-04 | 1.16 | 38.8K | 01:54:12 |  64.9%\n",
            "32460 | 4.2514 | 1.5e-04 | 1.10 | 38.8K | 01:54:14 |  64.9%\n",
            "32470 | 4.2549 | 1.5e-04 | 1.16 | 38.8K | 01:54:16 |  64.9%\n",
            "32480 | 4.2271 | 1.5e-04 | 1.19 | 38.8K | 01:54:17 |  65.0%\n",
            "32490 | 4.4005 | 1.5e-04 | 1.11 | 38.8K | 01:54:19 |  65.0%\n",
            "32500 | 4.7731 | 1.5e-04 | 1.18 | 38.8K | 01:54:21 |  65.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 32500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.2568\n",
            "  Perplexity: 70.58\n",
            "  Train loss (avg): 4.3139\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        kararan hangi b√∂lge olursa olsun, bir b√∂lge olursa olsun, b√ºt√ºn b√∂lge i√ßin hazƒ±rlƒ±klƒ± olmak lazƒ±m. B√∂lgenin kalbi, √ßevre temizliƒüi, havza ve √ßevre temizliƒüi, √ßevreye duyarlƒ±lƒ±k, √ßevre koruma, doƒüaya\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        ƒ∞stanbul'da yer alan Mimar Sinan √úniversitesi, ayrƒ±ca kendi mimarisi ile dikkat √ßeken ve T√ºrkiye'nin en b√ºy√ºk mimarlarƒ±ndan biri olan Mimar Sinan √úniversitesi, mimarlƒ±ƒüƒ± ile dikkat √ßeken mimarlarƒ± ile olduk√ßa iyi\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , her zaman yapay zeka ve yapay zeka teknolojisi ile i≈ü adamlarƒ± ve √ßalƒ±≈üanlar tarafƒ±ndan kullanƒ±lmaktadƒ±r. Bu teknolojinin t√ºm sistemleri sadece sosyal zekalar ve kararsƒ±zlƒ±klara a√ßƒ±k olan yapay zekalar, i≈ü kazalarƒ± ve\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.2568)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:01:45\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "32510 | 4.4650 | 1.5e-04 | 1.16 | 38.7K | 01:54:43 |  65.0%\n",
            "32520 | 4.1448 | 1.5e-04 | 1.28 | 38.7K | 01:54:45 |  65.0%\n",
            "32530 | 4.3622 | 1.5e-04 | 1.15 | 38.7K | 01:54:47 |  65.1%\n",
            "32540 | 4.2422 | 1.5e-04 | 1.14 | 38.7K | 01:54:48 |  65.1%\n",
            "32550 | 4.4627 | 1.5e-04 | 1.16 | 38.7K | 01:54:50 |  65.1%\n",
            "32560 | 4.3649 | 1.5e-04 | 1.11 | 38.7K | 01:54:52 |  65.1%\n",
            "32570 | 4.0955 | 1.5e-04 | 1.16 | 38.7K | 01:54:54 |  65.1%\n",
            "32580 | 4.5072 | 1.5e-04 | 1.13 | 38.7K | 01:54:55 |  65.2%\n",
            "32590 | 4.4890 | 1.5e-04 | 1.11 | 38.7K | 01:54:57 |  65.2%\n",
            "32600 | 4.2212 | 1.5e-04 | 1.14 | 38.7K | 01:54:59 |  65.2%\n",
            "32610 | 4.6833 | 1.5e-04 | 1.13 | 38.7K | 01:55:00 |  65.2%\n",
            "32620 | 4.4283 | 1.5e-04 | 1.18 | 38.7K | 01:55:02 |  65.2%\n",
            "32630 | 4.4089 | 1.4e-04 | 1.14 | 38.7K | 01:55:04 |  65.3%\n",
            "32640 | 4.1850 | 1.4e-04 | 1.38 | 38.7K | 01:55:05 |  65.3%\n",
            "32650 | 4.1975 | 1.4e-04 | 1.11 | 38.7K | 01:55:07 |  65.3%\n",
            "32660 | 4.4618 | 1.4e-04 | 1.13 | 38.7K | 01:55:09 |  65.3%\n",
            "32670 | 4.4306 | 1.4e-04 | 1.12 | 38.7K | 01:55:11 |  65.3%\n",
            "32680 | 4.1887 | 1.4e-04 | 1.13 | 38.7K | 01:55:12 |  65.4%\n",
            "32690 | 4.2051 | 1.4e-04 | 1.15 | 38.7K | 01:55:14 |  65.4%\n",
            "32700 | 4.2084 | 1.4e-04 | 1.26 | 38.7K | 01:55:16 |  65.4%\n",
            "32710 | 4.2904 | 1.4e-04 | 1.10 | 38.7K | 01:55:17 |  65.4%\n",
            "32720 | 4.2600 | 1.4e-04 | 1.09 | 38.7K | 01:55:19 |  65.4%\n",
            "32730 | 4.3539 | 1.4e-04 | 1.16 | 38.7K | 01:55:21 |  65.5%\n",
            "32740 | 4.3789 | 1.4e-04 | 1.13 | 38.7K | 01:55:23 |  65.5%\n",
            "32750 | 4.4305 | 1.4e-04 | 1.16 | 38.7K | 01:55:24 |  65.5%\n",
            "32760 | 4.1855 | 1.4e-04 | 1.30 | 38.7K | 01:55:26 |  65.5%\n",
            "32770 | 4.2292 | 1.4e-04 | 1.20 | 38.7K | 01:55:28 |  65.5%\n",
            "32780 | 4.4900 | 1.4e-04 | 1.16 | 38.7K | 01:55:29 |  65.6%\n",
            "32790 | 4.3499 | 1.4e-04 | 1.10 | 38.8K | 01:55:31 |  65.6%\n",
            "32800 | 4.2800 | 1.4e-04 | 1.13 | 38.8K | 01:55:33 |  65.6%\n",
            "32810 | 4.1594 | 1.4e-04 | 1.20 | 38.8K | 01:55:35 |  65.6%\n",
            "32820 | 4.1981 | 1.4e-04 | 1.10 | 38.8K | 01:55:36 |  65.6%\n",
            "32830 | 4.3600 | 1.4e-04 | 1.11 | 38.8K | 01:55:38 |  65.7%\n",
            "32840 | 4.6265 | 1.4e-04 | 1.13 | 38.8K | 01:55:40 |  65.7%\n",
            "32850 | 4.1705 | 1.4e-04 | 1.13 | 38.8K | 01:55:41 |  65.7%\n",
            "32860 | 4.5591 | 1.4e-04 | 1.17 | 38.8K | 01:55:43 |  65.7%\n",
            "32870 | 4.1792 | 1.4e-04 | 1.21 | 38.8K | 01:55:45 |  65.7%\n",
            "32880 | 4.1466 | 1.4e-04 | 1.11 | 38.8K | 01:55:47 |  65.8%\n",
            "32890 | 4.1670 | 1.4e-04 | 1.14 | 38.8K | 01:55:48 |  65.8%\n",
            "32900 | 4.2517 | 1.4e-04 | 1.09 | 38.8K | 01:55:50 |  65.8%\n",
            "32910 | 4.0365 | 1.4e-04 | 1.11 | 38.8K | 01:55:52 |  65.8%\n",
            "32920 | 4.3650 | 1.4e-04 | 1.12 | 38.8K | 01:55:53 |  65.8%\n",
            "32930 | 4.4185 | 1.4e-04 | 1.14 | 38.8K | 01:55:55 |  65.9%\n",
            "32940 | 4.2834 | 1.4e-04 | 1.20 | 38.8K | 01:55:57 |  65.9%\n",
            "32950 | 4.2604 | 1.4e-04 | 1.39 | 38.8K | 01:55:59 |  65.9%\n",
            "32960 | 4.1464 | 1.4e-04 | 1.34 | 38.8K | 01:56:00 |  65.9%\n",
            "32970 | 4.3446 | 1.4e-04 | 1.11 | 38.8K | 01:56:02 |  65.9%\n",
            "32980 | 4.3199 | 1.4e-04 | 1.18 | 38.8K | 01:56:04 |  66.0%\n",
            "32990 | 4.2938 | 1.4e-04 | 1.12 | 38.8K | 01:56:05 |  66.0%\n",
            "33000 | 4.5415 | 1.4e-04 | 1.16 | 38.8K | 01:56:07 |  66.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 33000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.2513\n",
            "  Perplexity: 70.19\n",
            "  Train loss (avg): 4.3492\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        sƒ±caklƒ±ƒüƒ±nƒ± en y√ºksek seviyeye √ßƒ±karmayƒ± hedefleyen ve hava sƒ±caklƒ±ƒüƒ±nƒ± en y√ºksek seviyeye √ßƒ±kartmayƒ± hedefleyen bir sistem olarak, hem daha hƒ±zlƒ± hem de daha verimli bir ≈üekilde kullanƒ±labilme olanaƒüƒ± ve y√ºksek kaliteli hava depolarƒ±\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Ankara'da bulunan MHP Genel Merkezi'nin genel ba≈ükanƒ± Muharrem ƒ∞nce, partisinin genel ba≈ükanƒ± Kemal Kƒ±lƒ±√ßdaroƒülu'nun moderat√∂rl√ºƒü√ºnde yaptƒ±ƒüƒ± konu≈ümada, T√ºrkiye'nin g√ºndemini ≈üu s√∂zlerle anlattƒ±: \"Hatta tek\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        sayesinde insan v√ºcudu ciddi bir √ßaba olarak bile kar≈üƒ± kar≈üƒ±ya kalabilir. Bundan dolayƒ± insan v√ºcudu i√ßin gerekli olan bilgiyi ve bilgileri elde etmenin √∂nemli olduƒüu bir ger√ßek. Bu durum insan v√ºcudu i√ßin gerekli olan bilgiyi √ºreterek elde\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.2513)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 01:00:00\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "33010 | 4.2435 | 1.4e-04 | 1.17 | 38.7K | 01:56:30 |  66.0%\n",
            "33020 | 4.3322 | 1.4e-04 | 1.16 | 38.7K | 01:56:31 |  66.0%\n",
            "33030 | 4.4587 | 1.4e-04 | 1.13 | 38.7K | 01:56:33 |  66.1%\n",
            "33040 | 4.4200 | 1.4e-04 | 1.16 | 38.7K | 01:56:35 |  66.1%\n",
            "33050 | 4.2246 | 1.4e-04 | 1.17 | 38.7K | 01:56:37 |  66.1%\n",
            "33060 | 4.0828 | 1.4e-04 | 1.27 | 38.7K | 01:56:38 |  66.1%\n",
            "33070 | 4.2902 | 1.4e-04 | 1.17 | 38.7K | 01:56:40 |  66.1%\n",
            "33080 | 4.4968 | 1.4e-04 | 1.17 | 38.7K | 01:56:42 |  66.2%\n",
            "33090 | 4.1419 | 1.4e-04 | 1.19 | 38.7K | 01:56:43 |  66.2%\n",
            "33100 | 4.3015 | 1.4e-04 | 1.21 | 38.7K | 01:56:45 |  66.2%\n",
            "33110 | 4.4103 | 1.4e-04 | 1.12 | 38.7K | 01:56:47 |  66.2%\n",
            "33120 | 4.4088 | 1.4e-04 | 1.10 | 38.7K | 01:56:49 |  66.2%\n",
            "33130 | 4.1609 | 1.4e-04 | 1.18 | 38.7K | 01:56:50 |  66.3%\n",
            "33140 | 4.4114 | 1.4e-04 | 1.21 | 38.7K | 01:56:52 |  66.3%\n",
            "33150 | 4.3231 | 1.4e-04 | 1.16 | 38.7K | 01:56:54 |  66.3%\n",
            "33160 | 4.4262 | 1.4e-04 | 1.14 | 38.7K | 01:56:55 |  66.3%\n",
            "33170 | 4.5332 | 1.4e-04 | 1.11 | 38.7K | 01:56:57 |  66.3%\n",
            "33180 | 4.1927 | 1.4e-04 | 1.18 | 38.7K | 01:56:59 |  66.4%\n",
            "33190 | 4.3592 | 1.4e-04 | 1.24 | 38.7K | 01:57:00 |  66.4%\n",
            "33200 | 4.3745 | 1.4e-04 | 1.12 | 38.7K | 01:57:02 |  66.4%\n",
            "33210 | 4.4133 | 1.4e-04 | 1.14 | 38.7K | 01:57:04 |  66.4%\n",
            "33220 | 3.8238 | 1.4e-04 | 1.28 | 38.7K | 01:57:06 |  66.4%\n",
            "33230 | 4.3715 | 1.4e-04 | 1.16 | 38.7K | 01:57:07 |  66.5%\n",
            "33240 | 4.2597 | 1.4e-04 | 1.19 | 38.7K | 01:57:09 |  66.5%\n",
            "33250 | 4.4998 | 1.4e-04 | 1.17 | 38.7K | 01:57:11 |  66.5%\n",
            "33260 | 4.4739 | 1.4e-04 | 1.11 | 38.7K | 01:57:12 |  66.5%\n",
            "33270 | 4.3594 | 1.4e-04 | 1.12 | 38.7K | 01:57:14 |  66.5%\n",
            "33280 | 3.9478 | 1.4e-04 | 1.19 | 38.7K | 01:57:16 |  66.6%\n",
            "33290 | 4.2492 | 1.4e-04 | 1.14 | 38.7K | 01:57:18 |  66.6%\n",
            "33300 | 4.3305 | 1.4e-04 | 1.14 | 38.8K | 01:57:19 |  66.6%\n",
            "33310 | 4.2282 | 1.3e-04 | 1.14 | 38.8K | 01:57:21 |  66.6%\n",
            "33320 | 4.0578 | 1.3e-04 | 1.16 | 38.8K | 01:57:23 |  66.6%\n",
            "33330 | 4.6048 | 1.3e-04 | 1.14 | 38.8K | 01:57:24 |  66.7%\n",
            "33340 | 4.3348 | 1.3e-04 | 1.18 | 38.8K | 01:57:26 |  66.7%\n",
            "33350 | 4.5909 | 1.3e-04 | 1.15 | 38.8K | 01:57:28 |  66.7%\n",
            "33360 | 4.4630 | 1.3e-04 | 1.19 | 38.8K | 01:57:30 |  66.7%\n",
            "33370 | 4.5414 | 1.3e-04 | 1.13 | 38.8K | 01:57:31 |  66.7%\n",
            "33380 | 4.3382 | 1.3e-04 | 1.19 | 38.8K | 01:57:33 |  66.8%\n",
            "33390 | 4.0173 | 1.3e-04 | 1.13 | 38.8K | 01:57:35 |  66.8%\n",
            "33400 | 4.1365 | 1.3e-04 | 1.14 | 38.8K | 01:57:36 |  66.8%\n",
            "33410 | 4.2785 | 1.3e-04 | 1.12 | 38.8K | 01:57:38 |  66.8%\n",
            "33420 | 4.5069 | 1.3e-04 | 1.17 | 38.8K | 01:57:40 |  66.8%\n",
            "33430 | 4.3840 | 1.3e-04 | 1.11 | 38.8K | 01:57:42 |  66.9%\n",
            "33440 | 4.2323 | 1.3e-04 | 1.15 | 38.8K | 01:57:43 |  66.9%\n",
            "33450 | 4.3550 | 1.3e-04 | 1.15 | 38.8K | 01:57:45 |  66.9%\n",
            "33460 | 4.2126 | 1.3e-04 | 1.20 | 38.8K | 01:57:47 |  66.9%\n",
            "33470 | 4.2124 | 1.3e-04 | 1.17 | 38.8K | 01:57:48 |  66.9%\n",
            "33480 | 4.3925 | 1.3e-04 | 1.17 | 38.8K | 01:57:50 |  67.0%\n",
            "33490 | 4.1313 | 1.3e-04 | 1.17 | 38.8K | 01:57:52 |  67.0%\n",
            "33500 | 4.1973 | 1.3e-04 | 1.23 | 38.8K | 01:57:54 |  67.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 33500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.2581\n",
            "  Perplexity: 70.68\n",
            "  Train loss (avg): 4.2899\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        durumu √ßok k√∂t√º bir ≈üey deƒüil. √á√ºnk√º g√ºnd√ºz ku≈üaƒüƒ± gibi bir ortam vardƒ±. Sƒ±cakta bir hava vardƒ±. Soƒüuklar soƒüuktu, sƒ±cakta bir ≈üeyler vardƒ±, sisler, y√ºkseklik, bu\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        ƒ∞stanbul'da bulunan Evoles b√∂lgesindeki √ñzel kaldƒ±mealƒ± alƒ±≈üveri≈ü merkezi ƒ∞stanbul'da a√ßƒ±ldƒ±. ƒ∞stanbul'da maƒüaza a√ßarak, 300'den fazla maƒüaza satƒ±n aldƒ±m. ƒ∞stanbul'da bulunan maƒüazalardaki\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , yapay zeka teknolojisinin tamamlayƒ±cƒ±sƒ± olarak bilgisayar teknolojisinin bir par√ßasƒ± haline geliyor. Yapay zeka teknolojisinin kullanƒ±mƒ±na a√ßƒ±k bir teknoloji olarak akƒ±llƒ± telefonlar ve tabletler arasƒ±ndaki baƒülantƒ± her ge√ßen g√ºn artƒ±yor. Yapay zekanƒ±n yapay zeka ile\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 00:58:12\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "33510 | 4.3127 | 1.3e-04 | 1.12 | 38.7K | 01:58:13 |  67.0%\n",
            "33520 | 4.3005 | 1.3e-04 | 1.14 | 38.7K | 01:58:14 |  67.0%\n",
            "33530 | 4.4716 | 1.3e-04 | 1.10 | 38.7K | 01:58:16 |  67.1%\n",
            "33540 | 4.3756 | 1.3e-04 | 1.21 | 38.7K | 01:58:18 |  67.1%\n",
            "33550 | 4.1296 | 1.3e-04 | 1.17 | 38.7K | 01:58:19 |  67.1%\n",
            "33560 | 4.4133 | 1.3e-04 | 1.16 | 38.7K | 01:58:21 |  67.1%\n",
            "33570 | 4.2922 | 1.3e-04 | 1.13 | 38.7K | 01:58:23 |  67.1%\n",
            "33580 | 4.3732 | 1.3e-04 | 1.11 | 38.7K | 01:58:25 |  67.2%\n",
            "33590 | 4.5417 | 1.3e-04 | 1.15 | 38.7K | 01:58:26 |  67.2%\n",
            "33600 | 4.1700 | 1.3e-04 | 1.14 | 38.7K | 01:58:28 |  67.2%\n",
            "33610 | 4.2716 | 1.3e-04 | 1.12 | 38.7K | 01:58:30 |  67.2%\n",
            "33620 | 4.3545 | 1.3e-04 | 1.14 | 38.7K | 01:58:31 |  67.2%\n",
            "33630 | 4.4526 | 1.3e-04 | 1.17 | 38.7K | 01:58:33 |  67.3%\n",
            "33640 | 4.3087 | 1.3e-04 | 1.14 | 38.7K | 01:58:35 |  67.3%\n",
            "33650 | 4.2404 | 1.3e-04 | 1.16 | 38.7K | 01:58:36 |  67.3%\n",
            "33660 | 4.1721 | 1.3e-04 | 1.20 | 38.7K | 01:58:38 |  67.3%\n",
            "33670 | 4.2831 | 1.3e-04 | 1.11 | 38.7K | 01:58:40 |  67.3%\n",
            "33680 | 4.3087 | 1.3e-04 | 1.11 | 38.7K | 01:58:42 |  67.4%\n",
            "33690 | 4.3582 | 1.3e-04 | 1.15 | 38.7K | 01:58:43 |  67.4%\n",
            "33700 | 4.1318 | 1.3e-04 | 1.15 | 38.7K | 01:58:45 |  67.4%\n",
            "33710 | 4.3397 | 1.3e-04 | 1.22 | 38.7K | 01:58:47 |  67.4%\n",
            "33720 | 4.4837 | 1.3e-04 | 1.14 | 38.7K | 01:58:48 |  67.4%\n",
            "33730 | 4.0708 | 1.3e-04 | 1.13 | 38.8K | 01:58:50 |  67.5%\n",
            "33740 | 4.1316 | 1.3e-04 | 1.16 | 38.8K | 01:58:52 |  67.5%\n",
            "33750 | 4.2426 | 1.3e-04 | 1.13 | 38.8K | 01:58:54 |  67.5%\n",
            "33760 | 4.2716 | 1.3e-04 | 1.23 | 38.8K | 01:58:55 |  67.5%\n",
            "33770 | 4.4056 | 1.3e-04 | 1.15 | 38.8K | 01:58:57 |  67.5%\n",
            "33780 | 4.0839 | 1.3e-04 | 1.22 | 38.8K | 01:58:59 |  67.6%\n",
            "33790 | 4.5802 | 1.3e-04 | 1.19 | 38.8K | 01:59:00 |  67.6%\n",
            "33800 | 4.5056 | 1.3e-04 | 1.41 | 38.8K | 01:59:02 |  67.6%\n",
            "33810 | 4.1166 | 1.3e-04 | 1.14 | 38.8K | 01:59:04 |  67.6%\n",
            "33820 | 4.5638 | 1.3e-04 | 1.14 | 38.8K | 01:59:06 |  67.6%\n",
            "33830 | 4.3758 | 1.3e-04 | 1.16 | 38.8K | 01:59:07 |  67.7%\n",
            "33840 | 4.4544 | 1.3e-04 | 1.14 | 38.8K | 01:59:09 |  67.7%\n",
            "33850 | 4.5486 | 1.3e-04 | 1.15 | 38.8K | 01:59:11 |  67.7%\n",
            "33860 | 4.1775 | 1.3e-04 | 1.23 | 38.8K | 01:59:12 |  67.7%\n",
            "33870 | 4.3255 | 1.3e-04 | 1.17 | 38.8K | 01:59:14 |  67.7%\n",
            "33880 | 4.3981 | 1.3e-04 | 1.20 | 38.8K | 01:59:16 |  67.8%\n",
            "33890 | 4.3837 | 1.3e-04 | 1.12 | 38.8K | 01:59:18 |  67.8%\n",
            "33900 | 4.0664 | 1.3e-04 | 1.42 | 38.8K | 01:59:19 |  67.8%\n",
            "33910 | 4.4377 | 1.3e-04 | 1.25 | 38.8K | 01:59:21 |  67.8%\n",
            "33920 | 4.3857 | 1.3e-04 | 1.13 | 38.8K | 01:59:23 |  67.8%\n",
            "33930 | 4.5083 | 1.3e-04 | 1.19 | 38.8K | 01:59:24 |  67.9%\n",
            "33940 | 3.9729 | 1.3e-04 | 1.19 | 38.8K | 01:59:26 |  67.9%\n",
            "33950 | 4.3648 | 1.3e-04 | 1.18 | 38.8K | 01:59:28 |  67.9%\n",
            "33960 | 4.0566 | 1.3e-04 | 1.10 | 38.8K | 01:59:30 |  67.9%\n",
            "33970 | 4.4977 | 1.3e-04 | 1.14 | 38.8K | 01:59:31 |  67.9%\n",
            "33980 | 4.2387 | 1.3e-04 | 1.16 | 38.8K | 01:59:33 |  68.0%\n",
            "33990 | 4.2352 | 1.3e-04 | 1.18 | 38.8K | 01:59:35 |  68.0%\n",
            "34000 | 4.2356 | 1.3e-04 | 1.14 | 38.8K | 01:59:36 |  68.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 34000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.2491\n",
            "  Perplexity: 70.04\n",
            "  Train loss (avg): 4.2984\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        nasƒ±ldƒ±? Nasƒ±ldƒ±? Neden mi? Neden? Neden? Neden? Neden? Neden? Neden? Neden? Neden? Neden? Neden? Neden? Neden? Neden? Neden? Neden? Neden\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Ankara'da ger√ßekle≈ütirilen DYP ƒ∞stanbul Avrupa Markalarƒ± Zirvesi'ne, T√ºrkiye'nin √∂nde gelen √∂zel sekt√∂r temsilcileri ve basƒ±n mensuplarƒ± katƒ±ldƒ±. ƒ∞stanbul Teknik √úniversitesi'nde d√ºzenlenen T√ºrkiye'nin 500,\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        sayesinde, s√ºre√ß i√ßerisindeki en b√ºy√ºk rekabet avantajƒ± (en iyi teknoloji) y√ºksek performanslƒ± bir sistem √ºretildi. Yeni nesil teknolojiyle, en √ßok kullanƒ±lan ve en √ßok kullanƒ±lan teknolojilerin en √ßok da daha fazla\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.2491)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 00:56:27\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "34010 | 4.2632 | 1.2e-04 | 1.15 | 38.7K | 01:59:59 |  68.0%\n",
            "34020 | 3.9736 | 1.2e-04 | 1.12 | 38.7K | 02:00:00 |  68.0%\n",
            "34030 | 4.2492 | 1.2e-04 | 1.11 | 38.7K | 02:00:02 |  68.1%\n",
            "34040 | 4.3415 | 1.2e-04 | 1.18 | 38.7K | 02:00:04 |  68.1%\n",
            "34050 | 4.4503 | 1.2e-04 | 1.13 | 38.7K | 02:00:06 |  68.1%\n",
            "34060 | 4.0155 | 1.2e-04 | 1.13 | 38.7K | 02:00:07 |  68.1%\n",
            "34070 | 4.3763 | 1.2e-04 | 1.12 | 38.7K | 02:00:09 |  68.1%\n",
            "34080 | 4.3367 | 1.2e-04 | 1.16 | 38.7K | 02:00:11 |  68.2%\n",
            "34090 | 4.3124 | 1.2e-04 | 1.19 | 38.7K | 02:00:12 |  68.2%\n",
            "34100 | 3.9973 | 1.2e-04 | 1.18 | 38.7K | 02:00:14 |  68.2%\n",
            "34110 | 4.3240 | 1.2e-04 | 1.32 | 38.7K | 02:00:16 |  68.2%\n",
            "34120 | 4.3635 | 1.2e-04 | 1.12 | 38.7K | 02:00:18 |  68.2%\n",
            "34130 | 4.2383 | 1.2e-04 | 1.20 | 38.7K | 02:00:19 |  68.3%\n",
            "34140 | 4.3153 | 1.2e-04 | 1.14 | 38.7K | 02:00:21 |  68.3%\n",
            "34150 | 4.2177 | 1.2e-04 | 1.17 | 38.7K | 02:00:23 |  68.3%\n",
            "34160 | 4.3391 | 1.2e-04 | 1.13 | 38.7K | 02:00:24 |  68.3%\n",
            "34170 | 4.0643 | 1.2e-04 | 1.38 | 38.7K | 02:00:26 |  68.3%\n",
            "34180 | 3.8391 | 1.2e-04 | 1.12 | 38.7K | 02:00:28 |  68.4%\n",
            "34190 | 4.5510 | 1.2e-04 | 1.13 | 38.7K | 02:00:30 |  68.4%\n",
            "34200 | 4.2236 | 1.2e-04 | 1.20 | 38.7K | 02:00:31 |  68.4%\n",
            "34210 | 4.1739 | 1.2e-04 | 1.11 | 38.7K | 02:00:33 |  68.4%\n",
            "34220 | 4.0310 | 1.2e-04 | 1.15 | 38.7K | 02:00:35 |  68.4%\n",
            "34230 | 4.1676 | 1.2e-04 | 1.19 | 38.7K | 02:00:36 |  68.5%\n",
            "34240 | 4.3405 | 1.2e-04 | 1.18 | 38.7K | 02:00:38 |  68.5%\n",
            "34250 | 4.5126 | 1.2e-04 | 1.21 | 38.8K | 02:00:40 |  68.5%\n",
            "34260 | 4.3289 | 1.2e-04 | 1.13 | 38.8K | 02:00:42 |  68.5%\n",
            "34270 | 4.3192 | 1.2e-04 | 1.15 | 38.8K | 02:00:43 |  68.5%\n",
            "34280 | 4.4999 | 1.2e-04 | 1.15 | 38.8K | 02:00:45 |  68.6%\n",
            "34290 | 4.0379 | 1.2e-04 | 1.18 | 38.8K | 02:00:47 |  68.6%\n",
            "34300 | 4.3856 | 1.2e-04 | 1.18 | 38.8K | 02:00:48 |  68.6%\n",
            "34310 | 4.3467 | 1.2e-04 | 1.14 | 38.8K | 02:00:50 |  68.6%\n",
            "34320 | 4.4469 | 1.2e-04 | 1.18 | 38.8K | 02:00:52 |  68.6%\n",
            "34330 | 4.3264 | 1.2e-04 | 1.16 | 38.8K | 02:00:54 |  68.7%\n",
            "34340 | 4.3835 | 1.2e-04 | 1.14 | 38.8K | 02:00:55 |  68.7%\n",
            "34350 | 4.4467 | 1.2e-04 | 1.14 | 38.8K | 02:00:57 |  68.7%\n",
            "34360 | 4.5820 | 1.2e-04 | 1.27 | 38.8K | 02:00:59 |  68.7%\n",
            "34370 | 4.2464 | 1.2e-04 | 1.14 | 38.8K | 02:01:00 |  68.7%\n",
            "34380 | 4.5060 | 1.2e-04 | 1.15 | 38.8K | 02:01:02 |  68.8%\n",
            "34390 | 4.4074 | 1.2e-04 | 1.14 | 38.8K | 02:01:04 |  68.8%\n",
            "34400 | 4.2825 | 1.2e-04 | 1.41 | 38.8K | 02:01:05 |  68.8%\n",
            "34410 | 4.4428 | 1.2e-04 | 1.16 | 38.8K | 02:01:07 |  68.8%\n",
            "34420 | 4.2455 | 1.2e-04 | 1.16 | 38.8K | 02:01:09 |  68.8%\n",
            "34430 | 4.5171 | 1.2e-04 | 1.16 | 38.8K | 02:01:11 |  68.9%\n",
            "34440 | 4.3633 | 1.2e-04 | 1.17 | 38.8K | 02:01:12 |  68.9%\n",
            "34450 | 4.2086 | 1.2e-04 | 1.13 | 38.8K | 02:01:14 |  68.9%\n",
            "34460 | 4.6826 | 1.2e-04 | 1.15 | 38.8K | 02:01:16 |  68.9%\n",
            "34470 | 4.1951 | 1.2e-04 | 1.19 | 38.8K | 02:01:17 |  68.9%\n",
            "34480 | 4.2369 | 1.2e-04 | 1.11 | 38.8K | 02:01:19 |  69.0%\n",
            "34490 | 4.2956 | 1.2e-04 | 1.20 | 38.8K | 02:01:21 |  69.0%\n",
            "34500 | 4.2783 | 1.2e-04 | 1.12 | 38.8K | 02:01:23 |  69.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 34500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.2423\n",
            "  Perplexity: 69.57\n",
            "  Train loss (avg): 4.2909\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        , ƒ∞stanbul‚Äôda kar yaƒüƒ±≈üƒ± ile birlikte par√ßalƒ± ve zaman zaman kar yaƒüƒ±≈üƒ± ile birlikte etkili oldu. Yakƒ±n Doƒüu Anadolu B√∂lgesi‚Äônde bazƒ± b√∂lgelerde kar yaƒüƒ±≈üƒ± devam ediyor. Bug√ºn kar yaƒüƒ±≈üƒ± ve yaƒüƒ±≈üƒ± ile birlikte\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        olarak tanƒ±mlanan, merkeziyet√ßi, b√∂lgesel bir g√º√ß olmasƒ±, T√ºrkiye'nin de yoƒüun bir y√∂netim aƒüƒ± olmasƒ±, √ºlkenin her t√ºrl√º geli≈ümi≈üliƒüi ve mutluluƒüu ile AB'yi uzun s√ºreli bir baƒülƒ±lƒ±k sarfetmesi\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        sayesinde, √ßok fazla insan biyolojik olarak da √ºretilen t√ºm yapay zeka teknolojilerini kullanmak zorunda. √áevre dostu teknolojilerin kullanƒ±mƒ±, daha az insan ya≈üam alanƒ±nda daha fazla insana hizmet vermektedir. D√ºnya √ºzerindeki insanlarƒ±mƒ±zƒ±n da ya≈üam\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.2423)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 00:54:41\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "34510 | 4.0754 | 1.2e-04 | 1.25 | 38.7K | 02:01:45 |  69.0%\n",
            "34520 | 4.2388 | 1.2e-04 | 1.17 | 38.7K | 02:01:47 |  69.0%\n",
            "34530 | 4.1626 | 1.2e-04 | 1.15 | 38.7K | 02:01:48 |  69.1%\n",
            "34540 | 4.3850 | 1.2e-04 | 1.19 | 38.7K | 02:01:50 |  69.1%\n",
            "34550 | 4.3380 | 1.2e-04 | 1.19 | 38.7K | 02:01:52 |  69.1%\n",
            "34560 | 4.3376 | 1.2e-04 | 1.13 | 38.7K | 02:01:54 |  69.1%\n",
            "34570 | 4.1510 | 1.2e-04 | 1.14 | 38.7K | 02:01:55 |  69.1%\n",
            "34580 | 4.2558 | 1.2e-04 | 1.14 | 38.7K | 02:01:57 |  69.2%\n",
            "34590 | 4.2275 | 1.2e-04 | 1.14 | 38.7K | 02:01:59 |  69.2%\n",
            "34600 | 4.0588 | 1.2e-04 | 1.14 | 38.7K | 02:02:00 |  69.2%\n",
            "34610 | 4.1866 | 1.2e-04 | 1.21 | 38.7K | 02:02:02 |  69.2%\n",
            "34620 | 4.1432 | 1.2e-04 | 1.16 | 38.7K | 02:02:04 |  69.2%\n",
            "34630 | 4.2660 | 1.2e-04 | 1.13 | 38.7K | 02:02:06 |  69.3%\n",
            "34640 | 4.2116 | 1.2e-04 | 1.22 | 38.7K | 02:02:07 |  69.3%\n",
            "34650 | 4.3131 | 1.2e-04 | 1.17 | 38.7K | 02:02:09 |  69.3%\n",
            "34660 | 4.2786 | 1.2e-04 | 1.15 | 38.7K | 02:02:11 |  69.3%\n",
            "34670 | 4.3518 | 1.2e-04 | 1.16 | 38.7K | 02:02:12 |  69.3%\n",
            "34680 | 4.5526 | 1.2e-04 | 1.16 | 38.7K | 02:02:14 |  69.4%\n",
            "34690 | 4.2309 | 1.2e-04 | 1.12 | 38.7K | 02:02:16 |  69.4%\n",
            "34700 | 4.3255 | 1.2e-04 | 1.15 | 38.7K | 02:02:18 |  69.4%\n",
            "34710 | 4.0250 | 1.2e-04 | 1.18 | 38.7K | 02:02:19 |  69.4%\n",
            "34720 | 4.0092 | 1.1e-04 | 1.12 | 38.7K | 02:02:21 |  69.4%\n",
            "34730 | 4.3670 | 1.1e-04 | 1.13 | 38.7K | 02:02:23 |  69.5%\n",
            "34740 | 4.1507 | 1.1e-04 | 1.15 | 38.7K | 02:02:24 |  69.5%\n",
            "34750 | 4.3439 | 1.1e-04 | 1.16 | 38.7K | 02:02:26 |  69.5%\n",
            "34760 | 4.1927 | 1.1e-04 | 1.15 | 38.8K | 02:02:28 |  69.5%\n",
            "34770 | 4.1724 | 1.1e-04 | 1.16 | 38.8K | 02:02:30 |  69.5%\n",
            "34780 | 4.1338 | 1.1e-04 | 1.17 | 38.8K | 02:02:31 |  69.6%\n",
            "34790 | 4.2746 | 1.1e-04 | 1.15 | 38.8K | 02:02:33 |  69.6%\n",
            "34800 | 4.4542 | 1.1e-04 | 1.19 | 38.8K | 02:02:35 |  69.6%\n",
            "34810 | 4.2084 | 1.1e-04 | 1.15 | 38.8K | 02:02:36 |  69.6%\n",
            "34820 | 4.3285 | 1.1e-04 | 1.16 | 38.8K | 02:02:38 |  69.6%\n",
            "34830 | 4.4716 | 1.1e-04 | 1.17 | 38.8K | 02:02:40 |  69.7%\n",
            "34840 | 4.5969 | 1.1e-04 | 1.23 | 38.8K | 02:02:42 |  69.7%\n",
            "34850 | 4.6060 | 1.1e-04 | 1.13 | 38.8K | 02:02:43 |  69.7%\n",
            "34860 | 4.2335 | 1.1e-04 | 1.17 | 38.8K | 02:02:45 |  69.7%\n",
            "34870 | 4.2513 | 1.1e-04 | 1.14 | 38.8K | 02:02:47 |  69.7%\n",
            "34880 | 4.3416 | 1.1e-04 | 1.15 | 38.8K | 02:02:48 |  69.8%\n",
            "34890 | 3.9354 | 1.1e-04 | 1.13 | 38.8K | 02:02:50 |  69.8%\n",
            "34900 | 4.3496 | 1.1e-04 | 1.16 | 38.8K | 02:02:52 |  69.8%\n",
            "34910 | 4.2706 | 1.1e-04 | 1.16 | 38.8K | 02:02:54 |  69.8%\n",
            "34920 | 4.3843 | 1.1e-04 | 1.17 | 38.8K | 02:02:55 |  69.8%\n",
            "34930 | 3.5710 | 1.1e-04 | 1.27 | 38.8K | 02:02:57 |  69.9%\n",
            "34940 | 4.3649 | 1.1e-04 | 1.15 | 38.8K | 02:02:59 |  69.9%\n",
            "34950 | 4.5250 | 1.1e-04 | 1.17 | 38.8K | 02:03:00 |  69.9%\n",
            "34960 | 4.0962 | 1.1e-04 | 1.26 | 38.8K | 02:03:02 |  69.9%\n",
            "34970 | 4.0772 | 1.1e-04 | 1.26 | 38.8K | 02:03:04 |  69.9%\n",
            "34980 | 3.9849 | 1.1e-04 | 1.19 | 38.8K | 02:03:06 |  70.0%\n",
            "34990 | 4.3328 | 1.1e-04 | 1.18 | 38.8K | 02:03:07 |  70.0%\n",
            "35000 | 4.5387 | 1.1e-04 | 1.14 | 38.8K | 02:03:09 |  70.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 35000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.2472\n",
            "  Perplexity: 69.91\n",
            "  Train loss (avg): 4.2948\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        √ßok sƒ±cak ve soƒüuk. Kƒ±≈ü aylarƒ±nƒ±n √ßok sƒ±cak ge√ßmesi ile, kƒ±≈üƒ±n, yazƒ±n donup, kƒ±≈üƒ±n da sƒ±cak olacak. Kƒ±≈ü geldi. Kƒ±≈ü geldi. Kƒ±≈ü geldi. G√ºn geldi. Kƒ±≈ü geldi. Kƒ±≈ü\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        ve en b√ºy√ºk ≈üehri olan T√ºrkiye, Avrupa'ya a√ßƒ±k bir konuma sahiptir. T√ºrkiye, Avrupa'nƒ±n en b√ºy√ºk ≈üehri olan Avrupa'ya a√ßƒ±lan kapƒ±sƒ± olarak bilinen d√ºnyanƒ±n en b√ºy√ºk ≈üehridir. T√ºrkiye'nin\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        g√ºn√ºm√ºzde, akƒ±llƒ± cihazlara iyi gelebiliyor. Sizin de b√∂yle bir ≈üey yapmƒ±≈ü olduƒüunuza inanmanƒ±z gerekiyor. Herhangi bir altyapƒ±yƒ± daƒüƒ±ttƒ±ƒüƒ±nƒ±z ya da satƒ±n aldƒ±ƒüƒ±nƒ±z marka, bir ≈üey satmak ya da daha fazlasƒ±nƒ±\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:52:54\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "üíæ Checkpoint kaydediliyor: /content/drive/MyDrive/turkish_llm/checkpoints//checkpoint_step_35000.pt\n",
            "  ‚úÖ Checkpoint kaydedildi!\n",
            "\n",
            "35010 | 4.1172 | 1.1e-04 | 1.13 | 38.7K | 02:03:31 |  70.0%\n",
            "35020 | 4.2884 | 1.1e-04 | 1.13 | 38.7K | 02:03:33 |  70.0%\n",
            "35030 | 4.6304 | 1.1e-04 | 1.20 | 38.7K | 02:03:35 |  70.1%\n",
            "35040 | 4.5377 | 1.1e-04 | 1.18 | 38.7K | 02:03:36 |  70.1%\n",
            "35050 | 4.3489 | 1.1e-04 | 1.16 | 38.7K | 02:03:38 |  70.1%\n",
            "35060 | 3.7630 | 1.1e-04 | 1.27 | 38.7K | 02:03:40 |  70.1%\n",
            "35070 | 4.5015 | 1.1e-04 | 1.18 | 38.7K | 02:03:41 |  70.1%\n",
            "35080 | 4.2593 | 1.1e-04 | 1.15 | 38.7K | 02:03:43 |  70.2%\n",
            "35090 | 4.2757 | 1.1e-04 | 1.16 | 38.7K | 02:03:45 |  70.2%\n",
            "35100 | 4.2478 | 1.1e-04 | 1.13 | 38.7K | 02:03:47 |  70.2%\n",
            "35110 | 4.3042 | 1.1e-04 | 1.15 | 38.7K | 02:03:48 |  70.2%\n",
            "35120 | 4.4338 | 1.1e-04 | 1.16 | 38.7K | 02:03:50 |  70.2%\n",
            "35130 | 4.1874 | 1.1e-04 | 1.20 | 38.7K | 02:03:52 |  70.3%\n",
            "35140 | 4.3374 | 1.1e-04 | 1.21 | 38.7K | 02:03:53 |  70.3%\n",
            "35150 | 4.5744 | 1.1e-04 | 1.27 | 38.7K | 02:03:55 |  70.3%\n",
            "35160 | 4.4135 | 1.1e-04 | 1.13 | 38.7K | 02:03:57 |  70.3%\n",
            "35170 | 4.1813 | 1.1e-04 | 1.16 | 38.7K | 02:03:59 |  70.3%\n",
            "35180 | 4.2871 | 1.1e-04 | 1.16 | 38.7K | 02:04:00 |  70.4%\n",
            "35190 | 4.2418 | 1.1e-04 | 1.19 | 38.7K | 02:04:02 |  70.4%\n",
            "35200 | 4.4868 | 1.1e-04 | 1.17 | 38.7K | 02:04:04 |  70.4%\n",
            "35210 | 4.4765 | 1.1e-04 | 1.16 | 38.7K | 02:04:05 |  70.4%\n",
            "35220 | 4.5188 | 1.1e-04 | 1.16 | 38.7K | 02:04:07 |  70.4%\n",
            "35230 | 4.3822 | 1.1e-04 | 1.18 | 38.7K | 02:04:09 |  70.5%\n",
            "35240 | 4.3112 | 1.1e-04 | 1.17 | 38.7K | 02:04:11 |  70.5%\n",
            "35250 | 4.2723 | 1.1e-04 | 1.19 | 38.7K | 02:04:12 |  70.5%\n",
            "35260 | 4.1843 | 1.1e-04 | 1.19 | 38.7K | 02:04:14 |  70.5%\n",
            "35270 | 4.3190 | 1.1e-04 | 1.25 | 38.8K | 02:04:16 |  70.5%\n",
            "35280 | 4.1814 | 1.1e-04 | 1.21 | 38.8K | 02:04:17 |  70.6%\n",
            "35290 | 4.6401 | 1.1e-04 | 1.21 | 38.8K | 02:04:19 |  70.6%\n",
            "35300 | 4.3475 | 1.1e-04 | 1.20 | 38.8K | 02:04:21 |  70.6%\n",
            "35310 | 4.3349 | 1.1e-04 | 1.13 | 38.8K | 02:04:23 |  70.6%\n",
            "35320 | 3.7434 | 1.1e-04 | 1.20 | 38.8K | 02:04:24 |  70.6%\n",
            "35330 | 4.0958 | 1.1e-04 | 1.19 | 38.8K | 02:04:26 |  70.7%\n",
            "35340 | 4.6973 | 1.1e-04 | 1.12 | 38.8K | 02:04:28 |  70.7%\n",
            "35350 | 4.3994 | 1.1e-04 | 1.20 | 38.8K | 02:04:29 |  70.7%\n",
            "35360 | 4.4263 | 1.1e-04 | 1.15 | 38.8K | 02:04:31 |  70.7%\n",
            "35370 | 4.3124 | 1.1e-04 | 1.16 | 38.8K | 02:04:33 |  70.7%\n",
            "35380 | 4.1703 | 1.1e-04 | 1.16 | 38.8K | 02:04:34 |  70.8%\n",
            "35390 | 4.3015 | 1.1e-04 | 1.16 | 38.8K | 02:04:36 |  70.8%\n",
            "35400 | 4.0265 | 1.1e-04 | 1.15 | 38.8K | 02:04:38 |  70.8%\n",
            "35410 | 4.3114 | 1.1e-04 | 1.25 | 38.8K | 02:04:40 |  70.8%\n",
            "35420 | 4.1283 | 1.1e-04 | 1.15 | 38.8K | 02:04:41 |  70.8%\n",
            "35430 | 4.3487 | 1.1e-04 | 1.16 | 38.8K | 02:04:43 |  70.9%\n",
            "35440 | 4.3632 | 1.1e-04 | 1.13 | 38.8K | 02:04:45 |  70.9%\n",
            "35450 | 3.4797 | 1.1e-04 | 1.23 | 38.8K | 02:04:46 |  70.9%\n",
            "35460 | 4.1995 | 1.0e-04 | 1.19 | 38.8K | 02:04:48 |  70.9%\n",
            "35470 | 4.4189 | 1.0e-04 | 1.18 | 38.8K | 02:04:50 |  70.9%\n",
            "35480 | 4.3836 | 1.0e-04 | 1.18 | 38.8K | 02:04:52 |  71.0%\n",
            "35490 | 4.0369 | 1.0e-04 | 1.15 | 38.8K | 02:04:53 |  71.0%\n",
            "35500 | 4.1093 | 1.0e-04 | 1.14 | 38.8K | 02:04:55 |  71.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 35500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.2304\n",
            "  Perplexity: 68.75\n",
            "  Train loss (avg): 4.2843\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        ≈üartlarƒ± ne olursa olsun hava ≈üartlarƒ± su ve toprak ƒ±sƒ±sƒ± ile sabittir. Hava ko≈üullarƒ± hava ≈üartlarƒ± hava ≈üartlarƒ±nƒ±n uygunluƒüuna g√∂re deƒüi≈üiklik g√∂stermektedir. Ancak hava ≈üartlarƒ±, hava ≈üartlarƒ± ve hava ≈üartlarƒ± bu belgeler √ºzerinde\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Ankara'da, Ankara merkezli √ßok sayƒ±da STK ve √ße≈üitli meslek kurulu≈üu vardƒ±r. Bunlardan bazƒ±larƒ±: Ankara, ƒ∞zmir, ƒ∞zmir, ƒ∞zmir, Eski≈üehir, ƒ∞zmir, Antalya, Diyarbakƒ±r, Samsun, Antalya, ƒ∞zmir,\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        sayesinde dijital uygulamalar daha az enerji t√ºketimine olanak saƒülar. Aslƒ±nda bu, bir bilgisayar tarafƒ±ndan y√∂nlendirilir. Ve neredeyse hi√ß tek bir √∂zelliƒüi yoktur. Eƒüer bilgisayarƒ±nƒ±z bu konuda bir √ßok konuda bilgi sahibi ve yetkin\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.2304)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 00:51:09\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "35510 | 4.1242 | 1.0e-04 | 1.15 | 38.7K | 02:05:17 |  71.0%\n",
            "35520 | 4.0997 | 1.0e-04 | 1.17 | 38.7K | 02:05:19 |  71.0%\n",
            "35530 | 4.3703 | 1.0e-04 | 1.16 | 38.7K | 02:05:21 |  71.1%\n",
            "35540 | 4.2852 | 1.0e-04 | 1.18 | 38.7K | 02:05:22 |  71.1%\n",
            "35550 | 4.3566 | 1.0e-04 | 1.15 | 38.7K | 02:05:24 |  71.1%\n",
            "35560 | 4.3132 | 1.0e-04 | 1.15 | 38.7K | 02:05:26 |  71.1%\n",
            "35570 | 4.4356 | 1.0e-04 | 1.19 | 38.7K | 02:05:28 |  71.1%\n",
            "35580 | 4.1503 | 1.0e-04 | 1.17 | 38.7K | 02:05:29 |  71.2%\n",
            "35590 | 4.1346 | 1.0e-04 | 1.25 | 38.7K | 02:05:31 |  71.2%\n",
            "35600 | 4.5042 | 1.0e-04 | 1.18 | 38.7K | 02:05:33 |  71.2%\n",
            "35610 | 4.3319 | 1.0e-04 | 1.18 | 38.7K | 02:05:34 |  71.2%\n",
            "35620 | 4.2539 | 1.0e-04 | 1.12 | 38.7K | 02:05:36 |  71.2%\n",
            "35630 | 4.3146 | 1.0e-04 | 1.16 | 38.7K | 02:05:38 |  71.3%\n",
            "35640 | 4.2118 | 1.0e-04 | 1.14 | 38.7K | 02:05:40 |  71.3%\n",
            "35650 | 4.4843 | 1.0e-04 | 1.17 | 38.7K | 02:05:41 |  71.3%\n",
            "35660 | 4.3039 | 1.0e-04 | 1.19 | 38.7K | 02:05:43 |  71.3%\n",
            "35670 | 4.7122 | 1.0e-04 | 1.20 | 38.7K | 02:05:45 |  71.3%\n",
            "35680 | 4.3794 | 1.0e-04 | 1.17 | 38.7K | 02:05:46 |  71.4%\n",
            "35690 | 4.2791 | 1.0e-04 | 1.21 | 38.7K | 02:05:48 |  71.4%\n",
            "35700 | 4.2941 | 1.0e-04 | 1.14 | 38.7K | 02:05:50 |  71.4%\n",
            "35710 | 4.2276 | 1.0e-04 | 1.33 | 38.7K | 02:05:52 |  71.4%\n",
            "35720 | 4.3256 | 1.0e-04 | 1.16 | 38.7K | 02:05:53 |  71.4%\n",
            "35730 | 4.1620 | 1.0e-04 | 1.12 | 38.7K | 02:05:55 |  71.5%\n",
            "35740 | 4.1244 | 1.0e-04 | 1.17 | 38.7K | 02:05:57 |  71.5%\n",
            "35750 | 4.3131 | 1.0e-04 | 1.18 | 38.7K | 02:05:58 |  71.5%\n",
            "35760 | 3.9916 | 1.0e-04 | 1.16 | 38.7K | 02:06:00 |  71.5%\n",
            "35770 | 4.2227 | 1.0e-04 | 1.17 | 38.7K | 02:06:02 |  71.5%\n",
            "35780 | 4.4829 | 1.0e-04 | 1.17 | 38.8K | 02:06:04 |  71.6%\n",
            "35790 | 4.3549 | 1.0e-04 | 1.15 | 38.8K | 02:06:05 |  71.6%\n",
            "35800 | 4.2126 | 1.0e-04 | 1.15 | 38.8K | 02:06:07 |  71.6%\n",
            "35810 | 4.2044 | 1.0e-04 | 1.18 | 38.8K | 02:06:09 |  71.6%\n",
            "35820 | 4.0546 | 1.0e-04 | 1.13 | 38.8K | 02:06:10 |  71.6%\n",
            "35830 | 4.2943 | 1.0e-04 | 1.13 | 38.8K | 02:06:12 |  71.7%\n",
            "35840 | 4.1629 | 1.0e-04 | 1.19 | 38.8K | 02:06:14 |  71.7%\n",
            "35850 | 4.3926 | 1.0e-04 | 1.18 | 38.8K | 02:06:16 |  71.7%\n",
            "35860 | 4.1515 | 1.0e-04 | 1.19 | 38.8K | 02:06:17 |  71.7%\n",
            "35870 | 4.4432 | 1.0e-04 | 1.19 | 38.8K | 02:06:19 |  71.7%\n",
            "35880 | 4.3464 | 9.9e-05 | 1.14 | 38.8K | 02:06:21 |  71.8%\n",
            "35890 | 4.4980 | 9.9e-05 | 1.20 | 38.8K | 02:06:22 |  71.8%\n",
            "35900 | 4.3239 | 9.9e-05 | 1.20 | 38.8K | 02:06:24 |  71.8%\n",
            "35910 | 4.1055 | 9.9e-05 | 1.19 | 38.8K | 02:06:26 |  71.8%\n",
            "35920 | 4.5209 | 9.9e-05 | 1.17 | 38.8K | 02:06:28 |  71.8%\n",
            "35930 | 4.4250 | 9.9e-05 | 1.19 | 38.8K | 02:06:29 |  71.9%\n",
            "35940 | 4.6266 | 9.9e-05 | 1.14 | 38.8K | 02:06:31 |  71.9%\n",
            "35950 | 4.3022 | 9.8e-05 | 1.22 | 38.8K | 02:06:33 |  71.9%\n",
            "35960 | 4.2902 | 9.8e-05 | 1.14 | 38.8K | 02:06:34 |  71.9%\n",
            "35970 | 4.2400 | 9.8e-05 | 1.20 | 38.8K | 02:06:36 |  71.9%\n",
            "35980 | 4.3243 | 9.8e-05 | 1.18 | 38.8K | 02:06:38 |  72.0%\n",
            "35990 | 4.2916 | 9.8e-05 | 1.17 | 38.8K | 02:06:40 |  72.0%\n",
            "36000 | 4.3592 | 9.8e-05 | 1.19 | 38.8K | 02:06:41 |  72.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 36000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.2141\n",
            "  Perplexity: 67.63\n",
            "  Train loss (avg): 4.2743\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        nasƒ±l? Karaciƒüer nedir? Karaciƒüer neden olu≈üur? Karaciƒüerin nasƒ±l bir halde olduƒüu, nasƒ±l geli≈ütiƒüi ve nasƒ±l geli≈ütiƒüi hakkƒ±nda bilgi verir. Karaciƒüer nasƒ±l √ßalƒ±≈üƒ±r? Karaciƒüer ve deniz biy\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Ankara'da bulunan OM√ú'de, iki ayrƒ± grup tarafƒ±ndan kurulan ve aralarƒ±nda yakla≈üƒ±k 20 ki≈üinin √ßalƒ±≈ütƒ±ƒüƒ± bir kurulu≈ü olan OM√ú'de, AK Parti ile CHP'nin Meclis'te temsil\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        ile pazarlama, pazarlama, sosyal medya ve satƒ±≈ü ve satƒ±≈ü gibi alanlarda √ßok geni≈ü kapsamlƒ± bir ≈üekilde √ßalƒ±≈üan pazarlama ve tanƒ±tƒ±m platformudur. Ayrƒ±ca dijital pazarlama alanƒ±nda m√º≈üteri portf√∂y√ºne y√∂nelik en yeni teknolojilere ve yatƒ±rƒ±mlara\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.2141)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 00:49:24\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "36010 | 4.2662 | 9.8e-05 | 1.27 | 38.7K | 02:07:04 |  72.0%\n",
            "36020 | 4.4723 | 9.8e-05 | 1.13 | 38.7K | 02:07:05 |  72.0%\n",
            "36030 | 4.4907 | 9.7e-05 | 1.21 | 38.7K | 02:07:07 |  72.1%\n",
            "36040 | 4.2032 | 9.7e-05 | 1.16 | 38.7K | 02:07:09 |  72.1%\n",
            "36050 | 4.0850 | 9.7e-05 | 1.19 | 38.7K | 02:07:10 |  72.1%\n",
            "36060 | 4.2781 | 9.7e-05 | 1.13 | 38.7K | 02:07:12 |  72.1%\n",
            "36070 | 4.3791 | 9.7e-05 | 1.16 | 38.7K | 02:07:14 |  72.1%\n",
            "36080 | 4.2336 | 9.7e-05 | 1.15 | 38.7K | 02:07:16 |  72.2%\n",
            "36090 | 4.1313 | 9.7e-05 | 1.18 | 38.7K | 02:07:17 |  72.2%\n",
            "36100 | 4.0667 | 9.7e-05 | 1.17 | 38.7K | 02:07:19 |  72.2%\n",
            "36110 | 4.0964 | 9.6e-05 | 1.12 | 38.7K | 02:07:21 |  72.2%\n",
            "36120 | 4.4561 | 9.6e-05 | 1.19 | 38.7K | 02:07:22 |  72.2%\n",
            "36130 | 4.1863 | 9.6e-05 | 1.13 | 38.7K | 02:07:24 |  72.3%\n",
            "36140 | 4.3641 | 9.6e-05 | 1.17 | 38.7K | 02:07:26 |  72.3%\n",
            "36150 | 4.1467 | 9.6e-05 | 1.20 | 38.7K | 02:07:28 |  72.3%\n",
            "36160 | 4.2850 | 9.6e-05 | 1.18 | 38.7K | 02:07:29 |  72.3%\n",
            "36170 | 4.4549 | 9.6e-05 | 1.17 | 38.7K | 02:07:31 |  72.3%\n",
            "36180 | 4.4682 | 9.5e-05 | 1.14 | 38.7K | 02:07:33 |  72.4%\n",
            "36190 | 4.0600 | 9.5e-05 | 1.14 | 38.7K | 02:07:34 |  72.4%\n",
            "36200 | 4.2887 | 9.5e-05 | 1.15 | 38.7K | 02:07:36 |  72.4%\n",
            "36210 | 4.3030 | 9.5e-05 | 1.13 | 38.7K | 02:07:38 |  72.4%\n",
            "36220 | 4.3542 | 9.5e-05 | 1.16 | 38.7K | 02:07:40 |  72.4%\n",
            "36230 | 4.4598 | 9.5e-05 | 1.20 | 38.7K | 02:07:41 |  72.5%\n",
            "36240 | 4.2294 | 9.5e-05 | 1.17 | 38.7K | 02:07:43 |  72.5%\n",
            "36250 | 4.1516 | 9.5e-05 | 1.17 | 38.7K | 02:07:45 |  72.5%\n",
            "36260 | 4.3751 | 9.4e-05 | 1.15 | 38.7K | 02:07:46 |  72.5%\n",
            "36270 | 4.2285 | 9.4e-05 | 1.18 | 38.7K | 02:07:48 |  72.5%\n",
            "36280 | 4.3760 | 9.4e-05 | 1.19 | 38.7K | 02:07:50 |  72.6%\n",
            "36290 | 4.0091 | 9.4e-05 | 1.18 | 38.7K | 02:07:52 |  72.6%\n",
            "36300 | 4.5738 | 9.4e-05 | 1.18 | 38.8K | 02:07:53 |  72.6%\n",
            "36310 | 4.2870 | 9.4e-05 | 1.13 | 38.8K | 02:07:55 |  72.6%\n",
            "36320 | 4.3755 | 9.4e-05 | 1.18 | 38.8K | 02:07:57 |  72.6%\n",
            "36330 | 4.2109 | 9.4e-05 | 1.18 | 38.8K | 02:07:58 |  72.7%\n",
            "36340 | 4.2479 | 9.3e-05 | 1.15 | 38.8K | 02:08:00 |  72.7%\n",
            "36350 | 4.0767 | 9.3e-05 | 1.23 | 38.8K | 02:08:02 |  72.7%\n",
            "36360 | 4.0521 | 9.3e-05 | 1.21 | 38.8K | 02:08:04 |  72.7%\n",
            "36370 | 4.3254 | 9.3e-05 | 1.19 | 38.8K | 02:08:05 |  72.7%\n",
            "36380 | 3.9842 | 9.3e-05 | 1.19 | 38.8K | 02:08:07 |  72.8%\n",
            "36390 | 4.2263 | 9.3e-05 | 1.16 | 38.8K | 02:08:09 |  72.8%\n",
            "36400 | 4.0299 | 9.3e-05 | 1.16 | 38.8K | 02:08:10 |  72.8%\n",
            "36410 | 3.9180 | 9.3e-05 | 1.18 | 38.8K | 02:08:12 |  72.8%\n",
            "36420 | 4.2006 | 9.2e-05 | 1.12 | 38.8K | 02:08:14 |  72.8%\n",
            "36430 | 4.7768 | 9.2e-05 | 1.23 | 38.8K | 02:08:16 |  72.9%\n",
            "36440 | 4.3053 | 9.2e-05 | 1.15 | 38.8K | 02:08:17 |  72.9%\n",
            "36450 | 4.2443 | 9.2e-05 | 1.28 | 38.8K | 02:08:19 |  72.9%\n",
            "36460 | 4.2808 | 9.2e-05 | 1.19 | 38.8K | 02:08:21 |  72.9%\n",
            "36470 | 4.2815 | 9.2e-05 | 1.16 | 38.8K | 02:08:22 |  72.9%\n",
            "36480 | 4.1069 | 9.2e-05 | 1.22 | 38.8K | 02:08:24 |  73.0%\n",
            "36490 | 4.0680 | 9.2e-05 | 1.20 | 38.8K | 02:08:26 |  73.0%\n",
            "36500 | 4.2256 | 9.1e-05 | 1.18 | 38.8K | 02:08:28 |  73.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 36500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.2066\n",
            "  Perplexity: 67.13\n",
            "  Train loss (avg): 4.2431\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        par√ßalƒ± ve vah≈üi ormanlarda can verme hareketi, daha sonra t√ºm ormanlar, daha sonra t√ºm ormanlar, daha sonra ise √ßok daha b√ºy√ºk bir ormanda ve daha sonra da uzun yƒ±llardƒ±r var olan orman\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Birg√ºn'de bir araya gelen ve iki √ºlke arasƒ±ndaki dƒ±≈ü ticaret anla≈ümasƒ±nƒ± da i√ßeren, T√ºrkiye, y√ºzde 17'lik bir oranda dƒ±≈ü ticaret hacmiyle ilgili reformlar yapmaya ba≈üladƒ±. Uluslararasƒ± ticaret anla≈ü\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , insanlarƒ±n kafasƒ±nƒ±n kesilmesini √∂nlemek i√ßin daha fazla potansiyel enerji tasarrufu saƒülƒ±yor. 16 ya≈üƒ±ndaki bir √ßocuk, artƒ±k kendi kendine d√º≈ü√ºnmeli ve bunlarƒ± √∂ƒürendikten sonra √∂nce kendi kendine d√º≈ü√ºnmelidir. √á√ºnk√º, bili≈üsel ve\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.2066)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 00:47:38\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "36510 | 4.3598 | 9.1e-05 | 1.23 | 38.7K | 02:08:50 |  73.0%\n",
            "36520 | 4.5252 | 9.1e-05 | 1.23 | 38.7K | 02:08:52 |  73.0%\n",
            "36530 | 4.2525 | 9.1e-05 | 1.18 | 38.7K | 02:08:53 |  73.1%\n",
            "36540 | 3.9535 | 9.1e-05 | 1.17 | 38.7K | 02:08:55 |  73.1%\n",
            "36550 | 4.2324 | 9.1e-05 | 1.17 | 38.7K | 02:08:57 |  73.1%\n",
            "36560 | 4.4490 | 9.1e-05 | 1.16 | 38.7K | 02:08:58 |  73.1%\n",
            "36570 | 4.4160 | 9.1e-05 | 1.14 | 38.7K | 02:09:00 |  73.1%\n",
            "36580 | 4.0199 | 9.0e-05 | 1.26 | 38.7K | 02:09:02 |  73.2%\n",
            "36590 | 3.9843 | 9.0e-05 | 1.18 | 38.7K | 02:09:04 |  73.2%\n",
            "36600 | 4.0816 | 9.0e-05 | 1.28 | 38.7K | 02:09:05 |  73.2%\n",
            "36610 | 4.2973 | 9.0e-05 | 1.26 | 38.7K | 02:09:07 |  73.2%\n",
            "36620 | 4.2443 | 9.0e-05 | 1.19 | 38.7K | 02:09:09 |  73.2%\n",
            "36630 | 4.3423 | 9.0e-05 | 1.18 | 38.7K | 02:09:10 |  73.3%\n",
            "36640 | 4.2326 | 9.0e-05 | 1.18 | 38.7K | 02:09:12 |  73.3%\n",
            "36650 | 4.1439 | 9.0e-05 | 1.19 | 38.7K | 02:09:14 |  73.3%\n",
            "36660 | 4.3015 | 8.9e-05 | 1.16 | 38.7K | 02:09:16 |  73.3%\n",
            "36670 | 4.5912 | 8.9e-05 | 1.17 | 38.7K | 02:09:17 |  73.3%\n",
            "36680 | 4.3475 | 8.9e-05 | 1.18 | 38.7K | 02:09:19 |  73.4%\n",
            "36690 | 4.0860 | 8.9e-05 | 1.15 | 38.7K | 02:09:21 |  73.4%\n",
            "36700 | 4.3372 | 8.9e-05 | 1.15 | 38.7K | 02:09:22 |  73.4%\n",
            "36710 | 4.1087 | 8.9e-05 | 1.31 | 38.7K | 02:09:24 |  73.4%\n",
            "36720 | 4.2719 | 8.9e-05 | 1.16 | 38.7K | 02:09:26 |  73.4%\n",
            "36730 | 4.6025 | 8.9e-05 | 1.16 | 38.7K | 02:09:28 |  73.5%\n",
            "36740 | 4.0786 | 8.8e-05 | 1.18 | 38.7K | 02:09:29 |  73.5%\n",
            "36750 | 4.4705 | 8.8e-05 | inf | 38.7K | 02:09:31 |  73.5%\n",
            "36760 | 4.3805 | 8.8e-05 | 1.25 | 38.7K | 02:09:33 |  73.5%\n",
            "36770 | 4.2332 | 8.8e-05 | 1.19 | 38.7K | 02:09:34 |  73.5%\n",
            "36780 | 4.0695 | 8.8e-05 | 1.13 | 38.7K | 02:09:36 |  73.6%\n",
            "36790 | 4.2221 | 8.8e-05 | 1.17 | 38.7K | 02:09:38 |  73.6%\n",
            "36800 | 4.2470 | 8.8e-05 | 1.17 | 38.7K | 02:09:40 |  73.6%\n",
            "36810 | 4.1916 | 8.8e-05 | 1.23 | 38.8K | 02:09:41 |  73.6%\n",
            "36820 | 3.9965 | 8.7e-05 | 1.16 | 38.8K | 02:09:43 |  73.6%\n",
            "36830 | 4.2609 | 8.7e-05 | 1.19 | 38.8K | 02:09:45 |  73.7%\n",
            "36840 | 4.2983 | 8.7e-05 | 1.21 | 38.8K | 02:09:46 |  73.7%\n",
            "36850 | 4.2930 | 8.7e-05 | 1.22 | 38.8K | 02:09:48 |  73.7%\n",
            "36860 | 4.2951 | 8.7e-05 | 1.17 | 38.8K | 02:09:50 |  73.7%\n",
            "36870 | 4.2694 | 8.7e-05 | 1.20 | 38.8K | 02:09:52 |  73.7%\n",
            "36880 | 4.3169 | 8.7e-05 | 1.19 | 38.8K | 02:09:53 |  73.8%\n",
            "36890 | 4.5107 | 8.7e-05 | 1.25 | 38.8K | 02:09:55 |  73.8%\n",
            "36900 | 4.2465 | 8.6e-05 | 1.22 | 38.8K | 02:09:57 |  73.8%\n",
            "36910 | 4.4554 | 8.6e-05 | 1.19 | 38.8K | 02:09:58 |  73.8%\n",
            "36920 | 4.1332 | 8.6e-05 | 1.18 | 38.8K | 02:10:00 |  73.8%\n",
            "36930 | 4.2936 | 8.6e-05 | 1.17 | 38.8K | 02:10:02 |  73.9%\n",
            "36940 | 4.3670 | 8.6e-05 | 1.17 | 38.8K | 02:10:04 |  73.9%\n",
            "36950 | 4.4245 | 8.6e-05 | 1.16 | 38.8K | 02:10:05 |  73.9%\n",
            "36960 | 4.4462 | 8.6e-05 | 1.16 | 38.8K | 02:10:07 |  73.9%\n",
            "36970 | 4.3342 | 8.6e-05 | 1.16 | 38.8K | 02:10:09 |  73.9%\n",
            "36980 | 4.2840 | 8.5e-05 | 1.22 | 38.8K | 02:10:10 |  74.0%\n",
            "36990 | 4.4428 | 8.5e-05 | 1.18 | 38.8K | 02:10:12 |  74.0%\n",
            "37000 | 4.2466 | 8.5e-05 | 1.31 | 38.8K | 02:10:14 |  74.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 37000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.2072\n",
            "  Perplexity: 67.17\n",
            "  Train loss (avg): 4.2809\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        kapalƒ±yken, bir anda baktƒ±k√ßa, hava iyice soƒüumaya ba≈üladƒ±. G√ºne≈ü Sistemini a√ßƒ±n, ona doƒüru s√ºr√ºkleyin. Kendinize iyi bakƒ±n, bir iyi g√ºn ge√ßireceksiniz. Bir hata yapmƒ±≈ü gibi g√∂r√ºnmeyin\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        ƒ∞stanbul'da kalan T√ºrk Milli Birliƒüi, T√ºrkiye'nin g√ºneyinde hem ekonomik hem de politik olarak barƒ±nan ve uluslararasƒ± alanda faaliyet g√∂steren yabancƒ± sermayenin faaliyetlerine devam ediyor. AB, T√ºrkiye'nin kuzeyinde de dƒ±≈ü\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        sayesinde, beyin ve sinir sistemlerindeki performansa paralel olarak, insan sinir sistemi savunma sistemlerindeki algƒ±yƒ± ifade edebilmektedir. Sonu√ß olarak, beyinde sinir sisteminin ger√ßek d√º≈ü√ºnme yeteneƒüi, beynin enerji ve sinir sistem\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 00:45:51\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "37010 | 4.0325 | 8.5e-05 | 1.15 | 38.7K | 02:10:33 |  74.0%\n",
            "37020 | 4.4097 | 8.5e-05 | 1.16 | 38.7K | 02:10:35 |  74.0%\n",
            "37030 | 3.9336 | 8.5e-05 | 1.27 | 38.7K | 02:10:36 |  74.1%\n",
            "37040 | 4.0194 | 8.5e-05 | 1.23 | 38.7K | 02:10:38 |  74.1%\n",
            "37050 | 4.1889 | 8.5e-05 | 1.20 | 38.7K | 02:10:40 |  74.1%\n",
            "37060 | 4.2664 | 8.4e-05 | 1.20 | 38.7K | 02:10:41 |  74.1%\n",
            "37070 | 4.1409 | 8.4e-05 | 1.18 | 38.7K | 02:10:43 |  74.1%\n",
            "37080 | 4.5291 | 8.4e-05 | 1.22 | 38.7K | 02:10:45 |  74.2%\n",
            "37090 | 4.1710 | 8.4e-05 | 1.17 | 38.7K | 02:10:47 |  74.2%\n",
            "37100 | 4.1366 | 8.4e-05 | 1.15 | 38.7K | 02:10:48 |  74.2%\n",
            "37110 | 4.4840 | 8.4e-05 | 1.20 | 38.7K | 02:10:50 |  74.2%\n",
            "37120 | 4.2495 | 8.4e-05 | 1.16 | 38.7K | 02:10:52 |  74.2%\n",
            "37130 | 4.2995 | 8.4e-05 | 1.17 | 38.7K | 02:10:53 |  74.3%\n",
            "37140 | 4.4617 | 8.3e-05 | 1.24 | 38.7K | 02:10:55 |  74.3%\n",
            "37150 | 4.3654 | 8.3e-05 | 1.17 | 38.7K | 02:10:57 |  74.3%\n",
            "37160 | 4.4197 | 8.3e-05 | 1.16 | 38.7K | 02:10:58 |  74.3%\n",
            "37170 | 4.2719 | 8.3e-05 | 1.17 | 38.7K | 02:11:00 |  74.3%\n",
            "37180 | 4.3227 | 8.3e-05 | 1.20 | 38.7K | 02:11:02 |  74.4%\n",
            "37190 | 4.2102 | 8.3e-05 | 1.17 | 38.7K | 02:11:04 |  74.4%\n",
            "37200 | 4.1567 | 8.3e-05 | 1.22 | 38.7K | 02:11:05 |  74.4%\n",
            "37210 | 4.2558 | 8.3e-05 | 1.19 | 38.7K | 02:11:07 |  74.4%\n",
            "37220 | 4.1483 | 8.2e-05 | 1.17 | 38.7K | 02:11:09 |  74.4%\n",
            "37230 | 4.1196 | 8.2e-05 | 1.15 | 38.7K | 02:11:10 |  74.5%\n",
            "37240 | 4.1315 | 8.2e-05 | 1.22 | 38.8K | 02:11:12 |  74.5%\n",
            "37250 | 3.8368 | 8.2e-05 | 1.28 | 38.8K | 02:11:14 |  74.5%\n",
            "37260 | 4.3260 | 8.2e-05 | 1.29 | 38.8K | 02:11:16 |  74.5%\n",
            "37270 | 4.3471 | 8.2e-05 | 1.17 | 38.8K | 02:11:17 |  74.5%\n",
            "37280 | 4.1632 | 8.2e-05 | 1.15 | 38.8K | 02:11:19 |  74.6%\n",
            "37290 | 4.0192 | 8.2e-05 | 1.21 | 38.8K | 02:11:21 |  74.6%\n",
            "37300 | 3.9811 | 8.2e-05 | 1.18 | 38.8K | 02:11:22 |  74.6%\n",
            "37310 | 4.4077 | 8.1e-05 | 1.15 | 38.8K | 02:11:24 |  74.6%\n",
            "37320 | 4.4213 | 8.1e-05 | 1.20 | 38.8K | 02:11:26 |  74.6%\n",
            "37330 | 4.0866 | 8.1e-05 | 1.26 | 38.8K | 02:11:28 |  74.7%\n",
            "37340 | 3.9554 | 8.1e-05 | 1.16 | 38.8K | 02:11:29 |  74.7%\n",
            "37350 | 4.1424 | 8.1e-05 | 1.19 | 38.8K | 02:11:31 |  74.7%\n",
            "37360 | 4.2086 | 8.1e-05 | 1.24 | 38.8K | 02:11:33 |  74.7%\n",
            "37370 | 4.2031 | 8.1e-05 | 1.14 | 38.8K | 02:11:34 |  74.7%\n",
            "37380 | 4.3659 | 8.1e-05 | 1.18 | 38.8K | 02:11:36 |  74.8%\n",
            "37390 | 4.3849 | 8.0e-05 | 1.24 | 38.8K | 02:11:38 |  74.8%\n",
            "37400 | 4.3341 | 8.0e-05 | 1.23 | 38.8K | 02:11:40 |  74.8%\n",
            "37410 | 4.4023 | 8.0e-05 | 1.16 | 38.8K | 02:11:41 |  74.8%\n",
            "37420 | 3.8670 | 8.0e-05 | 1.21 | 38.8K | 02:11:43 |  74.8%\n",
            "37430 | 4.3510 | 8.0e-05 | 1.16 | 38.8K | 02:11:45 |  74.9%\n",
            "37440 | 4.4033 | 8.0e-05 | 1.16 | 38.8K | 02:11:46 |  74.9%\n",
            "37450 | 4.4802 | 8.0e-05 | 1.16 | 38.8K | 02:11:48 |  74.9%\n",
            "37460 | 4.3934 | 8.0e-05 | 1.21 | 38.8K | 02:11:50 |  74.9%\n",
            "37470 | 4.3294 | 7.9e-05 | 1.17 | 38.8K | 02:11:51 |  74.9%\n",
            "37480 | 4.2171 | 7.9e-05 | 1.16 | 38.8K | 02:11:53 |  75.0%\n",
            "37490 | 4.1612 | 7.9e-05 | 1.18 | 38.8K | 02:11:55 |  75.0%\n",
            "37500 | 4.2088 | 7.9e-05 | 1.21 | 38.8K | 02:11:57 |  75.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 37500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1663\n",
            "  Perplexity: 64.48\n",
            "  Train loss (avg): 4.2537\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        durumu tahminleri, hava durumu tahminleri, hava durumu tahminleri ve hava durumu tahminleri olarak bilinmektedir. Eƒüer hava durumu tahminleri tahminleri ile birlikte hava durumu tahminleri tahminleri ile birlikte yer almak\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        olan ƒ∞stanbul'a uzaklƒ±ƒüƒ± 5 km. mesafededir. Ankara'nƒ±n en y√ºksek noktasƒ± olan Ankara, aynƒ± zamanda √ßok daha g√ºzel bir √ßevre kampƒ± ve de bir eƒüitim merkezidir. Ankara'nƒ±n\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        sayesinde de robotlarƒ±n ger√ßek zamanlƒ± bilgi ve deneyimlerini elde edebilmesi, √∂zel bilgisayarlardan bilgi edinilmesi ve ger√ßek zamanlƒ± bilgi edinme gibi basit ve hƒ±zlƒ± bilgi teknolojilerini geli≈ütirmek m√ºmk√ºn. Bu baƒülamda robotlarƒ±n ma\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.1663)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.72\n",
            "     ETA: 00:44:05\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "37510 | 4.1389 | 7.9e-05 | 1.19 | 38.7K | 02:12:19 |  75.0%\n",
            "37520 | 4.4416 | 7.9e-05 | 1.16 | 38.7K | 02:12:21 |  75.0%\n",
            "37530 | 4.2162 | 7.9e-05 | 1.19 | 38.7K | 02:12:22 |  75.1%\n",
            "37540 | 4.5333 | 7.9e-05 | 1.19 | 38.7K | 02:12:24 |  75.1%\n",
            "37550 | 4.1015 | 7.9e-05 | 1.18 | 38.7K | 02:12:26 |  75.1%\n",
            "37560 | 4.0577 | 7.8e-05 | 1.16 | 38.7K | 02:12:28 |  75.1%\n",
            "37570 | 4.1224 | 7.8e-05 | 1.24 | 38.7K | 02:12:29 |  75.1%\n",
            "37580 | 4.1679 | 7.8e-05 | 1.20 | 38.7K | 02:12:31 |  75.2%\n",
            "37590 | 4.3557 | 7.8e-05 | 1.16 | 38.7K | 02:12:33 |  75.2%\n",
            "37600 | 4.3886 | 7.8e-05 | 1.20 | 38.7K | 02:12:34 |  75.2%\n",
            "37610 | 4.2917 | 7.8e-05 | 1.20 | 38.7K | 02:12:36 |  75.2%\n",
            "37620 | 4.3850 | 7.8e-05 | 1.23 | 38.7K | 02:12:38 |  75.2%\n",
            "37630 | 4.0354 | 7.8e-05 | 1.18 | 38.7K | 02:12:40 |  75.3%\n",
            "37640 | 3.9313 | 7.7e-05 | 1.23 | 38.7K | 02:12:41 |  75.3%\n",
            "37650 | 4.1104 | 7.7e-05 | 1.21 | 38.7K | 02:12:43 |  75.3%\n",
            "37660 | 4.0890 | 7.7e-05 | 1.17 | 38.7K | 02:12:45 |  75.3%\n",
            "37670 | 4.1311 | 7.7e-05 | 1.20 | 38.7K | 02:12:46 |  75.3%\n",
            "37680 | 4.2156 | 7.7e-05 | 1.15 | 38.7K | 02:12:48 |  75.4%\n",
            "37690 | 4.1567 | 7.7e-05 | 1.21 | 38.7K | 02:12:50 |  75.4%\n",
            "37700 | 3.9444 | 7.7e-05 | 1.13 | 38.7K | 02:12:52 |  75.4%\n",
            "37710 | 4.1229 | 7.7e-05 | 1.19 | 38.7K | 02:12:53 |  75.4%\n",
            "37720 | 4.3967 | 7.7e-05 | 1.27 | 38.7K | 02:12:55 |  75.4%\n",
            "37730 | 4.1613 | 7.6e-05 | 1.25 | 38.7K | 02:12:57 |  75.5%\n",
            "37740 | 4.2351 | 7.6e-05 | 1.18 | 38.7K | 02:12:58 |  75.5%\n",
            "37750 | 4.2165 | 7.6e-05 | 1.14 | 38.7K | 02:13:00 |  75.5%\n",
            "37760 | 4.1993 | 7.6e-05 | 1.17 | 38.8K | 02:13:02 |  75.5%\n",
            "37770 | 4.2046 | 7.6e-05 | 1.28 | 38.8K | 02:13:04 |  75.5%\n",
            "37780 | 4.2581 | 7.6e-05 | 1.17 | 38.8K | 02:13:05 |  75.6%\n",
            "37790 | 4.0751 | 7.6e-05 | 1.17 | 38.8K | 02:13:07 |  75.6%\n",
            "37800 | 3.9955 | 7.6e-05 | 1.19 | 38.8K | 02:13:09 |  75.6%\n",
            "37810 | 4.5040 | 7.5e-05 | 1.17 | 38.8K | 02:13:10 |  75.6%\n",
            "37820 | 3.9632 | 7.5e-05 | 1.19 | 38.8K | 02:13:12 |  75.6%\n",
            "37830 | 4.3175 | 7.5e-05 | 1.18 | 38.8K | 02:13:14 |  75.7%\n",
            "37840 | 4.1862 | 7.5e-05 | 1.18 | 38.8K | 02:13:16 |  75.7%\n",
            "37850 | 4.2748 | 7.5e-05 | 1.20 | 38.8K | 02:13:17 |  75.7%\n",
            "37860 | 4.4077 | 7.5e-05 | 1.16 | 38.8K | 02:13:19 |  75.7%\n",
            "37870 | 4.4141 | 7.5e-05 | 1.20 | 38.8K | 02:13:21 |  75.7%\n",
            "37880 | 4.2357 | 7.5e-05 | 1.19 | 38.8K | 02:13:22 |  75.8%\n",
            "37890 | 4.5800 | 7.5e-05 | 1.21 | 38.8K | 02:13:24 |  75.8%\n",
            "37900 | 4.4861 | 7.4e-05 | 1.19 | 38.8K | 02:13:26 |  75.8%\n",
            "37910 | 4.5167 | 7.4e-05 | 1.18 | 38.8K | 02:13:28 |  75.8%\n",
            "37920 | 4.4767 | 7.4e-05 | 1.23 | 38.8K | 02:13:29 |  75.8%\n",
            "37930 | 4.1059 | 7.4e-05 | 1.23 | 38.8K | 02:13:31 |  75.9%\n",
            "37940 | 4.1453 | 7.4e-05 | 1.17 | 38.8K | 02:13:33 |  75.9%\n",
            "37950 | 3.8704 | 7.4e-05 | 1.24 | 38.8K | 02:13:34 |  75.9%\n",
            "37960 | 4.0663 | 7.4e-05 | 1.15 | 38.8K | 02:13:36 |  75.9%\n",
            "37970 | 4.2817 | 7.4e-05 | 1.20 | 38.8K | 02:13:38 |  75.9%\n",
            "37980 | 4.1765 | 7.3e-05 | 1.18 | 38.8K | 02:13:40 |  76.0%\n",
            "37990 | 3.9950 | 7.3e-05 | 1.15 | 38.8K | 02:13:41 |  76.0%\n",
            "38000 | 4.3859 | 7.3e-05 | 1.16 | 38.8K | 02:13:43 |  76.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 38000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1769\n",
            "  Perplexity: 65.16\n",
            "  Train loss (avg): 4.2415\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        sƒ±caklƒ±klarƒ±nda genel olarak 35-45 derecelik bir yaƒüƒ±≈ü var. Bu yaƒüƒ±≈ülarƒ±n √ßok d√º≈ü√ºk olduƒüu bir d√∂nemde olan yaƒüƒ±≈ülar, soƒüuk havalarda bile hava sƒ±caklƒ±ƒüƒ± azaltƒ±yor. Yeni kurulan okullara, yeni yapƒ±lan okul\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Ankara'da yerel televizyonlarda ve gazetelerde siyaset yapan gazeteci ve gazeteci Ali T√ºlay'ƒ±n \"Ben b√∂yle bir ≈üey yapabileceƒüimi sanmƒ±yorum. √á√ºnk√º bu durum T√ºrkiye'nin geleceƒüini tehlikeye atƒ±yor. √á√ºnk√º\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        sayesinde, robotlar, robotlarƒ±n zarar g√∂rmesini engelliyor. Arƒ±zalƒ± robotlar robotlara nasƒ±l bakƒ±lƒ±yor? Robotlarƒ±n yapay zekadan nasƒ±l etkilendiƒüi ve robotlarƒ±n yapay zekayla nasƒ±l deƒüi≈ütir\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:42:19\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "38010 | 4.2291 | 7.3e-05 | 1.16 | 38.7K | 02:14:02 |  76.0%\n",
            "38020 | 4.1455 | 7.3e-05 | 1.22 | 38.7K | 02:14:04 |  76.0%\n",
            "38030 | 4.5168 | 7.3e-05 | 1.18 | 38.7K | 02:14:05 |  76.1%\n",
            "38040 | 4.3807 | 7.3e-05 | 1.19 | 38.7K | 02:14:07 |  76.1%\n",
            "38050 | 3.9217 | 7.3e-05 | 1.17 | 38.7K | 02:14:09 |  76.1%\n",
            "38060 | 4.4206 | 7.3e-05 | 1.19 | 38.7K | 02:14:10 |  76.1%\n",
            "38070 | 4.3997 | 7.2e-05 | 1.24 | 38.7K | 02:14:12 |  76.1%\n",
            "38080 | 4.0949 | 7.2e-05 | 1.20 | 38.7K | 02:14:14 |  76.2%\n",
            "38090 | 3.8573 | 7.2e-05 | 1.19 | 38.7K | 02:14:16 |  76.2%\n",
            "38100 | 4.1233 | 7.2e-05 | 1.19 | 38.7K | 02:14:17 |  76.2%\n",
            "38110 | 4.2916 | 7.2e-05 | 1.16 | 38.7K | 02:14:19 |  76.2%\n",
            "38120 | 4.4043 | 7.2e-05 | 1.16 | 38.7K | 02:14:21 |  76.2%\n",
            "38130 | 4.3096 | 7.2e-05 | 1.16 | 38.7K | 02:14:22 |  76.3%\n",
            "38140 | 4.3352 | 7.2e-05 | 1.19 | 38.7K | 02:14:24 |  76.3%\n",
            "38150 | 4.2909 | 7.2e-05 | 1.25 | 38.7K | 02:14:26 |  76.3%\n",
            "38160 | 4.1633 | 7.1e-05 | 1.15 | 38.7K | 02:14:28 |  76.3%\n",
            "38170 | 4.0171 | 7.1e-05 | 1.19 | 38.7K | 02:14:29 |  76.3%\n",
            "38180 | 3.8009 | 7.1e-05 | 1.20 | 38.7K | 02:14:31 |  76.4%\n",
            "38190 | 4.3456 | 7.1e-05 | 1.21 | 38.8K | 02:14:33 |  76.4%\n",
            "38200 | 4.8255 | 7.1e-05 | 1.24 | 38.8K | 02:14:34 |  76.4%\n",
            "38210 | 4.1749 | 7.1e-05 | 1.25 | 38.8K | 02:14:36 |  76.4%\n",
            "38220 | 4.3223 | 7.1e-05 | 1.20 | 38.8K | 02:14:38 |  76.4%\n",
            "38230 | 4.0079 | 7.1e-05 | 1.22 | 38.8K | 02:14:40 |  76.5%\n",
            "38240 | 4.3196 | 7.0e-05 | 1.16 | 38.8K | 02:14:41 |  76.5%\n",
            "38250 | 4.3987 | 7.0e-05 | 1.22 | 38.8K | 02:14:43 |  76.5%\n",
            "38260 | 4.3599 | 7.0e-05 | 1.19 | 38.8K | 02:14:45 |  76.5%\n",
            "38270 | 3.8963 | 7.0e-05 | 1.14 | 38.8K | 02:14:46 |  76.5%\n",
            "38280 | 4.0319 | 7.0e-05 | 1.22 | 38.8K | 02:14:48 |  76.6%\n",
            "38290 | 4.1944 | 7.0e-05 | 1.18 | 38.8K | 02:14:50 |  76.6%\n",
            "38300 | 4.1913 | 7.0e-05 | 1.22 | 38.8K | 02:14:52 |  76.6%\n",
            "38310 | 4.2334 | 7.0e-05 | 1.16 | 38.8K | 02:14:53 |  76.6%\n",
            "38320 | 4.4139 | 7.0e-05 | 1.18 | 38.8K | 02:14:55 |  76.6%\n",
            "38330 | 4.1055 | 6.9e-05 | 1.21 | 38.8K | 02:14:57 |  76.7%\n",
            "38340 | 4.2749 | 6.9e-05 | 1.23 | 38.8K | 02:14:58 |  76.7%\n",
            "38350 | 4.2399 | 6.9e-05 | 1.19 | 38.8K | 02:15:00 |  76.7%\n",
            "38360 | 4.1568 | 6.9e-05 | 1.19 | 38.8K | 02:15:02 |  76.7%\n",
            "38370 | 4.1469 | 6.9e-05 | 1.17 | 38.8K | 02:15:04 |  76.7%\n",
            "38380 | 4.3690 | 6.9e-05 | 1.16 | 38.8K | 02:15:05 |  76.8%\n",
            "38390 | 3.6167 | 6.9e-05 | 1.18 | 38.8K | 02:15:07 |  76.8%\n",
            "38400 | 4.1355 | 6.9e-05 | 1.17 | 38.8K | 02:15:09 |  76.8%\n",
            "38410 | 4.3570 | 6.9e-05 | 1.19 | 38.8K | 02:15:10 |  76.8%\n",
            "38420 | 4.2507 | 6.8e-05 | 1.16 | 38.8K | 02:15:12 |  76.8%\n",
            "38430 | 4.4346 | 6.8e-05 | 1.22 | 38.8K | 02:15:14 |  76.9%\n",
            "38440 | 4.4405 | 6.8e-05 | 1.23 | 38.8K | 02:15:16 |  76.9%\n",
            "38450 | 4.1330 | 6.8e-05 | 1.17 | 38.8K | 02:15:17 |  76.9%\n",
            "38460 | 4.0688 | 6.8e-05 | 1.19 | 38.8K | 02:15:19 |  76.9%\n",
            "38470 | 4.1781 | 6.8e-05 | 1.19 | 38.8K | 02:15:21 |  76.9%\n",
            "38480 | 4.2970 | 6.8e-05 | 1.20 | 38.8K | 02:15:22 |  77.0%\n",
            "38490 | 4.3022 | 6.8e-05 | 1.21 | 38.8K | 02:15:24 |  77.0%\n",
            "38500 | 4.3373 | 6.8e-05 | 1.17 | 38.8K | 02:15:26 |  77.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 38500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1586\n",
            "  Perplexity: 63.98\n",
            "  Train loss (avg): 4.2329\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        sƒ±caklƒ±ƒüƒ±nƒ±n daha y√ºksek olduƒüu ve nem oranƒ±nƒ±n da y√ºksek olduƒüu, daha y√ºksek nem oranƒ±na sahip bir yaƒümur yaƒüƒ±na sahip olduƒüundan her birinizin ƒ±sƒ±nƒ±n d√º≈ü√ºk olmasƒ± m√ºmk√ºn. Hava sƒ±caklƒ±ƒüƒ±nƒ±n ise √ßok y√ºksek olduƒüu,\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        olan ƒ∞stanbul'un en kalabalƒ±k ve en kalabalƒ±k ≈üehri olan ƒ∞stanbul'da, her yƒ±l d√ºnyanƒ±n d√∂rt bir yanƒ±ndan bir√ßok √ºlkeye bu beldelerin tatil merkezi olan ƒ∞stanbul'un en kalabalƒ±k ≈üehri olan ƒ∞stanbul'un\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        g√ºn√ºm√ºzde son derece pop√ºler hale geldi. Uzun yƒ±llar yƒ±llar √∂nce inovatif projeler √ºreten ABD‚Äôde, Michael Sidney‚Äônin geli≈ütirdiƒüi bir yapay zeka teknolojisi sayesinde yapay zekanƒ±n bir araya gelmesi ve yapay\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.1586)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:40:33\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "38510 | 4.1411 | 6.7e-05 | 1.17 | 38.7K | 02:15:48 |  77.0%\n",
            "38520 | 3.7439 | 6.7e-05 | 1.24 | 38.7K | 02:15:50 |  77.0%\n",
            "38530 | 4.2081 | 6.7e-05 | 1.24 | 38.7K | 02:15:52 |  77.1%\n",
            "38540 | 4.4207 | 6.7e-05 | 1.20 | 38.7K | 02:15:53 |  77.1%\n",
            "38550 | 3.9585 | 6.7e-05 | 1.19 | 38.7K | 02:15:55 |  77.1%\n",
            "38560 | 4.2214 | 6.7e-05 | 1.17 | 38.7K | 02:15:57 |  77.1%\n",
            "38570 | 4.3533 | 6.7e-05 | 1.21 | 38.7K | 02:15:58 |  77.1%\n",
            "38580 | 3.9130 | 6.7e-05 | 1.24 | 38.7K | 02:16:00 |  77.2%\n",
            "38590 | 4.4643 | 6.7e-05 | 1.19 | 38.7K | 02:16:02 |  77.2%\n",
            "38600 | 4.2973 | 6.6e-05 | 1.21 | 38.7K | 02:16:04 |  77.2%\n",
            "38610 | 4.5772 | 6.6e-05 | 1.20 | 38.7K | 02:16:05 |  77.2%\n",
            "38620 | 4.0665 | 6.6e-05 | 1.18 | 38.7K | 02:16:07 |  77.2%\n",
            "38630 | 4.0145 | 6.6e-05 | 1.24 | 38.7K | 02:16:09 |  77.3%\n",
            "38640 | 4.3917 | 6.6e-05 | 1.17 | 38.7K | 02:16:10 |  77.3%\n",
            "38650 | 3.9702 | 6.6e-05 | 1.24 | 38.7K | 02:16:12 |  77.3%\n",
            "38660 | 3.9110 | 6.6e-05 | 1.17 | 38.7K | 02:16:14 |  77.3%\n",
            "38670 | 4.2695 | 6.6e-05 | 1.29 | 38.7K | 02:16:16 |  77.3%\n",
            "38680 | 4.0487 | 6.6e-05 | 1.21 | 38.7K | 02:16:17 |  77.4%\n",
            "38690 | 4.1782 | 6.5e-05 | 1.16 | 38.7K | 02:16:19 |  77.4%\n",
            "38700 | 4.1159 | 6.5e-05 | 1.20 | 38.8K | 02:16:21 |  77.4%\n",
            "38710 | 4.1905 | 6.5e-05 | 1.19 | 38.8K | 02:16:22 |  77.4%\n",
            "38720 | 4.5785 | 6.5e-05 | 1.21 | 38.8K | 02:16:24 |  77.4%\n",
            "38730 | 4.0759 | 6.5e-05 | 1.22 | 38.8K | 02:16:26 |  77.5%\n",
            "38740 | 4.1816 | 6.5e-05 | 1.22 | 38.8K | 02:16:28 |  77.5%\n",
            "38750 | 3.8759 | 6.5e-05 | 1.18 | 38.8K | 02:16:29 |  77.5%\n",
            "38760 | 4.6185 | 6.5e-05 | 1.14 | 38.8K | 02:16:31 |  77.5%\n",
            "38770 | 4.4700 | 6.5e-05 | 1.16 | 38.8K | 02:16:33 |  77.5%\n",
            "38780 | 4.3039 | 6.4e-05 | 1.19 | 38.8K | 02:16:34 |  77.6%\n",
            "38790 | 4.1278 | 6.4e-05 | 1.19 | 38.8K | 02:16:36 |  77.6%\n",
            "38800 | 4.1755 | 6.4e-05 | 1.20 | 38.8K | 02:16:38 |  77.6%\n",
            "38810 | 4.3870 | 6.4e-05 | 1.18 | 38.8K | 02:16:40 |  77.6%\n",
            "38820 | 4.3073 | 6.4e-05 | 1.20 | 38.8K | 02:16:41 |  77.6%\n",
            "38830 | 4.2135 | 6.4e-05 | 1.16 | 38.8K | 02:16:43 |  77.7%\n",
            "38840 | 3.9586 | 6.4e-05 | 1.15 | 38.8K | 02:16:45 |  77.7%\n",
            "38850 | 4.3094 | 6.4e-05 | 1.22 | 38.8K | 02:16:46 |  77.7%\n",
            "38860 | 3.9428 | 6.4e-05 | 1.24 | 38.8K | 02:16:48 |  77.7%\n",
            "38870 | 4.1995 | 6.3e-05 | 1.16 | 38.8K | 02:16:50 |  77.7%\n",
            "38880 | 3.9542 | 6.3e-05 | 1.41 | 38.8K | 02:16:52 |  77.8%\n",
            "38890 | 4.2427 | 6.3e-05 | 1.21 | 38.8K | 02:16:53 |  77.8%\n",
            "38900 | 4.2110 | 6.3e-05 | 1.18 | 38.8K | 02:16:55 |  77.8%\n",
            "38910 | 3.9752 | 6.3e-05 | 1.16 | 38.8K | 02:16:57 |  77.8%\n",
            "38920 | 4.1546 | 6.3e-05 | 1.29 | 38.8K | 02:16:58 |  77.8%\n",
            "38930 | 4.3865 | 6.3e-05 | 1.15 | 38.8K | 02:17:00 |  77.9%\n",
            "38940 | 3.7982 | 6.3e-05 | 1.18 | 38.8K | 02:17:02 |  77.9%\n",
            "38950 | 4.3748 | 6.3e-05 | 1.16 | 38.8K | 02:17:04 |  77.9%\n",
            "38960 | 4.3201 | 6.2e-05 | 1.19 | 38.8K | 02:17:05 |  77.9%\n",
            "38970 | 4.2703 | 6.2e-05 | 1.21 | 38.8K | 02:17:07 |  77.9%\n",
            "38980 | 4.2269 | 6.2e-05 | 1.15 | 38.8K | 02:17:09 |  78.0%\n",
            "38990 | 4.0315 | 6.2e-05 | 1.19 | 38.8K | 02:17:10 |  78.0%\n",
            "39000 | 4.2160 | 6.2e-05 | 1.23 | 38.8K | 02:17:12 |  78.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 39000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1749\n",
            "  Perplexity: 65.03\n",
            "  Train loss (avg): 4.2228\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        √ßok sƒ±cak, dƒ±≈üarƒ±da her yerde. B√∂yle g√ºzel i≈üler yapmak i√ßin uƒüra≈üƒ±p duruyorum. Yaptƒ±ƒüƒ±m bu g√ºzel ≈üeyleri √ßok seviyorum. Yaptƒ±ƒüƒ±m bu g√ºzel i≈üler i√ßin √ßok mutluyum. Umarƒ±m bu g√ºzel i≈üler i√ßin g√ºzel\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        olarak nitelendirdiƒüi bu ≈üehir, bizim en b√ºy√ºk ≈üehir, bizim en b√ºy√ºk ≈üehir. √á√ºnk√º ≈üehrin en b√ºy√ºk ≈üehri. Bu ≈üehir aslƒ±nda bir meydan. D√ºnyanƒ±n en b√ºy√ºk ≈üehri olarak kar≈üƒ±mƒ±za √ßƒ±kƒ±yor. ≈ûehrin en b√ºy√ºk ≈üehri\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        bu yeni teknolojiyle birlikte giderek yaygƒ±nla≈üƒ±yor. Bilgisayarlarƒ±n karma≈üƒ±k bir ≈üekilde i≈ülemesi ve yine bu algoritma sayesinde vir√ºsler arasƒ± etkile≈üimi azaltma olanaklarƒ±nƒ± da sunuyor. √ñzellikle yeni nesil bilgisayarlarda\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:38:46\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "39010 | 4.4284 | 6.2e-05 | 1.17 | 38.7K | 02:17:31 |  78.0%\n",
            "39020 | 4.2127 | 6.2e-05 | 1.17 | 38.7K | 02:17:33 |  78.0%\n",
            "39030 | 4.3236 | 6.2e-05 | 1.18 | 38.7K | 02:17:35 |  78.1%\n",
            "39040 | 4.1656 | 6.2e-05 | 1.21 | 38.7K | 02:17:36 |  78.1%\n",
            "39050 | 4.1044 | 6.2e-05 | 1.17 | 38.7K | 02:17:38 |  78.1%\n",
            "39060 | 4.4188 | 6.1e-05 | 1.19 | 38.7K | 02:17:40 |  78.1%\n",
            "39070 | 4.2927 | 6.1e-05 | 1.20 | 38.7K | 02:17:41 |  78.1%\n",
            "39080 | 4.1554 | 6.1e-05 | 1.23 | 38.7K | 02:17:43 |  78.2%\n",
            "39090 | 4.0041 | 6.1e-05 | 1.20 | 38.7K | 02:17:45 |  78.2%\n",
            "39100 | 4.3355 | 6.1e-05 | 1.23 | 38.7K | 02:17:47 |  78.2%\n",
            "39110 | 4.4165 | 6.1e-05 | 1.22 | 38.7K | 02:17:48 |  78.2%\n",
            "39120 | 4.4085 | 6.1e-05 | 1.20 | 38.7K | 02:17:50 |  78.2%\n",
            "39130 | 4.2278 | 6.1e-05 | 1.29 | 38.8K | 02:17:52 |  78.3%\n",
            "39140 | 4.2657 | 6.1e-05 | 1.20 | 38.8K | 02:17:53 |  78.3%\n",
            "39150 | 4.2349 | 6.0e-05 | 1.20 | 38.8K | 02:17:55 |  78.3%\n",
            "39160 | 4.2173 | 6.0e-05 | 1.19 | 38.8K | 02:17:57 |  78.3%\n",
            "39170 | 4.4003 | 6.0e-05 | 1.23 | 38.8K | 02:17:58 |  78.3%\n",
            "39180 | 4.1684 | 6.0e-05 | 1.16 | 38.8K | 02:18:00 |  78.4%\n",
            "39190 | 4.5777 | 6.0e-05 | 1.22 | 38.8K | 02:18:02 |  78.4%\n",
            "39200 | 4.3955 | 6.0e-05 | 1.15 | 38.8K | 02:18:04 |  78.4%\n",
            "39210 | 4.3060 | 6.0e-05 | 1.18 | 38.8K | 02:18:05 |  78.4%\n",
            "39220 | 4.2850 | 6.0e-05 | 1.24 | 38.8K | 02:18:07 |  78.4%\n",
            "39230 | 4.3824 | 6.0e-05 | 1.17 | 38.8K | 02:18:09 |  78.5%\n",
            "39240 | 4.2565 | 5.9e-05 | 1.18 | 38.8K | 02:18:10 |  78.5%\n",
            "39250 | 4.4323 | 5.9e-05 | 1.16 | 38.8K | 02:18:12 |  78.5%\n",
            "39260 | 4.4259 | 5.9e-05 | 1.19 | 38.8K | 02:18:14 |  78.5%\n",
            "39270 | 4.1651 | 5.9e-05 | 1.24 | 38.8K | 02:18:16 |  78.5%\n",
            "39280 | 4.0999 | 5.9e-05 | 1.16 | 38.8K | 02:18:17 |  78.6%\n",
            "39290 | 4.2637 | 5.9e-05 | 1.25 | 38.8K | 02:18:19 |  78.6%\n",
            "39300 | 4.3086 | 5.9e-05 | 1.20 | 38.8K | 02:18:21 |  78.6%\n",
            "39310 | 4.4706 | 5.9e-05 | 1.18 | 38.8K | 02:18:22 |  78.6%\n",
            "39320 | 4.0978 | 5.9e-05 | 1.19 | 38.8K | 02:18:24 |  78.6%\n",
            "39330 | 3.9260 | 5.9e-05 | 1.19 | 38.8K | 02:18:26 |  78.7%\n",
            "39340 | 4.3162 | 5.8e-05 | 1.17 | 38.8K | 02:18:28 |  78.7%\n",
            "39350 | 4.2745 | 5.8e-05 | 1.18 | 38.8K | 02:18:29 |  78.7%\n",
            "39360 | 4.4291 | 5.8e-05 | 1.19 | 38.8K | 02:18:31 |  78.7%\n",
            "39370 | 4.3039 | 5.8e-05 | 1.17 | 38.8K | 02:18:33 |  78.7%\n",
            "39380 | 3.9150 | 5.8e-05 | 1.13 | 38.8K | 02:18:34 |  78.8%\n",
            "39390 | 4.4534 | 5.8e-05 | 1.19 | 38.8K | 02:18:36 |  78.8%\n",
            "39400 | 4.1976 | 5.8e-05 | 1.28 | 38.8K | 02:18:38 |  78.8%\n",
            "39410 | 4.4133 | 5.8e-05 | 1.21 | 38.8K | 02:18:40 |  78.8%\n",
            "39420 | 4.2622 | 5.8e-05 | 1.17 | 38.8K | 02:18:41 |  78.8%\n",
            "39430 | 3.7476 | 5.7e-05 | 1.10 | 38.8K | 02:18:43 |  78.9%\n",
            "39440 | 4.5554 | 5.7e-05 | 1.18 | 38.8K | 02:18:45 |  78.9%\n",
            "39450 | 4.1355 | 5.7e-05 | 1.21 | 38.8K | 02:18:46 |  78.9%\n",
            "39460 | 4.4918 | 5.7e-05 | 1.18 | 38.8K | 02:18:48 |  78.9%\n",
            "39470 | 4.2045 | 5.7e-05 | 1.19 | 38.8K | 02:18:50 |  78.9%\n",
            "39480 | 3.8632 | 5.7e-05 | 1.23 | 38.8K | 02:18:52 |  79.0%\n",
            "39490 | 4.1627 | 5.7e-05 | 1.23 | 38.8K | 02:18:53 |  79.0%\n",
            "39500 | 4.2892 | 5.7e-05 | 1.18 | 38.8K | 02:18:55 |  79.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 39500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1710\n",
            "  Perplexity: 64.78\n",
            "  Train loss (avg): 4.2377\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        g√ºne≈üini iyice hissettirdiƒüine inananlara ilk olarak Aralƒ±k ayƒ± i√ßinde hava da pek √ßok yenilik getirdi. Hava genelinin sƒ±caklƒ±ƒüƒ±n 12 ila 12 derece arasƒ±nda olmasƒ± bekleniyor. Hava sƒ±caklƒ±klarƒ±nƒ±n √ßok y√ºksek olmasƒ± nedeniyle\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Washington'da d√ºzenlenen \"D√∂rd√ºnc√º D√ºnya Sava≈üƒ±'nƒ±n ilanƒ±nƒ±n hemen ardƒ±ndan Avrupa'nƒ±n bir√ßok yerine g√∂nderilmeye ba≈ülandƒ±. Batƒ±'nƒ±n dik duru≈üunun, sava≈üƒ±n T√ºrkiye ile birlikte T√ºrkiye arasƒ±ndaki ili≈ükileri,\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        ile kodlanmƒ±≈ü bir yapay zekaya sahipseniz, yapay zeka bu i≈üe ger√ßekten karar verir. Facebook, bir grup √ºr√ºn√º alarak yapay zekanƒ±n ne olduƒüunu √∂ƒüreniyor. Yapay zekayƒ± nasƒ±l geli≈ütirirseniz, geli≈ütir\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:37:00\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "39510 | 4.2567 | 5.7e-05 | 1.17 | 38.7K | 02:19:14 |  79.0%\n",
            "39520 | 4.2266 | 5.7e-05 | 1.22 | 38.7K | 02:19:16 |  79.0%\n",
            "39530 | 4.3336 | 5.6e-05 | 1.19 | 38.7K | 02:19:17 |  79.1%\n",
            "39540 | 4.3093 | 5.6e-05 | 1.19 | 38.7K | 02:19:19 |  79.1%\n",
            "39550 | 4.2481 | 5.6e-05 | 1.18 | 38.7K | 02:19:21 |  79.1%\n",
            "39560 | 4.3250 | 5.6e-05 | 1.21 | 38.8K | 02:19:23 |  79.1%\n",
            "39570 | 4.0399 | 5.6e-05 | 1.21 | 38.8K | 02:19:24 |  79.1%\n",
            "39580 | 4.2324 | 5.6e-05 | 1.18 | 38.8K | 02:19:26 |  79.2%\n",
            "39590 | 3.7439 | 5.6e-05 | 1.19 | 38.8K | 02:19:28 |  79.2%\n",
            "39600 | 4.2222 | 5.6e-05 | 1.27 | 38.8K | 02:19:29 |  79.2%\n",
            "39610 | 3.7772 | 5.6e-05 | 1.29 | 38.8K | 02:19:31 |  79.2%\n",
            "39620 | 4.0310 | 5.6e-05 | 1.20 | 38.8K | 02:19:33 |  79.2%\n",
            "39630 | 4.4291 | 5.5e-05 | 1.20 | 38.8K | 02:19:34 |  79.3%\n",
            "39640 | 4.2846 | 5.5e-05 | 1.15 | 38.8K | 02:19:36 |  79.3%\n",
            "39650 | 4.0765 | 5.5e-05 | 1.16 | 38.8K | 02:19:38 |  79.3%\n",
            "39660 | 4.3095 | 5.5e-05 | 1.20 | 38.8K | 02:19:40 |  79.3%\n",
            "39670 | 4.5471 | 5.5e-05 | 1.16 | 38.8K | 02:19:41 |  79.3%\n",
            "39680 | 4.3965 | 5.5e-05 | 1.21 | 38.8K | 02:19:43 |  79.4%\n",
            "39690 | 4.2083 | 5.5e-05 | 1.22 | 38.8K | 02:19:45 |  79.4%\n",
            "39700 | 4.2409 | 5.5e-05 | 1.17 | 38.8K | 02:19:46 |  79.4%\n",
            "39710 | 4.0800 | 5.5e-05 | 1.21 | 38.8K | 02:19:48 |  79.4%\n",
            "39720 | 4.3491 | 5.4e-05 | 1.27 | 38.8K | 02:19:50 |  79.4%\n",
            "39730 | 4.0695 | 5.4e-05 | 1.17 | 38.8K | 02:19:52 |  79.5%\n",
            "39740 | 4.3825 | 5.4e-05 | 1.21 | 38.8K | 02:19:53 |  79.5%\n",
            "39750 | 3.8303 | 5.4e-05 | 1.31 | 38.8K | 02:19:55 |  79.5%\n",
            "39760 | 4.4111 | 5.4e-05 | 1.20 | 38.8K | 02:19:57 |  79.5%\n",
            "39770 | 4.0879 | 5.4e-05 | 1.21 | 38.8K | 02:19:58 |  79.5%\n",
            "39780 | 3.9592 | 5.4e-05 | 1.18 | 38.8K | 02:20:00 |  79.6%\n",
            "39790 | 4.1325 | 5.4e-05 | 1.19 | 38.8K | 02:20:02 |  79.6%\n",
            "39800 | 4.3685 | 5.4e-05 | 1.19 | 38.8K | 02:20:04 |  79.6%\n",
            "39810 | 4.0040 | 5.4e-05 | 1.18 | 38.8K | 02:20:05 |  79.6%\n",
            "39820 | 4.2389 | 5.3e-05 | 1.19 | 38.8K | 02:20:07 |  79.6%\n",
            "39830 | 4.3136 | 5.3e-05 | 1.21 | 38.8K | 02:20:09 |  79.7%\n",
            "39840 | 4.2207 | 5.3e-05 | 1.18 | 38.8K | 02:20:10 |  79.7%\n",
            "39850 | 4.3446 | 5.3e-05 | 1.20 | 38.8K | 02:20:12 |  79.7%\n",
            "39860 | 4.1629 | 5.3e-05 | 1.19 | 38.8K | 02:20:14 |  79.7%\n",
            "39870 | 3.9365 | 5.3e-05 | 1.17 | 38.8K | 02:20:16 |  79.7%\n",
            "39880 | 4.3866 | 5.3e-05 | 1.17 | 38.8K | 02:20:17 |  79.8%\n",
            "39890 | 4.2142 | 5.3e-05 | 1.21 | 38.8K | 02:20:19 |  79.8%\n",
            "39900 | 4.0133 | 5.3e-05 | 1.15 | 38.8K | 02:20:21 |  79.8%\n",
            "39910 | 4.4898 | 5.3e-05 | 1.18 | 38.8K | 02:20:22 |  79.8%\n",
            "39920 | 4.4749 | 5.2e-05 | 1.25 | 38.8K | 02:20:24 |  79.8%\n",
            "39930 | 4.0792 | 5.2e-05 | 1.15 | 38.8K | 02:20:26 |  79.9%\n",
            "39940 | 4.2434 | 5.2e-05 | 1.17 | 38.8K | 02:20:28 |  79.9%\n",
            "39950 | 4.2029 | 5.2e-05 | 1.17 | 38.8K | 02:20:29 |  79.9%\n",
            "39960 | 4.1299 | 5.2e-05 | 1.20 | 38.8K | 02:20:31 |  79.9%\n",
            "39970 | 4.2105 | 5.2e-05 | 1.21 | 38.8K | 02:20:33 |  79.9%\n",
            "39980 | 4.3165 | 5.2e-05 | 1.28 | 38.8K | 02:20:34 |  80.0%\n",
            "39990 | 4.0808 | 5.2e-05 | 1.16 | 38.8K | 02:20:36 |  80.0%\n",
            "40000 | 4.6246 | 5.2e-05 | 1.22 | 38.8K | 02:20:38 |  80.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 40000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1307\n",
            "  Perplexity: 62.22\n",
            "  Train loss (avg): 4.2096\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        √ßok sƒ±cak ve nemli. Bu hafta, olduk√ßa sƒ±cak. 20-25 dakika, 15-25 dakika, 20 dakika. Sanki bir ba≈üka hava daha var. Hava sƒ±cak. T√ºrkiye'de hava √ßok soƒüuk. Hava\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        √ßimen'de, Eski≈üehir'de bir iki ki≈üi PKK'lƒ± grup tarafƒ±ndan ka√ßƒ±rƒ±ldƒ±. Kanlƒ± saldƒ±rƒ± sonrasƒ± d√ºzenlenen saldƒ±rƒ±da ≈üehit olan Uzman √áavu≈ü Mehmet Korkmaz'ƒ±n cenazesi, Eski≈üehir'e getirildi.\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , kendi kendini geli≈ütirmeyi ba≈üarmƒ±≈ü ve b√ºy√ºk √∂l√ß√ºde yeniden icat etmi≈ütir. Bu iki tekniƒüin, yeni bir yeni teknoloji geli≈ütirip, T√ºrkiye'de de tek ba≈ülarƒ±na geli≈ütirilen teknolojilere ula≈ümalarƒ±na olanak tanƒ±yacak ≈üekilde\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.1307)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:35:14\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "üíæ Checkpoint kaydediliyor: /content/drive/MyDrive/turkish_llm/checkpoints//checkpoint_step_40000.pt\n",
            "  ‚úÖ Checkpoint kaydedildi!\n",
            "\n",
            "40010 | 4.2527 | 5.2e-05 | 1.16 | 38.7K | 02:21:04 |  80.0%\n",
            "40020 | 4.0898 | 5.1e-05 | 1.19 | 38.7K | 02:21:05 |  80.0%\n",
            "40030 | 4.4829 | 5.1e-05 | 1.22 | 38.7K | 02:21:07 |  80.1%\n",
            "40040 | 3.9109 | 5.1e-05 | 1.24 | 38.7K | 02:21:09 |  80.1%\n",
            "40050 | 3.9421 | 5.1e-05 | 1.21 | 38.7K | 02:21:10 |  80.1%\n",
            "40060 | 4.1487 | 5.1e-05 | 1.22 | 38.7K | 02:21:12 |  80.1%\n",
            "40070 | 3.9972 | 5.1e-05 | 1.15 | 38.7K | 02:21:14 |  80.1%\n",
            "40080 | 4.0710 | 5.1e-05 | 1.21 | 38.7K | 02:21:16 |  80.2%\n",
            "40090 | 4.0628 | 5.1e-05 | 1.20 | 38.7K | 02:21:17 |  80.2%\n",
            "40100 | 4.2720 | 5.1e-05 | 1.17 | 38.7K | 02:21:19 |  80.2%\n",
            "40110 | 4.1062 | 5.1e-05 | 1.17 | 38.7K | 02:21:21 |  80.2%\n",
            "40120 | 4.0950 | 5.0e-05 | 1.22 | 38.7K | 02:21:22 |  80.2%\n",
            "40130 | 4.1096 | 5.0e-05 | 1.22 | 38.7K | 02:21:24 |  80.3%\n",
            "40140 | 3.9039 | 5.0e-05 | 1.24 | 38.7K | 02:21:26 |  80.3%\n",
            "40150 | 4.1347 | 5.0e-05 | 1.19 | 38.7K | 02:21:27 |  80.3%\n",
            "40160 | 4.2026 | 5.0e-05 | 1.16 | 38.8K | 02:21:29 |  80.3%\n",
            "40170 | 4.3311 | 5.0e-05 | 1.19 | 38.8K | 02:21:31 |  80.3%\n",
            "40180 | 4.3213 | 5.0e-05 | 1.19 | 38.8K | 02:21:33 |  80.4%\n",
            "40190 | 4.0845 | 5.0e-05 | 1.18 | 38.8K | 02:21:34 |  80.4%\n",
            "40200 | 3.9984 | 5.0e-05 | 1.17 | 38.8K | 02:21:36 |  80.4%\n",
            "40210 | 4.2577 | 5.0e-05 | 1.20 | 38.8K | 02:21:38 |  80.4%\n",
            "40220 | 3.9369 | 5.0e-05 | 1.19 | 38.8K | 02:21:39 |  80.4%\n",
            "40230 | 4.0413 | 4.9e-05 | 1.17 | 38.8K | 02:21:41 |  80.5%\n",
            "40240 | 4.3608 | 4.9e-05 | 1.18 | 38.8K | 02:21:43 |  80.5%\n",
            "40250 | 3.9081 | 4.9e-05 | 1.20 | 38.8K | 02:21:45 |  80.5%\n",
            "40260 | 4.1634 | 4.9e-05 | 1.24 | 38.8K | 02:21:46 |  80.5%\n",
            "40270 | 4.1341 | 4.9e-05 | 1.28 | 38.8K | 02:21:48 |  80.5%\n",
            "40280 | 4.2360 | 4.9e-05 | 1.23 | 38.8K | 02:21:50 |  80.6%\n",
            "40290 | 4.4367 | 4.9e-05 | 1.16 | 38.8K | 02:21:51 |  80.6%\n",
            "40300 | 3.9848 | 4.9e-05 | 1.21 | 38.8K | 02:21:53 |  80.6%\n",
            "40310 | 4.4290 | 4.9e-05 | 1.25 | 38.8K | 02:21:55 |  80.6%\n",
            "40320 | 4.2991 | 4.9e-05 | 1.24 | 38.8K | 02:21:57 |  80.6%\n",
            "40330 | 4.2304 | 4.8e-05 | 1.23 | 38.8K | 02:21:58 |  80.7%\n",
            "40340 | 4.1534 | 4.8e-05 | 1.25 | 38.8K | 02:22:00 |  80.7%\n",
            "40350 | 4.4244 | 4.8e-05 | 1.19 | 38.8K | 02:22:02 |  80.7%\n",
            "40360 | 4.2894 | 4.8e-05 | 1.21 | 38.8K | 02:22:03 |  80.7%\n",
            "40370 | 4.0681 | 4.8e-05 | 1.18 | 38.8K | 02:22:05 |  80.7%\n",
            "40380 | 4.3420 | 4.8e-05 | 1.20 | 38.8K | 02:22:07 |  80.8%\n",
            "40390 | 4.0020 | 4.8e-05 | 1.20 | 38.8K | 02:22:09 |  80.8%\n",
            "40400 | 4.2453 | 4.8e-05 | 1.20 | 38.8K | 02:22:10 |  80.8%\n",
            "40410 | 4.0716 | 4.8e-05 | 1.18 | 38.8K | 02:22:12 |  80.8%\n",
            "40420 | 4.3291 | 4.8e-05 | 1.21 | 38.8K | 02:22:14 |  80.8%\n",
            "40430 | 4.5135 | 4.7e-05 | 1.18 | 38.8K | 02:22:15 |  80.9%\n",
            "40440 | 4.1305 | 4.7e-05 | 1.25 | 38.8K | 02:22:17 |  80.9%\n",
            "40450 | 4.2651 | 4.7e-05 | 1.23 | 38.8K | 02:22:19 |  80.9%\n",
            "40460 | 4.1019 | 4.7e-05 | 1.22 | 38.8K | 02:22:21 |  80.9%\n",
            "40470 | 4.2237 | 4.7e-05 | 1.20 | 38.8K | 02:22:22 |  80.9%\n",
            "40480 | 4.1747 | 4.7e-05 | 1.18 | 38.8K | 02:22:24 |  81.0%\n",
            "40490 | 3.9931 | 4.7e-05 | 1.20 | 38.8K | 02:22:26 |  81.0%\n",
            "40500 | 4.2386 | 4.7e-05 | 1.27 | 38.8K | 02:22:27 |  81.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 40500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1138\n",
            "  Perplexity: 61.18\n",
            "  Train loss (avg): 4.1952\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        sƒ±cak, sƒ±cak ve yaƒümurlu. Her sabah yaƒümurlu. Hava sƒ±cak ve yaƒümurlu. Hava sƒ±cak ve yaƒümurlu. Yaƒüƒ±≈ülarƒ±n sƒ±cak olmasƒ± hava sƒ±cak. Hava sƒ±cak ve yaƒümurlu. Hava sƒ±cak\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Ankara'nƒ±n Ankara B√ºy√ºkel√ßisi Andriyoz Atay, \"T√ºrkiye'nin barƒ±≈ü ve istikrar i√ßin gelecek ilk ve tekeli a√ßƒ±sƒ±ndan √ßok √∂nemli bir adƒ±m olduƒüunu ve bunun da T√ºrkiye'nin AB'ye\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        geli≈ütirildi ve bu yeni teknoloji sayesinde √ßok daha ba≈üarƒ±lƒ± bir ileti≈üim bi√ßimi elde edildi. Teknoloji ile ileti≈üim de geli≈ütirildi. Telepatik teknolojisi ile ilgili √ßalƒ±≈ümalar yapan ve veri sorumlusu olarak √ßalƒ±≈üan Prof. Dr.\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.1138)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:33:29\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "40510 | 4.2961 | 4.7e-05 | 1.20 | 38.7K | 02:22:50 |  81.0%\n",
            "40520 | 3.9697 | 4.7e-05 | 1.19 | 38.7K | 02:22:51 |  81.0%\n",
            "40530 | 4.1366 | 4.7e-05 | 1.19 | 38.7K | 02:22:53 |  81.1%\n",
            "40540 | 4.1553 | 4.6e-05 | 1.19 | 38.7K | 02:22:55 |  81.1%\n",
            "40550 | 4.1388 | 4.6e-05 | 1.18 | 38.7K | 02:22:57 |  81.1%\n",
            "40560 | 4.2063 | 4.6e-05 | 1.22 | 38.7K | 02:22:58 |  81.1%\n",
            "40570 | 4.2068 | 4.6e-05 | 1.23 | 38.7K | 02:23:00 |  81.1%\n",
            "40580 | 4.1276 | 4.6e-05 | 1.22 | 38.7K | 02:23:02 |  81.2%\n",
            "40590 | 4.4044 | 4.6e-05 | 1.26 | 38.7K | 02:23:03 |  81.2%\n",
            "40600 | 4.2896 | 4.6e-05 | 1.16 | 38.7K | 02:23:05 |  81.2%\n",
            "40610 | 4.2404 | 4.6e-05 | 1.24 | 38.7K | 02:23:07 |  81.2%\n",
            "40620 | 4.0481 | 4.6e-05 | 1.20 | 38.7K | 02:23:09 |  81.2%\n",
            "40630 | 4.3212 | 4.6e-05 | 1.21 | 38.7K | 02:23:10 |  81.3%\n",
            "40640 | 3.8384 | 4.5e-05 | 1.21 | 38.7K | 02:23:12 |  81.3%\n",
            "40650 | 4.2040 | 4.5e-05 | 1.17 | 38.7K | 02:23:14 |  81.3%\n",
            "40660 | 4.1806 | 4.5e-05 | 1.16 | 38.7K | 02:23:15 |  81.3%\n",
            "40670 | 4.3844 | 4.5e-05 | 1.17 | 38.8K | 02:23:17 |  81.3%\n",
            "40680 | 4.1472 | 4.5e-05 | 1.20 | 38.8K | 02:23:19 |  81.4%\n",
            "40690 | 3.9651 | 4.5e-05 | 1.30 | 38.8K | 02:23:21 |  81.4%\n",
            "40700 | 4.3952 | 4.5e-05 | 1.21 | 38.8K | 02:23:22 |  81.4%\n",
            "40710 | 3.9202 | 4.5e-05 | 1.23 | 38.8K | 02:23:24 |  81.4%\n",
            "40720 | 4.0356 | 4.5e-05 | 1.19 | 38.8K | 02:23:26 |  81.4%\n",
            "40730 | 4.0785 | 4.5e-05 | 1.18 | 38.8K | 02:23:27 |  81.5%\n",
            "40740 | 4.1279 | 4.5e-05 | 1.19 | 38.8K | 02:23:29 |  81.5%\n",
            "40750 | 4.1612 | 4.4e-05 | 1.22 | 38.8K | 02:23:31 |  81.5%\n",
            "40760 | 4.2874 | 4.4e-05 | 1.26 | 38.8K | 02:23:33 |  81.5%\n",
            "40770 | 4.3734 | 4.4e-05 | 1.21 | 38.8K | 02:23:34 |  81.5%\n",
            "40780 | 4.2707 | 4.4e-05 | 1.19 | 38.8K | 02:23:36 |  81.6%\n",
            "40790 | 4.1932 | 4.4e-05 | 1.19 | 38.8K | 02:23:38 |  81.6%\n",
            "40800 | 4.1695 | 4.4e-05 | 1.20 | 38.8K | 02:23:39 |  81.6%\n",
            "40810 | 4.0453 | 4.4e-05 | 1.22 | 38.8K | 02:23:41 |  81.6%\n",
            "40820 | 4.3582 | 4.4e-05 | 1.18 | 38.8K | 02:23:43 |  81.6%\n",
            "40830 | 4.3738 | 4.4e-05 | 1.19 | 38.8K | 02:23:45 |  81.7%\n",
            "40840 | 4.1296 | 4.4e-05 | 1.19 | 38.8K | 02:23:46 |  81.7%\n",
            "40850 | 4.3279 | 4.4e-05 | 1.20 | 38.8K | 02:23:48 |  81.7%\n",
            "40860 | 4.2788 | 4.3e-05 | 1.21 | 38.8K | 02:23:50 |  81.7%\n",
            "40870 | 4.2286 | 4.3e-05 | 1.18 | 38.8K | 02:23:51 |  81.7%\n",
            "40880 | 4.0957 | 4.3e-05 | 1.17 | 38.8K | 02:23:53 |  81.8%\n",
            "40890 | 4.5789 | 4.3e-05 | 1.20 | 38.8K | 02:23:55 |  81.8%\n",
            "40900 | 4.2403 | 4.3e-05 | 1.18 | 38.8K | 02:23:57 |  81.8%\n",
            "40910 | 4.1957 | 4.3e-05 | 1.17 | 38.8K | 02:23:58 |  81.8%\n",
            "40920 | 4.0551 | 4.3e-05 | 1.23 | 38.8K | 02:24:00 |  81.8%\n",
            "40930 | 3.9915 | 4.3e-05 | 1.22 | 38.8K | 02:24:02 |  81.9%\n",
            "40940 | 3.9868 | 4.3e-05 | 1.20 | 38.8K | 02:24:03 |  81.9%\n",
            "40950 | 4.1042 | 4.3e-05 | 1.21 | 38.8K | 02:24:05 |  81.9%\n",
            "40960 | 4.3454 | 4.3e-05 | 1.29 | 38.8K | 02:24:07 |  81.9%\n",
            "40970 | 4.3739 | 4.2e-05 | 1.19 | 38.8K | 02:24:09 |  81.9%\n",
            "40980 | 4.1953 | 4.2e-05 | 1.22 | 38.8K | 02:24:10 |  82.0%\n",
            "40990 | 4.2325 | 4.2e-05 | 1.20 | 38.8K | 02:24:12 |  82.0%\n",
            "41000 | 4.3171 | 4.2e-05 | 1.22 | 38.8K | 02:24:14 |  82.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 41000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1224\n",
            "  Perplexity: 61.71\n",
            "  Train loss (avg): 4.2014\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        soƒüuksa ya da yaƒümur yaƒüsa, kuraklƒ±ƒüa dayanamazsak, kurda yaƒüa yakmaya kalkarƒ±z. Yer yer yaƒümur yaƒüsa, nem konusunda da √ßok dikkatli olmamƒ±z gerekir. Eƒüer yaƒümur yaƒü\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Ankara'da, 39 √ºlke arasƒ±nda 22 ayrƒ± kategoride toplam 218 √ºlke bulunuyor. T√ºrkiye'de toplam 18 farklƒ± kategoride toplam 208 √ºlke arasƒ±nda toplam 227 √ºlke bulunuyor. T√ºrkiye, ilk 500'e\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        sayesinde t√ºm akƒ±llƒ± telefonlara uygulama imkanƒ± elde edilir. Akƒ±llƒ± telefonlarƒ±n yaygƒ±n kullanƒ±mƒ± ise tercih edilmesi gereken bir teknolojidir. Yine akƒ±llƒ± telefonlarda daha √ßok mobil cihazlara uygulama imkanƒ± elde edilir. Bunun i√ßin sistem\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:31:43\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "41010 | 4.0766 | 4.2e-05 | 1.23 | 38.7K | 02:24:33 |  82.0%\n",
            "41020 | 4.3743 | 4.2e-05 | 1.23 | 38.7K | 02:24:34 |  82.0%\n",
            "41030 | 4.1742 | 4.2e-05 | 1.21 | 38.7K | 02:24:36 |  82.1%\n",
            "41040 | 4.2282 | 4.2e-05 | 1.24 | 38.7K | 02:24:38 |  82.1%\n",
            "41050 | 4.3624 | 4.2e-05 | 1.17 | 38.7K | 02:24:39 |  82.1%\n",
            "41060 | 4.2182 | 4.2e-05 | 1.24 | 38.7K | 02:24:41 |  82.1%\n",
            "41070 | 4.3697 | 4.2e-05 | 1.18 | 38.7K | 02:24:43 |  82.1%\n",
            "41080 | 3.9576 | 4.1e-05 | 1.21 | 38.7K | 02:24:45 |  82.2%\n",
            "41090 | 4.0319 | 4.1e-05 | 1.16 | 38.7K | 02:24:46 |  82.2%\n",
            "41100 | 4.0544 | 4.1e-05 | 1.18 | 38.8K | 02:24:48 |  82.2%\n",
            "41110 | 4.3629 | 4.1e-05 | 1.21 | 38.8K | 02:24:50 |  82.2%\n",
            "41120 | 4.3795 | 4.1e-05 | 1.21 | 38.8K | 02:24:51 |  82.2%\n",
            "41130 | 4.2377 | 4.1e-05 | 1.26 | 38.8K | 02:24:53 |  82.3%\n",
            "41140 | 4.2128 | 4.1e-05 | 1.23 | 38.8K | 02:24:55 |  82.3%\n",
            "41150 | 4.0356 | 4.1e-05 | 1.16 | 38.8K | 02:24:57 |  82.3%\n",
            "41160 | 4.3243 | 4.1e-05 | 1.20 | 38.8K | 02:24:58 |  82.3%\n",
            "41170 | 4.2537 | 4.1e-05 | 1.24 | 38.8K | 02:25:00 |  82.3%\n",
            "41180 | 4.2045 | 4.1e-05 | 1.17 | 38.8K | 02:25:02 |  82.4%\n",
            "41190 | 4.3460 | 4.0e-05 | 1.17 | 38.8K | 02:25:03 |  82.4%\n",
            "41200 | 4.3350 | 4.0e-05 | 1.21 | 38.8K | 02:25:05 |  82.4%\n",
            "41210 | 4.3075 | 4.0e-05 | 1.18 | 38.8K | 02:25:07 |  82.4%\n",
            "41220 | 4.3764 | 4.0e-05 | 1.27 | 38.8K | 02:25:09 |  82.4%\n",
            "41230 | 4.2251 | 4.0e-05 | 1.22 | 38.8K | 02:25:10 |  82.5%\n",
            "41240 | 4.1749 | 4.0e-05 | 1.15 | 38.8K | 02:25:12 |  82.5%\n",
            "41250 | 4.4519 | 4.0e-05 | 1.20 | 38.8K | 02:25:14 |  82.5%\n",
            "41260 | 4.3360 | 4.0e-05 | 1.18 | 38.8K | 02:25:15 |  82.5%\n",
            "41270 | 4.2142 | 4.0e-05 | 1.20 | 38.8K | 02:25:17 |  82.5%\n",
            "41280 | 4.2048 | 4.0e-05 | 1.19 | 38.8K | 02:25:19 |  82.6%\n",
            "41290 | 4.2257 | 4.0e-05 | 1.23 | 38.8K | 02:25:21 |  82.6%\n",
            "41300 | 4.1757 | 3.9e-05 | 1.19 | 38.8K | 02:25:22 |  82.6%\n",
            "41310 | 4.1680 | 3.9e-05 | 1.21 | 38.8K | 02:25:24 |  82.6%\n",
            "41320 | 4.4206 | 3.9e-05 | 1.21 | 38.8K | 02:25:26 |  82.6%\n",
            "41330 | 4.1511 | 3.9e-05 | 1.19 | 38.8K | 02:25:27 |  82.7%\n",
            "41340 | 4.4057 | 3.9e-05 | 1.22 | 38.8K | 02:25:29 |  82.7%\n",
            "41350 | 4.2041 | 3.9e-05 | 1.20 | 38.8K | 02:25:31 |  82.7%\n",
            "41360 | 4.0344 | 3.9e-05 | 1.18 | 38.8K | 02:25:32 |  82.7%\n",
            "41370 | 4.2768 | 3.9e-05 | 1.23 | 38.8K | 02:25:34 |  82.7%\n",
            "41380 | 4.3087 | 3.9e-05 | 1.18 | 38.8K | 02:25:36 |  82.8%\n",
            "41390 | 4.3130 | 3.9e-05 | 1.22 | 38.8K | 02:25:38 |  82.8%\n",
            "41400 | 4.0724 | 3.9e-05 | 1.23 | 38.8K | 02:25:39 |  82.8%\n",
            "41410 | 4.2601 | 3.8e-05 | 1.17 | 38.8K | 02:25:41 |  82.8%\n",
            "41420 | 4.4524 | 3.8e-05 | 1.19 | 38.8K | 02:25:43 |  82.8%\n",
            "41430 | 4.0373 | 3.8e-05 | 1.16 | 38.8K | 02:25:44 |  82.9%\n",
            "41440 | 3.9971 | 3.8e-05 | 1.31 | 38.8K | 02:25:46 |  82.9%\n",
            "41450 | 3.7524 | 3.8e-05 | 1.17 | 38.8K | 02:25:48 |  82.9%\n",
            "41460 | 4.1153 | 3.8e-05 | 1.21 | 38.8K | 02:25:50 |  82.9%\n",
            "41470 | 4.0940 | 3.8e-05 | 1.25 | 38.8K | 02:25:51 |  82.9%\n",
            "41480 | 4.2261 | 3.8e-05 | 1.24 | 38.8K | 02:25:53 |  83.0%\n",
            "41490 | 3.8088 | 3.8e-05 | 1.18 | 38.8K | 02:25:55 |  83.0%\n",
            "41500 | 4.1345 | 3.8e-05 | 1.22 | 38.8K | 02:25:56 |  83.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 41500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1283\n",
            "  Perplexity: 62.07\n",
            "  Train loss (avg): 4.2048\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        tahminimce % 25'e yakƒ±ndƒ±. Bu tahminim, % 45'e yakƒ±ndƒ±. Ve bu tahminim tahminimce % 25'e yakƒ±ndƒ±. Bu tahminim, tahmin\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        ƒ∞stanbul'da bulunan ve ƒ∞stanbul-Akdeniz-ƒ∞zmir arasƒ±ndaki Kƒ±zƒ±ldeniz-Eminovo-Governo-Governo-Governo-Governo-\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        ile fark ediliyor ve bir sonraki a≈üamada da artƒ±k zamanƒ± √ßabuk durduruyor. G√ºn√ºm√ºzde en √∂nemli ≈üey bir insansƒ±z bir d√ºnyadƒ±r. Bu teknoloji olduk√ßa yaygƒ±n ve yenilik√ßi bir ara√ßtƒ±r. Bununla birlikte, insanlar bir\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.7K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:29:57\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "41510 | 4.1564 | 3.8e-05 | 1.25 | 38.7K | 02:26:15 |  83.0%\n",
            "41520 | 4.1325 | 3.8e-05 | 1.25 | 38.7K | 02:26:17 |  83.0%\n",
            "41530 | 4.2318 | 3.7e-05 | 1.15 | 38.8K | 02:26:19 |  83.1%\n",
            "41540 | 4.3034 | 3.7e-05 | 1.21 | 38.8K | 02:26:21 |  83.1%\n",
            "41550 | 4.0258 | 3.7e-05 | 1.33 | 38.8K | 02:26:22 |  83.1%\n",
            "41560 | 4.1862 | 3.7e-05 | 1.21 | 38.8K | 02:26:24 |  83.1%\n",
            "41570 | 4.1310 | 3.7e-05 | 1.18 | 38.8K | 02:26:26 |  83.1%\n",
            "41580 | 4.0807 | 3.7e-05 | 1.21 | 38.8K | 02:26:27 |  83.2%\n",
            "41590 | 4.4093 | 3.7e-05 | 1.17 | 38.8K | 02:26:29 |  83.2%\n",
            "41600 | 4.3402 | 3.7e-05 | 1.20 | 38.8K | 02:26:31 |  83.2%\n",
            "41610 | 4.0677 | 3.7e-05 | 1.23 | 38.8K | 02:26:33 |  83.2%\n",
            "41620 | 4.1895 | 3.7e-05 | 1.17 | 38.8K | 02:26:34 |  83.2%\n",
            "41630 | 4.2572 | 3.7e-05 | 1.19 | 38.8K | 02:26:36 |  83.3%\n",
            "41640 | 3.8487 | 3.7e-05 | 1.24 | 38.8K | 02:26:38 |  83.3%\n",
            "41650 | 4.5330 | 3.6e-05 | 1.26 | 38.8K | 02:26:39 |  83.3%\n",
            "41660 | 4.1734 | 3.6e-05 | 1.18 | 38.8K | 02:26:41 |  83.3%\n",
            "41670 | 4.0488 | 3.6e-05 | 1.18 | 38.8K | 02:26:43 |  83.3%\n",
            "41680 | 4.1448 | 3.6e-05 | 1.21 | 38.8K | 02:26:45 |  83.4%\n",
            "41690 | 4.3156 | 3.6e-05 | 1.20 | 38.8K | 02:26:46 |  83.4%\n",
            "41700 | 4.0988 | 3.6e-05 | 1.19 | 38.8K | 02:26:48 |  83.4%\n",
            "41710 | 4.0025 | 3.6e-05 | 1.20 | 38.8K | 02:26:50 |  83.4%\n",
            "41720 | 4.1052 | 3.6e-05 | 1.23 | 38.8K | 02:26:51 |  83.4%\n",
            "41730 | 4.1577 | 3.6e-05 | 1.25 | 38.8K | 02:26:53 |  83.5%\n",
            "41740 | 3.9325 | 3.6e-05 | 1.22 | 38.8K | 02:26:55 |  83.5%\n",
            "41750 | 4.3666 | 3.6e-05 | 1.20 | 38.8K | 02:26:57 |  83.5%\n",
            "41760 | 4.0476 | 3.5e-05 | 1.21 | 38.8K | 02:26:58 |  83.5%\n",
            "41770 | 4.0626 | 3.5e-05 | 1.20 | 38.8K | 02:27:00 |  83.5%\n",
            "41780 | 4.1761 | 3.5e-05 | 1.17 | 38.8K | 02:27:02 |  83.6%\n",
            "41790 | 4.0910 | 3.5e-05 | 1.23 | 38.8K | 02:27:03 |  83.6%\n",
            "41800 | 4.0785 | 3.5e-05 | 1.20 | 38.8K | 02:27:05 |  83.6%\n",
            "41810 | 4.1656 | 3.5e-05 | 1.19 | 38.8K | 02:27:07 |  83.6%\n",
            "41820 | 4.5877 | 3.5e-05 | 1.20 | 38.8K | 02:27:09 |  83.6%\n",
            "41830 | 3.9979 | 3.5e-05 | 1.19 | 38.8K | 02:27:10 |  83.7%\n",
            "41840 | 4.2378 | 3.5e-05 | 1.18 | 38.8K | 02:27:12 |  83.7%\n",
            "41850 | 4.0208 | 3.5e-05 | 1.20 | 38.8K | 02:27:14 |  83.7%\n",
            "41860 | 4.1734 | 3.5e-05 | 1.17 | 38.8K | 02:27:15 |  83.7%\n",
            "41870 | 4.3887 | 3.5e-05 | 1.27 | 38.8K | 02:27:17 |  83.7%\n",
            "41880 | 4.0951 | 3.4e-05 | 1.15 | 38.8K | 02:27:19 |  83.8%\n",
            "41890 | 4.1936 | 3.4e-05 | 1.21 | 38.8K | 02:27:21 |  83.8%\n",
            "41900 | 4.2257 | 3.4e-05 | 1.19 | 38.8K | 02:27:22 |  83.8%\n",
            "41910 | 4.4172 | 3.4e-05 | 1.19 | 38.8K | 02:27:24 |  83.8%\n",
            "41920 | 4.2066 | 3.4e-05 | 1.23 | 38.8K | 02:27:26 |  83.8%\n",
            "41930 | 3.9004 | 3.4e-05 | 1.19 | 38.8K | 02:27:27 |  83.9%\n",
            "41940 | 4.3212 | 3.4e-05 | 1.20 | 38.8K | 02:27:29 |  83.9%\n",
            "41950 | 4.3966 | 3.4e-05 | 1.19 | 38.8K | 02:27:31 |  83.9%\n",
            "41960 | 4.2777 | 3.4e-05 | 1.20 | 38.8K | 02:27:33 |  83.9%\n",
            "41970 | 4.2812 | 3.4e-05 | 1.31 | 38.8K | 02:27:34 |  83.9%\n",
            "41980 | 4.1664 | 3.4e-05 | 1.23 | 38.8K | 02:27:36 |  84.0%\n",
            "41990 | 3.9774 | 3.4e-05 | 1.26 | 38.8K | 02:27:38 |  84.0%\n",
            "42000 | 3.9850 | 3.4e-05 | 1.23 | 38.8K | 02:27:39 |  84.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 42000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1467\n",
            "  Perplexity: 63.22\n",
            "  Train loss (avg): 4.1978\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        durumu hakkƒ±nda herhangi bir a√ßƒ±klama yapƒ±lmadƒ± ancak √∂zel eƒüitim kurumunun u√ßu≈ü eƒüitimlerini de desteklemesi bekleniyor. Neden? √á√ºnk√º kar nedeniyle u√ßaklarda hava durumu d√ºzenlenmemi≈üken u√ßaklarda yolcu olarak bir miktar u√ßak d√º≈ümesi\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        ve en b√ºy√ºk kenti olan Ye≈üiller, T√ºrkiye‚Äônin en b√ºy√ºk ≈üehridir. Ye≈üiller, T√ºrkiye‚Äônin en b√ºy√ºk ≈üehridir. Ye≈üiller ≈üehri, ƒ∞stanbul‚Äôun y√ºz√∂l√ß√ºm√ºn√ºn 172\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , olduk√ßa zeki bir yetenektir. Bu teknolojinin √ºlkemizde olduk√ßa pop√ºler olmasƒ±, herkesin kullanabileceƒüi bir teknoloji olmasƒ± gibi √∂zellikler √∂ne √ßƒ±kmaktadƒ±r. D√ºnyanƒ±n en b√ºy√ºk teknoloji ≈üirketleri arasƒ±nda yer alan ve d√ºnyada ilk 10'a giren i≈ületmeler\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:28:10\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "42010 | 4.2271 | 3.3e-05 | 1.19 | 38.8K | 02:27:58 |  84.0%\n",
            "42020 | 4.4124 | 3.3e-05 | 1.28 | 38.8K | 02:28:00 |  84.0%\n",
            "42030 | 4.3541 | 3.3e-05 | 1.22 | 38.8K | 02:28:02 |  84.1%\n",
            "42040 | 4.1493 | 3.3e-05 | 1.18 | 38.8K | 02:28:03 |  84.1%\n",
            "42050 | 4.0246 | 3.3e-05 | 1.26 | 38.8K | 02:28:05 |  84.1%\n",
            "42060 | 4.3384 | 3.3e-05 | 1.19 | 38.8K | 02:28:07 |  84.1%\n",
            "42070 | 4.2835 | 3.3e-05 | 1.19 | 38.8K | 02:28:09 |  84.1%\n",
            "42080 | 4.4242 | 3.3e-05 | 1.18 | 38.8K | 02:28:10 |  84.2%\n",
            "42090 | 4.1863 | 3.3e-05 | 1.20 | 38.8K | 02:28:12 |  84.2%\n",
            "42100 | 4.3612 | 3.3e-05 | 1.22 | 38.8K | 02:28:14 |  84.2%\n",
            "42110 | 4.2094 | 3.3e-05 | 1.18 | 38.8K | 02:28:15 |  84.2%\n",
            "42120 | 3.9725 | 3.3e-05 | 1.19 | 38.8K | 02:28:17 |  84.2%\n",
            "42130 | 4.0765 | 3.2e-05 | 1.15 | 38.8K | 02:28:19 |  84.3%\n",
            "42140 | 4.2242 | 3.2e-05 | 1.17 | 38.8K | 02:28:21 |  84.3%\n",
            "42150 | 4.3712 | 3.2e-05 | 1.20 | 38.8K | 02:28:22 |  84.3%\n",
            "42160 | 4.1305 | 3.2e-05 | 1.19 | 38.8K | 02:28:24 |  84.3%\n",
            "42170 | 4.1885 | 3.2e-05 | 1.21 | 38.8K | 02:28:26 |  84.3%\n",
            "42180 | 4.3178 | 3.2e-05 | 1.19 | 38.8K | 02:28:27 |  84.4%\n",
            "42190 | 3.7286 | 3.2e-05 | 1.16 | 38.8K | 02:28:29 |  84.4%\n",
            "42200 | 4.1294 | 3.2e-05 | 1.21 | 38.8K | 02:28:31 |  84.4%\n",
            "42210 | 4.2849 | 3.2e-05 | 1.23 | 38.8K | 02:28:33 |  84.4%\n",
            "42220 | 4.3523 | 3.2e-05 | 1.17 | 38.8K | 02:28:34 |  84.4%\n",
            "42230 | 4.2104 | 3.2e-05 | 1.19 | 38.8K | 02:28:36 |  84.5%\n",
            "42240 | 4.3527 | 3.2e-05 | 1.23 | 38.8K | 02:28:38 |  84.5%\n",
            "42250 | 4.2728 | 3.1e-05 | 1.23 | 38.8K | 02:28:39 |  84.5%\n",
            "42260 | 4.2615 | 3.1e-05 | 1.17 | 38.8K | 02:28:41 |  84.5%\n",
            "42270 | 4.2216 | 3.1e-05 | 1.19 | 38.8K | 02:28:43 |  84.5%\n",
            "42280 | 4.1024 | 3.1e-05 | 1.18 | 38.8K | 02:28:45 |  84.6%\n",
            "42290 | 4.2283 | 3.1e-05 | 1.19 | 38.8K | 02:28:46 |  84.6%\n",
            "42300 | 3.9497 | 3.1e-05 | 1.16 | 38.8K | 02:28:48 |  84.6%\n",
            "42310 | 4.1032 | 3.1e-05 | 1.25 | 38.8K | 02:28:50 |  84.6%\n",
            "42320 | 4.4322 | 3.1e-05 | 1.20 | 38.8K | 02:28:51 |  84.6%\n",
            "42330 | 3.8609 | 3.1e-05 | 1.16 | 38.8K | 02:28:53 |  84.7%\n",
            "42340 | 4.1485 | 3.1e-05 | 1.22 | 38.8K | 02:28:55 |  84.7%\n",
            "42350 | 4.2368 | 3.1e-05 | 1.22 | 38.8K | 02:28:57 |  84.7%\n",
            "42360 | 4.0846 | 3.1e-05 | 1.16 | 38.8K | 02:28:58 |  84.7%\n",
            "42370 | 4.2419 | 3.1e-05 | 1.22 | 38.8K | 02:29:00 |  84.7%\n",
            "42380 | 4.1256 | 3.0e-05 | 1.20 | 38.8K | 02:29:02 |  84.8%\n",
            "42390 | 4.0672 | 3.0e-05 | 1.28 | 38.8K | 02:29:03 |  84.8%\n",
            "42400 | 4.1530 | 3.0e-05 | 1.20 | 38.8K | 02:29:05 |  84.8%\n",
            "42410 | 4.2456 | 3.0e-05 | 1.22 | 38.8K | 02:29:07 |  84.8%\n",
            "42420 | 4.2545 | 3.0e-05 | 1.22 | 38.8K | 02:29:09 |  84.8%\n",
            "42430 | 4.3285 | 3.0e-05 | 1.20 | 38.8K | 02:29:10 |  84.9%\n",
            "42440 | 3.6659 | 3.0e-05 | 1.19 | 38.8K | 02:29:12 |  84.9%\n",
            "42450 | 4.2723 | 3.0e-05 | 1.22 | 38.8K | 02:29:14 |  84.9%\n",
            "42460 | 4.0389 | 3.0e-05 | 1.18 | 38.8K | 02:29:15 |  84.9%\n",
            "42470 | 4.3972 | 3.0e-05 | 1.19 | 38.8K | 02:29:17 |  84.9%\n",
            "42480 | 4.3304 | 3.0e-05 | 1.23 | 38.8K | 02:29:19 |  85.0%\n",
            "42490 | 4.3509 | 3.0e-05 | 1.20 | 38.8K | 02:29:21 |  85.0%\n",
            "42500 | 4.3755 | 3.0e-05 | 1.20 | 38.8K | 02:29:22 |  85.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 42500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1320\n",
            "  Perplexity: 62.30\n",
            "  Train loss (avg): 4.1920\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        sƒ±caklƒ±klarƒ±nƒ±n a≈üƒ±rƒ±, orta ve y√ºksek olduƒüu, subtropikal havalarƒ±n ve deniz i≈ügalinin en yoƒüun olduƒüu g√ºnler. Hava sƒ±caklƒ±klarƒ±nƒ±n d√º≈ü√ºk olmasƒ± da en b√ºy√ºk hava bo≈üluƒüu olabilir. Ayrƒ±ca hava sƒ±caklƒ±ƒüƒ±nƒ±n\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Berlin'de bulunan Berlin'in en b√ºy√ºk ≈üehri olan Berlin, ƒ∞stanbul'a bir √ßok il ve se√ßenekle geliyor. Berlin'in en √ºnl√º tarihi b√∂lgeleri arasƒ±nda yer alan Berlin, Berlin'in en\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , daha fazla bilgi ve deneyimle bir araya getiren bir yazƒ±lƒ±mdƒ±r. Bilgi bilimlerinin ortaya koyduƒüu veri ve teknolojisi i√ßin bilgiye ihtiya√ß duyulur. Ara≈ütƒ±rmacƒ±lar, bilginin b√ºy√ºk bir b√∂l√ºm√º, bilgiyi karma≈üƒ±k hale getiriyor\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:26:24\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "42510 | 4.3140 | 2.9e-05 | 1.19 | 38.8K | 02:29:41 |  85.0%\n",
            "42520 | 4.0823 | 2.9e-05 | 1.14 | 38.8K | 02:29:43 |  85.0%\n",
            "42530 | 4.3232 | 2.9e-05 | 1.18 | 38.8K | 02:29:45 |  85.1%\n",
            "42540 | 4.2324 | 2.9e-05 | 1.20 | 38.8K | 02:29:46 |  85.1%\n",
            "42550 | 4.2710 | 2.9e-05 | 1.19 | 38.8K | 02:29:48 |  85.1%\n",
            "42560 | 3.8263 | 2.9e-05 | 1.15 | 38.8K | 02:29:50 |  85.1%\n",
            "42570 | 4.2639 | 2.9e-05 | 1.19 | 38.8K | 02:29:52 |  85.1%\n",
            "42580 | 4.4594 | 2.9e-05 | 1.19 | 38.8K | 02:29:53 |  85.2%\n",
            "42590 | 4.2128 | 2.9e-05 | 1.20 | 38.8K | 02:29:55 |  85.2%\n",
            "42600 | 4.4863 | 2.9e-05 | 1.23 | 38.8K | 02:29:57 |  85.2%\n",
            "42610 | 4.1289 | 2.9e-05 | 1.22 | 38.8K | 02:29:58 |  85.2%\n",
            "42620 | 3.9618 | 2.9e-05 | 1.18 | 38.8K | 02:30:00 |  85.2%\n",
            "42630 | 4.1861 | 2.9e-05 | 1.19 | 38.8K | 02:30:02 |  85.3%\n",
            "42640 | 4.0141 | 2.8e-05 | 1.22 | 38.8K | 02:30:04 |  85.3%\n",
            "42650 | 4.3093 | 2.8e-05 | 1.20 | 38.8K | 02:30:05 |  85.3%\n",
            "42660 | 4.3872 | 2.8e-05 | 1.20 | 38.8K | 02:30:07 |  85.3%\n",
            "42670 | 4.3273 | 2.8e-05 | 1.21 | 38.8K | 02:30:09 |  85.3%\n",
            "42680 | 4.1191 | 2.8e-05 | 1.22 | 38.8K | 02:30:10 |  85.4%\n",
            "42690 | 4.1602 | 2.8e-05 | 1.23 | 38.8K | 02:30:12 |  85.4%\n",
            "42700 | 4.1968 | 2.8e-05 | 1.19 | 38.8K | 02:30:14 |  85.4%\n",
            "42710 | 4.1870 | 2.8e-05 | 1.17 | 38.8K | 02:30:16 |  85.4%\n",
            "42720 | 4.3464 | 2.8e-05 | 1.17 | 38.8K | 02:30:17 |  85.4%\n",
            "42730 | 3.9048 | 2.8e-05 | 1.15 | 38.8K | 02:30:19 |  85.5%\n",
            "42740 | 4.1552 | 2.8e-05 | 1.22 | 38.8K | 02:30:21 |  85.5%\n",
            "42750 | 3.8792 | 2.8e-05 | 1.21 | 38.8K | 02:30:22 |  85.5%\n",
            "42760 | 4.0629 | 2.8e-05 | 1.22 | 38.8K | 02:30:24 |  85.5%\n",
            "42770 | 4.5381 | 2.7e-05 | 1.23 | 38.8K | 02:30:26 |  85.5%\n",
            "42780 | 4.3646 | 2.7e-05 | 1.31 | 38.8K | 02:30:28 |  85.6%\n",
            "42790 | 4.1117 | 2.7e-05 | 1.18 | 38.8K | 02:30:29 |  85.6%\n",
            "42800 | 4.1069 | 2.7e-05 | 1.18 | 38.8K | 02:30:31 |  85.6%\n",
            "42810 | 4.2323 | 2.7e-05 | 1.19 | 38.8K | 02:30:33 |  85.6%\n",
            "42820 | 3.9554 | 2.7e-05 | 1.17 | 38.8K | 02:30:34 |  85.6%\n",
            "42830 | 4.0745 | 2.7e-05 | 1.19 | 38.8K | 02:30:36 |  85.7%\n",
            "42840 | 4.1108 | 2.7e-05 | 1.20 | 38.8K | 02:30:38 |  85.7%\n",
            "42850 | 4.3338 | 2.7e-05 | 1.27 | 38.8K | 02:30:40 |  85.7%\n",
            "42860 | 4.5386 | 2.7e-05 | 1.18 | 38.8K | 02:30:41 |  85.7%\n",
            "42870 | 4.0168 | 2.7e-05 | 1.17 | 38.8K | 02:30:43 |  85.7%\n",
            "42880 | 4.0792 | 2.7e-05 | 1.16 | 38.8K | 02:30:45 |  85.8%\n",
            "42890 | 4.2993 | 2.7e-05 | 1.25 | 38.8K | 02:30:46 |  85.8%\n",
            "42900 | 4.1449 | 2.7e-05 | 1.21 | 38.8K | 02:30:48 |  85.8%\n",
            "42910 | 4.1896 | 2.6e-05 | 1.18 | 38.8K | 02:30:50 |  85.8%\n",
            "42920 | 4.0111 | 2.6e-05 | 1.22 | 38.8K | 02:30:51 |  85.8%\n",
            "42930 | 3.4173 | 2.6e-05 | 1.17 | 38.8K | 02:30:53 |  85.9%\n",
            "42940 | 3.9059 | 2.6e-05 | 1.23 | 38.8K | 02:30:55 |  85.9%\n",
            "42950 | 4.3716 | 2.6e-05 | 1.22 | 38.8K | 02:30:57 |  85.9%\n",
            "42960 | 4.1079 | 2.6e-05 | 1.21 | 38.8K | 02:30:58 |  85.9%\n",
            "42970 | 4.4587 | 2.6e-05 | 1.20 | 38.9K | 02:31:00 |  85.9%\n",
            "42980 | 4.3622 | 2.6e-05 | 1.24 | 38.9K | 02:31:02 |  86.0%\n",
            "42990 | 4.3699 | 2.6e-05 | 1.18 | 38.9K | 02:31:03 |  86.0%\n",
            "43000 | 4.2711 | 2.6e-05 | 1.23 | 38.9K | 02:31:05 |  86.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 43000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.0995\n",
            "  Perplexity: 60.31\n",
            "  Train loss (avg): 4.1748\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        durumu ne olursa olsun b√∂yle deƒüil. Ne kadar k√∂t√º hava var, ne kadar ki≈üi hava ≈üartlarƒ± uygun olursa olsun soƒüuk hava, √ßok sƒ±cak deƒüil. Hava ne kadar soƒüuksa o kadar soƒüuk olacak. Hava yaƒüƒ±≈ülƒ±\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        olan Antalya'da, se√ßmenlerinin b√ºy√ºk √ßoƒüunluƒüu oy kullanabilecek. Antalya'da se√ßmenlerin √ßoƒüu oy kullanmayacak. Ayrƒ±ca Antalya, T√ºrkiye'nin d√∂rt bir yanƒ±ndan se√ßmenlerin y√ºzde 10'u oy kullanacak\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , korku ve korku ile sava≈ümayƒ± √∂ƒüreniyor. ABD‚Äôde ekip, bilim insanlarƒ± ve bilim adamlarƒ±, s√ºper kahramanlar gibi yeni bilim adamlarƒ± ve bilim adamlarƒ±nƒ±n bir araya gelip, yeni bir uzay aracƒ± geli≈ütir\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.0995)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:24:39\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "43010 | 4.3080 | 2.6e-05 | 1.27 | 38.8K | 02:31:30 |  86.0%\n",
            "43020 | 3.8790 | 2.6e-05 | 1.17 | 38.8K | 02:31:32 |  86.0%\n",
            "43030 | 4.1775 | 2.6e-05 | 1.21 | 38.8K | 02:31:34 |  86.1%\n",
            "43040 | 4.4308 | 2.6e-05 | 1.20 | 38.8K | 02:31:35 |  86.1%\n",
            "43050 | 4.4571 | 2.5e-05 | 1.24 | 38.8K | 02:31:37 |  86.1%\n",
            "43060 | 4.2377 | 2.5e-05 | 1.21 | 38.8K | 02:31:39 |  86.1%\n",
            "43070 | 4.1611 | 2.5e-05 | 1.21 | 38.8K | 02:31:40 |  86.1%\n",
            "43080 | 4.1910 | 2.5e-05 | 1.23 | 38.8K | 02:31:42 |  86.2%\n",
            "43090 | 4.2242 | 2.5e-05 | 1.21 | 38.8K | 02:31:44 |  86.2%\n",
            "43100 | 4.2229 | 2.5e-05 | 1.17 | 38.8K | 02:31:46 |  86.2%\n",
            "43110 | 4.0368 | 2.5e-05 | 1.20 | 38.8K | 02:31:47 |  86.2%\n",
            "43120 | 4.2474 | 2.5e-05 | 1.19 | 38.8K | 02:31:49 |  86.2%\n",
            "43130 | 4.0239 | 2.5e-05 | 1.28 | 38.8K | 02:31:51 |  86.3%\n",
            "43140 | 4.3564 | 2.5e-05 | 1.23 | 38.8K | 02:31:52 |  86.3%\n",
            "43150 | 4.1175 | 2.5e-05 | 1.20 | 38.8K | 02:31:54 |  86.3%\n",
            "43160 | 4.0341 | 2.5e-05 | 1.18 | 38.8K | 02:31:56 |  86.3%\n",
            "43170 | 4.2497 | 2.5e-05 | 1.20 | 38.8K | 02:31:58 |  86.3%\n",
            "43180 | 4.1510 | 2.5e-05 | 1.17 | 38.8K | 02:31:59 |  86.4%\n",
            "43190 | 4.2160 | 2.4e-05 | 1.21 | 38.8K | 02:32:01 |  86.4%\n",
            "43200 | 4.3573 | 2.4e-05 | 1.22 | 38.8K | 02:32:03 |  86.4%\n",
            "43210 | 4.2973 | 2.4e-05 | 1.22 | 38.8K | 02:32:04 |  86.4%\n",
            "43220 | 4.2032 | 2.4e-05 | 1.19 | 38.8K | 02:32:06 |  86.4%\n",
            "43230 | 3.8631 | 2.4e-05 | 1.23 | 38.8K | 02:32:08 |  86.5%\n",
            "43240 | 4.1248 | 2.4e-05 | 1.16 | 38.8K | 02:32:09 |  86.5%\n",
            "43250 | 4.1538 | 2.4e-05 | 1.24 | 38.8K | 02:32:11 |  86.5%\n",
            "43260 | 3.9799 | 2.4e-05 | 1.31 | 38.8K | 02:32:13 |  86.5%\n",
            "43270 | 4.0383 | 2.4e-05 | 1.15 | 38.8K | 02:32:15 |  86.5%\n",
            "43280 | 4.2831 | 2.4e-05 | 1.18 | 38.8K | 02:32:16 |  86.6%\n",
            "43290 | 4.2699 | 2.4e-05 | 1.23 | 38.8K | 02:32:18 |  86.6%\n",
            "43300 | 4.1255 | 2.4e-05 | 1.24 | 38.8K | 02:32:20 |  86.6%\n",
            "43310 | 4.1918 | 2.4e-05 | 1.19 | 38.8K | 02:32:21 |  86.6%\n",
            "43320 | 4.4084 | 2.4e-05 | 1.19 | 38.8K | 02:32:23 |  86.6%\n",
            "43330 | 4.4532 | 2.3e-05 | 1.26 | 38.8K | 02:32:25 |  86.7%\n",
            "43340 | 4.4704 | 2.3e-05 | 1.23 | 38.8K | 02:32:27 |  86.7%\n",
            "43350 | 4.2847 | 2.3e-05 | 1.19 | 38.8K | 02:32:28 |  86.7%\n",
            "43360 | 4.0134 | 2.3e-05 | 1.23 | 38.8K | 02:32:30 |  86.7%\n",
            "43370 | 3.6506 | 2.3e-05 | 1.19 | 38.8K | 02:32:32 |  86.7%\n",
            "43380 | 4.2095 | 2.3e-05 | 1.19 | 38.8K | 02:32:33 |  86.8%\n",
            "43390 | 4.0956 | 2.3e-05 | 1.23 | 38.8K | 02:32:35 |  86.8%\n",
            "43400 | 4.3115 | 2.3e-05 | 1.19 | 38.8K | 02:32:37 |  86.8%\n",
            "43410 | 4.2161 | 2.3e-05 | 1.17 | 38.8K | 02:32:39 |  86.8%\n",
            "43420 | 4.4108 | 2.3e-05 | 1.20 | 38.8K | 02:32:40 |  86.8%\n",
            "43430 | 4.3105 | 2.3e-05 | 1.21 | 38.8K | 02:32:42 |  86.9%\n",
            "43440 | 3.7063 | 2.3e-05 | 1.17 | 38.8K | 02:32:44 |  86.9%\n",
            "43450 | 4.2299 | 2.3e-05 | 1.20 | 38.8K | 02:32:45 |  86.9%\n",
            "43460 | 4.0294 | 2.3e-05 | 1.27 | 38.8K | 02:32:47 |  86.9%\n",
            "43470 | 4.4379 | 2.2e-05 | 1.20 | 38.8K | 02:32:49 |  86.9%\n",
            "43480 | 4.2214 | 2.2e-05 | 1.17 | 38.8K | 02:32:51 |  87.0%\n",
            "43490 | 4.1934 | 2.2e-05 | 1.21 | 38.8K | 02:32:52 |  87.0%\n",
            "43500 | 4.2128 | 2.2e-05 | 1.21 | 38.8K | 02:32:54 |  87.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 43500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1171\n",
            "  Perplexity: 61.38\n",
            "  Train loss (avg): 4.1806\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        sƒ±caklƒ±ƒüƒ±nƒ±n, pek √ßok ki≈üinin √ºzerindedir. Hava sƒ±caklƒ±ƒüƒ±nƒ±n, havanƒ±n sƒ±caklƒ±ƒüƒ±nƒ±n arttƒ±ƒüƒ± bir ortamda, hava sƒ±caklƒ±ƒüƒ±nƒ±n sandƒ±ƒüƒ±nƒ±zdan √ßok daha fazla olduƒüunu s√∂yleyebilir, ama sƒ±caklƒ±k, bu sƒ±caklƒ±ƒüƒ±n ya≈üandƒ±ƒüƒ±\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        olarak bilinen en b√ºy√ºk ≈üehri haline gelen ƒ∞stanbul, tarihiyle de en √ßok ilgi √ßeken kentlerden biri. Tarihi ve doƒüal g√ºzellikleri ile dikkat √ßeken ƒ∞stanbul, eski yapƒ±larƒ±yla da dikkat √ßekiyor. ƒ∞stanbul'un en\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , yapay zeka ve yapay zekanƒ±n kazandƒ±rdƒ±ƒüƒ± bir√ßok yeniliƒüi √ºretti. Yapay zeka teknolojilerine kar≈üƒ± yeni bir eƒüilim daha ve yapay zekayƒ± geli≈ütiriyor. Yapay zeka, yapay zeka ve yapay zeka teknoloj\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:22:53\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "43510 | 4.2459 | 2.2e-05 | 1.22 | 38.8K | 02:33:13 |  87.0%\n",
            "43520 | 4.2840 | 2.2e-05 | 1.20 | 38.8K | 02:33:15 |  87.0%\n",
            "43530 | 4.2348 | 2.2e-05 | 1.18 | 38.8K | 02:33:16 |  87.1%\n",
            "43540 | 4.2950 | 2.2e-05 | 1.20 | 38.8K | 02:33:18 |  87.1%\n",
            "43550 | 4.0484 | 2.2e-05 | 1.21 | 38.8K | 02:33:20 |  87.1%\n",
            "43560 | 4.1595 | 2.2e-05 | 1.22 | 38.8K | 02:33:22 |  87.1%\n",
            "43570 | 4.2532 | 2.2e-05 | 1.21 | 38.8K | 02:33:23 |  87.1%\n",
            "43580 | 4.1825 | 2.2e-05 | 1.19 | 38.8K | 02:33:25 |  87.2%\n",
            "43590 | 4.3231 | 2.2e-05 | 1.22 | 38.8K | 02:33:27 |  87.2%\n",
            "43600 | 4.1548 | 2.2e-05 | 1.19 | 38.8K | 02:33:28 |  87.2%\n",
            "43610 | 4.3159 | 2.2e-05 | 1.24 | 38.8K | 02:33:30 |  87.2%\n",
            "43620 | 4.2594 | 2.1e-05 | 1.22 | 38.8K | 02:33:32 |  87.2%\n",
            "43630 | 4.2207 | 2.1e-05 | 1.18 | 38.8K | 02:33:34 |  87.3%\n",
            "43640 | 4.0473 | 2.1e-05 | 1.20 | 38.8K | 02:33:35 |  87.3%\n",
            "43650 | 4.3506 | 2.1e-05 | 1.26 | 38.8K | 02:33:37 |  87.3%\n",
            "43660 | 4.1090 | 2.1e-05 | 1.24 | 38.8K | 02:33:39 |  87.3%\n",
            "43670 | 4.2422 | 2.1e-05 | 1.23 | 38.8K | 02:33:40 |  87.3%\n",
            "43680 | 4.4093 | 2.1e-05 | 1.19 | 38.8K | 02:33:42 |  87.4%\n",
            "43690 | 4.3417 | 2.1e-05 | 1.22 | 38.8K | 02:33:44 |  87.4%\n",
            "43700 | 3.9710 | 2.1e-05 | 1.23 | 38.8K | 02:33:46 |  87.4%\n",
            "43710 | 4.2761 | 2.1e-05 | 1.20 | 38.8K | 02:33:47 |  87.4%\n",
            "43720 | 4.0410 | 2.1e-05 | 1.20 | 38.8K | 02:33:49 |  87.4%\n",
            "43730 | 4.1073 | 2.1e-05 | 1.23 | 38.8K | 02:33:51 |  87.5%\n",
            "43740 | 4.1027 | 2.1e-05 | 1.23 | 38.8K | 02:33:52 |  87.5%\n",
            "43750 | 4.0380 | 2.1e-05 | 1.22 | 38.8K | 02:33:54 |  87.5%\n",
            "43760 | 4.1057 | 2.1e-05 | 1.24 | 38.8K | 02:33:56 |  87.5%\n",
            "43770 | 4.1124 | 2.1e-05 | 1.24 | 38.8K | 02:33:58 |  87.5%\n",
            "43780 | 4.0588 | 2.0e-05 | 1.22 | 38.8K | 02:33:59 |  87.6%\n",
            "43790 | 4.1013 | 2.0e-05 | 1.17 | 38.8K | 02:34:01 |  87.6%\n",
            "43800 | 4.2311 | 2.0e-05 | 1.17 | 38.8K | 02:34:03 |  87.6%\n",
            "43810 | 4.2157 | 2.0e-05 | 1.24 | 38.8K | 02:34:04 |  87.6%\n",
            "43820 | 3.9614 | 2.0e-05 | 1.25 | 38.8K | 02:34:06 |  87.6%\n",
            "43830 | 3.8415 | 2.0e-05 | 1.21 | 38.8K | 02:34:08 |  87.7%\n",
            "43840 | 4.3705 | 2.0e-05 | 1.19 | 38.8K | 02:34:10 |  87.7%\n",
            "43850 | 4.3461 | 2.0e-05 | 1.21 | 38.8K | 02:34:11 |  87.7%\n",
            "43860 | 4.2225 | 2.0e-05 | 1.22 | 38.8K | 02:34:13 |  87.7%\n",
            "43870 | 4.1511 | 2.0e-05 | 1.20 | 38.8K | 02:34:15 |  87.7%\n",
            "43880 | 4.1893 | 2.0e-05 | 1.18 | 38.8K | 02:34:16 |  87.8%\n",
            "43890 | 4.1932 | 2.0e-05 | 1.20 | 38.8K | 02:34:18 |  87.8%\n",
            "43900 | 4.1982 | 2.0e-05 | 1.20 | 38.8K | 02:34:20 |  87.8%\n",
            "43910 | 4.0821 | 2.0e-05 | 1.21 | 38.8K | 02:34:21 |  87.8%\n",
            "43920 | 4.2649 | 2.0e-05 | 1.20 | 38.8K | 02:34:23 |  87.8%\n",
            "43930 | 4.2006 | 1.9e-05 | 1.19 | 38.8K | 02:34:25 |  87.9%\n",
            "43940 | 4.3699 | 1.9e-05 | 1.18 | 38.8K | 02:34:27 |  87.9%\n",
            "43950 | 4.1016 | 1.9e-05 | 1.18 | 38.8K | 02:34:28 |  87.9%\n",
            "43960 | 4.2265 | 1.9e-05 | 1.18 | 38.8K | 02:34:30 |  87.9%\n",
            "43970 | 4.3259 | 1.9e-05 | 1.21 | 38.8K | 02:34:32 |  87.9%\n",
            "43980 | 4.2984 | 1.9e-05 | 1.22 | 38.8K | 02:34:33 |  88.0%\n",
            "43990 | 3.8999 | 1.9e-05 | 1.16 | 38.9K | 02:34:35 |  88.0%\n",
            "44000 | 4.1408 | 1.9e-05 | 1.19 | 38.9K | 02:34:37 |  88.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 44000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1278\n",
            "  Perplexity: 62.04\n",
            "  Train loss (avg): 4.1717\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        ve deniz seviyelerinin aynƒ± olmasƒ± nedeniyle iki √ºlkenin i√ß ve dƒ±≈ü politikasƒ±nda belirleyici olacak olan ekonomi, politika ve politikalarƒ±n yanƒ± sƒ±ra, dƒ±≈ü politikanƒ±n i√ß politikada da etki etmesini saƒülayacak. En azƒ±ndan T√ºrkiye\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Moskova'da d√ºzenlenen 2. D√ºnya Sava≈üƒ±'na katƒ±lanlar arasƒ±nda Sovyetler Birliƒüi'nin dƒ±≈üƒ±nda kalan Putin'in kendisine soru sormasƒ± √ºzerine Moskova'da bulunan Prof. Dr. Alberta Von Ver\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , insanƒ±n ya≈üamsal geli≈üiminin anahtarƒ±nƒ± olu≈üturuyor. Bir bilim insanƒ±, g√ºnl√ºk ya≈üamla ilgili eksikleri, problemleri, ba≈üarƒ±sƒ±zlƒ±klarƒ± ve kusurlarƒ± tespit etmek i√ßin karma≈üƒ±k √ß√∂z√ºmler sunuyor. Anasayfa > √úr√ºn &\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:21:07\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "44010 | 4.4707 | 1.9e-05 | 1.21 | 38.8K | 02:34:56 |  88.0%\n",
            "44020 | 4.4252 | 1.9e-05 | 1.24 | 38.8K | 02:34:58 |  88.0%\n",
            "44030 | 4.3678 | 1.9e-05 | 1.18 | 38.8K | 02:34:59 |  88.1%\n",
            "44040 | 4.3997 | 1.9e-05 | 1.20 | 38.8K | 02:35:01 |  88.1%\n",
            "44050 | 4.0411 | 1.9e-05 | 1.27 | 38.8K | 02:35:03 |  88.1%\n",
            "44060 | 4.1459 | 1.9e-05 | 1.17 | 38.8K | 02:35:04 |  88.1%\n",
            "44070 | 4.1652 | 1.9e-05 | 1.21 | 38.8K | 02:35:06 |  88.1%\n",
            "44080 | 4.3966 | 1.9e-05 | 1.18 | 38.8K | 02:35:08 |  88.2%\n",
            "44090 | 4.0337 | 1.8e-05 | 1.21 | 38.8K | 02:35:10 |  88.2%\n",
            "44100 | 4.0078 | 1.8e-05 | 1.22 | 38.8K | 02:35:11 |  88.2%\n",
            "44110 | 4.3396 | 1.8e-05 | 1.21 | 38.8K | 02:35:13 |  88.2%\n",
            "44120 | 4.2635 | 1.8e-05 | 1.21 | 38.8K | 02:35:15 |  88.2%\n",
            "44130 | 4.5740 | 1.8e-05 | 1.25 | 38.8K | 02:35:16 |  88.3%\n",
            "44140 | 3.8597 | 1.8e-05 | 1.47 | 38.8K | 02:35:18 |  88.3%\n",
            "44150 | 4.2475 | 1.8e-05 | 1.20 | 38.8K | 02:35:20 |  88.3%\n",
            "44160 | 4.0466 | 1.8e-05 | 1.21 | 38.8K | 02:35:22 |  88.3%\n",
            "44170 | 4.1573 | 1.8e-05 | 1.20 | 38.8K | 02:35:23 |  88.3%\n",
            "44180 | 4.2714 | 1.8e-05 | 1.18 | 38.8K | 02:35:25 |  88.4%\n",
            "44190 | 4.2500 | 1.8e-05 | 1.22 | 38.8K | 02:35:27 |  88.4%\n",
            "44200 | 4.0255 | 1.8e-05 | 1.23 | 38.8K | 02:35:28 |  88.4%\n",
            "44210 | 3.8596 | 1.8e-05 | 1.18 | 38.8K | 02:35:30 |  88.4%\n",
            "44220 | 4.2403 | 1.8e-05 | 1.20 | 38.8K | 02:35:32 |  88.4%\n",
            "44230 | 4.1001 | 1.8e-05 | 1.23 | 38.8K | 02:35:34 |  88.5%\n",
            "44240 | 4.0771 | 1.8e-05 | 1.17 | 38.8K | 02:35:35 |  88.5%\n",
            "44250 | 4.2234 | 1.8e-05 | 1.24 | 38.8K | 02:35:37 |  88.5%\n",
            "44260 | 4.2654 | 1.7e-05 | 1.20 | 38.8K | 02:35:39 |  88.5%\n",
            "44270 | 4.1186 | 1.7e-05 | 1.18 | 38.8K | 02:35:40 |  88.5%\n",
            "44280 | 4.2886 | 1.7e-05 | 1.21 | 38.8K | 02:35:42 |  88.6%\n",
            "44290 | 4.0350 | 1.7e-05 | 1.20 | 38.8K | 02:35:44 |  88.6%\n",
            "44300 | 3.9652 | 1.7e-05 | 1.23 | 38.8K | 02:35:45 |  88.6%\n",
            "44310 | 3.8846 | 1.7e-05 | 1.24 | 38.8K | 02:35:47 |  88.6%\n",
            "44320 | 4.3041 | 1.7e-05 | 1.20 | 38.8K | 02:35:49 |  88.6%\n",
            "44330 | 4.3461 | 1.7e-05 | 1.20 | 38.8K | 02:35:51 |  88.7%\n",
            "44340 | 4.0148 | 1.7e-05 | 1.22 | 38.8K | 02:35:52 |  88.7%\n",
            "44350 | 4.2141 | 1.7e-05 | 1.21 | 38.8K | 02:35:54 |  88.7%\n",
            "44360 | 3.7641 | 1.7e-05 | 1.24 | 38.8K | 02:35:56 |  88.7%\n",
            "44370 | 4.0873 | 1.7e-05 | 1.27 | 38.8K | 02:35:57 |  88.7%\n",
            "44380 | 4.4406 | 1.7e-05 | 1.20 | 38.8K | 02:35:59 |  88.8%\n",
            "44390 | 4.4119 | 1.7e-05 | 1.20 | 38.8K | 02:36:01 |  88.8%\n",
            "44400 | 4.1117 | 1.7e-05 | 1.23 | 38.8K | 02:36:03 |  88.8%\n",
            "44410 | 4.1938 | 1.7e-05 | 1.26 | 38.8K | 02:36:04 |  88.8%\n",
            "44420 | 4.2238 | 1.6e-05 | 1.21 | 38.8K | 02:36:06 |  88.8%\n",
            "44430 | 4.4053 | 1.6e-05 | 1.23 | 38.9K | 02:36:08 |  88.9%\n",
            "44440 | 4.3458 | 1.6e-05 | 1.16 | 38.9K | 02:36:09 |  88.9%\n",
            "44450 | 4.4319 | 1.6e-05 | 1.28 | 38.9K | 02:36:11 |  88.9%\n",
            "44460 | 4.2694 | 1.6e-05 | 1.22 | 38.9K | 02:36:13 |  88.9%\n",
            "44470 | 4.3650 | 1.6e-05 | 1.21 | 38.9K | 02:36:15 |  88.9%\n",
            "44480 | 4.0591 | 1.6e-05 | 1.23 | 38.9K | 02:36:16 |  89.0%\n",
            "44490 | 4.5197 | 1.6e-05 | 1.21 | 38.9K | 02:36:18 |  89.0%\n",
            "44500 | 4.2240 | 1.6e-05 | 1.22 | 38.9K | 02:36:20 |  89.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 44500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1539\n",
            "  Perplexity: 63.68\n",
            "  Train loss (avg): 4.2032\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        sƒ±caklƒ±klarƒ±nƒ±n geldiƒüini g√∂rmek beni √ßok mutlu ediyor. Bu y√ºzden pek √ßok yerde bu sƒ±cakta hava sƒ±caklƒ±ƒüƒ± √ßok iyi geliyor. Hava sƒ±caklƒ±klarƒ±nƒ±n i√ß sƒ±caklƒ±ƒüƒ±nƒ±n y√ºksek olmasƒ± nedeniyle insanlar kendi aralarƒ±nda √ßok iyi anla≈üƒ±yor.\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Mara'da, aralarƒ±nda ABD Ba≈ükanƒ± Donald Trump'ƒ±n da bulunduƒüu 40 ki≈üilik bir grup, \"Para krizi, √ºlke i√ßin bir felakettir\" diyerek, \"birileri i√ß sava≈üa sokuyor\"\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        kullanƒ±larak geli≈ütirilecek olan bir oyunun ve bu oyunun ileri ya≈üta diƒüer oyunlardan farkƒ± ise oyunun donma ve donma hƒ±zlarƒ±na g√∂re farklƒ± bir ≈üekilde oynanmasƒ±dƒ±r. √ústelik oyun d√ºnyanƒ±n en hƒ±zlƒ± oyunu olarak kabul edilir\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.74\n",
            "     ETA: 00:19:21\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "44510 | 4.1552 | 1.6e-05 | 1.24 | 38.8K | 02:36:39 |  89.0%\n",
            "44520 | 4.2859 | 1.6e-05 | 1.24 | 38.8K | 02:36:40 |  89.0%\n",
            "44530 | 3.9635 | 1.6e-05 | 1.22 | 38.8K | 02:36:42 |  89.1%\n",
            "44540 | 4.2857 | 1.6e-05 | 1.25 | 38.8K | 02:36:44 |  89.1%\n",
            "44550 | 4.1181 | 1.6e-05 | 1.19 | 38.8K | 02:36:46 |  89.1%\n",
            "44560 | 4.1550 | 1.6e-05 | 1.20 | 38.8K | 02:36:47 |  89.1%\n",
            "44570 | 3.8829 | 1.6e-05 | 1.21 | 38.8K | 02:36:49 |  89.1%\n",
            "44580 | 4.2647 | 1.6e-05 | 1.19 | 38.8K | 02:36:51 |  89.2%\n",
            "44590 | 4.3732 | 1.6e-05 | 1.23 | 38.8K | 02:36:52 |  89.2%\n",
            "44600 | 3.9905 | 1.5e-05 | 1.21 | 38.8K | 02:36:54 |  89.2%\n",
            "44610 | 4.2043 | 1.5e-05 | 1.18 | 38.8K | 02:36:56 |  89.2%\n",
            "44620 | 4.1131 | 1.5e-05 | 1.18 | 38.8K | 02:36:58 |  89.2%\n",
            "44630 | 4.4288 | 1.5e-05 | 1.19 | 38.8K | 02:36:59 |  89.3%\n",
            "44640 | 4.4084 | 1.5e-05 | 1.19 | 38.8K | 02:37:01 |  89.3%\n",
            "44650 | 4.3600 | 1.5e-05 | 1.21 | 38.8K | 02:37:03 |  89.3%\n",
            "44660 | 4.4217 | 1.5e-05 | 1.21 | 38.8K | 02:37:04 |  89.3%\n",
            "44670 | 4.3260 | 1.5e-05 | 1.20 | 38.8K | 02:37:06 |  89.3%\n",
            "44680 | 4.2425 | 1.5e-05 | 1.24 | 38.8K | 02:37:08 |  89.4%\n",
            "44690 | 3.9245 | 1.5e-05 | 1.21 | 38.8K | 02:37:10 |  89.4%\n",
            "44700 | 4.0001 | 1.5e-05 | 1.19 | 38.8K | 02:37:11 |  89.4%\n",
            "44710 | 4.1232 | 1.5e-05 | 1.19 | 38.8K | 02:37:13 |  89.4%\n",
            "44720 | 3.8539 | 1.5e-05 | 1.20 | 38.8K | 02:37:15 |  89.4%\n",
            "44730 | 4.2158 | 1.5e-05 | 1.17 | 38.8K | 02:37:16 |  89.5%\n",
            "44740 | 3.8923 | 1.5e-05 | 1.16 | 38.8K | 02:37:18 |  89.5%\n",
            "44750 | 4.0720 | 1.5e-05 | 1.30 | 38.8K | 02:37:20 |  89.5%\n",
            "44760 | 4.2436 | 1.5e-05 | 1.21 | 38.8K | 02:37:22 |  89.5%\n",
            "44770 | 4.2464 | 1.5e-05 | 1.25 | 38.8K | 02:37:23 |  89.5%\n",
            "44780 | 4.0268 | 1.4e-05 | 1.20 | 38.8K | 02:37:25 |  89.6%\n",
            "44790 | 3.8857 | 1.4e-05 | 1.19 | 38.8K | 02:37:27 |  89.6%\n",
            "44800 | 4.1645 | 1.4e-05 | 1.20 | 38.8K | 02:37:28 |  89.6%\n",
            "44810 | 4.1437 | 1.4e-05 | 1.21 | 38.8K | 02:37:30 |  89.6%\n",
            "44820 | 4.0811 | 1.4e-05 | 1.17 | 38.8K | 02:37:32 |  89.6%\n",
            "44830 | 4.3421 | 1.4e-05 | 1.21 | 38.8K | 02:37:34 |  89.7%\n",
            "44840 | 4.2050 | 1.4e-05 | 1.21 | 38.8K | 02:37:35 |  89.7%\n",
            "44850 | 4.3611 | 1.4e-05 | 1.23 | 38.8K | 02:37:37 |  89.7%\n",
            "44860 | 4.0268 | 1.4e-05 | 1.19 | 38.9K | 02:37:39 |  89.7%\n",
            "44870 | 4.0827 | 1.4e-05 | 1.27 | 38.9K | 02:37:40 |  89.7%\n",
            "44880 | 4.1304 | 1.4e-05 | 1.22 | 38.9K | 02:37:42 |  89.8%\n",
            "44890 | 4.4083 | 1.4e-05 | 1.23 | 38.9K | 02:37:44 |  89.8%\n",
            "44900 | 3.9998 | 1.4e-05 | 1.24 | 38.9K | 02:37:46 |  89.8%\n",
            "44910 | 4.0504 | 1.4e-05 | 1.21 | 38.9K | 02:37:47 |  89.8%\n",
            "44920 | 4.1804 | 1.4e-05 | 1.22 | 38.9K | 02:37:49 |  89.8%\n",
            "44930 | 4.0684 | 1.4e-05 | 1.22 | 38.9K | 02:37:51 |  89.9%\n",
            "44940 | 4.1822 | 1.4e-05 | 1.24 | 38.9K | 02:37:52 |  89.9%\n",
            "44950 | 4.2793 | 1.4e-05 | 1.17 | 38.9K | 02:37:54 |  89.9%\n",
            "44960 | 4.2592 | 1.3e-05 | 1.23 | 38.9K | 02:37:56 |  89.9%\n",
            "44970 | 4.2508 | 1.3e-05 | 1.21 | 38.9K | 02:37:58 |  89.9%\n",
            "44980 | 4.1779 | 1.3e-05 | 1.20 | 38.9K | 02:37:59 |  90.0%\n",
            "44990 | 4.2457 | 1.3e-05 | 1.19 | 38.9K | 02:38:01 |  90.0%\n",
            "45000 | 4.2479 | 1.3e-05 | 1.22 | 38.9K | 02:38:03 |  90.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 45000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.0716\n",
            "  Perplexity: 58.65\n",
            "  Train loss (avg): 4.1761\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        larƒ±n soƒüumasƒ±yla beraber bazƒ± hava ≈üartlarƒ± da deƒüi≈üerek yerini de bƒ±raktƒ±. Hava ≈üartlarƒ±nƒ±n meydana geldiƒüi yer de ‚Äúzehirli‚Äù hava da diyebiliriz. Hava ≈üartlarƒ± da olduk√ßa uygun. Hava ≈üartlarƒ± da elveri≈üli\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Ankara'da T√ºrk Telekom'un aboneleri, kendi √ºlkelerinde iken, T√ºrk Telekom, uluslararasƒ± alanda 3 yƒ±l g√∂rev yapmƒ±≈ü T√ºrk Telekom ile s√∂zle≈üme imzaladƒ±. Yeni anla≈üma ile T√ºrk Telekom'un abonelerine mevcut fatura\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , insan biyolojisi ve doƒüanƒ±n ihtiya√ß duyduƒüu dejenerasyona baƒülƒ± olarak, ‚Äòkara delikler‚Äô olarak adlandƒ±rƒ±lan, milyonlarca yƒ±l √∂nce tamamlandƒ±ƒüƒ±nda, v√ºcudun canlƒ±lƒ±ƒüƒ±nƒ± ve dokusunu alƒ±p bu konudaki en\n",
            "\n",
            "  üèÜ Yeni en iyi model! (loss: 4.0716)\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:17:35\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "üíæ Checkpoint kaydediliyor: /content/drive/MyDrive/turkish_llm/checkpoints//checkpoint_step_45000.pt\n",
            "  ‚úÖ Checkpoint kaydedildi!\n",
            "\n",
            "45010 | 4.2918 | 1.3e-05 | 1.19 | 38.8K | 02:38:28 |  90.0%\n",
            "45020 | 4.3647 | 1.3e-05 | 1.22 | 38.8K | 02:38:30 |  90.0%\n",
            "45030 | 4.2132 | 1.3e-05 | 1.22 | 38.8K | 02:38:32 |  90.1%\n",
            "45040 | 4.4248 | 1.3e-05 | 1.22 | 38.8K | 02:38:34 |  90.1%\n",
            "45050 | 4.2824 | 1.3e-05 | 1.18 | 38.8K | 02:38:35 |  90.1%\n",
            "45060 | 4.1765 | 1.3e-05 | 1.19 | 38.8K | 02:38:37 |  90.1%\n",
            "45070 | 4.1361 | 1.3e-05 | 1.19 | 38.8K | 02:38:39 |  90.1%\n",
            "45080 | 4.2895 | 1.3e-05 | 1.22 | 38.8K | 02:38:40 |  90.2%\n",
            "45090 | 4.0855 | 1.3e-05 | 1.18 | 38.8K | 02:38:42 |  90.2%\n",
            "45100 | 4.2344 | 1.3e-05 | 1.19 | 38.8K | 02:38:44 |  90.2%\n",
            "45110 | 4.1776 | 1.3e-05 | 1.22 | 38.8K | 02:38:46 |  90.2%\n",
            "45120 | 4.0848 | 1.3e-05 | 1.18 | 38.8K | 02:38:47 |  90.2%\n",
            "45130 | 4.1196 | 1.3e-05 | 1.19 | 38.8K | 02:38:49 |  90.3%\n",
            "45140 | 4.3721 | 1.3e-05 | 1.20 | 38.8K | 02:38:51 |  90.3%\n",
            "45150 | 4.1850 | 1.2e-05 | 1.25 | 38.8K | 02:38:52 |  90.3%\n",
            "45160 | 4.1827 | 1.2e-05 | 1.22 | 38.8K | 02:38:54 |  90.3%\n",
            "45170 | 4.1391 | 1.2e-05 | 1.30 | 38.8K | 02:38:56 |  90.3%\n",
            "45180 | 4.2133 | 1.2e-05 | 1.19 | 38.8K | 02:38:58 |  90.4%\n",
            "45190 | 4.1193 | 1.2e-05 | 1.20 | 38.8K | 02:38:59 |  90.4%\n",
            "45200 | 4.1712 | 1.2e-05 | 1.23 | 38.8K | 02:39:01 |  90.4%\n",
            "45210 | 4.2496 | 1.2e-05 | 1.21 | 38.8K | 02:39:03 |  90.4%\n",
            "45220 | 4.4418 | 1.2e-05 | 1.20 | 38.8K | 02:39:04 |  90.4%\n",
            "45230 | 3.9243 | 1.2e-05 | 1.23 | 38.8K | 02:39:06 |  90.5%\n",
            "45240 | 4.0449 | 1.2e-05 | 1.23 | 38.8K | 02:39:08 |  90.5%\n",
            "45250 | 4.3864 | 1.2e-05 | 1.20 | 38.8K | 02:39:10 |  90.5%\n",
            "45260 | 4.2003 | 1.2e-05 | 1.22 | 38.8K | 02:39:11 |  90.5%\n",
            "45270 | 4.1052 | 1.2e-05 | 1.19 | 38.8K | 02:39:13 |  90.5%\n",
            "45280 | 4.1124 | 1.2e-05 | 1.18 | 38.8K | 02:39:15 |  90.6%\n",
            "45290 | 4.2958 | 1.2e-05 | 1.23 | 38.8K | 02:39:16 |  90.6%\n",
            "45300 | 4.1553 | 1.2e-05 | 1.18 | 38.8K | 02:39:18 |  90.6%\n",
            "45310 | 4.2233 | 1.2e-05 | 1.19 | 38.8K | 02:39:20 |  90.6%\n",
            "45320 | 4.2672 | 1.2e-05 | 1.22 | 38.8K | 02:39:22 |  90.6%\n",
            "45330 | 4.1862 | 1.2e-05 | 1.24 | 38.8K | 02:39:23 |  90.7%\n",
            "45340 | 4.1017 | 1.2e-05 | 1.23 | 38.8K | 02:39:25 |  90.7%\n",
            "45350 | 3.7544 | 1.1e-05 | 1.22 | 38.8K | 02:39:27 |  90.7%\n",
            "45360 | 3.8041 | 1.1e-05 | 1.25 | 38.8K | 02:39:28 |  90.7%\n",
            "45370 | 4.3059 | 1.1e-05 | 1.21 | 38.8K | 02:39:30 |  90.7%\n",
            "45380 | 4.2880 | 1.1e-05 | 1.19 | 38.8K | 02:39:32 |  90.8%\n",
            "45390 | 4.2507 | 1.1e-05 | 1.23 | 38.8K | 02:39:34 |  90.8%\n",
            "45400 | 4.5418 | 1.1e-05 | 1.20 | 38.8K | 02:39:35 |  90.8%\n",
            "45410 | 4.3438 | 1.1e-05 | 1.21 | 38.8K | 02:39:37 |  90.8%\n",
            "45420 | 4.3408 | 1.1e-05 | 1.24 | 38.8K | 02:39:39 |  90.8%\n",
            "45430 | 4.0955 | 1.1e-05 | 1.18 | 38.8K | 02:39:40 |  90.9%\n",
            "45440 | 4.1164 | 1.1e-05 | 1.21 | 38.8K | 02:39:42 |  90.9%\n",
            "45450 | 4.2795 | 1.1e-05 | 1.22 | 38.8K | 02:39:44 |  90.9%\n",
            "45460 | 4.1567 | 1.1e-05 | 1.20 | 38.8K | 02:39:46 |  90.9%\n",
            "45470 | 4.2348 | 1.1e-05 | 1.21 | 38.9K | 02:39:47 |  90.9%\n",
            "45480 | 4.0809 | 1.1e-05 | 1.19 | 38.9K | 02:39:49 |  91.0%\n",
            "45490 | 4.3230 | 1.1e-05 | 1.21 | 38.9K | 02:39:51 |  91.0%\n",
            "45500 | 4.0940 | 1.1e-05 | 1.21 | 38.9K | 02:39:52 |  91.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 45500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.0948\n",
            "  Perplexity: 60.03\n",
            "  Train loss (avg): 4.1499\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        durumu iyi, hava sƒ±caklƒ±ƒüƒ± iyi, yaƒümurda yaƒüan yaƒümur nedeniyle √ßok sƒ±cak. √á√ºnk√º bir √ßok sebebi var. Her sene yaƒümur yaƒüƒ±yor. Aldƒ±ƒüƒ±mƒ±zdan beri hava √ßok soƒüuk. Hava bu sƒ±caklardan\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Ankara'da bulunan ve son bir yƒ±l i√ßerisinde ya≈üanan trafik kazalarƒ± ve kazalarƒ±n azaldƒ±ƒüƒ± bildirildi. Peki, Ankara'da bu kazalar ne oldu? Ankara'da son bir yƒ±l i√ßerisinde ya≈üanan trafik\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , ‚Äòen eski √ßaƒülardan g√ºn√ºm√ºze, ‚Äòen eski √ßaƒülardan g√ºn√ºm√ºze‚Äô ve ‚Äòen eski √ßaƒülardan bug√ºne‚Äô kadar pek √ßok alanƒ±nda ba≈üarƒ±lƒ± olmu≈ü ve bir√ßok alanda ba≈üarƒ±lƒ± √ßalƒ±≈ümalara imza atmƒ±≈ü oldu. Bu sayede\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.73\n",
            "     ETA: 00:15:50\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "45510 | 3.9215 | 1.1e-05 | 1.20 | 38.8K | 02:40:11 |  91.0%\n",
            "45520 | 4.3178 | 1.1e-05 | 1.22 | 38.8K | 02:40:13 |  91.0%\n",
            "45530 | 3.9412 | 1.1e-05 | 1.24 | 38.8K | 02:40:15 |  91.1%\n",
            "45540 | 4.4666 | 1.1e-05 | 1.22 | 38.8K | 02:40:16 |  91.1%\n",
            "45550 | 4.2990 | 1.1e-05 | 1.22 | 38.8K | 02:40:18 |  91.1%\n",
            "45560 | 4.4814 | 1.0e-05 | 1.19 | 38.8K | 02:40:20 |  91.1%\n",
            "45570 | 4.3763 | 1.0e-05 | 1.26 | 38.8K | 02:40:22 |  91.1%\n",
            "45580 | 4.0745 | 1.0e-05 | 1.20 | 38.8K | 02:40:23 |  91.2%\n",
            "45590 | 4.1927 | 1.0e-05 | 1.20 | 38.8K | 02:40:25 |  91.2%\n",
            "45600 | 3.7567 | 1.0e-05 | 1.23 | 38.8K | 02:40:27 |  91.2%\n",
            "45610 | 4.1508 | 1.0e-05 | 1.27 | 38.8K | 02:40:28 |  91.2%\n",
            "45620 | 4.3240 | 1.0e-05 | 1.19 | 38.8K | 02:40:30 |  91.2%\n",
            "45630 | 4.0608 | 1.0e-05 | 1.16 | 38.8K | 02:40:32 |  91.3%\n",
            "45640 | 3.8864 | 1.0e-05 | 1.18 | 38.8K | 02:40:34 |  91.3%\n",
            "45650 | 3.8461 | 1.0e-05 | 1.23 | 38.8K | 02:40:35 |  91.3%\n",
            "45660 | 4.2480 | 1.0e-05 | 1.25 | 38.8K | 02:40:37 |  91.3%\n",
            "45670 | 4.0763 | 1.0e-05 | 1.22 | 38.8K | 02:40:39 |  91.3%\n",
            "45680 | 3.8663 | 9.9e-06 | 1.14 | 38.8K | 02:40:40 |  91.4%\n",
            "45690 | 4.1671 | 9.9e-06 | 1.25 | 38.8K | 02:40:42 |  91.4%\n",
            "45700 | 4.3292 | 9.8e-06 | 1.25 | 38.8K | 02:40:44 |  91.4%\n",
            "45710 | 3.9962 | 9.8e-06 | 1.35 | 38.8K | 02:40:46 |  91.4%\n",
            "45720 | 3.9458 | 9.7e-06 | 1.16 | 38.8K | 02:40:47 |  91.4%\n",
            "45730 | 4.2774 | 9.7e-06 | 1.18 | 38.8K | 02:40:49 |  91.5%\n",
            "45740 | 4.1991 | 9.7e-06 | 1.19 | 38.8K | 02:40:51 |  91.5%\n",
            "45750 | 4.0072 | 9.6e-06 | 1.23 | 38.8K | 02:40:52 |  91.5%\n",
            "45760 | 4.3779 | 9.6e-06 | 1.18 | 38.8K | 02:40:54 |  91.5%\n",
            "45770 | 4.0997 | 9.5e-06 | 1.20 | 38.8K | 02:40:56 |  91.5%\n",
            "45780 | 4.1479 | 9.5e-06 | 1.26 | 38.8K | 02:40:58 |  91.6%\n",
            "45790 | 4.0159 | 9.4e-06 | 1.17 | 38.8K | 02:40:59 |  91.6%\n",
            "45800 | 4.3203 | 9.4e-06 | 1.23 | 38.8K | 02:41:01 |  91.6%\n",
            "45810 | 4.1883 | 9.3e-06 | 1.24 | 38.8K | 02:41:03 |  91.6%\n",
            "45820 | 4.1974 | 9.3e-06 | 1.23 | 38.8K | 02:41:04 |  91.6%\n",
            "45830 | 4.2326 | 9.3e-06 | 1.22 | 38.8K | 02:41:06 |  91.7%\n",
            "45840 | 4.3379 | 9.2e-06 | 1.20 | 38.8K | 02:41:08 |  91.7%\n",
            "45850 | 4.2132 | 9.2e-06 | 1.24 | 38.8K | 02:41:10 |  91.7%\n",
            "45860 | 4.1583 | 9.1e-06 | 1.18 | 38.8K | 02:41:11 |  91.7%\n",
            "45870 | 4.3316 | 9.1e-06 | 1.22 | 38.8K | 02:41:13 |  91.7%\n",
            "45880 | 4.0324 | 9.0e-06 | 1.26 | 38.8K | 02:41:15 |  91.8%\n",
            "45890 | 3.9408 | 9.0e-06 | 1.21 | 38.8K | 02:41:16 |  91.8%\n",
            "45900 | 4.2721 | 9.0e-06 | 1.20 | 38.8K | 02:41:18 |  91.8%\n",
            "45910 | 3.8788 | 8.9e-06 | 1.17 | 38.9K | 02:41:20 |  91.8%\n",
            "45920 | 4.0901 | 8.9e-06 | 1.19 | 38.9K | 02:41:22 |  91.8%\n",
            "45930 | 4.1287 | 8.8e-06 | 1.23 | 38.9K | 02:41:23 |  91.9%\n",
            "45940 | 4.1252 | 8.8e-06 | 1.21 | 38.9K | 02:41:25 |  91.9%\n",
            "45950 | 3.6348 | 8.7e-06 | 1.15 | 38.9K | 02:41:27 |  91.9%\n",
            "45960 | 4.1135 | 8.7e-06 | 1.24 | 38.9K | 02:41:28 |  91.9%\n",
            "45970 | 4.1770 | 8.7e-06 | 1.24 | 38.9K | 02:41:30 |  91.9%\n",
            "45980 | 4.2344 | 8.6e-06 | 1.24 | 38.9K | 02:41:32 |  92.0%\n",
            "45990 | 4.0547 | 8.6e-06 | 1.23 | 38.9K | 02:41:34 |  92.0%\n",
            "46000 | 4.2790 | 8.5e-06 | 1.20 | 38.9K | 02:41:35 |  92.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 46000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.0947\n",
            "  Perplexity: 60.02\n",
            "  Train loss (avg): 4.1399\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        , bu g√ºzel, ƒ∞stanbul'da kar yaƒüƒ±≈üƒ± ba≈ülƒ±yor. ƒ∞stanbul'da kar yaƒüƒ±≈üƒ± ba≈ülƒ±yor. Meteoroloji'den de bir a√ßƒ±klama yapƒ±ldƒ±. Meteoroloji'den yapƒ±lan a√ßƒ±klamada, ƒ∞stanbul'un bug√ºn yaƒümura hazƒ±r olarak\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Ankara'da yapƒ±lan ve √∂n√ºm√ºzdeki aylarda da devam edecek olan 'ƒ∞stanbul'daki 10 Atat√ºrk Havalimanƒ±'nda, 'Business T√ºrkiye'nin 'Business T√ºrkiye'si' olarak adlandƒ±rƒ±lan projede,\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , artƒ±k her ≈üeyin ve her ≈üeyin √ßift y√∂nl√º, birbirine yakƒ±n, daha uzak, daha iyi, daha verimli, daha derin ve daha derin anlamlara ula≈üabileceƒüini g√∂steren bir teknolojidir. Bu teknolojiler, hem\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.74\n",
            "     ETA: 00:14:04\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "46010 | 4.3403 | 8.5e-06 | 1.28 | 38.8K | 02:41:54 |  92.0%\n",
            "46020 | 4.4776 | 8.4e-06 | 1.20 | 38.8K | 02:41:56 |  92.0%\n",
            "46030 | 4.4143 | 8.4e-06 | 1.21 | 38.8K | 02:41:58 |  92.1%\n",
            "46040 | 4.0260 | 8.4e-06 | 1.18 | 38.8K | 02:41:59 |  92.1%\n",
            "46050 | 4.3914 | 8.3e-06 | 1.23 | 38.8K | 02:42:01 |  92.1%\n",
            "46060 | 4.3641 | 8.3e-06 | 1.22 | 38.8K | 02:42:03 |  92.1%\n",
            "46070 | 4.1609 | 8.2e-06 | 1.22 | 38.8K | 02:42:04 |  92.1%\n",
            "46080 | 4.1695 | 8.2e-06 | 1.24 | 38.8K | 02:42:06 |  92.2%\n",
            "46090 | 4.2859 | 8.1e-06 | 1.20 | 38.8K | 02:42:08 |  92.2%\n",
            "46100 | 4.3326 | 8.1e-06 | 1.21 | 38.8K | 02:42:10 |  92.2%\n",
            "46110 | 4.0795 | 8.1e-06 | 1.16 | 38.8K | 02:42:11 |  92.2%\n",
            "46120 | 4.1409 | 8.0e-06 | 1.18 | 38.8K | 02:42:13 |  92.2%\n",
            "46130 | 4.2704 | 8.0e-06 | 1.18 | 38.8K | 02:42:15 |  92.3%\n",
            "46140 | 4.1154 | 7.9e-06 | 1.27 | 38.8K | 02:42:16 |  92.3%\n",
            "46150 | 4.0944 | 7.9e-06 | 1.21 | 38.8K | 02:42:18 |  92.3%\n",
            "46160 | 4.2574 | 7.9e-06 | 1.20 | 38.8K | 02:42:20 |  92.3%\n",
            "46170 | 4.3424 | 7.8e-06 | 1.21 | 38.8K | 02:42:22 |  92.3%\n",
            "46180 | 3.7793 | 7.8e-06 | 1.21 | 38.8K | 02:42:23 |  92.4%\n",
            "46190 | 3.9397 | 7.7e-06 | 1.29 | 38.8K | 02:42:25 |  92.4%\n",
            "46200 | 3.9969 | 7.7e-06 | 1.19 | 38.8K | 02:42:27 |  92.4%\n",
            "46210 | 4.4167 | 7.7e-06 | 1.19 | 38.8K | 02:42:28 |  92.4%\n",
            "46220 | 4.0981 | 7.6e-06 | 1.21 | 38.8K | 02:42:30 |  92.4%\n",
            "46230 | 4.2491 | 7.6e-06 | 1.22 | 38.8K | 02:42:32 |  92.5%\n",
            "46240 | 4.4551 | 7.5e-06 | 1.22 | 38.8K | 02:42:34 |  92.5%\n",
            "46250 | 4.2943 | 7.5e-06 | 1.18 | 38.8K | 02:42:35 |  92.5%\n",
            "46260 | 4.2255 | 7.5e-06 | 1.18 | 38.8K | 02:42:37 |  92.5%\n",
            "46270 | 4.4722 | 7.4e-06 | 1.22 | 38.8K | 02:42:39 |  92.5%\n",
            "46280 | 4.2369 | 7.4e-06 | 1.19 | 38.8K | 02:42:40 |  92.6%\n",
            "46290 | 4.1748 | 7.3e-06 | 1.19 | 38.8K | 02:42:42 |  92.6%\n",
            "46300 | 4.2500 | 7.3e-06 | 1.22 | 38.8K | 02:42:44 |  92.6%\n",
            "46310 | 4.2086 | 7.3e-06 | 1.20 | 38.8K | 02:42:46 |  92.6%\n",
            "46320 | 4.1326 | 7.2e-06 | 1.18 | 38.8K | 02:42:47 |  92.6%\n",
            "46330 | 4.2255 | 7.2e-06 | 1.21 | 38.8K | 02:42:49 |  92.7%\n",
            "46340 | 3.8852 | 7.1e-06 | 1.28 | 38.9K | 02:42:51 |  92.7%\n",
            "46350 | 4.1285 | 7.1e-06 | 1.22 | 38.9K | 02:42:52 |  92.7%\n",
            "46360 | 3.6212 | 7.1e-06 | 1.25 | 38.9K | 02:42:54 |  92.7%\n",
            "46370 | 4.1530 | 7.0e-06 | 1.17 | 38.9K | 02:42:56 |  92.7%\n",
            "46380 | 4.3487 | 7.0e-06 | 1.20 | 38.9K | 02:42:58 |  92.8%\n",
            "46390 | 4.2579 | 6.9e-06 | 1.19 | 38.9K | 02:42:59 |  92.8%\n",
            "46400 | 4.2876 | 6.9e-06 | 1.28 | 38.9K | 02:43:01 |  92.8%\n",
            "46410 | 3.9488 | 6.9e-06 | 1.23 | 38.9K | 02:43:03 |  92.8%\n",
            "46420 | 4.1086 | 6.8e-06 | 1.17 | 38.9K | 02:43:04 |  92.8%\n",
            "46430 | 4.3417 | 6.8e-06 | 1.22 | 38.9K | 02:43:06 |  92.9%\n",
            "46440 | 3.9601 | 6.8e-06 | 1.22 | 38.9K | 02:43:08 |  92.9%\n",
            "46450 | 4.2639 | 6.7e-06 | 1.21 | 38.9K | 02:43:09 |  92.9%\n",
            "46460 | 4.0344 | 6.7e-06 | 1.21 | 38.9K | 02:43:11 |  92.9%\n",
            "46470 | 4.0082 | 6.6e-06 | 1.19 | 38.9K | 02:43:13 |  92.9%\n",
            "46480 | 4.4063 | 6.6e-06 | 1.20 | 38.9K | 02:43:15 |  93.0%\n",
            "46490 | 3.9415 | 6.6e-06 | 1.34 | 38.9K | 02:43:16 |  93.0%\n",
            "46500 | 4.1694 | 6.5e-06 | 1.22 | 38.9K | 02:43:18 |  93.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 46500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1271\n",
            "  Perplexity: 62.00\n",
            "  Train loss (avg): 4.1506\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        larƒ±n ƒ±sƒ±nmasƒ±, hƒ±zlƒ± bir ≈üekilde yayƒ±lacak. Havalarƒ±n ƒ±sƒ±nmasƒ± ile birlikte hava, her yerden daha sƒ±cak oluyor. Hava, daha kƒ±sa s√ºre i√ßinde etkili oluyor. Hava kirliliƒüi, sel ve su kaynaklƒ±\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Ankara'da T√ºrk Kƒ±zƒ±layƒ± ƒ∞stanbul ≈ûubesi tarafƒ±ndan d√ºzenlenen silahlƒ± saldƒ±rƒ± sonucu, birka√ß ki≈üi yaralanmƒ±≈ütƒ±. Olay yerine gelen polis, polis ve ambulanslarla Ankara'daki binalara sƒ±√ßradƒ±. Saldƒ±rƒ±ya ili≈ükin\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        sayesinde, sizin, sizin ve sevdiklerinizin ve size zarar vermeme ya da zarar verme ihtimali olabilir. Size uygun olmayan bir ≈üey bulmanƒ±zƒ± gerektirebilir. Eƒüer sizin gibi bir g√ºvensizlik ya≈üamamƒ±≈üsanƒ±z,\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.74\n",
            "     ETA: 00:12:18\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "46510 | 4.1519 | 6.5e-06 | 1.17 | 38.8K | 02:43:37 |  93.0%\n",
            "46520 | 4.1520 | 6.5e-06 | 1.20 | 38.8K | 02:43:39 |  93.0%\n",
            "46530 | 4.1441 | 6.4e-06 | 1.21 | 38.8K | 02:43:41 |  93.1%\n",
            "46540 | 4.0427 | 6.4e-06 | 1.22 | 38.8K | 02:43:42 |  93.1%\n",
            "46550 | 4.1157 | 6.3e-06 | 1.20 | 38.8K | 02:43:44 |  93.1%\n",
            "46560 | 3.6736 | 6.3e-06 | 1.17 | 38.8K | 02:43:46 |  93.1%\n",
            "46570 | 4.3232 | 6.3e-06 | 1.19 | 38.8K | 02:43:47 |  93.1%\n",
            "46580 | 4.5638 | 6.2e-06 | 1.23 | 38.8K | 02:43:49 |  93.2%\n",
            "46590 | 4.3502 | 6.2e-06 | 1.21 | 38.8K | 02:43:51 |  93.2%\n",
            "46600 | 4.1299 | 6.2e-06 | 1.23 | 38.8K | 02:43:53 |  93.2%\n",
            "46610 | 3.8666 | 6.1e-06 | 1.15 | 38.8K | 02:43:54 |  93.2%\n",
            "46620 | 3.6479 | 6.1e-06 | 1.15 | 38.8K | 02:43:56 |  93.2%\n",
            "46630 | 4.1520 | 6.1e-06 | 1.17 | 38.8K | 02:43:58 |  93.3%\n",
            "46640 | 4.1163 | 6.0e-06 | 1.23 | 38.8K | 02:43:59 |  93.3%\n",
            "46650 | 4.0819 | 6.0e-06 | 1.17 | 38.8K | 02:44:01 |  93.3%\n",
            "46660 | 4.2435 | 6.0e-06 | 1.18 | 38.8K | 02:44:03 |  93.3%\n",
            "46670 | 4.2434 | 5.9e-06 | 1.20 | 38.8K | 02:44:05 |  93.3%\n",
            "46680 | 4.2185 | 5.9e-06 | 1.29 | 38.8K | 02:44:06 |  93.4%\n",
            "46690 | 4.2713 | 5.8e-06 | 1.22 | 38.8K | 02:44:08 |  93.4%\n",
            "46700 | 4.1233 | 5.8e-06 | 1.22 | 38.8K | 02:44:10 |  93.4%\n",
            "46710 | 4.2137 | 5.8e-06 | 1.26 | 38.8K | 02:44:11 |  93.4%\n",
            "46720 | 3.7246 | 5.7e-06 | 1.20 | 38.8K | 02:44:13 |  93.4%\n",
            "46730 | 3.9932 | 5.7e-06 | 1.25 | 38.8K | 02:44:15 |  93.5%\n",
            "46740 | 3.8375 | 5.7e-06 | 1.20 | 38.8K | 02:44:17 |  93.5%\n",
            "46750 | 4.2139 | 5.6e-06 | 1.18 | 38.8K | 02:44:18 |  93.5%\n",
            "46760 | 4.3063 | 5.6e-06 | 1.20 | 38.8K | 02:44:20 |  93.5%\n",
            "46770 | 4.2209 | 5.6e-06 | 1.20 | 38.8K | 02:44:22 |  93.5%\n",
            "46780 | 4.4591 | 5.5e-06 | 1.22 | 38.9K | 02:44:23 |  93.6%\n",
            "46790 | 4.3761 | 5.5e-06 | 1.19 | 38.9K | 02:44:25 |  93.6%\n",
            "46800 | 4.2761 | 5.5e-06 | 1.20 | 38.9K | 02:44:27 |  93.6%\n",
            "46810 | 4.0875 | 5.4e-06 | 1.20 | 38.9K | 02:44:28 |  93.6%\n",
            "46820 | 4.1365 | 5.4e-06 | 1.21 | 38.9K | 02:44:30 |  93.6%\n",
            "46830 | 4.6056 | 5.4e-06 | 1.28 | 38.9K | 02:44:32 |  93.7%\n",
            "46840 | 3.8467 | 5.3e-06 | 1.19 | 38.9K | 02:44:34 |  93.7%\n",
            "46850 | 4.1583 | 5.3e-06 | 1.19 | 38.9K | 02:44:35 |  93.7%\n",
            "46860 | 4.1804 | 5.3e-06 | 1.18 | 38.9K | 02:44:37 |  93.7%\n",
            "46870 | 4.1807 | 5.2e-06 | 1.17 | 38.9K | 02:44:39 |  93.7%\n",
            "46880 | 4.0441 | 5.2e-06 | 1.19 | 38.9K | 02:44:40 |  93.8%\n",
            "46890 | 4.1034 | 5.2e-06 | 1.20 | 38.9K | 02:44:42 |  93.8%\n",
            "46900 | 4.0755 | 5.1e-06 | 1.25 | 38.9K | 02:44:44 |  93.8%\n",
            "46910 | 4.1637 | 5.1e-06 | 1.23 | 38.9K | 02:44:46 |  93.8%\n",
            "46920 | 4.1417 | 5.1e-06 | 1.19 | 38.9K | 02:44:47 |  93.8%\n",
            "46930 | 4.2121 | 5.0e-06 | 1.18 | 38.9K | 02:44:49 |  93.9%\n",
            "46940 | 4.2549 | 5.0e-06 | 1.20 | 38.9K | 02:44:51 |  93.9%\n",
            "46950 | 4.3328 | 5.0e-06 | 1.25 | 38.9K | 02:44:52 |  93.9%\n",
            "46960 | 4.1231 | 4.9e-06 | 1.34 | 38.9K | 02:44:54 |  93.9%\n",
            "46970 | 4.1686 | 4.9e-06 | 1.28 | 38.9K | 02:44:56 |  93.9%\n",
            "46980 | 4.2711 | 4.9e-06 | 1.18 | 38.9K | 02:44:58 |  94.0%\n",
            "46990 | 4.2573 | 4.8e-06 | 1.21 | 38.9K | 02:44:59 |  94.0%\n",
            "47000 | 4.3973 | 4.8e-06 | 1.23 | 38.9K | 02:45:01 |  94.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 47000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1013\n",
            "  Perplexity: 60.42\n",
            "  Train loss (avg): 4.1633\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        durumu tahminleri, hava durumu tahminleri, web site haritalarƒ±, forumlar ve bloglar da dahil olmak √ºzere pek √ßok farklƒ± √∂zellikte ba≈üka pek √ßok bilgi ve ayrƒ±ntƒ±yƒ± bulabileceƒüiniz bir √ßok site.\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        ƒ∞stanbul'un fethinin 2. yƒ±lƒ±nda B√ºy√ºk √ñnder Mustafa Kemal Atat√ºrk'√ºn ve b√ºy√ºkannesinin vefatƒ±nƒ±n ardƒ±ndan bug√ºnlerin bir benzeri ya≈üanƒ±yor. ƒ∞stanbul'un fethinin 3. yƒ±lƒ±nda B√ºy√ºk √ñnder Mustafa Kemal Atat√ºrk'\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , y√ºksek seviyede bilme ve geli≈ümi≈ü performans, y√ºksek hƒ±z ve y√ºksek hƒ±z i√ßin temel olarak ortaya √ßƒ±ktƒ±. En √∂nemli nokta, makine √∂ƒürenmesi ve daha b√ºy√ºk bir zeka performansƒ±. Amacƒ±nƒ±n, makine √∂ƒürenmesi\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.74\n",
            "     ETA: 00:10:33\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "47010 | 4.2270 | 4.8e-06 | 1.23 | 38.8K | 02:45:20 |  94.0%\n",
            "47020 | 4.4684 | 4.7e-06 | 1.23 | 38.8K | 02:45:22 |  94.0%\n",
            "47030 | 4.0997 | 4.7e-06 | 1.17 | 38.8K | 02:45:23 |  94.1%\n",
            "47040 | 4.1953 | 4.7e-06 | 1.17 | 38.8K | 02:45:25 |  94.1%\n",
            "47050 | 4.0799 | 4.6e-06 | 1.16 | 38.8K | 02:45:27 |  94.1%\n",
            "47060 | 4.3364 | 4.6e-06 | 1.24 | 38.8K | 02:45:29 |  94.1%\n",
            "47070 | 4.0594 | 4.6e-06 | 1.23 | 38.8K | 02:45:30 |  94.1%\n",
            "47080 | 4.1042 | 4.6e-06 | 1.21 | 38.8K | 02:45:32 |  94.2%\n",
            "47090 | 4.1982 | 4.5e-06 | 1.23 | 38.8K | 02:45:34 |  94.2%\n",
            "47100 | 4.2691 | 4.5e-06 | 1.20 | 38.8K | 02:45:35 |  94.2%\n",
            "47110 | 4.4474 | 4.5e-06 | 1.19 | 38.8K | 02:45:37 |  94.2%\n",
            "47120 | 4.2439 | 4.4e-06 | 1.19 | 38.8K | 02:45:39 |  94.2%\n",
            "47130 | 4.1236 | 4.4e-06 | 1.24 | 38.8K | 02:45:41 |  94.3%\n",
            "47140 | 4.1522 | 4.4e-06 | 1.21 | 38.8K | 02:45:42 |  94.3%\n",
            "47150 | 4.4436 | 4.3e-06 | 1.19 | 38.8K | 02:45:44 |  94.3%\n",
            "47160 | 4.3527 | 4.3e-06 | 1.29 | 38.8K | 02:45:46 |  94.3%\n",
            "47170 | 4.2817 | 4.3e-06 | 1.23 | 38.8K | 02:45:47 |  94.3%\n",
            "47180 | 4.2288 | 4.2e-06 | 1.19 | 38.8K | 02:45:49 |  94.4%\n",
            "47190 | 4.1918 | 4.2e-06 | 1.18 | 38.8K | 02:45:51 |  94.4%\n",
            "47200 | 4.0847 | 4.2e-06 | 1.21 | 38.8K | 02:45:53 |  94.4%\n",
            "47210 | 4.2226 | 4.2e-06 | 1.20 | 38.9K | 02:45:54 |  94.4%\n",
            "47220 | 4.3014 | 4.1e-06 | 1.23 | 38.9K | 02:45:56 |  94.4%\n",
            "47230 | 4.1387 | 4.1e-06 | 1.20 | 38.9K | 02:45:58 |  94.5%\n",
            "47240 | 3.9952 | 4.1e-06 | 1.24 | 38.9K | 02:45:59 |  94.5%\n",
            "47250 | 4.3487 | 4.0e-06 | 1.22 | 38.9K | 02:46:01 |  94.5%\n",
            "47260 | 4.3002 | 4.0e-06 | 1.20 | 38.9K | 02:46:03 |  94.5%\n",
            "47270 | 4.0154 | 4.0e-06 | 1.24 | 38.9K | 02:46:04 |  94.5%\n",
            "47280 | 4.2044 | 4.0e-06 | 1.19 | 38.9K | 02:46:06 |  94.6%\n",
            "47290 | 4.1479 | 3.9e-06 | 1.24 | 38.9K | 02:46:08 |  94.6%\n",
            "47300 | 4.0657 | 3.9e-06 | 1.19 | 38.9K | 02:46:10 |  94.6%\n",
            "47310 | 3.9598 | 3.9e-06 | 1.17 | 38.9K | 02:46:11 |  94.6%\n",
            "47320 | 4.1810 | 3.8e-06 | 1.19 | 38.9K | 02:46:13 |  94.6%\n",
            "47330 | 4.1452 | 3.8e-06 | 1.20 | 38.9K | 02:46:15 |  94.7%\n",
            "47340 | 4.3796 | 3.8e-06 | 1.22 | 38.9K | 02:46:16 |  94.7%\n",
            "47350 | 4.2443 | 3.8e-06 | 1.21 | 38.9K | 02:46:18 |  94.7%\n",
            "47360 | 4.2885 | 3.7e-06 | 1.26 | 38.9K | 02:46:20 |  94.7%\n",
            "47370 | 4.2965 | 3.7e-06 | 1.20 | 38.9K | 02:46:22 |  94.7%\n",
            "47380 | 4.1107 | 3.7e-06 | 1.22 | 38.9K | 02:46:23 |  94.8%\n",
            "47390 | 4.4312 | 3.6e-06 | 1.23 | 38.9K | 02:46:25 |  94.8%\n",
            "47400 | 4.2187 | 3.6e-06 | 1.19 | 38.9K | 02:46:27 |  94.8%\n",
            "47410 | 3.8910 | 3.6e-06 | 1.27 | 38.9K | 02:46:28 |  94.8%\n",
            "47420 | 4.0638 | 3.6e-06 | 1.17 | 38.9K | 02:46:30 |  94.8%\n",
            "47430 | 4.0842 | 3.5e-06 | 1.21 | 38.9K | 02:46:32 |  94.9%\n",
            "47440 | 3.9295 | 3.5e-06 | 1.21 | 38.9K | 02:46:34 |  94.9%\n",
            "47450 | 4.1846 | 3.5e-06 | 1.19 | 38.9K | 02:46:35 |  94.9%\n",
            "47460 | 4.3166 | 3.4e-06 | 1.21 | 38.9K | 02:46:37 |  94.9%\n",
            "47470 | 4.2741 | 3.4e-06 | 1.19 | 38.9K | 02:46:39 |  94.9%\n",
            "47480 | 4.1701 | 3.4e-06 | 1.19 | 38.9K | 02:46:40 |  95.0%\n",
            "47490 | 4.2346 | 3.4e-06 | 1.18 | 38.9K | 02:46:42 |  95.0%\n",
            "47500 | 4.4657 | 3.3e-06 | 1.19 | 38.9K | 02:46:44 |  95.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 47500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1453\n",
            "  Perplexity: 63.14\n",
            "  Train loss (avg): 4.1262\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        durumu nedir? T√ºrkiye‚Äônin g√ºney sƒ±nƒ±rƒ±ndaki bu sƒ±cak hava hi√ß bir zaman T√ºrkiye‚Äônin g√ºney sƒ±nƒ±rlarƒ±nda da √ßok sƒ±cak ve yaƒüƒ±≈ülƒ± bir hava deƒüildir. Ancak bu hava daha fazla sƒ±cak ve yaƒüƒ±≈ülƒ± g√ºnlerde daha\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        olan ƒ∞stanbul'un ƒ∞stanbul ve Anadolu yakasƒ±nƒ±n en kalabalƒ±k ≈üehri olan ƒ∞stanbul, ƒ∞stanbul'un en kalabalƒ±k ≈üehri konumundadƒ±r. ƒ∞stanbul'un tam bir projesi olan ƒ∞stanbul, ƒ∞stanbul'un en kalabalƒ±k ≈üehridir\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        sayesinde, her biri aynƒ± anda, 2 dakika boyunca, 5 saniye i√ßerisinde ve 5 dakika i√ßinde, en hƒ±zlƒ± ≈üekilde parmaklarƒ±nƒ±zƒ±, parmaklarƒ±nƒ±zƒ± ve parmaklarƒ±nƒ±zƒ± algƒ±layarak, bir veri i≈üleme merkezine doƒüru yakla≈ümaya\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.74\n",
            "     ETA: 00:08:47\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "47510 | 4.1404 | 3.3e-06 | 1.28 | 38.8K | 02:47:03 |  95.0%\n",
            "47520 | 4.2147 | 3.3e-06 | 1.22 | 38.8K | 02:47:05 |  95.0%\n",
            "47530 | 4.1019 | 3.3e-06 | 1.21 | 38.8K | 02:47:06 |  95.1%\n",
            "47540 | 4.1491 | 3.2e-06 | 1.20 | 38.8K | 02:47:08 |  95.1%\n",
            "47550 | 4.1846 | 3.2e-06 | 1.19 | 38.8K | 02:47:10 |  95.1%\n",
            "47560 | 4.0086 | 3.2e-06 | 1.44 | 38.8K | 02:47:11 |  95.1%\n",
            "47570 | 4.1443 | 3.2e-06 | 1.19 | 38.8K | 02:47:13 |  95.1%\n",
            "47580 | 3.9503 | 3.1e-06 | 1.24 | 38.8K | 02:47:15 |  95.2%\n",
            "47590 | 4.4116 | 3.1e-06 | 1.19 | 38.8K | 02:47:17 |  95.2%\n",
            "47600 | 4.3276 | 3.1e-06 | 1.19 | 38.8K | 02:47:18 |  95.2%\n",
            "47610 | 4.2769 | 3.1e-06 | 1.18 | 38.8K | 02:47:20 |  95.2%\n",
            "47620 | 4.1669 | 3.0e-06 | 1.21 | 38.8K | 02:47:22 |  95.2%\n",
            "47630 | 4.0637 | 3.0e-06 | 1.18 | 38.8K | 02:47:23 |  95.3%\n",
            "47640 | 4.2290 | 3.0e-06 | 1.21 | 38.8K | 02:47:25 |  95.3%\n",
            "47650 | 3.8892 | 3.0e-06 | 1.23 | 38.9K | 02:47:27 |  95.3%\n",
            "47660 | 4.1001 | 2.9e-06 | 1.25 | 38.9K | 02:47:28 |  95.3%\n",
            "47670 | 4.1547 | 2.9e-06 | 1.24 | 38.9K | 02:47:30 |  95.3%\n",
            "47680 | 3.8598 | 2.9e-06 | 1.17 | 38.9K | 02:47:32 |  95.4%\n",
            "47690 | 4.5900 | 2.9e-06 | 1.21 | 38.9K | 02:47:34 |  95.4%\n",
            "47700 | 4.1044 | 2.8e-06 | 1.24 | 38.9K | 02:47:35 |  95.4%\n",
            "47710 | 4.1305 | 2.8e-06 | 1.21 | 38.9K | 02:47:37 |  95.4%\n",
            "47720 | 4.1555 | 2.8e-06 | 1.22 | 38.9K | 02:47:39 |  95.4%\n",
            "47730 | 3.7163 | 2.8e-06 | 1.23 | 38.9K | 02:47:40 |  95.5%\n",
            "47740 | 4.2133 | 2.7e-06 | 1.22 | 38.9K | 02:47:42 |  95.5%\n",
            "47750 | 4.2154 | 2.7e-06 | 1.24 | 38.9K | 02:47:44 |  95.5%\n",
            "47760 | 4.0535 | 2.7e-06 | 1.19 | 38.9K | 02:47:46 |  95.5%\n",
            "47770 | 3.8206 | 2.7e-06 | 1.18 | 38.9K | 02:47:47 |  95.5%\n",
            "47780 | 4.2216 | 2.6e-06 | 1.28 | 38.9K | 02:47:49 |  95.6%\n",
            "47790 | 4.2060 | 2.6e-06 | 1.21 | 38.9K | 02:47:51 |  95.6%\n",
            "47800 | 3.9436 | 2.6e-06 | 1.16 | 38.9K | 02:47:52 |  95.6%\n",
            "47810 | 4.4450 | 2.6e-06 | 1.22 | 38.9K | 02:47:54 |  95.6%\n",
            "47820 | 3.9358 | 2.5e-06 | 1.18 | 38.9K | 02:47:56 |  95.6%\n",
            "47830 | 3.9022 | 2.5e-06 | 1.17 | 38.9K | 02:47:58 |  95.7%\n",
            "47840 | 3.9544 | 2.5e-06 | 1.18 | 38.9K | 02:47:59 |  95.7%\n",
            "47850 | 4.3389 | 2.5e-06 | 1.20 | 38.9K | 02:48:01 |  95.7%\n",
            "47860 | 4.2288 | 2.5e-06 | 1.23 | 38.9K | 02:48:03 |  95.7%\n",
            "47870 | 4.3338 | 2.4e-06 | 1.21 | 38.9K | 02:48:04 |  95.7%\n",
            "47880 | 4.4353 | 2.4e-06 | 1.19 | 38.9K | 02:48:06 |  95.8%\n",
            "47890 | 4.1892 | 2.4e-06 | 1.25 | 38.9K | 02:48:08 |  95.8%\n",
            "47900 | 4.2117 | 2.4e-06 | 1.23 | 38.9K | 02:48:10 |  95.8%\n",
            "47910 | 4.2088 | 2.3e-06 | 1.21 | 38.9K | 02:48:11 |  95.8%\n",
            "47920 | 4.1659 | 2.3e-06 | 1.24 | 38.9K | 02:48:13 |  95.8%\n",
            "47930 | 4.2234 | 2.3e-06 | 1.24 | 38.9K | 02:48:15 |  95.9%\n",
            "47940 | 4.1712 | 2.3e-06 | 1.22 | 38.9K | 02:48:16 |  95.9%\n",
            "47950 | 4.0020 | 2.2e-06 | 1.19 | 38.9K | 02:48:18 |  95.9%\n",
            "47960 | 4.5096 | 2.2e-06 | 1.25 | 38.9K | 02:48:20 |  95.9%\n",
            "47970 | 3.9399 | 2.2e-06 | 1.51 | 38.9K | 02:48:22 |  95.9%\n",
            "47980 | 4.0575 | 2.2e-06 | 1.21 | 38.9K | 02:48:23 |  96.0%\n",
            "47990 | 4.2322 | 2.2e-06 | 1.20 | 38.9K | 02:48:25 |  96.0%\n",
            "48000 | 3.7433 | 2.1e-06 | 1.14 | 38.9K | 02:48:27 |  96.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 48000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1047\n",
            "  Perplexity: 60.63\n",
            "  Train loss (avg): 4.1395\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        durumu tahminleri, en d√º≈ü√ºk saatteki tatil d√∂nemlerinde √∂zellikle yer altƒ± ve g√∂k g√ºr√ºlt√ºl√º saƒüanak yaƒüƒ±≈ülarƒ±n bu ak≈üam saatlerinde etkili olmasƒ±nƒ± saƒüladƒ±. Bu b√∂lge, y√ºksek sƒ±caklƒ±klara sahip ve a≈üƒ±rƒ± sƒ±caklar nedeniyle sualtƒ±\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Moskova'da d√ºzenlenen 29 Ekim Cumhuriyet Bayramƒ±'nda Cumhuriyet Bayramƒ±'nƒ±n ikinci g√ºn√ºnde, Rusya'dan bu yƒ±l onbinlerce vatanda≈ü, b√ºy√ºk bir co≈ükuyla kutladƒ±klarƒ±nƒ± belirtti. Rusya'nƒ±n ba≈ükenti Moskova'\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , √ßok fonksiyonlu davranƒ±≈ülara sahip, k√º√ß√ºk bir yapay zeka, geleneksel yapay zeka teknolojisi, b√ºy√ºk bir hƒ±zla hƒ±zla devreye giriyor ve robotlar tarafƒ±ndan, robotlara kendi ilgi alanƒ±nƒ±z ve hizmetiniz ile ula≈ü\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.74\n",
            "     ETA: 00:07:01\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "48010 | 4.2592 | 2.1e-06 | 1.23 | 38.8K | 02:48:46 |  96.0%\n",
            "48020 | 4.2390 | 2.1e-06 | 1.20 | 38.8K | 02:48:47 |  96.0%\n",
            "48030 | 4.0219 | 2.1e-06 | 1.19 | 38.8K | 02:48:49 |  96.1%\n",
            "48040 | 4.3892 | 2.1e-06 | 1.21 | 38.8K | 02:48:51 |  96.1%\n",
            "48050 | 4.2657 | 2.0e-06 | 1.20 | 38.8K | 02:48:52 |  96.1%\n",
            "48060 | 4.1007 | 2.0e-06 | 1.21 | 38.8K | 02:48:54 |  96.1%\n",
            "48070 | 4.2417 | 2.0e-06 | 1.22 | 38.8K | 02:48:56 |  96.1%\n",
            "48080 | 4.3928 | 2.0e-06 | 1.23 | 38.9K | 02:48:58 |  96.2%\n",
            "48090 | 4.4074 | 2.0e-06 | 1.21 | 38.9K | 02:48:59 |  96.2%\n",
            "48100 | 4.0712 | 1.9e-06 | 1.18 | 38.9K | 02:49:01 |  96.2%\n",
            "48110 | 4.2437 | 1.9e-06 | 1.20 | 38.9K | 02:49:03 |  96.2%\n",
            "48120 | 4.0889 | 1.9e-06 | 1.20 | 38.9K | 02:49:04 |  96.2%\n",
            "48130 | 4.0831 | 1.9e-06 | 1.20 | 38.9K | 02:49:06 |  96.3%\n",
            "48140 | 4.2314 | 1.9e-06 | 1.20 | 38.9K | 02:49:08 |  96.3%\n",
            "48150 | 4.1092 | 1.8e-06 | 1.18 | 38.9K | 02:49:10 |  96.3%\n",
            "48160 | 4.0501 | 1.8e-06 | 1.24 | 38.9K | 02:49:11 |  96.3%\n",
            "48170 | 4.3907 | 1.8e-06 | 1.21 | 38.9K | 02:49:13 |  96.3%\n",
            "48180 | 4.4739 | 1.8e-06 | 1.19 | 38.9K | 02:49:15 |  96.4%\n",
            "48190 | 4.1964 | 1.8e-06 | 1.19 | 38.9K | 02:49:16 |  96.4%\n",
            "48200 | 4.1987 | 1.7e-06 | 1.20 | 38.9K | 02:49:18 |  96.4%\n",
            "48210 | 4.1408 | 1.7e-06 | 1.27 | 38.9K | 02:49:20 |  96.4%\n",
            "48220 | 4.3767 | 1.7e-06 | 1.19 | 38.9K | 02:49:22 |  96.4%\n",
            "48230 | 3.8655 | 1.7e-06 | 1.17 | 38.9K | 02:49:23 |  96.5%\n",
            "48240 | 4.1551 | 1.7e-06 | 1.22 | 38.9K | 02:49:25 |  96.5%\n",
            "48250 | 4.2399 | 1.6e-06 | 1.20 | 38.9K | 02:49:27 |  96.5%\n",
            "48260 | 4.3503 | 1.6e-06 | 1.20 | 38.9K | 02:49:28 |  96.5%\n",
            "48270 | 4.2330 | 1.6e-06 | 1.25 | 38.9K | 02:49:30 |  96.5%\n",
            "48280 | 4.3739 | 1.6e-06 | 1.22 | 38.9K | 02:49:32 |  96.6%\n",
            "48290 | 3.9720 | 1.6e-06 | 1.18 | 38.9K | 02:49:34 |  96.6%\n",
            "48300 | 4.1521 | 1.5e-06 | 1.19 | 38.9K | 02:49:35 |  96.6%\n",
            "48310 | 4.0310 | 1.5e-06 | 1.19 | 38.9K | 02:49:37 |  96.6%\n",
            "48320 | 4.2942 | 1.5e-06 | 1.19 | 38.9K | 02:49:39 |  96.6%\n",
            "48330 | 4.0290 | 1.5e-06 | 1.24 | 38.9K | 02:49:40 |  96.7%\n",
            "48340 | 4.0610 | 1.5e-06 | 1.23 | 38.9K | 02:49:42 |  96.7%\n",
            "48350 | 4.1998 | 1.5e-06 | 1.24 | 38.9K | 02:49:44 |  96.7%\n",
            "48360 | 4.2223 | 1.4e-06 | 1.20 | 38.9K | 02:49:46 |  96.7%\n",
            "48370 | 4.0073 | 1.4e-06 | 1.24 | 38.9K | 02:49:47 |  96.7%\n",
            "48380 | 4.2452 | 1.4e-06 | 1.22 | 38.9K | 02:49:49 |  96.8%\n",
            "48390 | 4.3465 | 1.4e-06 | 1.18 | 38.9K | 02:49:51 |  96.8%\n",
            "48400 | 4.0712 | 1.4e-06 | 1.22 | 38.9K | 02:49:52 |  96.8%\n",
            "48410 | 4.2984 | 1.4e-06 | 1.21 | 38.9K | 02:49:54 |  96.8%\n",
            "48420 | 4.2252 | 1.3e-06 | 1.17 | 38.9K | 02:49:56 |  96.8%\n",
            "48430 | 3.8786 | 1.3e-06 | 1.25 | 38.9K | 02:49:57 |  96.9%\n",
            "48440 | 4.4703 | 1.3e-06 | 1.25 | 38.9K | 02:49:59 |  96.9%\n",
            "48450 | 4.2559 | 1.3e-06 | 1.20 | 38.9K | 02:50:01 |  96.9%\n",
            "48460 | 3.8877 | 1.3e-06 | 1.17 | 38.9K | 02:50:03 |  96.9%\n",
            "48470 | 3.9908 | 1.3e-06 | 1.16 | 38.9K | 02:50:04 |  96.9%\n",
            "48480 | 4.1451 | 1.2e-06 | 1.22 | 38.9K | 02:50:06 |  97.0%\n",
            "48490 | 4.2363 | 1.2e-06 | 1.23 | 38.9K | 02:50:08 |  97.0%\n",
            "48500 | 4.4674 | 1.2e-06 | 1.23 | 38.9K | 02:50:09 |  97.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 48500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1152\n",
            "  Perplexity: 61.27\n",
            "  Train loss (avg): 4.1397\n",
            "\n",
            "  üéØ √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        larƒ±n ƒ±sƒ±nmasƒ±yla birlikte pencereler a√ßƒ±k kalƒ±yor. √ñzellikle m√ºziklerin artmasƒ± ve her saat ƒ±≈üƒ±ƒüƒ± engelleyen bu ate≈ü de bir yandan saƒülƒ±klƒ± ≈üekilde korunmaya √ßalƒ±≈üan bir a≈ük belirtisi ta≈üƒ±yor. G√∂zden ka√ßan bir fƒ±rtƒ±na gibi g√∂r√ºnen\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        olan ƒ∞stanbul'da insanlarƒ±n kendine has bir yapƒ±ya sahip olduƒüu biliniyor. ƒ∞stanbul'un n√ºfusu ise 4 milyon civarƒ±nda. ƒ∞stanbul'un n√ºfusu ise 500 bin civarƒ±nda. ƒ∞stanbul'un n√ºfusu ise 2 milyon. ƒ∞stanbul\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , hayal g√ºc√ºn√º artƒ±rmayƒ± ve yeni g√∂zlerin yaratmasƒ±nƒ± kolayla≈ütƒ±rmayƒ± ama√ßlƒ±yor. Bu teknolojideki en √∂nemli yeniliklerden biri, teknoloji oldu. Tobey, d√∂rt farklƒ± alanlarda √ßok sayƒ±da rakiple kar≈üƒ± kar≈üƒ±ya\n",
            "\n",
            "  üìà Performans:\n",
            "     Tokens/sec: 38.8K\n",
            "     Steps/sec: 4.74\n",
            "     ETA: 00:05:16\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "48510 | 4.0325 | 1.2e-06 | 1.18 | 38.8K | 02:50:28 |  97.0%\n",
            "48520 | 4.1170 | 1.2e-06 | 1.20 | 38.9K | 02:50:30 |  97.0%\n",
            "48530 | 4.0275 | 1.2e-06 | 1.26 | 38.9K | 02:50:32 |  97.1%\n",
            "48540 | 4.1289 | 1.1e-06 | 1.23 | 38.9K | 02:50:34 |  97.1%\n",
            "48550 | 4.0235 | 1.1e-06 | 1.19 | 38.9K | 02:50:35 |  97.1%\n",
            "48560 | 4.0810 | 1.1e-06 | 1.22 | 38.9K | 02:50:37 |  97.1%\n",
            "48570 | 4.3605 | 1.1e-06 | 1.18 | 38.9K | 02:50:39 |  97.1%\n",
            "48580 | 3.8551 | 1.1e-06 | 1.16 | 38.9K | 02:50:40 |  97.2%\n",
            "48590 | 4.1504 | 1.1e-06 | 1.22 | 38.9K | 02:50:42 |  97.2%\n",
            "48600 | 4.0640 | 1.1e-06 | 1.22 | 38.9K | 02:50:44 |  97.2%\n",
            "48610 | 4.4378 | 1.0e-06 | 1.23 | 38.9K | 02:50:46 |  97.2%\n",
            "48620 | 4.1881 | 1.0e-06 | 1.22 | 38.9K | 02:50:47 |  97.2%\n",
            "48630 | 4.1893 | 1.0e-06 | 1.20 | 38.9K | 02:50:49 |  97.3%\n",
            "48640 | 3.8592 | 9.9e-07 | 1.29 | 38.9K | 02:50:51 |  97.3%\n",
            "48650 | 4.0892 | 9.8e-07 | 1.21 | 38.9K | 02:50:52 |  97.3%\n",
            "48660 | 4.3865 | 9.6e-07 | 1.23 | 38.9K | 02:50:54 |  97.3%\n",
            "48670 | 4.3362 | 9.5e-07 | 1.19 | 38.9K | 02:50:56 |  97.3%\n",
            "48680 | 4.2088 | 9.3e-07 | 1.19 | 38.9K | 02:50:58 |  97.4%\n",
            "48690 | 3.9976 | 9.2e-07 | 1.19 | 38.9K | 02:50:59 |  97.4%\n",
            "48700 | 4.3178 | 9.1e-07 | 1.23 | 38.9K | 02:51:01 |  97.4%\n",
            "48710 | 4.0554 | 8.9e-07 | 1.18 | 38.9K | 02:51:03 |  97.4%\n",
            "48720 | 4.0876 | 8.8e-07 | 1.16 | 38.9K | 02:51:04 |  97.4%\n",
            "48730 | 3.8441 | 8.6e-07 | 1.24 | 38.9K | 02:51:06 |  97.5%\n",
            "48740 | 3.9698 | 8.5e-07 | 1.23 | 38.9K | 02:51:08 |  97.5%\n",
            "48750 | 4.2419 | 8.4e-07 | 1.22 | 38.9K | 02:51:10 |  97.5%\n",
            "48760 | 4.0044 | 8.2e-07 | 1.22 | 38.9K | 02:51:11 |  97.5%\n",
            "48770 | 4.3727 | 8.1e-07 | 1.17 | 38.9K | 02:51:13 |  97.5%\n",
            "48780 | 4.4635 | 8.0e-07 | 1.21 | 38.9K | 02:51:15 |  97.6%\n",
            "48790 | 4.0690 | 7.8e-07 | 1.17 | 38.9K | 02:51:16 |  97.6%\n",
            "48800 | 4.0873 | 7.7e-07 | 1.24 | 38.9K | 02:51:18 |  97.6%\n",
            "48810 | 4.0854 | 7.6e-07 | 1.29 | 38.9K | 02:51:20 |  97.6%\n",
            "48820 | 4.4044 | 7.5e-07 | 1.19 | 38.9K | 02:51:21 |  97.6%\n",
            "48830 | 4.3679 | 7.3e-07 | 1.19 | 38.9K | 02:51:23 |  97.7%\n",
            "48840 | 4.2169 | 7.2e-07 | 1.22 | 38.9K | 02:51:25 |  97.7%\n",
            "48850 | 4.1436 | 7.1e-07 | 1.24 | 38.9K | 02:51:27 |  97.7%\n",
            "48860 | 4.0831 | 7.0e-07 | 1.19 | 38.9K | 02:51:28 |  97.7%\n",
            "48870 | 4.2999 | 6.8e-07 | 1.21 | 38.9K | 02:51:30 |  97.7%\n",
            "48880 | 4.2392 | 6.7e-07 | 1.20 | 38.9K | 02:51:32 |  97.8%\n",
            "48890 | 4.1035 | 6.6e-07 | 1.20 | 38.9K | 02:51:33 |  97.8%\n",
            "48900 | 4.1326 | 6.5e-07 | 1.32 | 38.9K | 02:51:35 |  97.8%\n",
            "48910 | 3.9236 | 6.4e-07 | 1.22 | 38.9K | 02:51:37 |  97.8%\n",
            "48920 | 4.4211 | 6.3e-07 | 1.20 | 38.9K | 02:51:39 |  97.8%\n",
            "48930 | 4.1761 | 6.1e-07 | 1.17 | 38.9K | 02:51:40 |  97.9%\n",
            "48940 | 4.0722 | 6.0e-07 | 1.18 | 38.9K | 02:51:42 |  97.9%\n",
            "48950 | 4.2943 | 5.9e-07 | 1.20 | 38.9K | 02:51:44 |  97.9%\n",
            "48960 | 3.9119 | 5.8e-07 | 1.20 | 38.9K | 02:51:45 |  97.9%\n",
            "48970 | 4.2867 | 5.7e-07 | 1.24 | 38.9K | 02:51:47 |  97.9%\n",
            "48980 | 3.9992 | 5.6e-07 | 1.20 | 38.9K | 02:51:49 |  98.0%\n",
            "48990 | 3.8847 | 5.5e-07 | 1.19 | 38.9K | 02:51:51 |  98.0%\n",
            "49000 | 4.1647 | 5.4e-07 | 1.18 | 38.9K | 02:51:52 |  98.0%\n",
            "\n",
            "======================================================================\n",
            "üìä EVALUATION @ Step 49000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.0810\n",
            "  Perplexity: 59.20\n",
            "  Train loss (avg): 4.1615\n",
            "\n",
            "   √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        ≈üartlarƒ± gereƒüi ne kadar geni≈ü bir alanda √ßalƒ±≈ütƒ±ƒüƒ±mƒ±zƒ± bug√ºn inceleyebilirsiniz. Cumartesi g√ºn√º saat 16.00‚Äôda ba≈ülayacak olan kar yaƒüƒ±≈üƒ± ve yaƒümur nedeniyle hava ≈üartlarƒ±nƒ±n √ßok aƒüƒ±r olduƒüu Londra‚Äôda, hava durumu beklen\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Moskova'nƒ±n yanƒ± sƒ±ra Moskova, ƒ∞stanbul, ƒ∞zmir, Eski≈üehir ve Kocaeli'nin de aralarƒ±nda bulunduƒüu Batƒ± Anadolu B√∂lgesi'nin √∂nemli illerinden biri olarak bilinen Moskova'da, d√ºnyanƒ±n bir√ßok √ºlkesinde de binlerce turist\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        , d√ºnyanƒ±n en √∂nemli cihazlarƒ±ndan biri haline geliyor. Bazƒ± bilim adamlarƒ±, teknoloji ve teknoloji, geleceƒüin teknolojilerini nasƒ±l geli≈ütireceƒüini √∂neriyor. Bilim insanlarƒ±, teknolojideki en b√ºy√ºk yeniliklerin ≈üirketlerin zorlayarak y√ºz\n",
            "\n",
            "   Performans:\n",
            "     Tokens/sec: 38.9K\n",
            "     Steps/sec: 4.74\n",
            "     ETA: 00:03:30\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "49010 | 4.1335 | 5.3e-07 | 1.17 | 38.9K | 02:52:11 |  98.0%\n",
            "49020 | 4.3356 | 5.2e-07 | 1.17 | 38.9K | 02:52:13 |  98.0%\n",
            "49030 | 4.2382 | 5.0e-07 | 1.19 | 38.9K | 02:52:15 |  98.1%\n",
            "49040 | 4.3592 | 4.9e-07 | 1.21 | 38.9K | 02:52:16 |  98.1%\n",
            "49050 | 3.6105 | 4.8e-07 | 1.22 | 38.9K | 02:52:18 |  98.1%\n",
            "49060 | 4.1878 | 4.7e-07 | 1.22 | 38.9K | 02:52:20 |  98.1%\n",
            "49070 | 4.3380 | 4.6e-07 | 1.23 | 38.9K | 02:52:22 |  98.1%\n",
            "49080 | 4.3047 | 4.5e-07 | 1.19 | 38.9K | 02:52:23 |  98.2%\n",
            "49090 | 4.1513 | 4.4e-07 | 1.21 | 38.9K | 02:52:25 |  98.2%\n",
            "49100 | 4.2380 | 4.3e-07 | 1.21 | 38.9K | 02:52:27 |  98.2%\n",
            "49110 | 4.0803 | 4.2e-07 | 1.19 | 38.9K | 02:52:28 |  98.2%\n",
            "49120 | 4.1905 | 4.2e-07 | 1.21 | 38.9K | 02:52:30 |  98.2%\n",
            "49130 | 4.2691 | 4.1e-07 | 1.21 | 38.9K | 02:52:32 |  98.3%\n",
            "49140 | 4.1907 | 4.0e-07 | 1.18 | 38.9K | 02:52:34 |  98.3%\n",
            "49150 | 4.2283 | 3.9e-07 | 1.21 | 38.9K | 02:52:35 |  98.3%\n",
            "49160 | 3.6974 | 3.8e-07 | 1.14 | 38.9K | 02:52:37 |  98.3%\n",
            "49170 | 4.0797 | 3.7e-07 | 1.22 | 38.9K | 02:52:39 |  98.3%\n",
            "49180 | 4.2946 | 3.6e-07 | 1.21 | 38.9K | 02:52:40 |  98.4%\n",
            "49190 | 4.0790 | 3.5e-07 | 1.18 | 38.9K | 02:52:42 |  98.4%\n",
            "49200 | 4.1461 | 3.4e-07 | 1.20 | 38.9K | 02:52:44 |  98.4%\n",
            "49210 | 4.2943 | 3.3e-07 | 1.24 | 38.9K | 02:52:45 |  98.4%\n",
            "49220 | 4.2316 | 3.3e-07 | 1.19 | 38.9K | 02:52:47 |  98.4%\n",
            "49230 | 4.0824 | 3.2e-07 | 1.23 | 38.9K | 02:52:49 |  98.5%\n",
            "49240 | 4.5526 | 3.1e-07 | 1.20 | 38.9K | 02:52:51 |  98.5%\n",
            "49250 | 4.1380 | 3.0e-07 | 1.20 | 38.9K | 02:52:52 |  98.5%\n",
            "49260 | 4.3546 | 2.9e-07 | 1.19 | 38.9K | 02:52:54 |  98.5%\n",
            "49270 | 4.4431 | 2.9e-07 | 1.19 | 38.9K | 02:52:56 |  98.5%\n",
            "49280 | 4.1967 | 2.8e-07 | 1.22 | 38.9K | 02:52:57 |  98.6%\n",
            "49290 | 4.3129 | 2.7e-07 | 1.23 | 38.9K | 02:52:59 |  98.6%\n",
            "49300 | 4.2947 | 2.6e-07 | 1.22 | 38.9K | 02:53:01 |  98.6%\n",
            "49310 | 4.4036 | 2.6e-07 | 1.25 | 38.9K | 02:53:03 |  98.6%\n",
            "49320 | 4.1467 | 2.5e-07 | 1.19 | 38.9K | 02:53:04 |  98.6%\n",
            "49330 | 4.0853 | 2.4e-07 | 1.17 | 38.9K | 02:53:06 |  98.7%\n",
            "49340 | 4.2206 | 2.3e-07 | 1.19 | 38.9K | 02:53:08 |  98.7%\n",
            "49350 | 4.4797 | 2.3e-07 | 1.19 | 38.9K | 02:53:09 |  98.7%\n",
            "49360 | 4.4355 | 2.2e-07 | 1.21 | 38.9K | 02:53:11 |  98.7%\n",
            "49370 | 3.9057 | 2.1e-07 | 1.17 | 38.9K | 02:53:13 |  98.7%\n",
            "49380 | 4.2048 | 2.1e-07 | 1.28 | 38.9K | 02:53:15 |  98.8%\n",
            "49390 | 4.3187 | 2.0e-07 | 1.28 | 38.9K | 02:53:16 |  98.8%\n",
            "49400 | 4.3715 | 1.9e-07 | 1.21 | 38.9K | 02:53:18 |  98.8%\n",
            "49410 | 3.8557 | 1.9e-07 | 1.16 | 38.9K | 02:53:20 |  98.8%\n",
            "49420 | 4.1787 | 1.8e-07 | 1.22 | 38.9K | 02:53:21 |  98.8%\n",
            "49430 | 4.2311 | 1.7e-07 | 1.26 | 38.9K | 02:53:23 |  98.9%\n",
            "49440 | 4.3402 | 1.7e-07 | 1.24 | 38.9K | 02:53:25 |  98.9%\n",
            "49450 | 4.2735 | 1.6e-07 | 1.18 | 38.9K | 02:53:27 |  98.9%\n",
            "49460 | 4.2103 | 1.6e-07 | 1.21 | 38.9K | 02:53:28 |  98.9%\n",
            "49470 | 4.0840 | 1.5e-07 | 1.29 | 38.9K | 02:53:30 |  98.9%\n",
            "49480 | 4.2144 | 1.5e-07 | 1.23 | 38.9K | 02:53:32 |  99.0%\n",
            "49490 | 3.9803 | 1.4e-07 | 1.20 | 38.9K | 02:53:33 |  99.0%\n",
            "49500 | 3.8979 | 1.3e-07 | 1.29 | 38.9K | 02:53:35 |  99.0%\n",
            "\n",
            "======================================================================\n",
            " EVALUATION @ Step 49500\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.1092\n",
            "  Perplexity: 60.90\n",
            "  Train loss (avg): 4.1625\n",
            "\n",
            "   √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        √ßok sƒ±cak, insanlarƒ±n kendine ait bir kokusundan ibaret deƒüil. Hatta d√ºnya genelinde neredeyse her g√ºn yeni bir koku ve tat alma hissi ya≈üƒ±yoruz. Her iki kokunun da aynƒ± kokulara sahip olduƒüu biliniyordu.\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Ankara'da ya≈üayan T√ºrk vatanda≈ülarƒ±na y√∂nelik ger√ßekle≈ütirilen ilk ≈üiddet olayƒ±nƒ±n ya≈üandƒ±ƒüƒ± 19 Ekim'de yapƒ±lan basƒ±n a√ßƒ±klamasƒ±yla vatanda≈ülarƒ±mƒ±zƒ±n bir kƒ±smƒ± bu katliama maruz kaldƒ±klarƒ±nƒ±, bir kƒ±smƒ± ise zorla Kayseri'\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        sayesinde, bilgisayar ve bilgi teknolojileri olmadan insanlar rahat√ßa hareket edebiliyorlar. Bu teknolojinin hi√ßbir etkisi yok. En √ßok kullanƒ±lan teknolojiler ve ≈üeyler de bilim adamlarƒ± tarafƒ±ndan geli≈ütirildi. Teknolojinin nasƒ±l olduƒüu da merak ediliyor.\n",
            "\n",
            "   Performans:\n",
            "     Tokens/sec: 38.9K\n",
            "     Steps/sec: 4.74\n",
            "     ETA: 00:01:45\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "49510 | 4.0671 | 1.3e-07 | 1.18 | 38.9K | 02:53:54 |  99.0%\n",
            "49520 | 3.8706 | 1.2e-07 | 1.21 | 38.9K | 02:53:56 |  99.0%\n",
            "49530 | 4.1307 | 1.2e-07 | 1.19 | 38.9K | 02:53:58 |  99.1%\n",
            "49540 | 4.0757 | 1.1e-07 | 1.21 | 38.9K | 02:53:59 |  99.1%\n",
            "49550 | 4.2312 | 1.1e-07 | 1.22 | 38.9K | 02:54:01 |  99.1%\n",
            "49560 | 4.0259 | 1.0e-07 | 1.21 | 38.9K | 02:54:03 |  99.1%\n",
            "49570 | 4.1237 | 9.9e-08 | 1.25 | 38.9K | 02:54:04 |  99.1%\n",
            "49580 | 4.2912 | 9.5e-08 | 1.19 | 38.9K | 02:54:06 |  99.2%\n",
            "49590 | 3.7354 | 9.0e-08 | 1.20 | 38.9K | 02:54:08 |  99.2%\n",
            "49600 | 4.0607 | 8.6e-08 | 1.19 | 38.9K | 02:54:09 |  99.2%\n",
            "49610 | 4.0763 | 8.2e-08 | 1.19 | 38.9K | 02:54:11 |  99.2%\n",
            "49620 | 4.1110 | 7.8e-08 | 1.21 | 38.9K | 02:54:13 |  99.2%\n",
            "49630 | 4.2676 | 7.4e-08 | 1.18 | 38.9K | 02:54:15 |  99.3%\n",
            "49640 | 4.0301 | 7.0e-08 | 1.18 | 38.9K | 02:54:16 |  99.3%\n",
            "49650 | 4.1633 | 6.6e-08 | 1.18 | 38.9K | 02:54:18 |  99.3%\n",
            "49660 | 4.3111 | 6.2e-08 | 1.20 | 38.9K | 02:54:20 |  99.3%\n",
            "49670 | 4.1393 | 5.9e-08 | 1.26 | 38.9K | 02:54:21 |  99.3%\n",
            "49680 | 4.2249 | 5.5e-08 | 1.21 | 38.9K | 02:54:23 |  99.4%\n",
            "49690 | 3.9465 | 5.2e-08 | 1.24 | 38.9K | 02:54:25 |  99.4%\n",
            "49700 | 4.1393 | 4.9e-08 | 1.22 | 38.9K | 02:54:27 |  99.4%\n",
            "49710 | 4.2585 | 4.5e-08 | 1.19 | 38.9K | 02:54:28 |  99.4%\n",
            "49720 | 4.0947 | 4.2e-08 | 1.21 | 38.9K | 02:54:30 |  99.4%\n",
            "49730 | 4.2874 | 3.9e-08 | 1.24 | 38.9K | 02:54:32 |  99.5%\n",
            "49740 | 4.1833 | 3.6e-08 | 1.21 | 38.9K | 02:54:33 |  99.5%\n",
            "49750 | 4.2631 | 3.4e-08 | 1.22 | 38.9K | 02:54:35 |  99.5%\n",
            "49760 | 3.9861 | 3.1e-08 | 1.25 | 38.9K | 02:54:37 |  99.5%\n",
            "49770 | 4.1149 | 2.9e-08 | 1.22 | 38.9K | 02:54:39 |  99.5%\n",
            "49780 | 4.5076 | 2.6e-08 | 1.20 | 38.9K | 02:54:40 |  99.6%\n",
            "49790 | 4.2833 | 2.4e-08 | 1.20 | 38.9K | 02:54:42 |  99.6%\n",
            "49800 | 4.1279 | 2.2e-08 | 1.22 | 38.9K | 02:54:44 |  99.6%\n",
            "49810 | 4.0149 | 2.0e-08 | 1.24 | 38.9K | 02:54:45 |  99.6%\n",
            "49820 | 4.0402 | 1.8e-08 | 1.21 | 38.9K | 02:54:47 |  99.6%\n",
            "49830 | 4.0589 | 1.6e-08 | 1.21 | 38.9K | 02:54:49 |  99.7%\n",
            "49840 | 4.3767 | 1.4e-08 | 1.20 | 38.9K | 02:54:51 |  99.7%\n",
            "49850 | 4.1657 | 1.2e-08 | 1.20 | 38.9K | 02:54:52 |  99.7%\n",
            "49860 | 4.1632 | 1.1e-08 | 1.20 | 38.9K | 02:54:54 |  99.7%\n",
            "49870 | 4.3541 | 9.2e-09 | 1.19 | 38.9K | 02:54:56 |  99.7%\n",
            "49880 | 4.1606 | 7.8e-09 | 1.21 | 38.9K | 02:54:57 |  99.8%\n",
            "49890 | 4.0334 | 6.6e-09 | 1.18 | 38.9K | 02:54:59 |  99.8%\n",
            "49900 | 4.2016 | 5.5e-09 | 1.24 | 38.9K | 02:55:01 |  99.8%\n",
            "49910 | 4.0114 | 4.4e-09 | 1.20 | 38.9K | 02:55:02 |  99.8%\n",
            "49920 | 4.1072 | 3.5e-09 | 1.19 | 38.9K | 02:55:04 |  99.8%\n",
            "49930 | 4.2467 | 2.7e-09 | 1.24 | 38.9K | 02:55:06 |  99.9%\n",
            "49940 | 4.2663 | 2.0e-09 | 1.21 | 38.9K | 02:55:08 |  99.9%\n",
            "49950 | 4.1963 | 1.4e-09 | 1.20 | 38.9K | 02:55:09 |  99.9%\n",
            "49960 | 4.0162 | 9.0e-10 | 1.19 | 38.9K | 02:55:11 |  99.9%\n",
            "49970 | 4.2545 | 5.1e-10 | 1.23 | 38.9K | 02:55:13 |  99.9%\n",
            "49980 | 4.3397 | 2.4e-10 | 1.20 | 38.9K | 02:55:14 | 100.0%\n",
            "49990 | 3.9306 | 6.5e-11 | 1.20 | 38.9K | 02:55:16 | 100.0%\n",
            "50000 | 4.0653 | 5.4e-13 | 1.19 | 38.9K | 02:55:18 | 100.0%\n",
            "\n",
            "======================================================================\n",
            " EVALUATION @ Step 50000\n",
            "----------------------------------------------------------------------\n",
            "  Eval loss: 4.0945\n",
            "  Perplexity: 60.01\n",
            "  Train loss (avg): 4.1512\n",
            "\n",
            "   √úretim √∂rnekleri:\n",
            "    [1] 'Bug√ºn hava' ‚Üí\n",
            "        biraz soƒüuk, √∂yle g√ºzel, √∂yle g√ºzel ki deniz √ßok sƒ±cak, bu da karlar altƒ±nda, ne √ßok seveceksin, ne de √ßok seveceksin... √ñzellikle de bahar aylarƒ±ydƒ±. Hava g√ºzel ve temiz\n",
            "    [2] 'T√ºrkiye'nin ba≈ükenti' ‚Üí\n",
            "        Londra'da hizmet veren ƒ∞iberal ve Landing, uluslararasƒ± turizm ve yerel y√∂netimlerin olu≈üturduƒüu bir organizasyon. ƒ∞stanbul'un k√ºlt√ºr sanat ve sanat ≈üehri olan Londra'da, 4 farklƒ± √ºlkeye de\n",
            "    [3] 'Yapay zeka teknolojisi' ‚Üí\n",
            "        sayesinde ‚Äúyeni ≈üeyler i√ßin‚Äù ve ‚Äúi√ßeriƒüi‚Äù ile de otomatik olarak ‚Äúyeni ≈üeyler‚Äùler √ºretilebileceƒüini g√∂zlemliyorsunuz. Her hal√ºkarda yeni ≈üeyler de olabilir. Hatta √∂zellikle de\n",
            "\n",
            "   Performans:\n",
            "     Tokens/sec: 38.9K\n",
            "     Steps/sec: 4.75\n",
            "     ETA: 00:00:00\n",
            "======================================================================\n",
            "\n",
            "Step |  Loss  |  LR   | Grad | Token/s |  Time  | Progress\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "üíæ Checkpoint kaydediliyor: /content/drive/MyDrive/turkish_llm/checkpoints//checkpoint_step_50000.pt\n",
            "   Checkpoint kaydedildi!\n",
            "\n",
            "\n",
            "======================================================================\n",
            "                         ‚ú® Eƒûƒ∞Tƒ∞M TAMAMLANDI!\n",
            "======================================================================\n",
            "\n",
            " Final ƒ∞statistikler:\n",
            "  Toplam s√ºre: 02:55:38\n",
            "  Toplam step: 50,000\n",
            "  Toplam token: 0.41B\n",
            "  Final loss: 4.0653\n",
            "  Best eval loss: 4.0716\n",
            "  Ortalama hƒ±z: 38.9K token/s\n",
            "\n",
            " Final model kaydedildi: /content/drive/MyDrive/turkish_llm/checkpoints//final_model.pt\n",
            "\n",
            " Final √ºretim √∂rnekleri:\n",
            "\n",
            "'Bug√ºn hava':\n",
            "  ‚Üí durumu tahminleri i√ßin tƒ±klayƒ±n: T√ºrkiye‚Äôde hava durumu tahminleri i√ßin tƒ±klayƒ±n: T√ºrkiye‚Äôde hava durumu tahminleri i√ßin tƒ±klayƒ±n: T√ºrkiye‚Äôde hava durumu tahminleri i√ßin tƒ±klayƒ±n: T√ºrkiye‚Äôde hava durumu tahminleri i√ßin tƒ±klayƒ±n: T√ºrkiye‚Äôde hava\n",
            "\n",
            "'T√ºrkiye'nin ba≈ükenti':\n",
            "  ‚Üí Ankara'da, ABD'nin Suriye'ye m√ºdahalesinin ardƒ±ndan, T√ºrkiye'nin Suriye'de yaptƒ±ƒüƒ± m√ºdahalelerin ardƒ±ndan Ankara'da da bir araya gelen Suriyeli bir grup, T√ºrkiye'nin Suriye'ye m√ºdahale ettiƒüi ve T√ºrk yetkililere de herhangi bir\n",
            "\n",
            "'Yapay zeka teknolojisi':\n",
            "  ‚Üí , yapay zeka teknolojilerinin daha √ßok yaygƒ±nla≈ümasƒ±nƒ± ve bir√ßok ki≈üinin daha hƒ±zlƒ± √ßalƒ±≈üƒ±lmasƒ±nƒ± saƒülar. Bu teknoloji, ki≈üinin en √ßok ilgi g√∂sterdiƒüi, en √ßok ilgi g√∂ren ve en √ßok ilgi g√∂ren teknolojik √ºr√ºnleridir. Ne yazƒ±k ki, bu teknoloji sayesinde, daha √ßok\n",
            "\n",
            "'ƒ∞nsanlar neden':\n",
            "  ‚Üí azarlar? Onlar ne kadar √ßok biliyor? Onlarƒ±n seni √ßok sevdiƒüine inanƒ±rlar. Onlarƒ±n bu nedenle, onlarla birlikte yarattƒ±klarƒ± b√ºt√ºn davranƒ±≈ülarƒ±nda, ba≈ükalarƒ±nƒ±n senin i√ßin daha √ßok bir ≈üey yapmalarƒ±nƒ± ister. Onlar, onlardan daha √ßok sevilirler. Onlar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def generate_improved(model, prompt, max_tokens=50, temperature=0.7, top_p=0.9, repetition_penalty=1.2):\n",
        "    \"\"\"Geli≈ütirilmi≈ü generation\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    tokens = sp.encode(prompt)\n",
        "    tokens = torch.tensor([tokens], dtype=torch.long).cuda()\n",
        "    generated = []\n",
        "\n",
        "    for _ in range(max_tokens):\n",
        "        logits = model(tokens)[:, -1, :]\n",
        "\n",
        "        # Repetition penalty uygula\n",
        "        for token_id in set(generated[-20:]):  # Son 20 token\n",
        "            logits[0, token_id] /= repetition_penalty\n",
        "\n",
        "        # Temperature ve top-p\n",
        "        logits = logits / temperature\n",
        "        # ... (top-p sampling)\n",
        "\n",
        "        next_token = torch.multinomial(F.softmax(logits, dim=-1), 1)\n",
        "        if next_token.item() == sp.eos_id():\n",
        "            break\n",
        "        generated.append(next_token.item())\n",
        "        tokens = torch.cat([tokens, next_token], dim=1)\n",
        "\n",
        "    return sp.decode(generated)\n",
        "\n",
        "# Test\n",
        "prompts = [\"Ben bir\", \"ƒ∞stanbul\", \"Yapay zeka\"]\n",
        "for p in prompts:\n",
        "    result = generate_improved(model, p, temperature=0.7, repetition_penalty=1.3)\n",
        "    print(f\"'{p}': {result}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFApN7iA3l0j",
        "outputId": "151cf286-85f7-456d-dcb8-8fc761653a61"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Ben bir': √∂nceki yazƒ±mda ƒ∞stanbul √úniversitesi ƒ∞≈ületme Fak√ºltesi‚Äônden mezun oldum. √úniversite, T√ºrkiye‚Äôde ‚ÄúMatematik‚Äù alanƒ±nda eƒüitim almƒ±≈ü veya ‚ÄúT√ºrkiye‚Äônin En ƒ∞yi √ñƒürenci Derneƒüi‚Äù olarak mezun oldum. Buƒ±mdaki en b√ºy√ºk ba≈üarƒ±lardan biri de ku≈ükusuz ‚ÄúMate\n",
            "\n",
            "'ƒ∞stanbul': ‚Äôun en g√∂zde semtlerinden biri olan ƒ∞zmir, senelerdir de b√∂lgede hayat kurtarƒ±yor. ƒ∞zmir B√ºy√ºk≈üehir Belediyesi‚Äônin sunduƒüu bayramla≈üma programƒ±na katƒ±lan Ba≈ükan Aziz Kocaoƒülu, ‚Äú≈ûehir merkezimiz her t√ºrl√º hizmeti vermeye devam ediyor‚Äù ≈üeklinde konu≈ütu. ƒ∞zmir B√ºy√ºk≈üehir Belediyesi\n",
            "\n",
            "'Yapay zeka': ve Cosmic IBM, en √ßok kullanƒ±lan yazƒ±lƒ±m platformlardan biri olan Y-Bi7 ile birlikte en k√º√ß√ºk bir bilgiye sahip olmak i√ßin, yalnƒ±zca √∂ƒürenciler i√ßin tasarlanmƒ±≈ütƒ±r. Veriler ve bilgiler doƒürulayacak ≈üekilde tasarlanmalƒ±dƒ±r. Tether\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === MODEL TESTƒ∞ ===================================\n",
        "\n",
        "# Test prompts\n",
        "test_prompts = [\n",
        "    \"Bug√ºn hava\",\n",
        "    \"ƒ∞stanbul'un\",\n",
        "    \"T√ºrkiye ekonomisi\",\n",
        "    \"Yapay zeka nedir\",\n",
        "    \"En sevdiƒüim\",\n",
        "    \"Bir varmƒ±≈ü bir yokmu≈ü\",\n",
        "    \"Python programlama dili\",\n",
        "]\n",
        "\n",
        "print(\"GENERATION TESTLERƒ∞\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for prompt in test_prompts:\n",
        "    print(f\"\\n Prompt: '{prompt}'\")\n",
        "\n",
        "    # Farklƒ± temperature'larla test\n",
        "    for temp in [0.5, 0.8]:\n",
        "        output = generate_improved(\n",
        "            model,\n",
        "            prompt,\n",
        "            max_tokens=40,\n",
        "            temperature=temp,\n",
        "            top_p=0.9,\n",
        "            repetition_penalty=1.3\n",
        "        )\n",
        "        print(f\"  (temp={temp}): {output}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# ƒ∞nteraktif test\n",
        "print(\"\\nüí¨ ƒ∞NTERAKTƒ∞F TEST (√ßƒ±kmak i√ßin 'quit' yazƒ±n)\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"\\n Siz: \")\n",
        "    if user_input.lower() in ['quit', '√ßƒ±k', 'exit']:\n",
        "        break\n",
        "\n",
        "    response = generate_improved(\n",
        "        model,\n",
        "        user_input,\n",
        "        max_tokens=80,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        repetition_penalty=1.25\n",
        "    )\n",
        "\n",
        "    print(f\" Model: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98qzrhnP4Tej",
        "outputId": "c609543d-cb3b-4160-9ec4-866a35a07548"
      },
      "execution_count": 22,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " GENERATION TESTLERƒ∞\n",
            "============================================================\n",
            "\n",
            " Prompt: 'Bug√ºn hava'\n",
            "  (temp=0.5): , i≈ü√ßi ve emek√ßi kesimlere g√∂re daha √ßok sorun √ßƒ±karƒ±yor. ƒ∞≈ü√ßiler, emek√ßilerin, emek√ßilerin, emek√ßinin ve emek√ßi kesimlerin sorunlarƒ± ile m√ºcadele ederken, i≈ü g√ºc√º piyasasƒ±nƒ± da olumsuz\n",
            "  (temp=0.8): ≈üartlarƒ± √ßok k√∂t√º deƒüil. Oh deƒüil mi? Sokaƒüƒ±mƒ±za girecek oyuncular sanƒ±rƒ±m y√ºzde 80 civarƒ±nda! W Yunusemre‚Äônin en √ºnl√º oyuncusunun sol bek olmasƒ±, kaleci Meclis Ba≈ükanƒ± ve eski futbolcu Metin\n",
            "\n",
            " Prompt: 'ƒ∞stanbul'un'\n",
            "  (temp=0.5): en b√ºy√ºk ve modern alƒ±≈üveri≈ü merkezi olan ƒ∞stanbul'un merkezinde yer alan, ≈üehrin binlerce kilometre uzaƒüƒ±nda bulunan bir restorandƒ±r. ≈ûehrin en b√ºy√ºk ve modern alƒ±≈üveri≈ü merkezi olan ƒ∞stanbul'un merkezinde yer alan, ≈üehrin\n",
            "  (temp=0.8): en b√ºy√ºk ve pop√ºler alƒ±≈üveri≈ü caddesi Hermessi'nin D&R maƒüazalarƒ±nda stoksuz olarak yer alan Parf√ºm, fiyatlarƒ± ile alƒ±≈üveri≈ü yapan ve alƒ±≈üveri≈ü yapmak isteyen ki≈üilerin ilk adresi. Parmessa\n",
            "\n",
            " Prompt: 'T√ºrkiye ekonomisi'\n",
            "  (temp=0.5): y√ºzde 12 ile y√ºzde 4 arasƒ±nda deƒüi≈üen bir b√ºy√ºme kaydetti. T√ºrkiye'nin en b√ºy√ºk sanayi kurulu≈üu olan Avrupa Birliƒüi, √∂zellikle de T√ºrkiye ekonomisinin lokomotif sekt√∂rlerinden biri haline geldi. Bu yƒ±l ikinci kez istihdam edilen T√ºrkiye\n",
            "  (temp=0.8): bir b√ºt√ºn olarak T√ºrkiye'nin ekonomisini de kar≈üƒ±layabilecek d√ºzeyde finansal b√ºy√ºkl√ºƒüe sahip. Bu √∂zelliƒüin enerji ve doƒüal gaz verimi seferberliƒüine girdiƒüi, en fazla naho≈ü TL'nin deƒüer kazan\n",
            "\n",
            " Prompt: 'Yapay zeka nedir'\n",
            "  (temp=0.5): ? Yapay zeka ne demektir, yapay zekayƒ± nasƒ±l etkiler ? Yapay zeka nedir? Yapay zeka nedir ve yapay zeka hakkƒ±nda bilgi sahibi olmak i√ßin en iyi yol yapay zekanƒ±n nasƒ±l √ßalƒ±≈ütƒ±ƒüƒ±nƒ± √∂ƒürenmektir. Yapay zeka\n",
            "  (temp=0.8): , benim aklƒ±ma ge√ßtiƒüimiz 15-30 yƒ±lda yapƒ±lan bir ara≈ütƒ±rma denek yaparak bu sistemi test eden insanlarƒ±n, bunun nasƒ±l olduƒüunu ve bunun evrimsel olmadƒ±ƒüƒ±nƒ± g√∂zlemledim. Bu durumda beyindeki en b√ºy√ºk dildeki insanlarƒ±n kaf\n",
            "\n",
            " Prompt: 'En sevdiƒüim'\n",
            "  (temp=0.5): ≈üeyse, bu hafta i√ßinde en √ßok sevdiƒüim ≈üey sanƒ±rƒ±m, bu ay da √ßok fazla bloga bakmam. Bu ay bir blog a√ßmayƒ± d√º≈ü√ºn√ºyorum ve en sevdiƒüim ≈üey ise, blogumu a√ßtƒ±ƒüƒ±m ilk\n",
            "  (temp=0.8): arkada≈ülardan biri olan Etiketler: eteƒüi (kuru) kol, fƒ±rƒ±na ,≈üi≈üman ve sarƒ±k ile seyahat eden ≈üehrimizde nerelere gidilebilir? Elbette. G√∂r√ºp de g√∂rmediƒüini\n",
            "\n",
            " Prompt: 'Bir varmƒ±≈ü bir yokmu≈ü'\n",
            "  (temp=0.5): . O da bir g√ºn, bu gece de yine iki ayrƒ± g√ºne≈ü ƒ±≈üƒ±ƒüƒ± altƒ±nda toplanƒ±p eve varƒ±nca bir yerde yatƒ±yormu≈ü. \"Seyahatin sonu nereye gidiyor?\" diye sormu≈ülar, bir de\n",
            "  (temp=0.8): . Vay be! Kendimi var artƒ±k: \"Gelin ≈üu elinizden, belki bir k√∂lesiniz\" dedim... Ne olduƒüunu unutmu≈ütum. Boynum kaydƒ±; ben de bir tek, b\n",
            "\n",
            " Prompt: 'Python programlama dili'\n",
            "  (temp=0.5): ile ilgili en iyi ≈üey, bir komut veya komuta sahip olmak. Bu durumda, komutlar bir komutla ilgili olarak ayarlanabilir. Bu komut, komutlarƒ±n herhangi biri tarafƒ±ndan olu≈üturulan bir komuta sahip\n",
            "  (temp=0.8): ile ilgili her t√ºrl√º bilgiyi bulabileceƒüiniz ve en kolay bi√ßimde kullanabileceƒüiniz bir dildir. Bu nedenle, daha detaylƒ± bilgi i√ßin bizimle ileti≈üime ge√ßebilirsiniz: Bu t√ºyo hakkƒ±nda daha fazla bilgi edinmek ve bu alandaki uzmanla≈ümayƒ±\n",
            "\n",
            "============================================================\n",
            "\n",
            "üí¨ ƒ∞NTERAKTƒ∞F TEST (√ßƒ±kmak i√ßin 'quit' yazƒ±n)\n",
            "------------------------------------------------------------\n",
            "\n",
            " Siz: merhaba\n",
            " Model: . Feyza bey, √∂ncelikle bana da mail yoluyla ula≈ümanƒ±z gerekmekte ve kesinlikle bu konuda bilgi sahibi olduƒüunuzu s√∂ylemek istiyorum. Ayrƒ±ca ‚ÄúPara nasƒ±l ba≈ülar?‚Äù diye sorsanƒ±z 1 hafta sonra ikinci sorum olacak: 1- √ñncelikle, ‚Äúnefes alma‚Äù nedir? 2- Bir s√ºre √∂nce ‚ÄúPara nasƒ±l ba≈ülar?‚Äù diye sorsanƒ±z 1 hafta sonra ikinci sorumun cevabƒ± yazarƒ±z. 3- Tahsilat edilen ifad\n",
            "\n",
            " Siz: s√ºleyman demirel\n",
            " Model: , bir alƒ±ntƒ± ekledi. Ne kadar geriƒüin var o ki... Psk.Murat √ñZG√úR, \"Canlƒ±lar, b√ºt√ºn bunlar i√ßin bir ≈üey yapmazlar\" diyor. Bedeviler, \"Madem ki, bu, millet i√ßin bir ≈üey yapsan, sen de artƒ±k her yerde sulh ve selamet vardƒ±r. Bu millet, kendi ba≈üƒ±na d√ºnyanƒ±n hi√ßbir yerinde sulh olamaz\"\n",
            "\n",
            " Siz: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Checkpoint'leri kontrol et\n",
        "checkpoint_dir = '/content/drive/MyDrive/turkish_llm/checkpoints/'\n",
        "print(\" Kaydedilen checkpoint'ler:\")\n",
        "for file in os.listdir(checkpoint_dir):\n",
        "    if file.endswith('.pt'):\n",
        "        size = os.path.getsize(os.path.join(checkpoint_dir, file)) / (1024**3)\n",
        "        print(f\"  ‚úì {file} ({size:.2f} GB)\")\n",
        "\n",
        "# Tokenizer'ƒ± kontrol et\n",
        "tokenizer_path = '/content/drive/MyDrive/turkish_llm/tokenizer_tr_32k_v2.model'\n",
        "if os.path.exists(tokenizer_path):\n",
        "    print(f\"‚úì Tokenizer mevcut: {tokenizer_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weJ2HXVO9MpV",
        "outputId": "3aaa5efc-48d5-4525-d282-be215ea9834c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Kaydedilen checkpoint'ler:\n",
            "  ‚úì best_model.pt (1.34 GB)\n",
            "  ‚úì checkpoint_step_5000.pt (1.34 GB)\n",
            "  ‚úì checkpoint_step_10000.pt (1.34 GB)\n",
            "  ‚úì checkpoint_step_15000.pt (1.34 GB)\n",
            "  ‚úì checkpoint_step_20000.pt (1.34 GB)\n",
            "  ‚úì checkpoint_step_25000.pt (1.34 GB)\n",
            "  ‚úì checkpoint_step_30000.pt (1.34 GB)\n",
            "  ‚úì checkpoint_step_35000.pt (1.34 GB)\n",
            "  ‚úì checkpoint_step_40000.pt (1.34 GB)\n",
            "  ‚úì checkpoint_step_45000.pt (1.34 GB)\n",
            "  ‚úì checkpoint_step_50000.pt (1.34 GB)\n",
            "  ‚úì final_model.pt (1.34 GB)\n",
            "‚úì Tokenizer mevcut: /content/drive/MyDrive/turkish_llm/tokenizer_tr_32k_v2.model\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
